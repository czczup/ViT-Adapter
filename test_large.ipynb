{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hit:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
      "Hit:2 http://archive.ubuntu.com/ubuntu bionic InRelease                        \n",
      "Hit:3 http://security.ubuntu.com/ubuntu bionic-security InRelease              \n",
      "Hit:4 http://archive.ubuntu.com/ubuntu bionic-updates InRelease\n",
      "Hit:5 http://archive.ubuntu.com/ubuntu bionic-backports InRelease\n",
      "Reading package lists... Done                      \n",
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "git is already the newest version (1:2.17.1-1ubuntu0.18).\n",
      "0 upgraded, 0 newly installed, 0 to remove and 76 not upgraded.\n"
     ]
    }
   ],
   "source": [
    "!apt-get update && apt-get install git -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: 'ViT-Adapter/segmentation'\n",
      "/workspace/ViT-Adapter/segmentation\n"
     ]
    }
   ],
   "source": [
    "#!git clone https://github.com/czczup/ViT-Adapter.git\n",
    "%cd ViT-Adapter/segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
      "Requirement already satisfied: torch==1.9.0+cu111 in /opt/conda/lib/python3.7/site-packages (1.9.0+cu111)\n",
      "Requirement already satisfied: torchvision==0.10.0+cu111 in /opt/conda/lib/python3.7/site-packages (0.10.0+cu111)\n",
      "Requirement already satisfied: torchaudio==0.9.0 in /opt/conda/lib/python3.7/site-packages (0.9.0)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from torch==1.9.0+cu111) (4.7.1)\n",
      "Requirement already satisfied: pillow>=5.3.0 in /opt/conda/lib/python3.7/site-packages (from torchvision==0.10.0+cu111) (9.0.1)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from torchvision==0.10.0+cu111) (1.21.5)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mLooking in links: https://download.openmmlab.com/mmcv/dist/cu111/torch1.9.0/index.html\n",
      "Requirement already satisfied: mmcv-full==1.4.2 in /opt/conda/lib/python3.7/site-packages (1.4.2)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from mmcv-full==1.4.2) (1.21.5)\n",
      "Requirement already satisfied: opencv-python>=3 in /opt/conda/lib/python3.7/site-packages (from mmcv-full==1.4.2) (4.9.0.80)\n",
      "Requirement already satisfied: yapf in /opt/conda/lib/python3.7/site-packages (from mmcv-full==1.4.2) (0.40.1)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from mmcv-full==1.4.2) (23.2)\n",
      "Requirement already satisfied: Pillow in /opt/conda/lib/python3.7/site-packages (from mmcv-full==1.4.2) (9.0.1)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.7/site-packages (from mmcv-full==1.4.2) (6.0)\n",
      "Requirement already satisfied: addict in /opt/conda/lib/python3.7/site-packages (from mmcv-full==1.4.2) (2.4.0)\n",
      "Requirement already satisfied: tomli>=2.0.1 in /opt/conda/lib/python3.7/site-packages (from yapf->mmcv-full==1.4.2) (2.0.1)\n",
      "Requirement already satisfied: importlib-metadata>=6.6.0 in /opt/conda/lib/python3.7/site-packages (from yapf->mmcv-full==1.4.2) (6.7.0)\n",
      "Requirement already satisfied: platformdirs>=3.5.1 in /opt/conda/lib/python3.7/site-packages (from yapf->mmcv-full==1.4.2) (4.0.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata>=6.6.0->yapf->mmcv-full==1.4.2) (4.7.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata>=6.6.0->yapf->mmcv-full==1.4.2) (3.15.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: timm==0.4.12 in /opt/conda/lib/python3.7/site-packages (0.4.12)\n",
      "Requirement already satisfied: torchvision in /opt/conda/lib/python3.7/site-packages (from timm==0.4.12) (0.10.0+cu111)\n",
      "Requirement already satisfied: torch>=1.4 in /opt/conda/lib/python3.7/site-packages (from timm==0.4.12) (1.9.0+cu111)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from torch>=1.4->timm==0.4.12) (4.7.1)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from torchvision->timm==0.4.12) (1.21.5)\n",
      "Requirement already satisfied: pillow>=5.3.0 in /opt/conda/lib/python3.7/site-packages (from torchvision->timm==0.4.12) (9.0.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: mmdet==2.22.0 in /opt/conda/lib/python3.7/site-packages (2.22.0)\n",
      "Requirement already satisfied: pycocotools in /opt/conda/lib/python3.7/site-packages (from mmdet==2.22.0) (2.0.7)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from mmdet==2.22.0) (1.21.5)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from mmdet==2.22.0) (1.16.0)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.7/site-packages (from mmdet==2.22.0) (3.5.3)\n",
      "Requirement already satisfied: terminaltables in /opt/conda/lib/python3.7/site-packages (from mmdet==2.22.0) (3.1.10)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->mmdet==2.22.0) (1.4.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.7/site-packages (from matplotlib->mmdet==2.22.0) (2.8.2)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->mmdet==2.22.0) (3.1.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib->mmdet==2.22.0) (23.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib->mmdet==2.22.0) (9.0.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib->mmdet==2.22.0) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib->mmdet==2.22.0) (4.38.0)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from kiwisolver>=1.0.1->matplotlib->mmdet==2.22.0) (4.7.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: mmsegmentation==0.20.2 in /opt/conda/lib/python3.7/site-packages (0.20.2)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.7/site-packages (from mmsegmentation==0.20.2) (3.5.3)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from mmsegmentation==0.20.2) (23.2)\n",
      "Requirement already satisfied: prettytable in /opt/conda/lib/python3.7/site-packages (from mmsegmentation==0.20.2) (3.7.0)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from mmsegmentation==0.20.2) (1.21.5)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib->mmsegmentation==0.20.2) (9.0.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->mmsegmentation==0.20.2) (1.4.5)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib->mmsegmentation==0.20.2) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib->mmsegmentation==0.20.2) (4.38.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.7/site-packages (from matplotlib->mmsegmentation==0.20.2) (2.8.2)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->mmsegmentation==0.20.2) (3.1.1)\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.7/site-packages (from prettytable->mmsegmentation==0.20.2) (0.2.5)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from prettytable->mmsegmentation==0.20.2) (6.7.0)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from kiwisolver>=1.0.1->matplotlib->mmsegmentation==0.20.2) (4.7.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil>=2.7->matplotlib->mmsegmentation==0.20.2) (1.16.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->prettytable->mmsegmentation==0.20.2) (3.15.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "wget is already the newest version (1.19.4-1ubuntu2.2).\n",
      "0 upgraded, 0 newly installed, 0 to remove and 76 not upgraded.\n",
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "unzip is already the newest version (6.0-21ubuntu1.2).\n",
      "0 upgraded, 0 newly installed, 0 to remove and 76 not upgraded.\n",
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "libsm6 is already the newest version (2:1.2.2-1).\n",
      "libxext6 is already the newest version (2:1.3.3-1).\n",
      "ffmpeg is already the newest version (7:3.4.11-0ubuntu0.1).\n",
      "0 upgraded, 0 newly installed, 0 to remove and 76 not upgraded.\n",
      "Requirement already satisfied: yapf==0.40.1 in /opt/conda/lib/python3.7/site-packages (0.40.1)\n",
      "Requirement already satisfied: tomli>=2.0.1 in /opt/conda/lib/python3.7/site-packages (from yapf==0.40.1) (2.0.1)\n",
      "Requirement already satisfied: platformdirs>=3.5.1 in /opt/conda/lib/python3.7/site-packages (from yapf==0.40.1) (4.0.0)\n",
      "Requirement already satisfied: importlib-metadata>=6.6.0 in /opt/conda/lib/python3.7/site-packages (from yapf==0.40.1) (6.7.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata>=6.6.0->yapf==0.40.1) (3.15.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata>=6.6.0->yapf==0.40.1) (4.7.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: scipy in /opt/conda/lib/python3.7/site-packages (1.7.3)\n",
      "Requirement already satisfied: numpy<1.23.0,>=1.16.5 in /opt/conda/lib/python3.7/site-packages (from scipy) (1.21.5)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install torch==1.9.0+cu111 torchvision==0.10.0+cu111 torchaudio==0.9.0 -f https://download.pytorch.org/whl/torch_stable.html\n",
    "!pip install mmcv-full==1.4.2 -f https://download.openmmlab.com/mmcv/dist/cu111/torch1.9.0/index.html\n",
    "!pip install timm==0.4.12\n",
    "!pip install mmdet==2.22.0 # for Mask2Former\n",
    "!pip install mmsegmentation==0.20.2\n",
    "!ln -s ../detection/ops ./\n",
    "\n",
    "!apt-get install wget\n",
    "!apt-get install unzip\n",
    "!apt-get install ffmpeg libsm6 libxext6  -y\n",
    "!pip install yapf==0.40.1 \n",
    "!pip install scipy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/ViT-Adapter/detection/ops\n",
      "running build\n",
      "running build_py\n",
      "running build_ext\n",
      "/opt/conda/lib/python3.7/site-packages/torch/utils/cpp_extension.py:370: UserWarning: Attempted to use ninja as the BuildExtension backend but we could not find ninja.. Falling back to using the slow distutils backend.\n",
      "  warnings.warn(msg.format('we could not find ninja.'))\n",
      "running install\n",
      "/opt/conda/lib/python3.7/site-packages/setuptools/command/install.py:37: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools.\n",
      "  setuptools.SetuptoolsDeprecationWarning,\n",
      "/opt/conda/lib/python3.7/site-packages/setuptools/command/easy_install.py:147: EasyInstallDeprecationWarning: easy_install command is deprecated. Use build and pip and other standards-based tools.\n",
      "  EasyInstallDeprecationWarning,\n",
      "running bdist_egg\n",
      "running egg_info\n",
      "writing MultiScaleDeformableAttention.egg-info/PKG-INFO\n",
      "writing dependency_links to MultiScaleDeformableAttention.egg-info/dependency_links.txt\n",
      "writing top-level names to MultiScaleDeformableAttention.egg-info/top_level.txt\n",
      "reading manifest file 'MultiScaleDeformableAttention.egg-info/SOURCES.txt'\n",
      "writing manifest file 'MultiScaleDeformableAttention.egg-info/SOURCES.txt'\n",
      "installing library code to build/bdist.linux-x86_64/egg\n",
      "running install_lib\n",
      "creating build/bdist.linux-x86_64\n",
      "creating build/bdist.linux-x86_64/egg\n",
      "copying build/lib.linux-x86_64-3.7/MultiScaleDeformableAttention.cpython-37m-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/egg\n",
      "creating build/bdist.linux-x86_64/egg/functions\n",
      "copying build/lib.linux-x86_64-3.7/functions/ms_deform_attn_func.py -> build/bdist.linux-x86_64/egg/functions\n",
      "copying build/lib.linux-x86_64-3.7/functions/__init__.py -> build/bdist.linux-x86_64/egg/functions\n",
      "creating build/bdist.linux-x86_64/egg/modules\n",
      "copying build/lib.linux-x86_64-3.7/modules/__init__.py -> build/bdist.linux-x86_64/egg/modules\n",
      "copying build/lib.linux-x86_64-3.7/modules/ms_deform_attn.py -> build/bdist.linux-x86_64/egg/modules\n",
      "byte-compiling build/bdist.linux-x86_64/egg/functions/ms_deform_attn_func.py to ms_deform_attn_func.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/functions/__init__.py to __init__.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/modules/__init__.py to __init__.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/modules/ms_deform_attn.py to ms_deform_attn.cpython-37.pyc\n",
      "creating stub loader for MultiScaleDeformableAttention.cpython-37m-x86_64-linux-gnu.so\n",
      "byte-compiling build/bdist.linux-x86_64/egg/MultiScaleDeformableAttention.py to MultiScaleDeformableAttention.cpython-37.pyc\n",
      "creating build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying MultiScaleDeformableAttention.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying MultiScaleDeformableAttention.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying MultiScaleDeformableAttention.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying MultiScaleDeformableAttention.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "writing build/bdist.linux-x86_64/egg/EGG-INFO/native_libs.txt\n",
      "zip_safe flag not set; analyzing archive contents...\n",
      "__pycache__.MultiScaleDeformableAttention.cpython-37: module references __file__\n",
      "creating 'dist/MultiScaleDeformableAttention-1.0-py3.7-linux-x86_64.egg' and adding 'build/bdist.linux-x86_64/egg' to it\n",
      "removing 'build/bdist.linux-x86_64/egg' (and everything under it)\n",
      "Processing MultiScaleDeformableAttention-1.0-py3.7-linux-x86_64.egg\n",
      "creating /opt/conda/lib/python3.7/site-packages/MultiScaleDeformableAttention-1.0-py3.7-linux-x86_64.egg\n",
      "Extracting MultiScaleDeformableAttention-1.0-py3.7-linux-x86_64.egg to /opt/conda/lib/python3.7/site-packages\n",
      "Adding MultiScaleDeformableAttention 1.0 to easy-install.pth file\n",
      "\n",
      "Installed /opt/conda/lib/python3.7/site-packages/MultiScaleDeformableAttention-1.0-py3.7-linux-x86_64.egg\n",
      "Processing dependencies for MultiScaleDeformableAttention==1.0\n",
      "Finished processing dependencies for MultiScaleDeformableAttention==1.0\n",
      "/workspace/ViT-Adapter/detection\n"
     ]
    }
   ],
   "source": [
    "%cd ops\n",
    "!sh make.sh # compile deformable attention\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-02-13 14:35:33--  https://github.com/czczup/ViT-Adapter/releases/download/v0.2.9/mask2former_beit_adapter_base_512_40k_cocostuff10k.pth.tar\n",
      "Resolving github.com (github.com)... 140.82.114.3\n",
      "Connecting to github.com (github.com)|140.82.114.3|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/492936445/a196d979-d78e-40e8-a52f-46130bdf782e?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVCODYLSA53PQK4ZA%2F20240213%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240213T143533Z&X-Amz-Expires=300&X-Amz-Signature=f6c052e8cc1b47bf39470ce126da783a083f5256575a7d5d2448769d4f6c2288&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=492936445&response-content-disposition=attachment%3B%20filename%3Dmask2former_beit_adapter_base_512_40k_cocostuff10k.pth.tar&response-content-type=application%2Foctet-stream [following]\n",
      "--2024-02-13 14:35:33--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/492936445/a196d979-d78e-40e8-a52f-46130bdf782e?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVCODYLSA53PQK4ZA%2F20240213%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240213T143533Z&X-Amz-Expires=300&X-Amz-Signature=f6c052e8cc1b47bf39470ce126da783a083f5256575a7d5d2448769d4f6c2288&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=492936445&response-content-disposition=attachment%3B%20filename%3Dmask2former_beit_adapter_base_512_40k_cocostuff10k.pth.tar&response-content-type=application%2Foctet-stream\n",
      "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.110.133, ...\n",
      "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.111.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 582305785 (555M) [application/octet-stream]\n",
      "Saving to: ‘mask2former_beit_adapter_base_512_40k_cocostuff10k.pth.tar’\n",
      "\n",
      "mask2former_beit_ad 100%[===================>] 555.33M  97.9MB/s    in 5.9s    \n",
      "\n",
      "2024-02-13 14:35:40 (94.7 MB/s) - ‘mask2former_beit_adapter_base_512_40k_cocostuff10k.pth.tar’ saved [582305785/582305785]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#!wget https://github.com/czczup/ViT-Adapter/releases/download/v0.2.0/mask2former_beit_adapter_large_896_80k_ade20k.zip \n",
    "!wget https://github.com/czczup/ViT-Adapter/releases/download/v0.2.9/mask2former_beit_adapter_base_512_40k_cocostuff10k.pth.tar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  mask2former_beit_adapter_base_512_40k_cocostuff10k.pth.tar\n",
      " extracting: archive/data.pkl        \n",
      " extracting: archive/data/0          \n",
      " extracting: archive/data/1          \n",
      " extracting: archive/data/10         \n",
      " extracting: archive/data/100        \n",
      " extracting: archive/data/101        \n",
      " extracting: archive/data/102        \n",
      " extracting: archive/data/103        \n",
      " extracting: archive/data/104        \n",
      " extracting: archive/data/105        \n",
      " extracting: archive/data/106        \n",
      " extracting: archive/data/107        \n",
      " extracting: archive/data/108        \n",
      " extracting: archive/data/109        \n",
      " extracting: archive/data/11         \n",
      " extracting: archive/data/110        \n",
      " extracting: archive/data/111        \n",
      " extracting: archive/data/112        \n",
      " extracting: archive/data/113        \n",
      " extracting: archive/data/114        \n",
      " extracting: archive/data/115        \n",
      " extracting: archive/data/116        \n",
      " extracting: archive/data/117        \n",
      " extracting: archive/data/118        \n",
      " extracting: archive/data/119        \n",
      " extracting: archive/data/12         \n",
      " extracting: archive/data/120        \n",
      " extracting: archive/data/121        \n",
      " extracting: archive/data/122        \n",
      " extracting: archive/data/123        \n",
      " extracting: archive/data/124        \n",
      " extracting: archive/data/125        \n",
      " extracting: archive/data/126        \n",
      " extracting: archive/data/127        \n",
      " extracting: archive/data/128        \n",
      " extracting: archive/data/129        \n",
      " extracting: archive/data/13         \n",
      " extracting: archive/data/130        \n",
      " extracting: archive/data/131        \n",
      " extracting: archive/data/132        \n",
      " extracting: archive/data/133        \n",
      " extracting: archive/data/134        \n",
      " extracting: archive/data/135        \n",
      " extracting: archive/data/136        \n",
      " extracting: archive/data/137        \n",
      " extracting: archive/data/138        \n",
      " extracting: archive/data/139        \n",
      " extracting: archive/data/14         \n",
      " extracting: archive/data/140        \n",
      " extracting: archive/data/141        \n",
      " extracting: archive/data/142        \n",
      " extracting: archive/data/143        \n",
      " extracting: archive/data/144        \n",
      " extracting: archive/data/145        \n",
      " extracting: archive/data/146        \n",
      " extracting: archive/data/147        \n",
      " extracting: archive/data/148        \n",
      " extracting: archive/data/149        \n",
      " extracting: archive/data/15         \n",
      " extracting: archive/data/150        \n",
      " extracting: archive/data/151        \n",
      " extracting: archive/data/152        \n",
      " extracting: archive/data/153        \n",
      " extracting: archive/data/154        \n",
      " extracting: archive/data/155        \n",
      " extracting: archive/data/156        \n",
      " extracting: archive/data/157        \n",
      " extracting: archive/data/158        \n",
      " extracting: archive/data/159        \n",
      " extracting: archive/data/16         \n",
      " extracting: archive/data/160        \n",
      " extracting: archive/data/161        \n",
      " extracting: archive/data/162        \n",
      " extracting: archive/data/163        \n",
      " extracting: archive/data/164        \n",
      " extracting: archive/data/165        \n",
      " extracting: archive/data/166        \n",
      " extracting: archive/data/167        \n",
      " extracting: archive/data/168        \n",
      " extracting: archive/data/169        \n",
      " extracting: archive/data/17         \n",
      " extracting: archive/data/170        \n",
      " extracting: archive/data/171        \n",
      " extracting: archive/data/172        \n",
      " extracting: archive/data/173        \n",
      " extracting: archive/data/174        \n",
      " extracting: archive/data/175        \n",
      " extracting: archive/data/176        \n",
      " extracting: archive/data/177        \n",
      " extracting: archive/data/178        \n",
      " extracting: archive/data/179        \n",
      " extracting: archive/data/18         \n",
      " extracting: archive/data/180        \n",
      " extracting: archive/data/181        \n",
      " extracting: archive/data/182        \n",
      " extracting: archive/data/183        \n",
      " extracting: archive/data/184        \n",
      " extracting: archive/data/185        \n",
      " extracting: archive/data/186        \n",
      " extracting: archive/data/187        \n",
      " extracting: archive/data/188        \n",
      " extracting: archive/data/189        \n",
      " extracting: archive/data/19         \n",
      " extracting: archive/data/190        \n",
      " extracting: archive/data/191        \n",
      " extracting: archive/data/192        \n",
      " extracting: archive/data/193        \n",
      " extracting: archive/data/194        \n",
      " extracting: archive/data/195        \n",
      " extracting: archive/data/196        \n",
      " extracting: archive/data/197        \n",
      " extracting: archive/data/198        \n",
      " extracting: archive/data/199        \n",
      " extracting: archive/data/2          \n",
      " extracting: archive/data/20         \n",
      " extracting: archive/data/200        \n",
      " extracting: archive/data/201        \n",
      " extracting: archive/data/202        \n",
      " extracting: archive/data/203        \n",
      " extracting: archive/data/204        \n",
      " extracting: archive/data/205        \n",
      " extracting: archive/data/206        \n",
      " extracting: archive/data/207        \n",
      " extracting: archive/data/208        \n",
      " extracting: archive/data/209        \n",
      " extracting: archive/data/21         \n",
      " extracting: archive/data/210        \n",
      " extracting: archive/data/211        \n",
      " extracting: archive/data/212        \n",
      " extracting: archive/data/213        \n",
      " extracting: archive/data/214        \n",
      " extracting: archive/data/215        \n",
      " extracting: archive/data/216        \n",
      " extracting: archive/data/217        \n",
      " extracting: archive/data/218        \n",
      " extracting: archive/data/219        \n",
      " extracting: archive/data/22         \n",
      " extracting: archive/data/220        \n",
      " extracting: archive/data/221        \n",
      " extracting: archive/data/222        \n",
      " extracting: archive/data/223        \n",
      " extracting: archive/data/224        \n",
      " extracting: archive/data/225        \n",
      " extracting: archive/data/226        \n",
      " extracting: archive/data/227        \n",
      " extracting: archive/data/228        \n",
      " extracting: archive/data/229        \n",
      " extracting: archive/data/23         \n",
      " extracting: archive/data/230        \n",
      " extracting: archive/data/231        \n",
      " extracting: archive/data/232        \n",
      " extracting: archive/data/233        \n",
      " extracting: archive/data/234        \n",
      " extracting: archive/data/235        \n",
      " extracting: archive/data/236        \n",
      " extracting: archive/data/237        \n",
      " extracting: archive/data/238        \n",
      " extracting: archive/data/239        \n",
      " extracting: archive/data/24         \n",
      " extracting: archive/data/240        \n",
      " extracting: archive/data/241        \n",
      " extracting: archive/data/242        \n",
      " extracting: archive/data/243        \n",
      " extracting: archive/data/244        \n",
      " extracting: archive/data/245        \n",
      " extracting: archive/data/246        \n",
      " extracting: archive/data/247        \n",
      " extracting: archive/data/248        \n",
      " extracting: archive/data/249        \n",
      " extracting: archive/data/25         \n",
      " extracting: archive/data/250        \n",
      " extracting: archive/data/251        \n",
      " extracting: archive/data/252        \n",
      " extracting: archive/data/253        \n",
      " extracting: archive/data/254        \n",
      " extracting: archive/data/255        \n",
      " extracting: archive/data/256        \n",
      " extracting: archive/data/257        \n",
      " extracting: archive/data/258        \n",
      " extracting: archive/data/259        \n",
      " extracting: archive/data/26         \n",
      " extracting: archive/data/260        \n",
      " extracting: archive/data/261        \n",
      " extracting: archive/data/262        \n",
      " extracting: archive/data/263        \n",
      " extracting: archive/data/264        \n",
      " extracting: archive/data/265        \n",
      " extracting: archive/data/266        \n",
      " extracting: archive/data/267        \n",
      " extracting: archive/data/268        \n",
      " extracting: archive/data/269        \n",
      " extracting: archive/data/27         \n",
      " extracting: archive/data/270        \n",
      " extracting: archive/data/271        \n",
      " extracting: archive/data/272        \n",
      " extracting: archive/data/273        \n",
      " extracting: archive/data/274        \n",
      " extracting: archive/data/275        \n",
      " extracting: archive/data/276        \n",
      " extracting: archive/data/277        \n",
      " extracting: archive/data/278        \n",
      " extracting: archive/data/279        \n",
      " extracting: archive/data/28         \n",
      " extracting: archive/data/280        \n",
      " extracting: archive/data/281        \n",
      " extracting: archive/data/282        \n",
      " extracting: archive/data/283        \n",
      " extracting: archive/data/284        \n",
      " extracting: archive/data/285        \n",
      " extracting: archive/data/286        \n",
      " extracting: archive/data/287        \n",
      " extracting: archive/data/288        \n",
      " extracting: archive/data/289        \n",
      " extracting: archive/data/29         \n",
      " extracting: archive/data/290        \n",
      " extracting: archive/data/291        \n",
      " extracting: archive/data/292        \n",
      " extracting: archive/data/293        \n",
      " extracting: archive/data/294        \n",
      " extracting: archive/data/295        \n",
      " extracting: archive/data/296        \n",
      " extracting: archive/data/297        \n",
      " extracting: archive/data/298        \n",
      " extracting: archive/data/299        \n",
      " extracting: archive/data/3          \n",
      " extracting: archive/data/30         \n",
      " extracting: archive/data/300        \n",
      " extracting: archive/data/301        \n",
      " extracting: archive/data/302        \n",
      " extracting: archive/data/303        \n",
      " extracting: archive/data/304        \n",
      " extracting: archive/data/305        \n",
      " extracting: archive/data/306        \n",
      " extracting: archive/data/307        \n",
      " extracting: archive/data/308        \n",
      " extracting: archive/data/309        \n",
      " extracting: archive/data/31         \n",
      " extracting: archive/data/310        \n",
      " extracting: archive/data/311        \n",
      " extracting: archive/data/312        \n",
      " extracting: archive/data/313        \n",
      " extracting: archive/data/314        \n",
      " extracting: archive/data/315        \n",
      " extracting: archive/data/316        \n",
      " extracting: archive/data/317        \n",
      " extracting: archive/data/318        \n",
      " extracting: archive/data/319        \n",
      " extracting: archive/data/32         \n",
      " extracting: archive/data/320        \n",
      " extracting: archive/data/321        \n",
      " extracting: archive/data/322        \n",
      " extracting: archive/data/323        \n",
      " extracting: archive/data/324        \n",
      " extracting: archive/data/325        \n",
      " extracting: archive/data/326        \n",
      " extracting: archive/data/327        \n",
      " extracting: archive/data/328        \n",
      " extracting: archive/data/329        \n",
      " extracting: archive/data/33         \n",
      " extracting: archive/data/330        \n",
      " extracting: archive/data/331        \n",
      " extracting: archive/data/332        \n",
      " extracting: archive/data/333        \n",
      " extracting: archive/data/334        \n",
      " extracting: archive/data/335        \n",
      " extracting: archive/data/336        \n",
      " extracting: archive/data/337        \n",
      " extracting: archive/data/338        \n",
      " extracting: archive/data/339        \n",
      " extracting: archive/data/34         \n",
      " extracting: archive/data/340        \n",
      " extracting: archive/data/341        \n",
      " extracting: archive/data/342        \n",
      " extracting: archive/data/343        \n",
      " extracting: archive/data/344        \n",
      " extracting: archive/data/345        \n",
      " extracting: archive/data/346        \n",
      " extracting: archive/data/347        \n",
      " extracting: archive/data/348        \n",
      " extracting: archive/data/349        \n",
      " extracting: archive/data/35         \n",
      " extracting: archive/data/350        \n",
      " extracting: archive/data/351        \n",
      " extracting: archive/data/352        \n",
      " extracting: archive/data/353        \n",
      " extracting: archive/data/354        \n",
      " extracting: archive/data/355        \n",
      " extracting: archive/data/356        \n",
      " extracting: archive/data/357        \n",
      " extracting: archive/data/358        \n",
      " extracting: archive/data/359        \n",
      " extracting: archive/data/36         \n",
      " extracting: archive/data/360        \n",
      " extracting: archive/data/361        \n",
      " extracting: archive/data/362        \n",
      " extracting: archive/data/363        \n",
      " extracting: archive/data/364        \n",
      " extracting: archive/data/365        \n",
      " extracting: archive/data/366        \n",
      " extracting: archive/data/367        \n",
      " extracting: archive/data/368        \n",
      " extracting: archive/data/369        \n",
      " extracting: archive/data/37         \n",
      " extracting: archive/data/370        \n",
      " extracting: archive/data/371        \n",
      " extracting: archive/data/372        \n",
      " extracting: archive/data/373        \n",
      " extracting: archive/data/374        \n",
      " extracting: archive/data/375        \n",
      " extracting: archive/data/376        \n",
      " extracting: archive/data/377        \n",
      " extracting: archive/data/378        \n",
      " extracting: archive/data/379        \n",
      " extracting: archive/data/38         \n",
      " extracting: archive/data/380        \n",
      " extracting: archive/data/381        \n",
      " extracting: archive/data/382        \n",
      " extracting: archive/data/383        \n",
      " extracting: archive/data/384        \n",
      " extracting: archive/data/385        \n",
      " extracting: archive/data/386        \n",
      " extracting: archive/data/387        \n",
      " extracting: archive/data/388        \n",
      " extracting: archive/data/389        \n",
      " extracting: archive/data/39         \n",
      " extracting: archive/data/390        \n",
      " extracting: archive/data/391        \n",
      " extracting: archive/data/392        \n",
      " extracting: archive/data/393        \n",
      " extracting: archive/data/394        \n",
      " extracting: archive/data/395        \n",
      " extracting: archive/data/396        \n",
      " extracting: archive/data/397        \n",
      " extracting: archive/data/398        \n",
      " extracting: archive/data/399        \n",
      " extracting: archive/data/4          \n",
      " extracting: archive/data/40         \n",
      " extracting: archive/data/400        \n",
      " extracting: archive/data/401        \n",
      " extracting: archive/data/402        \n",
      " extracting: archive/data/403        \n",
      " extracting: archive/data/404        \n",
      " extracting: archive/data/405        \n",
      " extracting: archive/data/406        \n",
      " extracting: archive/data/407        \n",
      " extracting: archive/data/408        \n",
      " extracting: archive/data/409        \n",
      " extracting: archive/data/41         \n",
      " extracting: archive/data/410        \n",
      " extracting: archive/data/411        \n",
      " extracting: archive/data/412        \n",
      " extracting: archive/data/413        \n",
      " extracting: archive/data/414        \n",
      " extracting: archive/data/415        \n",
      " extracting: archive/data/416        \n",
      " extracting: archive/data/417        \n",
      " extracting: archive/data/418        \n",
      " extracting: archive/data/419        \n",
      " extracting: archive/data/42         \n",
      " extracting: archive/data/420        \n",
      " extracting: archive/data/421        \n",
      " extracting: archive/data/422        \n",
      " extracting: archive/data/423        \n",
      " extracting: archive/data/424        \n",
      " extracting: archive/data/425        \n",
      " extracting: archive/data/426        \n",
      " extracting: archive/data/427        \n",
      " extracting: archive/data/428        \n",
      " extracting: archive/data/429        \n",
      " extracting: archive/data/43         \n",
      " extracting: archive/data/430        \n",
      " extracting: archive/data/431        \n",
      " extracting: archive/data/432        \n",
      " extracting: archive/data/433        \n",
      " extracting: archive/data/434        \n",
      " extracting: archive/data/435        \n",
      " extracting: archive/data/436        \n",
      " extracting: archive/data/437        \n",
      " extracting: archive/data/438        \n",
      " extracting: archive/data/439        \n",
      " extracting: archive/data/44         \n",
      " extracting: archive/data/440        \n",
      " extracting: archive/data/441        \n",
      " extracting: archive/data/442        \n",
      " extracting: archive/data/443        \n",
      " extracting: archive/data/444        \n",
      " extracting: archive/data/445        \n",
      " extracting: archive/data/446        \n",
      " extracting: archive/data/447        \n",
      " extracting: archive/data/448        \n",
      " extracting: archive/data/449        \n",
      " extracting: archive/data/45         \n",
      " extracting: archive/data/450        \n",
      " extracting: archive/data/451        \n",
      " extracting: archive/data/452        \n",
      " extracting: archive/data/453        \n",
      " extracting: archive/data/454        \n",
      " extracting: archive/data/455        \n",
      " extracting: archive/data/456        \n",
      " extracting: archive/data/457        \n",
      " extracting: archive/data/458        \n",
      " extracting: archive/data/459        \n",
      " extracting: archive/data/46         \n",
      " extracting: archive/data/460        \n",
      " extracting: archive/data/461        \n",
      " extracting: archive/data/462        \n",
      " extracting: archive/data/463        \n",
      " extracting: archive/data/464        \n",
      " extracting: archive/data/465        \n",
      " extracting: archive/data/466        \n",
      " extracting: archive/data/467        \n",
      " extracting: archive/data/468        \n",
      " extracting: archive/data/469        \n",
      " extracting: archive/data/47         \n",
      " extracting: archive/data/470        \n",
      " extracting: archive/data/471        \n",
      " extracting: archive/data/472        \n",
      " extracting: archive/data/473        \n",
      " extracting: archive/data/474        \n",
      " extracting: archive/data/475        \n",
      " extracting: archive/data/476        \n",
      " extracting: archive/data/477        \n",
      " extracting: archive/data/478        \n",
      " extracting: archive/data/479        \n",
      " extracting: archive/data/48         \n",
      " extracting: archive/data/480        \n",
      " extracting: archive/data/481        \n",
      " extracting: archive/data/482        \n",
      " extracting: archive/data/483        \n",
      " extracting: archive/data/484        \n",
      " extracting: archive/data/485        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " extracting: archive/data/486        \n",
      " extracting: archive/data/487        \n",
      " extracting: archive/data/488        \n",
      " extracting: archive/data/489        \n",
      " extracting: archive/data/49         \n",
      " extracting: archive/data/490        \n",
      " extracting: archive/data/491        \n",
      " extracting: archive/data/492        \n",
      " extracting: archive/data/493        \n",
      " extracting: archive/data/494        \n",
      " extracting: archive/data/495        \n",
      " extracting: archive/data/496        \n",
      " extracting: archive/data/497        \n",
      " extracting: archive/data/498        \n",
      " extracting: archive/data/499        \n",
      " extracting: archive/data/5          \n",
      " extracting: archive/data/50         \n",
      " extracting: archive/data/500        \n",
      " extracting: archive/data/501        \n",
      " extracting: archive/data/502        \n",
      " extracting: archive/data/503        \n",
      " extracting: archive/data/504        \n",
      " extracting: archive/data/505        \n",
      " extracting: archive/data/506        \n",
      " extracting: archive/data/507        \n",
      " extracting: archive/data/508        \n",
      " extracting: archive/data/509        \n",
      " extracting: archive/data/51         \n",
      " extracting: archive/data/510        \n",
      " extracting: archive/data/511        \n",
      " extracting: archive/data/512        \n",
      " extracting: archive/data/513        \n",
      " extracting: archive/data/514        \n",
      " extracting: archive/data/515        \n",
      " extracting: archive/data/516        \n",
      " extracting: archive/data/517        \n",
      " extracting: archive/data/518        \n",
      " extracting: archive/data/519        \n",
      " extracting: archive/data/52         \n",
      " extracting: archive/data/520        \n",
      " extracting: archive/data/521        \n",
      " extracting: archive/data/522        \n",
      " extracting: archive/data/523        \n",
      " extracting: archive/data/524        \n",
      " extracting: archive/data/525        \n",
      " extracting: archive/data/526        \n",
      " extracting: archive/data/527        \n",
      " extracting: archive/data/528        \n",
      " extracting: archive/data/529        \n",
      " extracting: archive/data/53         \n",
      " extracting: archive/data/530        \n",
      " extracting: archive/data/531        \n",
      " extracting: archive/data/532        \n",
      " extracting: archive/data/533        \n",
      " extracting: archive/data/534        \n",
      " extracting: archive/data/535        \n",
      " extracting: archive/data/536        \n",
      " extracting: archive/data/537        \n",
      " extracting: archive/data/538        \n",
      " extracting: archive/data/539        \n",
      " extracting: archive/data/54         \n",
      " extracting: archive/data/540        \n",
      " extracting: archive/data/541        \n",
      " extracting: archive/data/542        \n",
      " extracting: archive/data/543        \n",
      " extracting: archive/data/544        \n",
      " extracting: archive/data/545        \n",
      " extracting: archive/data/546        \n",
      " extracting: archive/data/547        \n",
      " extracting: archive/data/548        \n",
      " extracting: archive/data/549        \n",
      " extracting: archive/data/55         \n",
      " extracting: archive/data/550        \n",
      " extracting: archive/data/551        \n",
      " extracting: archive/data/552        \n",
      " extracting: archive/data/553        \n",
      " extracting: archive/data/554        \n",
      " extracting: archive/data/555        \n",
      " extracting: archive/data/556        \n",
      " extracting: archive/data/557        \n",
      " extracting: archive/data/558        \n",
      " extracting: archive/data/559        \n",
      " extracting: archive/data/56         \n",
      " extracting: archive/data/560        \n",
      " extracting: archive/data/561        \n",
      " extracting: archive/data/562        \n",
      " extracting: archive/data/563        \n",
      " extracting: archive/data/564        \n",
      " extracting: archive/data/565        \n",
      " extracting: archive/data/566        \n",
      " extracting: archive/data/567        \n",
      " extracting: archive/data/568        \n",
      " extracting: archive/data/569        \n",
      " extracting: archive/data/57         \n",
      " extracting: archive/data/570        \n",
      " extracting: archive/data/571        \n",
      " extracting: archive/data/572        \n",
      " extracting: archive/data/573        \n",
      " extracting: archive/data/574        \n",
      " extracting: archive/data/575        \n",
      " extracting: archive/data/576        \n",
      " extracting: archive/data/577        \n",
      " extracting: archive/data/578        \n",
      " extracting: archive/data/579        \n",
      " extracting: archive/data/58         \n",
      " extracting: archive/data/580        \n",
      " extracting: archive/data/581        \n",
      " extracting: archive/data/582        \n",
      " extracting: archive/data/583        \n",
      " extracting: archive/data/584        \n",
      " extracting: archive/data/585        \n",
      " extracting: archive/data/586        \n",
      " extracting: archive/data/587        \n",
      " extracting: archive/data/588        \n",
      " extracting: archive/data/589        \n",
      " extracting: archive/data/59         \n",
      " extracting: archive/data/590        \n",
      " extracting: archive/data/591        \n",
      " extracting: archive/data/592        \n",
      " extracting: archive/data/593        \n",
      " extracting: archive/data/594        \n",
      " extracting: archive/data/595        \n",
      " extracting: archive/data/596        \n",
      " extracting: archive/data/597        \n",
      " extracting: archive/data/598        \n",
      " extracting: archive/data/599        \n",
      " extracting: archive/data/6          \n",
      " extracting: archive/data/60         \n",
      " extracting: archive/data/600        \n",
      " extracting: archive/data/601        \n",
      " extracting: archive/data/602        \n",
      " extracting: archive/data/603        \n",
      " extracting: archive/data/604        \n",
      " extracting: archive/data/605        \n",
      " extracting: archive/data/606        \n",
      " extracting: archive/data/607        \n",
      " extracting: archive/data/608        \n",
      " extracting: archive/data/609        \n",
      " extracting: archive/data/61         \n",
      " extracting: archive/data/610        \n",
      " extracting: archive/data/611        \n",
      " extracting: archive/data/612        \n",
      " extracting: archive/data/613        \n",
      " extracting: archive/data/614        \n",
      " extracting: archive/data/615        \n",
      " extracting: archive/data/616        \n",
      " extracting: archive/data/617        \n",
      " extracting: archive/data/618        \n",
      " extracting: archive/data/619        \n",
      " extracting: archive/data/62         \n",
      " extracting: archive/data/620        \n",
      " extracting: archive/data/621        \n",
      " extracting: archive/data/622        \n",
      " extracting: archive/data/623        \n",
      " extracting: archive/data/624        \n",
      " extracting: archive/data/625        \n",
      " extracting: archive/data/626        \n",
      " extracting: archive/data/627        \n",
      " extracting: archive/data/628        \n",
      " extracting: archive/data/629        \n",
      " extracting: archive/data/63         \n",
      " extracting: archive/data/630        \n",
      " extracting: archive/data/631        \n",
      " extracting: archive/data/632        \n",
      " extracting: archive/data/633        \n",
      " extracting: archive/data/634        \n",
      " extracting: archive/data/635        \n",
      " extracting: archive/data/636        \n",
      " extracting: archive/data/637        \n",
      " extracting: archive/data/638        \n",
      " extracting: archive/data/639        \n",
      " extracting: archive/data/64         \n",
      " extracting: archive/data/640        \n",
      " extracting: archive/data/641        \n",
      " extracting: archive/data/642        \n",
      " extracting: archive/data/643        \n",
      " extracting: archive/data/644        \n",
      " extracting: archive/data/645        \n",
      " extracting: archive/data/646        \n",
      " extracting: archive/data/647        \n",
      " extracting: archive/data/648        \n",
      " extracting: archive/data/649        \n",
      " extracting: archive/data/65         \n",
      " extracting: archive/data/650        \n",
      " extracting: archive/data/651        \n",
      " extracting: archive/data/652        \n",
      " extracting: archive/data/653        \n",
      " extracting: archive/data/654        \n",
      " extracting: archive/data/655        \n",
      " extracting: archive/data/656        \n",
      " extracting: archive/data/657        \n",
      " extracting: archive/data/658        \n",
      " extracting: archive/data/659        \n",
      " extracting: archive/data/66         \n",
      " extracting: archive/data/660        \n",
      " extracting: archive/data/661        \n",
      " extracting: archive/data/662        \n",
      " extracting: archive/data/663        \n",
      " extracting: archive/data/664        \n",
      " extracting: archive/data/665        \n",
      " extracting: archive/data/666        \n",
      " extracting: archive/data/667        \n",
      " extracting: archive/data/668        \n",
      " extracting: archive/data/669        \n",
      " extracting: archive/data/67         \n",
      " extracting: archive/data/670        \n",
      " extracting: archive/data/671        \n",
      " extracting: archive/data/672        \n",
      " extracting: archive/data/673        \n",
      " extracting: archive/data/674        \n",
      " extracting: archive/data/675        \n",
      " extracting: archive/data/676        \n",
      " extracting: archive/data/677        \n",
      " extracting: archive/data/678        \n",
      " extracting: archive/data/679        \n",
      " extracting: archive/data/68         \n",
      " extracting: archive/data/680        \n",
      " extracting: archive/data/681        \n",
      " extracting: archive/data/682        \n",
      " extracting: archive/data/683        \n",
      " extracting: archive/data/684        \n",
      " extracting: archive/data/685        \n",
      " extracting: archive/data/686        \n",
      " extracting: archive/data/687        \n",
      " extracting: archive/data/688        \n",
      " extracting: archive/data/689        \n",
      " extracting: archive/data/69         \n",
      " extracting: archive/data/690        \n",
      " extracting: archive/data/691        \n",
      " extracting: archive/data/692        \n",
      " extracting: archive/data/693        \n",
      " extracting: archive/data/694        \n",
      " extracting: archive/data/695        \n",
      " extracting: archive/data/696        \n",
      " extracting: archive/data/697        \n",
      " extracting: archive/data/698        \n",
      " extracting: archive/data/699        \n",
      " extracting: archive/data/7          \n",
      " extracting: archive/data/70         \n",
      " extracting: archive/data/700        \n",
      " extracting: archive/data/701        \n",
      " extracting: archive/data/702        \n",
      " extracting: archive/data/703        \n",
      " extracting: archive/data/704        \n",
      " extracting: archive/data/705        \n",
      " extracting: archive/data/706        \n",
      " extracting: archive/data/707        \n",
      " extracting: archive/data/708        \n",
      " extracting: archive/data/709        \n",
      " extracting: archive/data/71         \n",
      " extracting: archive/data/710        \n",
      " extracting: archive/data/711        \n",
      " extracting: archive/data/712        \n",
      " extracting: archive/data/713        \n",
      " extracting: archive/data/714        \n",
      " extracting: archive/data/715        \n",
      " extracting: archive/data/716        \n",
      " extracting: archive/data/717        \n",
      " extracting: archive/data/718        \n",
      " extracting: archive/data/719        \n",
      " extracting: archive/data/72         \n",
      " extracting: archive/data/720        \n",
      " extracting: archive/data/721        \n",
      " extracting: archive/data/722        \n",
      " extracting: archive/data/723        \n",
      " extracting: archive/data/724        \n",
      " extracting: archive/data/725        \n",
      " extracting: archive/data/726        \n",
      " extracting: archive/data/727        \n",
      " extracting: archive/data/728        \n",
      " extracting: archive/data/729        \n",
      " extracting: archive/data/73         \n",
      " extracting: archive/data/730        \n",
      " extracting: archive/data/731        \n",
      " extracting: archive/data/732        \n",
      " extracting: archive/data/733        \n",
      " extracting: archive/data/734        \n",
      " extracting: archive/data/735        \n",
      " extracting: archive/data/736        \n",
      " extracting: archive/data/737        \n",
      " extracting: archive/data/738        \n",
      " extracting: archive/data/739        \n",
      " extracting: archive/data/74         \n",
      " extracting: archive/data/75         \n",
      " extracting: archive/data/76         \n",
      " extracting: archive/data/77         \n",
      " extracting: archive/data/78         \n",
      " extracting: archive/data/79         \n",
      " extracting: archive/data/8          \n",
      " extracting: archive/data/80         \n",
      " extracting: archive/data/81         \n",
      " extracting: archive/data/82         \n",
      " extracting: archive/data/83         \n",
      " extracting: archive/data/84         \n",
      " extracting: archive/data/85         \n",
      " extracting: archive/data/86         \n",
      " extracting: archive/data/87         \n",
      " extracting: archive/data/88         \n",
      " extracting: archive/data/89         \n",
      " extracting: archive/data/9          \n",
      " extracting: archive/data/90         \n",
      " extracting: archive/data/91         \n",
      " extracting: archive/data/92         \n",
      " extracting: archive/data/93         \n",
      " extracting: archive/data/94         \n",
      " extracting: archive/data/95         \n",
      " extracting: archive/data/96         \n",
      " extracting: archive/data/97         \n",
      " extracting: archive/data/98         \n",
      " extracting: archive/data/99         \n",
      " extracting: archive/version         \n"
     ]
    }
   ],
   "source": [
    "#!unzip mask2former_beit_adapter_large_896_80k_ade20k.zip \n",
    "!unzip mask2former_beit_adapter_base_512_40k_cocostuff10k.pth.tar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/ViT-Adapter/segmentation\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "!chmod +x dist_train.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/ViT-Adapter/segmentation\n"
     ]
    }
   ],
   "source": [
    "%cd /workspace/ViT-Adapter/segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "!chmod +x dist_train.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/ViT-Adapter/segmentation\n"
     ]
    }
   ],
   "source": [
    "%cd /workspace/ViT-Adapter/segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/distributed/launch.py:164: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead\n",
      "  \"The module torch.distributed.launch is deprecated \"\n",
      "The module torch.distributed.launch is deprecated and going to be removed in future.Migrate to torch.distributed.run\n",
      "*****************************************\n",
      "Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "*****************************************\n",
      "WARNING:torch.distributed.run:--use_env is deprecated and will be removed in future releases.\n",
      " Please read local_rank from `os.environ('LOCAL_RANK')` instead.\n",
      "INFO:torch.distributed.launcher.api:Starting elastic_operator with launch configs:\n",
      "  entrypoint       : ./train.py\n",
      "  min_nodes        : 1\n",
      "  max_nodes        : 1\n",
      "  nproc_per_node   : 4\n",
      "  run_id           : none\n",
      "  rdzv_backend     : static\n",
      "  rdzv_endpoint    : 127.0.0.1:29300\n",
      "  rdzv_configs     : {'rank': 0, 'timeout': 900}\n",
      "  max_restarts     : 3\n",
      "  monitor_interval : 5\n",
      "  log_dir          : None\n",
      "  metrics_cfg      : {}\n",
      "\n",
      "INFO:torch.distributed.elastic.agent.server.local_elastic_agent:log directory set to: /tmp/torchelastic_lttx7602/none_hhjakjua\n",
      "INFO:torch.distributed.elastic.agent.server.api:[default] starting workers for entrypoint: python\n",
      "INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous'ing worker group\n",
      "/opt/conda/lib/python3.7/site-packages/torch/distributed/elastic/utils/store.py:53: FutureWarning: This is an experimental API and will be changed in future.\n",
      "  \"This is an experimental API and will be changed in future.\", FutureWarning\n",
      "INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous complete for workers. Result:\n",
      "  restart_count=0\n",
      "  master_addr=127.0.0.1\n",
      "  master_port=29300\n",
      "  group_rank=0\n",
      "  group_world_size=1\n",
      "  local_ranks=[0, 1, 2, 3]\n",
      "  role_ranks=[0, 1, 2, 3]\n",
      "  global_ranks=[0, 1, 2, 3]\n",
      "  role_world_sizes=[4, 4, 4, 4]\n",
      "  global_world_sizes=[4, 4, 4, 4]\n",
      "\n",
      "INFO:torch.distributed.elastic.agent.server.api:[default] Starting worker group\n",
      "INFO:torch.distributed.elastic.multiprocessing:Setting worker0 reply file to: /tmp/torchelastic_lttx7602/none_hhjakjua/attempt_0/0/error.json\n",
      "INFO:torch.distributed.elastic.multiprocessing:Setting worker1 reply file to: /tmp/torchelastic_lttx7602/none_hhjakjua/attempt_0/1/error.json\n",
      "INFO:torch.distributed.elastic.multiprocessing:Setting worker2 reply file to: /tmp/torchelastic_lttx7602/none_hhjakjua/attempt_0/2/error.json\n",
      "INFO:torch.distributed.elastic.multiprocessing:Setting worker3 reply file to: /tmp/torchelastic_lttx7602/none_hhjakjua/attempt_0/3/error.json\n",
      "2024-02-14 13:32:01,293 - mmseg - INFO - Environment info:\n",
      "------------------------------------------------------------\n",
      "sys.platform: linux\n",
      "Python: 3.7.13 (default, Mar 29 2022, 02:18:16) [GCC 7.5.0]\n",
      "CUDA available: True\n",
      "GPU 0,1,2,3: NVIDIA L40\n",
      "CUDA_HOME: /usr/local/cuda\n",
      "NVCC: Build cuda_11.3.r11.3/compiler.29920130_0\n",
      "GCC: gcc (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0\n",
      "PyTorch: 1.9.0+cu111\n",
      "PyTorch compiling details: PyTorch built with:\n",
      "  - GCC 7.3\n",
      "  - C++ Version: 201402\n",
      "  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications\n",
      "  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)\n",
      "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
      "  - NNPACK is enabled\n",
      "  - CPU capability usage: AVX2\n",
      "  - CUDA Runtime 11.1\n",
      "  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86\n",
      "  - CuDNN 8.0.5\n",
      "  - Magma 2.5.2\n",
      "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, \n",
      "\n",
      "TorchVision: 0.10.0+cu111\n",
      "OpenCV: 4.9.0\n",
      "MMCV: 1.4.2\n",
      "MMCV Compiler: GCC 7.3\n",
      "MMCV CUDA Compiler: 11.1\n",
      "MMSegmentation: 0.20.2+94ffa6b\n",
      "------------------------------------------------------------\n",
      "\n",
      "2024-02-14 13:32:01,293 - mmseg - INFO - Distributed training: True\n",
      "2024-02-14 13:32:01,867 - mmseg - INFO - Config:\n",
      "num_things_classes = 6\n",
      "num_stuff_classes = 0\n",
      "num_classes = 6\n",
      "norm_cfg = dict(type='SyncBN', requires_grad=True)\n",
      "model = dict(\n",
      "    type='EncoderDecoderMask2Former',\n",
      "    pretrained=\n",
      "    '/workspace/ViT-Adapter/segmentation/mask2former_beit_adapter_large_896_80k_ade20k.pth.tar',\n",
      "    backbone=dict(\n",
      "        type='BEiTAdapter',\n",
      "        patch_size=16,\n",
      "        embed_dim=1024,\n",
      "        depth=24,\n",
      "        num_heads=16,\n",
      "        mlp_ratio=4,\n",
      "        qkv_bias=True,\n",
      "        use_abs_pos_emb=False,\n",
      "        use_rel_pos_bias=True,\n",
      "        img_size=896,\n",
      "        init_values=1e-06,\n",
      "        drop_path_rate=0.3,\n",
      "        conv_inplane=64,\n",
      "        n_points=4,\n",
      "        deform_num_heads=16,\n",
      "        cffn_ratio=0.25,\n",
      "        deform_ratio=0.5,\n",
      "        with_cp=True,\n",
      "        interaction_indexes=[[0, 5], [6, 11], [12, 17], [18, 23]]),\n",
      "    decode_head=dict(\n",
      "        type='Mask2FormerHead',\n",
      "        in_channels=[1024, 1024, 1024, 1024],\n",
      "        feat_channels=1024,\n",
      "        out_channels=1024,\n",
      "        in_index=[0, 1, 2, 3],\n",
      "        num_things_classes=6,\n",
      "        num_stuff_classes=0,\n",
      "        num_queries=200,\n",
      "        num_transformer_feat_level=3,\n",
      "        pixel_decoder=dict(\n",
      "            type='MSDeformAttnPixelDecoder',\n",
      "            num_outs=3,\n",
      "            norm_cfg=dict(type='GN', num_groups=32),\n",
      "            act_cfg=dict(type='ReLU'),\n",
      "            encoder=dict(\n",
      "                type='DetrTransformerEncoder',\n",
      "                num_layers=6,\n",
      "                transformerlayers=dict(\n",
      "                    type='BaseTransformerLayer',\n",
      "                    attn_cfgs=dict(\n",
      "                        type='MultiScaleDeformableAttention',\n",
      "                        embed_dims=1024,\n",
      "                        num_heads=32,\n",
      "                        num_levels=3,\n",
      "                        num_points=4,\n",
      "                        im2col_step=64,\n",
      "                        dropout=0.0,\n",
      "                        batch_first=False,\n",
      "                        norm_cfg=None,\n",
      "                        init_cfg=None),\n",
      "                    ffn_cfgs=dict(\n",
      "                        type='FFN',\n",
      "                        embed_dims=1024,\n",
      "                        feedforward_channels=4096,\n",
      "                        num_fcs=2,\n",
      "                        ffn_drop=0.0,\n",
      "                        act_cfg=dict(type='ReLU', inplace=True),\n",
      "                        with_cp=True),\n",
      "                    operation_order=('self_attn', 'norm', 'ffn', 'norm')),\n",
      "                init_cfg=None),\n",
      "            positional_encoding=dict(\n",
      "                type='SinePositionalEncoding', num_feats=512, normalize=True),\n",
      "            init_cfg=None),\n",
      "        enforce_decoder_input_project=False,\n",
      "        positional_encoding=dict(\n",
      "            type='SinePositionalEncoding', num_feats=512, normalize=True),\n",
      "        transformer_decoder=dict(\n",
      "            type='DetrTransformerDecoder',\n",
      "            return_intermediate=True,\n",
      "            num_layers=9,\n",
      "            transformerlayers=dict(\n",
      "                type='DetrTransformerDecoderLayer',\n",
      "                attn_cfgs=dict(\n",
      "                    type='MultiheadAttention',\n",
      "                    embed_dims=1024,\n",
      "                    num_heads=32,\n",
      "                    attn_drop=0.0,\n",
      "                    proj_drop=0.0,\n",
      "                    dropout_layer=None,\n",
      "                    batch_first=False),\n",
      "                ffn_cfgs=dict(\n",
      "                    embed_dims=1024,\n",
      "                    feedforward_channels=4096,\n",
      "                    num_fcs=2,\n",
      "                    act_cfg=dict(type='ReLU', inplace=True),\n",
      "                    ffn_drop=0.0,\n",
      "                    dropout_layer=None,\n",
      "                    add_identity=True,\n",
      "                    with_cp=True),\n",
      "                feedforward_channels=4096,\n",
      "                operation_order=('cross_attn', 'norm', 'self_attn', 'norm',\n",
      "                                 'ffn', 'norm')),\n",
      "            init_cfg=None),\n",
      "        loss_cls=dict(\n",
      "            type='CrossEntropyLoss',\n",
      "            use_sigmoid=False,\n",
      "            loss_weight=2.0,\n",
      "            reduction='mean',\n",
      "            class_weight=[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.1]),\n",
      "        loss_mask=dict(\n",
      "            type='CrossEntropyLoss',\n",
      "            use_sigmoid=True,\n",
      "            reduction='mean',\n",
      "            loss_weight=5.0),\n",
      "        loss_dice=dict(\n",
      "            type='DiceLoss',\n",
      "            use_sigmoid=True,\n",
      "            activate=True,\n",
      "            reduction='mean',\n",
      "            naive_dice=True,\n",
      "            eps=1.0,\n",
      "            loss_weight=5.0)),\n",
      "    train_cfg=dict(\n",
      "        num_points=12544,\n",
      "        oversample_ratio=3.0,\n",
      "        importance_sample_ratio=0.75,\n",
      "        assigner=dict(\n",
      "            type='MaskHungarianAssigner',\n",
      "            cls_cost=dict(type='ClassificationCost', weight=2.0),\n",
      "            mask_cost=dict(\n",
      "                type='CrossEntropyLossCost', weight=5.0, use_sigmoid=True),\n",
      "            dice_cost=dict(\n",
      "                type='DiceCost', weight=5.0, pred_act=True, eps=1.0)),\n",
      "        sampler=dict(type='MaskPseudoSampler')),\n",
      "    test_cfg=dict(\n",
      "        panoptic_on=True,\n",
      "        semantic_on=False,\n",
      "        instance_on=True,\n",
      "        max_per_image=100,\n",
      "        iou_thr=0.8,\n",
      "        filter_low_score=True,\n",
      "        mode='slide',\n",
      "        crop_size=(896, 896),\n",
      "        stride=(512, 512)),\n",
      "    init_cfg=None)\n",
      "dataset_type = 'PizzeDataset'\n",
      "data_root = 'data/dataset'\n",
      "img_norm_cfg = dict(\n",
      "    mean=[71.20378926, 49.96402668, 36.47249101],\n",
      "    std=[40.74672974, 30.74751057, 20.52758501],\n",
      "    to_rgb=True)\n",
      "crop_size = (896, 896)\n",
      "train_pipeline = [\n",
      "    dict(type='LoadImageFromFile'),\n",
      "    dict(type='LoadAnnotations', reduce_zero_label=False),\n",
      "    dict(type='RandomFlip', prob=0),\n",
      "    dict(\n",
      "        type='Normalize',\n",
      "        mean=[71.20378926, 49.96402668, 36.47249101],\n",
      "        std=[40.74672974, 30.74751057, 20.52758501],\n",
      "        to_rgb=True),\n",
      "    dict(type='Pad', size=(896, 896), pad_val=0, seg_pad_val=0),\n",
      "    dict(type='ToMask'),\n",
      "    dict(type='DefaultFormatBundle'),\n",
      "    dict(\n",
      "        type='Collect',\n",
      "        keys=['img', 'gt_semantic_seg', 'gt_masks', 'gt_labels'])\n",
      "]\n",
      "test_pipeline = [\n",
      "    dict(type='LoadImageFromFile'),\n",
      "    dict(\n",
      "        type='MultiScaleFlipAug',\n",
      "        img_scale=(3584, 896),\n",
      "        flip=False,\n",
      "        transforms=[\n",
      "            dict(type='Resize', keep_ratio=True),\n",
      "            dict(type='ResizeToMultiple', size_divisor=32),\n",
      "            dict(type='RandomFlip'),\n",
      "            dict(\n",
      "                type='Normalize',\n",
      "                mean=[71.20378926, 49.96402668, 36.47249101],\n",
      "                std=[40.74672974, 30.74751057, 20.52758501],\n",
      "                to_rgb=True),\n",
      "            dict(type='ImageToTensor', keys=['img']),\n",
      "            dict(type='Collect', keys=['img'])\n",
      "        ])\n",
      "]\n",
      "data = dict(\n",
      "    samples_per_gpu=1,\n",
      "    workers_per_gpu=4,\n",
      "    train=dict(\n",
      "        type='PizzeDataset',\n",
      "        data_root='data/dataset',\n",
      "        img_dir='images/training',\n",
      "        ann_dir='annotations/training',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(type='LoadAnnotations', reduce_zero_label=False),\n",
      "            dict(type='RandomFlip', prob=0),\n",
      "            dict(\n",
      "                type='Normalize',\n",
      "                mean=[71.20378926, 49.96402668, 36.47249101],\n",
      "                std=[40.74672974, 30.74751057, 20.52758501],\n",
      "                to_rgb=True),\n",
      "            dict(type='Pad', size=(896, 896), pad_val=0, seg_pad_val=0),\n",
      "            dict(type='ToMask'),\n",
      "            dict(type='DefaultFormatBundle'),\n",
      "            dict(\n",
      "                type='Collect',\n",
      "                keys=['img', 'gt_semantic_seg', 'gt_masks', 'gt_labels'])\n",
      "        ]),\n",
      "    val=dict(\n",
      "        type='PizzeDataset',\n",
      "        data_root='data/dataset',\n",
      "        img_dir='images/validation',\n",
      "        ann_dir='annotations/validation',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(\n",
      "                type='MultiScaleFlipAug',\n",
      "                img_scale=(3584, 896),\n",
      "                flip=False,\n",
      "                transforms=[\n",
      "                    dict(type='Resize', keep_ratio=True),\n",
      "                    dict(type='ResizeToMultiple', size_divisor=32),\n",
      "                    dict(type='RandomFlip'),\n",
      "                    dict(\n",
      "                        type='Normalize',\n",
      "                        mean=[71.20378926, 49.96402668, 36.47249101],\n",
      "                        std=[40.74672974, 30.74751057, 20.52758501],\n",
      "                        to_rgb=True),\n",
      "                    dict(type='ImageToTensor', keys=['img']),\n",
      "                    dict(type='Collect', keys=['img'])\n",
      "                ])\n",
      "        ]),\n",
      "    test=dict(\n",
      "        type='PizzeDataset',\n",
      "        data_root='data/dataset',\n",
      "        img_dir='images/validation',\n",
      "        ann_dir='annotations/validation',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(\n",
      "                type='MultiScaleFlipAug',\n",
      "                img_scale=(3584, 896),\n",
      "                flip=False,\n",
      "                transforms=[\n",
      "                    dict(type='Resize', keep_ratio=True),\n",
      "                    dict(type='ResizeToMultiple', size_divisor=32),\n",
      "                    dict(type='RandomFlip'),\n",
      "                    dict(\n",
      "                        type='Normalize',\n",
      "                        mean=[71.20378926, 49.96402668, 36.47249101],\n",
      "                        std=[40.74672974, 30.74751057, 20.52758501],\n",
      "                        to_rgb=True),\n",
      "                    dict(type='ImageToTensor', keys=['img']),\n",
      "                    dict(type='Collect', keys=['img'])\n",
      "                ])\n",
      "        ]))\n",
      "log_config = dict(\n",
      "    interval=10, hooks=[dict(type='TextLoggerHook', by_epoch=False)])\n",
      "dist_params = dict(backend='nccl')\n",
      "log_level = 'INFO'\n",
      "load_from = '/workspace/ViT-Adapter/segmentation/mask2former_beit_adapter_large_896_80k_ade20k.pth.tar'\n",
      "resume_from = None\n",
      "workflow = [('train', 1)]\n",
      "cudnn_benchmark = True\n",
      "optimizer = dict(\n",
      "    type='AdamW',\n",
      "    lr=2e-05,\n",
      "    betas=(0.9, 0.999),\n",
      "    weight_decay=0.05,\n",
      "    constructor='LayerDecayOptimizerConstructor',\n",
      "    paramwise_cfg=dict(num_layers=24, layer_decay_rate=0.9))\n",
      "optimizer_config = dict()\n",
      "lr_config = dict(\n",
      "    policy='poly',\n",
      "    warmup='linear',\n",
      "    warmup_iters=1500,\n",
      "    warmup_ratio=1e-06,\n",
      "    power=1.0,\n",
      "    min_lr=0.0,\n",
      "    by_epoch=False)\n",
      "runner = dict(type='IterBasedRunner', max_iters=80000)\n",
      "checkpoint_config = dict(by_epoch=False, interval=10000, max_keep_ckpts=1)\n",
      "evaluation = dict(interval=200, metric='mIoU', pre_eval=True, save_best='mIoU')\n",
      "pretrained = '/workspace/ViT-Adapter/segmentation/mask2former_beit_adapter_large_896_80k_ade20k.pth.tar'\n",
      "work_dir = './work_dirs/pizze_training_large'\n",
      "gpu_ids = range(0, 4)\n",
      "auto_resume = False\n",
      "device = 'cuda'\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-14 13:32:05,909 - mmseg - INFO - Set random seed to 1356978594, deterministic: True\n",
      "2024-02-14 13:32:20,298 - mmseg - WARNING - The model and loaded state dict do not match exactly\n",
      "\n",
      "unexpected key in source state_dict: backbone.cls_token, backbone.level_embed, backbone.patch_embed.proj.weight, backbone.patch_embed.proj.bias, backbone.blocks.0.gamma_1, backbone.blocks.0.gamma_2, backbone.blocks.0.norm1.weight, backbone.blocks.0.norm1.bias, backbone.blocks.0.attn.q_bias, backbone.blocks.0.attn.v_bias, backbone.blocks.0.attn.relative_position_bias_table, backbone.blocks.0.attn.qkv.weight, backbone.blocks.0.attn.proj.weight, backbone.blocks.0.attn.proj.bias, backbone.blocks.0.norm2.weight, backbone.blocks.0.norm2.bias, backbone.blocks.0.mlp.fc1.weight, backbone.blocks.0.mlp.fc1.bias, backbone.blocks.0.mlp.fc2.weight, backbone.blocks.0.mlp.fc2.bias, backbone.blocks.1.gamma_1, backbone.blocks.1.gamma_2, backbone.blocks.1.norm1.weight, backbone.blocks.1.norm1.bias, backbone.blocks.1.attn.q_bias, backbone.blocks.1.attn.v_bias, backbone.blocks.1.attn.relative_position_bias_table, backbone.blocks.1.attn.qkv.weight, backbone.blocks.1.attn.proj.weight, backbone.blocks.1.attn.proj.bias, backbone.blocks.1.norm2.weight, backbone.blocks.1.norm2.bias, backbone.blocks.1.mlp.fc1.weight, backbone.blocks.1.mlp.fc1.bias, backbone.blocks.1.mlp.fc2.weight, backbone.blocks.1.mlp.fc2.bias, backbone.blocks.2.gamma_1, backbone.blocks.2.gamma_2, backbone.blocks.2.norm1.weight, backbone.blocks.2.norm1.bias, backbone.blocks.2.attn.q_bias, backbone.blocks.2.attn.v_bias, backbone.blocks.2.attn.relative_position_bias_table, backbone.blocks.2.attn.qkv.weight, backbone.blocks.2.attn.proj.weight, backbone.blocks.2.attn.proj.bias, backbone.blocks.2.norm2.weight, backbone.blocks.2.norm2.bias, backbone.blocks.2.mlp.fc1.weight, backbone.blocks.2.mlp.fc1.bias, backbone.blocks.2.mlp.fc2.weight, backbone.blocks.2.mlp.fc2.bias, backbone.blocks.3.gamma_1, backbone.blocks.3.gamma_2, backbone.blocks.3.norm1.weight, backbone.blocks.3.norm1.bias, backbone.blocks.3.attn.q_bias, backbone.blocks.3.attn.v_bias, backbone.blocks.3.attn.relative_position_bias_table, backbone.blocks.3.attn.qkv.weight, backbone.blocks.3.attn.proj.weight, backbone.blocks.3.attn.proj.bias, backbone.blocks.3.norm2.weight, backbone.blocks.3.norm2.bias, backbone.blocks.3.mlp.fc1.weight, backbone.blocks.3.mlp.fc1.bias, backbone.blocks.3.mlp.fc2.weight, backbone.blocks.3.mlp.fc2.bias, backbone.blocks.4.gamma_1, backbone.blocks.4.gamma_2, backbone.blocks.4.norm1.weight, backbone.blocks.4.norm1.bias, backbone.blocks.4.attn.q_bias, backbone.blocks.4.attn.v_bias, backbone.blocks.4.attn.relative_position_bias_table, backbone.blocks.4.attn.qkv.weight, backbone.blocks.4.attn.proj.weight, backbone.blocks.4.attn.proj.bias, backbone.blocks.4.norm2.weight, backbone.blocks.4.norm2.bias, backbone.blocks.4.mlp.fc1.weight, backbone.blocks.4.mlp.fc1.bias, backbone.blocks.4.mlp.fc2.weight, backbone.blocks.4.mlp.fc2.bias, backbone.blocks.5.gamma_1, backbone.blocks.5.gamma_2, backbone.blocks.5.norm1.weight, backbone.blocks.5.norm1.bias, backbone.blocks.5.attn.q_bias, backbone.blocks.5.attn.v_bias, backbone.blocks.5.attn.relative_position_bias_table, backbone.blocks.5.attn.qkv.weight, backbone.blocks.5.attn.proj.weight, backbone.blocks.5.attn.proj.bias, backbone.blocks.5.norm2.weight, backbone.blocks.5.norm2.bias, backbone.blocks.5.mlp.fc1.weight, backbone.blocks.5.mlp.fc1.bias, backbone.blocks.5.mlp.fc2.weight, backbone.blocks.5.mlp.fc2.bias, backbone.blocks.6.gamma_1, backbone.blocks.6.gamma_2, backbone.blocks.6.norm1.weight, backbone.blocks.6.norm1.bias, backbone.blocks.6.attn.q_bias, backbone.blocks.6.attn.v_bias, backbone.blocks.6.attn.relative_position_bias_table, backbone.blocks.6.attn.qkv.weight, backbone.blocks.6.attn.proj.weight, backbone.blocks.6.attn.proj.bias, backbone.blocks.6.norm2.weight, backbone.blocks.6.norm2.bias, backbone.blocks.6.mlp.fc1.weight, backbone.blocks.6.mlp.fc1.bias, backbone.blocks.6.mlp.fc2.weight, backbone.blocks.6.mlp.fc2.bias, backbone.blocks.7.gamma_1, backbone.blocks.7.gamma_2, backbone.blocks.7.norm1.weight, backbone.blocks.7.norm1.bias, backbone.blocks.7.attn.q_bias, backbone.blocks.7.attn.v_bias, backbone.blocks.7.attn.relative_position_bias_table, backbone.blocks.7.attn.qkv.weight, backbone.blocks.7.attn.proj.weight, backbone.blocks.7.attn.proj.bias, backbone.blocks.7.norm2.weight, backbone.blocks.7.norm2.bias, backbone.blocks.7.mlp.fc1.weight, backbone.blocks.7.mlp.fc1.bias, backbone.blocks.7.mlp.fc2.weight, backbone.blocks.7.mlp.fc2.bias, backbone.blocks.8.gamma_1, backbone.blocks.8.gamma_2, backbone.blocks.8.norm1.weight, backbone.blocks.8.norm1.bias, backbone.blocks.8.attn.q_bias, backbone.blocks.8.attn.v_bias, backbone.blocks.8.attn.relative_position_bias_table, backbone.blocks.8.attn.qkv.weight, backbone.blocks.8.attn.proj.weight, backbone.blocks.8.attn.proj.bias, backbone.blocks.8.norm2.weight, backbone.blocks.8.norm2.bias, backbone.blocks.8.mlp.fc1.weight, backbone.blocks.8.mlp.fc1.bias, backbone.blocks.8.mlp.fc2.weight, backbone.blocks.8.mlp.fc2.bias, backbone.blocks.9.gamma_1, backbone.blocks.9.gamma_2, backbone.blocks.9.norm1.weight, backbone.blocks.9.norm1.bias, backbone.blocks.9.attn.q_bias, backbone.blocks.9.attn.v_bias, backbone.blocks.9.attn.relative_position_bias_table, backbone.blocks.9.attn.qkv.weight, backbone.blocks.9.attn.proj.weight, backbone.blocks.9.attn.proj.bias, backbone.blocks.9.norm2.weight, backbone.blocks.9.norm2.bias, backbone.blocks.9.mlp.fc1.weight, backbone.blocks.9.mlp.fc1.bias, backbone.blocks.9.mlp.fc2.weight, backbone.blocks.9.mlp.fc2.bias, backbone.blocks.10.gamma_1, backbone.blocks.10.gamma_2, backbone.blocks.10.norm1.weight, backbone.blocks.10.norm1.bias, backbone.blocks.10.attn.q_bias, backbone.blocks.10.attn.v_bias, backbone.blocks.10.attn.relative_position_bias_table, backbone.blocks.10.attn.qkv.weight, backbone.blocks.10.attn.proj.weight, backbone.blocks.10.attn.proj.bias, backbone.blocks.10.norm2.weight, backbone.blocks.10.norm2.bias, backbone.blocks.10.mlp.fc1.weight, backbone.blocks.10.mlp.fc1.bias, backbone.blocks.10.mlp.fc2.weight, backbone.blocks.10.mlp.fc2.bias, backbone.blocks.11.gamma_1, backbone.blocks.11.gamma_2, backbone.blocks.11.norm1.weight, backbone.blocks.11.norm1.bias, backbone.blocks.11.attn.q_bias, backbone.blocks.11.attn.v_bias, backbone.blocks.11.attn.relative_position_bias_table, backbone.blocks.11.attn.qkv.weight, backbone.blocks.11.attn.proj.weight, backbone.blocks.11.attn.proj.bias, backbone.blocks.11.norm2.weight, backbone.blocks.11.norm2.bias, backbone.blocks.11.mlp.fc1.weight, backbone.blocks.11.mlp.fc1.bias, backbone.blocks.11.mlp.fc2.weight, backbone.blocks.11.mlp.fc2.bias, backbone.blocks.12.gamma_1, backbone.blocks.12.gamma_2, backbone.blocks.12.norm1.weight, backbone.blocks.12.norm1.bias, backbone.blocks.12.attn.q_bias, backbone.blocks.12.attn.v_bias, backbone.blocks.12.attn.relative_position_bias_table, backbone.blocks.12.attn.qkv.weight, backbone.blocks.12.attn.proj.weight, backbone.blocks.12.attn.proj.bias, backbone.blocks.12.norm2.weight, backbone.blocks.12.norm2.bias, backbone.blocks.12.mlp.fc1.weight, backbone.blocks.12.mlp.fc1.bias, backbone.blocks.12.mlp.fc2.weight, backbone.blocks.12.mlp.fc2.bias, backbone.blocks.13.gamma_1, backbone.blocks.13.gamma_2, backbone.blocks.13.norm1.weight, backbone.blocks.13.norm1.bias, backbone.blocks.13.attn.q_bias, backbone.blocks.13.attn.v_bias, backbone.blocks.13.attn.relative_position_bias_table, backbone.blocks.13.attn.qkv.weight, backbone.blocks.13.attn.proj.weight, backbone.blocks.13.attn.proj.bias, backbone.blocks.13.norm2.weight, backbone.blocks.13.norm2.bias, backbone.blocks.13.mlp.fc1.weight, backbone.blocks.13.mlp.fc1.bias, backbone.blocks.13.mlp.fc2.weight, backbone.blocks.13.mlp.fc2.bias, backbone.blocks.14.gamma_1, backbone.blocks.14.gamma_2, backbone.blocks.14.norm1.weight, backbone.blocks.14.norm1.bias, backbone.blocks.14.attn.q_bias, backbone.blocks.14.attn.v_bias, backbone.blocks.14.attn.relative_position_bias_table, backbone.blocks.14.attn.qkv.weight, backbone.blocks.14.attn.proj.weight, backbone.blocks.14.attn.proj.bias, backbone.blocks.14.norm2.weight, backbone.blocks.14.norm2.bias, backbone.blocks.14.mlp.fc1.weight, backbone.blocks.14.mlp.fc1.bias, backbone.blocks.14.mlp.fc2.weight, backbone.blocks.14.mlp.fc2.bias, backbone.blocks.15.gamma_1, backbone.blocks.15.gamma_2, backbone.blocks.15.norm1.weight, backbone.blocks.15.norm1.bias, backbone.blocks.15.attn.q_bias, backbone.blocks.15.attn.v_bias, backbone.blocks.15.attn.relative_position_bias_table, backbone.blocks.15.attn.qkv.weight, backbone.blocks.15.attn.proj.weight, backbone.blocks.15.attn.proj.bias, backbone.blocks.15.norm2.weight, backbone.blocks.15.norm2.bias, backbone.blocks.15.mlp.fc1.weight, backbone.blocks.15.mlp.fc1.bias, backbone.blocks.15.mlp.fc2.weight, backbone.blocks.15.mlp.fc2.bias, backbone.blocks.16.gamma_1, backbone.blocks.16.gamma_2, backbone.blocks.16.norm1.weight, backbone.blocks.16.norm1.bias, backbone.blocks.16.attn.q_bias, backbone.blocks.16.attn.v_bias, backbone.blocks.16.attn.relative_position_bias_table, backbone.blocks.16.attn.qkv.weight, backbone.blocks.16.attn.proj.weight, backbone.blocks.16.attn.proj.bias, backbone.blocks.16.norm2.weight, backbone.blocks.16.norm2.bias, backbone.blocks.16.mlp.fc1.weight, backbone.blocks.16.mlp.fc1.bias, backbone.blocks.16.mlp.fc2.weight, backbone.blocks.16.mlp.fc2.bias, backbone.blocks.17.gamma_1, backbone.blocks.17.gamma_2, backbone.blocks.17.norm1.weight, backbone.blocks.17.norm1.bias, backbone.blocks.17.attn.q_bias, backbone.blocks.17.attn.v_bias, backbone.blocks.17.attn.relative_position_bias_table, backbone.blocks.17.attn.qkv.weight, backbone.blocks.17.attn.proj.weight, backbone.blocks.17.attn.proj.bias, backbone.blocks.17.norm2.weight, backbone.blocks.17.norm2.bias, backbone.blocks.17.mlp.fc1.weight, backbone.blocks.17.mlp.fc1.bias, backbone.blocks.17.mlp.fc2.weight, backbone.blocks.17.mlp.fc2.bias, backbone.blocks.18.gamma_1, backbone.blocks.18.gamma_2, backbone.blocks.18.norm1.weight, backbone.blocks.18.norm1.bias, backbone.blocks.18.attn.q_bias, backbone.blocks.18.attn.v_bias, backbone.blocks.18.attn.relative_position_bias_table, backbone.blocks.18.attn.qkv.weight, backbone.blocks.18.attn.proj.weight, backbone.blocks.18.attn.proj.bias, backbone.blocks.18.norm2.weight, backbone.blocks.18.norm2.bias, backbone.blocks.18.mlp.fc1.weight, backbone.blocks.18.mlp.fc1.bias, backbone.blocks.18.mlp.fc2.weight, backbone.blocks.18.mlp.fc2.bias, backbone.blocks.19.gamma_1, backbone.blocks.19.gamma_2, backbone.blocks.19.norm1.weight, backbone.blocks.19.norm1.bias, backbone.blocks.19.attn.q_bias, backbone.blocks.19.attn.v_bias, backbone.blocks.19.attn.relative_position_bias_table, backbone.blocks.19.attn.qkv.weight, backbone.blocks.19.attn.proj.weight, backbone.blocks.19.attn.proj.bias, backbone.blocks.19.norm2.weight, backbone.blocks.19.norm2.bias, backbone.blocks.19.mlp.fc1.weight, backbone.blocks.19.mlp.fc1.bias, backbone.blocks.19.mlp.fc2.weight, backbone.blocks.19.mlp.fc2.bias, backbone.blocks.20.gamma_1, backbone.blocks.20.gamma_2, backbone.blocks.20.norm1.weight, backbone.blocks.20.norm1.bias, backbone.blocks.20.attn.q_bias, backbone.blocks.20.attn.v_bias, backbone.blocks.20.attn.relative_position_bias_table, backbone.blocks.20.attn.qkv.weight, backbone.blocks.20.attn.proj.weight, backbone.blocks.20.attn.proj.bias, backbone.blocks.20.norm2.weight, backbone.blocks.20.norm2.bias, backbone.blocks.20.mlp.fc1.weight, backbone.blocks.20.mlp.fc1.bias, backbone.blocks.20.mlp.fc2.weight, backbone.blocks.20.mlp.fc2.bias, backbone.blocks.21.gamma_1, backbone.blocks.21.gamma_2, backbone.blocks.21.norm1.weight, backbone.blocks.21.norm1.bias, backbone.blocks.21.attn.q_bias, backbone.blocks.21.attn.v_bias, backbone.blocks.21.attn.relative_position_bias_table, backbone.blocks.21.attn.qkv.weight, backbone.blocks.21.attn.proj.weight, backbone.blocks.21.attn.proj.bias, backbone.blocks.21.norm2.weight, backbone.blocks.21.norm2.bias, backbone.blocks.21.mlp.fc1.weight, backbone.blocks.21.mlp.fc1.bias, backbone.blocks.21.mlp.fc2.weight, backbone.blocks.21.mlp.fc2.bias, backbone.blocks.22.gamma_1, backbone.blocks.22.gamma_2, backbone.blocks.22.norm1.weight, backbone.blocks.22.norm1.bias, backbone.blocks.22.attn.q_bias, backbone.blocks.22.attn.v_bias, backbone.blocks.22.attn.relative_position_bias_table, backbone.blocks.22.attn.qkv.weight, backbone.blocks.22.attn.proj.weight, backbone.blocks.22.attn.proj.bias, backbone.blocks.22.norm2.weight, backbone.blocks.22.norm2.bias, backbone.blocks.22.mlp.fc1.weight, backbone.blocks.22.mlp.fc1.bias, backbone.blocks.22.mlp.fc2.weight, backbone.blocks.22.mlp.fc2.bias, backbone.blocks.23.gamma_1, backbone.blocks.23.gamma_2, backbone.blocks.23.norm1.weight, backbone.blocks.23.norm1.bias, backbone.blocks.23.attn.q_bias, backbone.blocks.23.attn.v_bias, backbone.blocks.23.attn.relative_position_bias_table, backbone.blocks.23.attn.qkv.weight, backbone.blocks.23.attn.proj.weight, backbone.blocks.23.attn.proj.bias, backbone.blocks.23.norm2.weight, backbone.blocks.23.norm2.bias, backbone.blocks.23.mlp.fc1.weight, backbone.blocks.23.mlp.fc1.bias, backbone.blocks.23.mlp.fc2.weight, backbone.blocks.23.mlp.fc2.bias, backbone.spm.stem.0.weight, backbone.spm.stem.1.weight, backbone.spm.stem.1.bias, backbone.spm.stem.1.running_mean, backbone.spm.stem.1.running_var, backbone.spm.stem.1.num_batches_tracked, backbone.spm.stem.3.weight, backbone.spm.stem.4.weight, backbone.spm.stem.4.bias, backbone.spm.stem.4.running_mean, backbone.spm.stem.4.running_var, backbone.spm.stem.4.num_batches_tracked, backbone.spm.stem.6.weight, backbone.spm.stem.7.weight, backbone.spm.stem.7.bias, backbone.spm.stem.7.running_mean, backbone.spm.stem.7.running_var, backbone.spm.stem.7.num_batches_tracked, backbone.spm.conv2.0.weight, backbone.spm.conv2.1.weight, backbone.spm.conv2.1.bias, backbone.spm.conv2.1.running_mean, backbone.spm.conv2.1.running_var, backbone.spm.conv2.1.num_batches_tracked, backbone.spm.conv3.0.weight, backbone.spm.conv3.1.weight, backbone.spm.conv3.1.bias, backbone.spm.conv3.1.running_mean, backbone.spm.conv3.1.running_var, backbone.spm.conv3.1.num_batches_tracked, backbone.spm.conv4.0.weight, backbone.spm.conv4.1.weight, backbone.spm.conv4.1.bias, backbone.spm.conv4.1.running_mean, backbone.spm.conv4.1.running_var, backbone.spm.conv4.1.num_batches_tracked, backbone.spm.fc1.weight, backbone.spm.fc1.bias, backbone.spm.fc2.weight, backbone.spm.fc2.bias, backbone.spm.fc3.weight, backbone.spm.fc3.bias, backbone.spm.fc4.weight, backbone.spm.fc4.bias, backbone.interactions.0.extractor.query_norm.weight, backbone.interactions.0.extractor.query_norm.bias, backbone.interactions.0.extractor.feat_norm.weight, backbone.interactions.0.extractor.feat_norm.bias, backbone.interactions.0.extractor.attn.sampling_offsets.weight, backbone.interactions.0.extractor.attn.sampling_offsets.bias, backbone.interactions.0.extractor.attn.attention_weights.weight, backbone.interactions.0.extractor.attn.attention_weights.bias, backbone.interactions.0.extractor.attn.value_proj.weight, backbone.interactions.0.extractor.attn.value_proj.bias, backbone.interactions.0.extractor.attn.output_proj.weight, backbone.interactions.0.extractor.attn.output_proj.bias, backbone.interactions.0.injector.gamma, backbone.interactions.0.injector.query_norm.weight, backbone.interactions.0.injector.query_norm.bias, backbone.interactions.0.injector.feat_norm.weight, backbone.interactions.0.injector.feat_norm.bias, backbone.interactions.0.injector.attn.sampling_offsets.weight, backbone.interactions.0.injector.attn.sampling_offsets.bias, backbone.interactions.0.injector.attn.attention_weights.weight, backbone.interactions.0.injector.attn.attention_weights.bias, backbone.interactions.0.injector.attn.value_proj.weight, backbone.interactions.0.injector.attn.value_proj.bias, backbone.interactions.0.injector.attn.output_proj.weight, backbone.interactions.0.injector.attn.output_proj.bias, backbone.interactions.0.extractor.ffn.fc1.weight, backbone.interactions.0.extractor.ffn.fc1.bias, backbone.interactions.0.extractor.ffn.dwconv.dwconv.weight, backbone.interactions.0.extractor.ffn.dwconv.dwconv.bias, backbone.interactions.0.extractor.ffn.fc2.weight, backbone.interactions.0.extractor.ffn.fc2.bias, backbone.interactions.0.extractor.ffn_norm.weight, backbone.interactions.0.extractor.ffn_norm.bias, backbone.interactions.1.extractor.query_norm.weight, backbone.interactions.1.extractor.query_norm.bias, backbone.interactions.1.extractor.feat_norm.weight, backbone.interactions.1.extractor.feat_norm.bias, backbone.interactions.1.extractor.attn.sampling_offsets.weight, backbone.interactions.1.extractor.attn.sampling_offsets.bias, backbone.interactions.1.extractor.attn.attention_weights.weight, backbone.interactions.1.extractor.attn.attention_weights.bias, backbone.interactions.1.extractor.attn.value_proj.weight, backbone.interactions.1.extractor.attn.value_proj.bias, backbone.interactions.1.extractor.attn.output_proj.weight, backbone.interactions.1.extractor.attn.output_proj.bias, backbone.interactions.1.injector.gamma, backbone.interactions.1.injector.query_norm.weight, backbone.interactions.1.injector.query_norm.bias, backbone.interactions.1.injector.feat_norm.weight, backbone.interactions.1.injector.feat_norm.bias, backbone.interactions.1.injector.attn.sampling_offsets.weight, backbone.interactions.1.injector.attn.sampling_offsets.bias, backbone.interactions.1.injector.attn.attention_weights.weight, backbone.interactions.1.injector.attn.attention_weights.bias, backbone.interactions.1.injector.attn.value_proj.weight, backbone.interactions.1.injector.attn.value_proj.bias, backbone.interactions.1.injector.attn.output_proj.weight, backbone.interactions.1.injector.attn.output_proj.bias, backbone.interactions.1.extractor.ffn.fc1.weight, backbone.interactions.1.extractor.ffn.fc1.bias, backbone.interactions.1.extractor.ffn.dwconv.dwconv.weight, backbone.interactions.1.extractor.ffn.dwconv.dwconv.bias, backbone.interactions.1.extractor.ffn.fc2.weight, backbone.interactions.1.extractor.ffn.fc2.bias, backbone.interactions.1.extractor.ffn_norm.weight, backbone.interactions.1.extractor.ffn_norm.bias, backbone.interactions.2.extractor.query_norm.weight, backbone.interactions.2.extractor.query_norm.bias, backbone.interactions.2.extractor.feat_norm.weight, backbone.interactions.2.extractor.feat_norm.bias, backbone.interactions.2.extractor.attn.sampling_offsets.weight, backbone.interactions.2.extractor.attn.sampling_offsets.bias, backbone.interactions.2.extractor.attn.attention_weights.weight, backbone.interactions.2.extractor.attn.attention_weights.bias, backbone.interactions.2.extractor.attn.value_proj.weight, backbone.interactions.2.extractor.attn.value_proj.bias, backbone.interactions.2.extractor.attn.output_proj.weight, backbone.interactions.2.extractor.attn.output_proj.bias, backbone.interactions.2.injector.gamma, backbone.interactions.2.injector.query_norm.weight, backbone.interactions.2.injector.query_norm.bias, backbone.interactions.2.injector.feat_norm.weight, backbone.interactions.2.injector.feat_norm.bias, backbone.interactions.2.injector.attn.sampling_offsets.weight, backbone.interactions.2.injector.attn.sampling_offsets.bias, backbone.interactions.2.injector.attn.attention_weights.weight, backbone.interactions.2.injector.attn.attention_weights.bias, backbone.interactions.2.injector.attn.value_proj.weight, backbone.interactions.2.injector.attn.value_proj.bias, backbone.interactions.2.injector.attn.output_proj.weight, backbone.interactions.2.injector.attn.output_proj.bias, backbone.interactions.2.extractor.ffn.fc1.weight, backbone.interactions.2.extractor.ffn.fc1.bias, backbone.interactions.2.extractor.ffn.dwconv.dwconv.weight, backbone.interactions.2.extractor.ffn.dwconv.dwconv.bias, backbone.interactions.2.extractor.ffn.fc2.weight, backbone.interactions.2.extractor.ffn.fc2.bias, backbone.interactions.2.extractor.ffn_norm.weight, backbone.interactions.2.extractor.ffn_norm.bias, backbone.interactions.3.extractor.query_norm.weight, backbone.interactions.3.extractor.query_norm.bias, backbone.interactions.3.extractor.feat_norm.weight, backbone.interactions.3.extractor.feat_norm.bias, backbone.interactions.3.extractor.attn.sampling_offsets.weight, backbone.interactions.3.extractor.attn.sampling_offsets.bias, backbone.interactions.3.extractor.attn.attention_weights.weight, backbone.interactions.3.extractor.attn.attention_weights.bias, backbone.interactions.3.extractor.attn.value_proj.weight, backbone.interactions.3.extractor.attn.value_proj.bias, backbone.interactions.3.extractor.attn.output_proj.weight, backbone.interactions.3.extractor.attn.output_proj.bias, backbone.interactions.3.injector.gamma, backbone.interactions.3.injector.query_norm.weight, backbone.interactions.3.injector.query_norm.bias, backbone.interactions.3.injector.feat_norm.weight, backbone.interactions.3.injector.feat_norm.bias, backbone.interactions.3.injector.attn.sampling_offsets.weight, backbone.interactions.3.injector.attn.sampling_offsets.bias, backbone.interactions.3.injector.attn.attention_weights.weight, backbone.interactions.3.injector.attn.attention_weights.bias, backbone.interactions.3.injector.attn.value_proj.weight, backbone.interactions.3.injector.attn.value_proj.bias, backbone.interactions.3.injector.attn.output_proj.weight, backbone.interactions.3.injector.attn.output_proj.bias, backbone.interactions.3.extractor.ffn.fc1.weight, backbone.interactions.3.extractor.ffn.fc1.bias, backbone.interactions.3.extractor.ffn.dwconv.dwconv.weight, backbone.interactions.3.extractor.ffn.dwconv.dwconv.bias, backbone.interactions.3.extractor.ffn.fc2.weight, backbone.interactions.3.extractor.ffn.fc2.bias, backbone.interactions.3.extractor.ffn_norm.weight, backbone.interactions.3.extractor.ffn_norm.bias, backbone.interactions.3.extra_extractors.0.query_norm.weight, backbone.interactions.3.extra_extractors.0.query_norm.bias, backbone.interactions.3.extra_extractors.0.feat_norm.weight, backbone.interactions.3.extra_extractors.0.feat_norm.bias, backbone.interactions.3.extra_extractors.0.attn.sampling_offsets.weight, backbone.interactions.3.extra_extractors.0.attn.sampling_offsets.bias, backbone.interactions.3.extra_extractors.0.attn.attention_weights.weight, backbone.interactions.3.extra_extractors.0.attn.attention_weights.bias, backbone.interactions.3.extra_extractors.0.attn.value_proj.weight, backbone.interactions.3.extra_extractors.0.attn.value_proj.bias, backbone.interactions.3.extra_extractors.0.attn.output_proj.weight, backbone.interactions.3.extra_extractors.0.attn.output_proj.bias, backbone.interactions.3.extra_extractors.0.ffn.fc1.weight, backbone.interactions.3.extra_extractors.0.ffn.fc1.bias, backbone.interactions.3.extra_extractors.0.ffn.dwconv.dwconv.weight, backbone.interactions.3.extra_extractors.0.ffn.dwconv.dwconv.bias, backbone.interactions.3.extra_extractors.0.ffn.fc2.weight, backbone.interactions.3.extra_extractors.0.ffn.fc2.bias, backbone.interactions.3.extra_extractors.0.ffn_norm.weight, backbone.interactions.3.extra_extractors.0.ffn_norm.bias, backbone.interactions.3.extra_extractors.1.query_norm.weight, backbone.interactions.3.extra_extractors.1.query_norm.bias, backbone.interactions.3.extra_extractors.1.feat_norm.weight, backbone.interactions.3.extra_extractors.1.feat_norm.bias, backbone.interactions.3.extra_extractors.1.attn.sampling_offsets.weight, backbone.interactions.3.extra_extractors.1.attn.sampling_offsets.bias, backbone.interactions.3.extra_extractors.1.attn.attention_weights.weight, backbone.interactions.3.extra_extractors.1.attn.attention_weights.bias, backbone.interactions.3.extra_extractors.1.attn.value_proj.weight, backbone.interactions.3.extra_extractors.1.attn.value_proj.bias, backbone.interactions.3.extra_extractors.1.attn.output_proj.weight, backbone.interactions.3.extra_extractors.1.attn.output_proj.bias, backbone.interactions.3.extra_extractors.1.ffn.fc1.weight, backbone.interactions.3.extra_extractors.1.ffn.fc1.bias, backbone.interactions.3.extra_extractors.1.ffn.dwconv.dwconv.weight, backbone.interactions.3.extra_extractors.1.ffn.dwconv.dwconv.bias, backbone.interactions.3.extra_extractors.1.ffn.fc2.weight, backbone.interactions.3.extra_extractors.1.ffn.fc2.bias, backbone.interactions.3.extra_extractors.1.ffn_norm.weight, backbone.interactions.3.extra_extractors.1.ffn_norm.bias, backbone.up.weight, backbone.up.bias, backbone.norm1.weight, backbone.norm1.bias, backbone.norm1.running_mean, backbone.norm1.running_var, backbone.norm1.num_batches_tracked, backbone.norm2.weight, backbone.norm2.bias, backbone.norm2.running_mean, backbone.norm2.running_var, backbone.norm2.num_batches_tracked, backbone.norm3.weight, backbone.norm3.bias, backbone.norm3.running_mean, backbone.norm3.running_var, backbone.norm3.num_batches_tracked, backbone.norm4.weight, backbone.norm4.bias, backbone.norm4.running_mean, backbone.norm4.running_var, backbone.norm4.num_batches_tracked, decode_head.conv_seg.weight, decode_head.conv_seg.bias, decode_head.pixel_decoder.input_convs.0.conv.weight, decode_head.pixel_decoder.input_convs.0.conv.bias, decode_head.pixel_decoder.input_convs.0.gn.weight, decode_head.pixel_decoder.input_convs.0.gn.bias, decode_head.pixel_decoder.input_convs.1.conv.weight, decode_head.pixel_decoder.input_convs.1.conv.bias, decode_head.pixel_decoder.input_convs.1.gn.weight, decode_head.pixel_decoder.input_convs.1.gn.bias, decode_head.pixel_decoder.input_convs.2.conv.weight, decode_head.pixel_decoder.input_convs.2.conv.bias, decode_head.pixel_decoder.input_convs.2.gn.weight, decode_head.pixel_decoder.input_convs.2.gn.bias, decode_head.pixel_decoder.encoder.layers.0.attentions.0.sampling_offsets.weight, decode_head.pixel_decoder.encoder.layers.0.attentions.0.sampling_offsets.bias, decode_head.pixel_decoder.encoder.layers.0.attentions.0.attention_weights.weight, decode_head.pixel_decoder.encoder.layers.0.attentions.0.attention_weights.bias, decode_head.pixel_decoder.encoder.layers.0.attentions.0.value_proj.weight, decode_head.pixel_decoder.encoder.layers.0.attentions.0.value_proj.bias, decode_head.pixel_decoder.encoder.layers.0.attentions.0.output_proj.weight, decode_head.pixel_decoder.encoder.layers.0.attentions.0.output_proj.bias, decode_head.pixel_decoder.encoder.layers.0.ffns.0.layers.0.0.weight, decode_head.pixel_decoder.encoder.layers.0.ffns.0.layers.0.0.bias, decode_head.pixel_decoder.encoder.layers.0.ffns.0.layers.1.weight, decode_head.pixel_decoder.encoder.layers.0.ffns.0.layers.1.bias, decode_head.pixel_decoder.encoder.layers.0.norms.0.weight, decode_head.pixel_decoder.encoder.layers.0.norms.0.bias, decode_head.pixel_decoder.encoder.layers.0.norms.1.weight, decode_head.pixel_decoder.encoder.layers.0.norms.1.bias, decode_head.pixel_decoder.encoder.layers.1.attentions.0.sampling_offsets.weight, decode_head.pixel_decoder.encoder.layers.1.attentions.0.sampling_offsets.bias, decode_head.pixel_decoder.encoder.layers.1.attentions.0.attention_weights.weight, decode_head.pixel_decoder.encoder.layers.1.attentions.0.attention_weights.bias, decode_head.pixel_decoder.encoder.layers.1.attentions.0.value_proj.weight, decode_head.pixel_decoder.encoder.layers.1.attentions.0.value_proj.bias, decode_head.pixel_decoder.encoder.layers.1.attentions.0.output_proj.weight, decode_head.pixel_decoder.encoder.layers.1.attentions.0.output_proj.bias, decode_head.pixel_decoder.encoder.layers.1.ffns.0.layers.0.0.weight, decode_head.pixel_decoder.encoder.layers.1.ffns.0.layers.0.0.bias, decode_head.pixel_decoder.encoder.layers.1.ffns.0.layers.1.weight, decode_head.pixel_decoder.encoder.layers.1.ffns.0.layers.1.bias, decode_head.pixel_decoder.encoder.layers.1.norms.0.weight, decode_head.pixel_decoder.encoder.layers.1.norms.0.bias, decode_head.pixel_decoder.encoder.layers.1.norms.1.weight, decode_head.pixel_decoder.encoder.layers.1.norms.1.bias, decode_head.pixel_decoder.encoder.layers.2.attentions.0.sampling_offsets.weight, decode_head.pixel_decoder.encoder.layers.2.attentions.0.sampling_offsets.bias, decode_head.pixel_decoder.encoder.layers.2.attentions.0.attention_weights.weight, decode_head.pixel_decoder.encoder.layers.2.attentions.0.attention_weights.bias, decode_head.pixel_decoder.encoder.layers.2.attentions.0.value_proj.weight, decode_head.pixel_decoder.encoder.layers.2.attentions.0.value_proj.bias, decode_head.pixel_decoder.encoder.layers.2.attentions.0.output_proj.weight, decode_head.pixel_decoder.encoder.layers.2.attentions.0.output_proj.bias, decode_head.pixel_decoder.encoder.layers.2.ffns.0.layers.0.0.weight, decode_head.pixel_decoder.encoder.layers.2.ffns.0.layers.0.0.bias, decode_head.pixel_decoder.encoder.layers.2.ffns.0.layers.1.weight, decode_head.pixel_decoder.encoder.layers.2.ffns.0.layers.1.bias, decode_head.pixel_decoder.encoder.layers.2.norms.0.weight, decode_head.pixel_decoder.encoder.layers.2.norms.0.bias, decode_head.pixel_decoder.encoder.layers.2.norms.1.weight, decode_head.pixel_decoder.encoder.layers.2.norms.1.bias, decode_head.pixel_decoder.encoder.layers.3.attentions.0.sampling_offsets.weight, decode_head.pixel_decoder.encoder.layers.3.attentions.0.sampling_offsets.bias, decode_head.pixel_decoder.encoder.layers.3.attentions.0.attention_weights.weight, decode_head.pixel_decoder.encoder.layers.3.attentions.0.attention_weights.bias, decode_head.pixel_decoder.encoder.layers.3.attentions.0.value_proj.weight, decode_head.pixel_decoder.encoder.layers.3.attentions.0.value_proj.bias, decode_head.pixel_decoder.encoder.layers.3.attentions.0.output_proj.weight, decode_head.pixel_decoder.encoder.layers.3.attentions.0.output_proj.bias, decode_head.pixel_decoder.encoder.layers.3.ffns.0.layers.0.0.weight, decode_head.pixel_decoder.encoder.layers.3.ffns.0.layers.0.0.bias, decode_head.pixel_decoder.encoder.layers.3.ffns.0.layers.1.weight, decode_head.pixel_decoder.encoder.layers.3.ffns.0.layers.1.bias, decode_head.pixel_decoder.encoder.layers.3.norms.0.weight, decode_head.pixel_decoder.encoder.layers.3.norms.0.bias, decode_head.pixel_decoder.encoder.layers.3.norms.1.weight, decode_head.pixel_decoder.encoder.layers.3.norms.1.bias, decode_head.pixel_decoder.encoder.layers.4.attentions.0.sampling_offsets.weight, decode_head.pixel_decoder.encoder.layers.4.attentions.0.sampling_offsets.bias, decode_head.pixel_decoder.encoder.layers.4.attentions.0.attention_weights.weight, decode_head.pixel_decoder.encoder.layers.4.attentions.0.attention_weights.bias, decode_head.pixel_decoder.encoder.layers.4.attentions.0.value_proj.weight, decode_head.pixel_decoder.encoder.layers.4.attentions.0.value_proj.bias, decode_head.pixel_decoder.encoder.layers.4.attentions.0.output_proj.weight, decode_head.pixel_decoder.encoder.layers.4.attentions.0.output_proj.bias, decode_head.pixel_decoder.encoder.layers.4.ffns.0.layers.0.0.weight, decode_head.pixel_decoder.encoder.layers.4.ffns.0.layers.0.0.bias, decode_head.pixel_decoder.encoder.layers.4.ffns.0.layers.1.weight, decode_head.pixel_decoder.encoder.layers.4.ffns.0.layers.1.bias, decode_head.pixel_decoder.encoder.layers.4.norms.0.weight, decode_head.pixel_decoder.encoder.layers.4.norms.0.bias, decode_head.pixel_decoder.encoder.layers.4.norms.1.weight, decode_head.pixel_decoder.encoder.layers.4.norms.1.bias, decode_head.pixel_decoder.encoder.layers.5.attentions.0.sampling_offsets.weight, decode_head.pixel_decoder.encoder.layers.5.attentions.0.sampling_offsets.bias, decode_head.pixel_decoder.encoder.layers.5.attentions.0.attention_weights.weight, decode_head.pixel_decoder.encoder.layers.5.attentions.0.attention_weights.bias, decode_head.pixel_decoder.encoder.layers.5.attentions.0.value_proj.weight, decode_head.pixel_decoder.encoder.layers.5.attentions.0.value_proj.bias, decode_head.pixel_decoder.encoder.layers.5.attentions.0.output_proj.weight, decode_head.pixel_decoder.encoder.layers.5.attentions.0.output_proj.bias, decode_head.pixel_decoder.encoder.layers.5.ffns.0.layers.0.0.weight, decode_head.pixel_decoder.encoder.layers.5.ffns.0.layers.0.0.bias, decode_head.pixel_decoder.encoder.layers.5.ffns.0.layers.1.weight, decode_head.pixel_decoder.encoder.layers.5.ffns.0.layers.1.bias, decode_head.pixel_decoder.encoder.layers.5.norms.0.weight, decode_head.pixel_decoder.encoder.layers.5.norms.0.bias, decode_head.pixel_decoder.encoder.layers.5.norms.1.weight, decode_head.pixel_decoder.encoder.layers.5.norms.1.bias, decode_head.pixel_decoder.level_encoding.weight, decode_head.pixel_decoder.lateral_convs.0.conv.weight, decode_head.pixel_decoder.lateral_convs.0.gn.weight, decode_head.pixel_decoder.lateral_convs.0.gn.bias, decode_head.pixel_decoder.output_convs.0.conv.weight, decode_head.pixel_decoder.output_convs.0.gn.weight, decode_head.pixel_decoder.output_convs.0.gn.bias, decode_head.pixel_decoder.mask_feature.weight, decode_head.pixel_decoder.mask_feature.bias, decode_head.transformer_decoder.layers.0.attentions.0.attn.in_proj_weight, decode_head.transformer_decoder.layers.0.attentions.0.attn.in_proj_bias, decode_head.transformer_decoder.layers.0.attentions.0.attn.out_proj.weight, decode_head.transformer_decoder.layers.0.attentions.0.attn.out_proj.bias, decode_head.transformer_decoder.layers.0.attentions.1.attn.in_proj_weight, decode_head.transformer_decoder.layers.0.attentions.1.attn.in_proj_bias, decode_head.transformer_decoder.layers.0.attentions.1.attn.out_proj.weight, decode_head.transformer_decoder.layers.0.attentions.1.attn.out_proj.bias, decode_head.transformer_decoder.layers.0.ffns.0.layers.0.0.weight, decode_head.transformer_decoder.layers.0.ffns.0.layers.0.0.bias, decode_head.transformer_decoder.layers.0.ffns.0.layers.1.weight, decode_head.transformer_decoder.layers.0.ffns.0.layers.1.bias, decode_head.transformer_decoder.layers.0.norms.0.weight, decode_head.transformer_decoder.layers.0.norms.0.bias, decode_head.transformer_decoder.layers.0.norms.1.weight, decode_head.transformer_decoder.layers.0.norms.1.bias, decode_head.transformer_decoder.layers.0.norms.2.weight, decode_head.transformer_decoder.layers.0.norms.2.bias, decode_head.transformer_decoder.layers.1.attentions.0.attn.in_proj_weight, decode_head.transformer_decoder.layers.1.attentions.0.attn.in_proj_bias, decode_head.transformer_decoder.layers.1.attentions.0.attn.out_proj.weight, decode_head.transformer_decoder.layers.1.attentions.0.attn.out_proj.bias, decode_head.transformer_decoder.layers.1.attentions.1.attn.in_proj_weight, decode_head.transformer_decoder.layers.1.attentions.1.attn.in_proj_bias, decode_head.transformer_decoder.layers.1.attentions.1.attn.out_proj.weight, decode_head.transformer_decoder.layers.1.attentions.1.attn.out_proj.bias, decode_head.transformer_decoder.layers.1.ffns.0.layers.0.0.weight, decode_head.transformer_decoder.layers.1.ffns.0.layers.0.0.bias, decode_head.transformer_decoder.layers.1.ffns.0.layers.1.weight, decode_head.transformer_decoder.layers.1.ffns.0.layers.1.bias, decode_head.transformer_decoder.layers.1.norms.0.weight, decode_head.transformer_decoder.layers.1.norms.0.bias, decode_head.transformer_decoder.layers.1.norms.1.weight, decode_head.transformer_decoder.layers.1.norms.1.bias, decode_head.transformer_decoder.layers.1.norms.2.weight, decode_head.transformer_decoder.layers.1.norms.2.bias, decode_head.transformer_decoder.layers.2.attentions.0.attn.in_proj_weight, decode_head.transformer_decoder.layers.2.attentions.0.attn.in_proj_bias, decode_head.transformer_decoder.layers.2.attentions.0.attn.out_proj.weight, decode_head.transformer_decoder.layers.2.attentions.0.attn.out_proj.bias, decode_head.transformer_decoder.layers.2.attentions.1.attn.in_proj_weight, decode_head.transformer_decoder.layers.2.attentions.1.attn.in_proj_bias, decode_head.transformer_decoder.layers.2.attentions.1.attn.out_proj.weight, decode_head.transformer_decoder.layers.2.attentions.1.attn.out_proj.bias, decode_head.transformer_decoder.layers.2.ffns.0.layers.0.0.weight, decode_head.transformer_decoder.layers.2.ffns.0.layers.0.0.bias, decode_head.transformer_decoder.layers.2.ffns.0.layers.1.weight, decode_head.transformer_decoder.layers.2.ffns.0.layers.1.bias, decode_head.transformer_decoder.layers.2.norms.0.weight, decode_head.transformer_decoder.layers.2.norms.0.bias, decode_head.transformer_decoder.layers.2.norms.1.weight, decode_head.transformer_decoder.layers.2.norms.1.bias, decode_head.transformer_decoder.layers.2.norms.2.weight, decode_head.transformer_decoder.layers.2.norms.2.bias, decode_head.transformer_decoder.layers.3.attentions.0.attn.in_proj_weight, decode_head.transformer_decoder.layers.3.attentions.0.attn.in_proj_bias, decode_head.transformer_decoder.layers.3.attentions.0.attn.out_proj.weight, decode_head.transformer_decoder.layers.3.attentions.0.attn.out_proj.bias, decode_head.transformer_decoder.layers.3.attentions.1.attn.in_proj_weight, decode_head.transformer_decoder.layers.3.attentions.1.attn.in_proj_bias, decode_head.transformer_decoder.layers.3.attentions.1.attn.out_proj.weight, decode_head.transformer_decoder.layers.3.attentions.1.attn.out_proj.bias, decode_head.transformer_decoder.layers.3.ffns.0.layers.0.0.weight, decode_head.transformer_decoder.layers.3.ffns.0.layers.0.0.bias, decode_head.transformer_decoder.layers.3.ffns.0.layers.1.weight, decode_head.transformer_decoder.layers.3.ffns.0.layers.1.bias, decode_head.transformer_decoder.layers.3.norms.0.weight, decode_head.transformer_decoder.layers.3.norms.0.bias, decode_head.transformer_decoder.layers.3.norms.1.weight, decode_head.transformer_decoder.layers.3.norms.1.bias, decode_head.transformer_decoder.layers.3.norms.2.weight, decode_head.transformer_decoder.layers.3.norms.2.bias, decode_head.transformer_decoder.layers.4.attentions.0.attn.in_proj_weight, decode_head.transformer_decoder.layers.4.attentions.0.attn.in_proj_bias, decode_head.transformer_decoder.layers.4.attentions.0.attn.out_proj.weight, decode_head.transformer_decoder.layers.4.attentions.0.attn.out_proj.bias, decode_head.transformer_decoder.layers.4.attentions.1.attn.in_proj_weight, decode_head.transformer_decoder.layers.4.attentions.1.attn.in_proj_bias, decode_head.transformer_decoder.layers.4.attentions.1.attn.out_proj.weight, decode_head.transformer_decoder.layers.4.attentions.1.attn.out_proj.bias, decode_head.transformer_decoder.layers.4.ffns.0.layers.0.0.weight, decode_head.transformer_decoder.layers.4.ffns.0.layers.0.0.bias, decode_head.transformer_decoder.layers.4.ffns.0.layers.1.weight, decode_head.transformer_decoder.layers.4.ffns.0.layers.1.bias, decode_head.transformer_decoder.layers.4.norms.0.weight, decode_head.transformer_decoder.layers.4.norms.0.bias, decode_head.transformer_decoder.layers.4.norms.1.weight, decode_head.transformer_decoder.layers.4.norms.1.bias, decode_head.transformer_decoder.layers.4.norms.2.weight, decode_head.transformer_decoder.layers.4.norms.2.bias, decode_head.transformer_decoder.layers.5.attentions.0.attn.in_proj_weight, decode_head.transformer_decoder.layers.5.attentions.0.attn.in_proj_bias, decode_head.transformer_decoder.layers.5.attentions.0.attn.out_proj.weight, decode_head.transformer_decoder.layers.5.attentions.0.attn.out_proj.bias, decode_head.transformer_decoder.layers.5.attentions.1.attn.in_proj_weight, decode_head.transformer_decoder.layers.5.attentions.1.attn.in_proj_bias, decode_head.transformer_decoder.layers.5.attentions.1.attn.out_proj.weight, decode_head.transformer_decoder.layers.5.attentions.1.attn.out_proj.bias, decode_head.transformer_decoder.layers.5.ffns.0.layers.0.0.weight, decode_head.transformer_decoder.layers.5.ffns.0.layers.0.0.bias, decode_head.transformer_decoder.layers.5.ffns.0.layers.1.weight, decode_head.transformer_decoder.layers.5.ffns.0.layers.1.bias, decode_head.transformer_decoder.layers.5.norms.0.weight, decode_head.transformer_decoder.layers.5.norms.0.bias, decode_head.transformer_decoder.layers.5.norms.1.weight, decode_head.transformer_decoder.layers.5.norms.1.bias, decode_head.transformer_decoder.layers.5.norms.2.weight, decode_head.transformer_decoder.layers.5.norms.2.bias, decode_head.transformer_decoder.layers.6.attentions.0.attn.in_proj_weight, decode_head.transformer_decoder.layers.6.attentions.0.attn.in_proj_bias, decode_head.transformer_decoder.layers.6.attentions.0.attn.out_proj.weight, decode_head.transformer_decoder.layers.6.attentions.0.attn.out_proj.bias, decode_head.transformer_decoder.layers.6.attentions.1.attn.in_proj_weight, decode_head.transformer_decoder.layers.6.attentions.1.attn.in_proj_bias, decode_head.transformer_decoder.layers.6.attentions.1.attn.out_proj.weight, decode_head.transformer_decoder.layers.6.attentions.1.attn.out_proj.bias, decode_head.transformer_decoder.layers.6.ffns.0.layers.0.0.weight, decode_head.transformer_decoder.layers.6.ffns.0.layers.0.0.bias, decode_head.transformer_decoder.layers.6.ffns.0.layers.1.weight, decode_head.transformer_decoder.layers.6.ffns.0.layers.1.bias, decode_head.transformer_decoder.layers.6.norms.0.weight, decode_head.transformer_decoder.layers.6.norms.0.bias, decode_head.transformer_decoder.layers.6.norms.1.weight, decode_head.transformer_decoder.layers.6.norms.1.bias, decode_head.transformer_decoder.layers.6.norms.2.weight, decode_head.transformer_decoder.layers.6.norms.2.bias, decode_head.transformer_decoder.layers.7.attentions.0.attn.in_proj_weight, decode_head.transformer_decoder.layers.7.attentions.0.attn.in_proj_bias, decode_head.transformer_decoder.layers.7.attentions.0.attn.out_proj.weight, decode_head.transformer_decoder.layers.7.attentions.0.attn.out_proj.bias, decode_head.transformer_decoder.layers.7.attentions.1.attn.in_proj_weight, decode_head.transformer_decoder.layers.7.attentions.1.attn.in_proj_bias, decode_head.transformer_decoder.layers.7.attentions.1.attn.out_proj.weight, decode_head.transformer_decoder.layers.7.attentions.1.attn.out_proj.bias, decode_head.transformer_decoder.layers.7.ffns.0.layers.0.0.weight, decode_head.transformer_decoder.layers.7.ffns.0.layers.0.0.bias, decode_head.transformer_decoder.layers.7.ffns.0.layers.1.weight, decode_head.transformer_decoder.layers.7.ffns.0.layers.1.bias, decode_head.transformer_decoder.layers.7.norms.0.weight, decode_head.transformer_decoder.layers.7.norms.0.bias, decode_head.transformer_decoder.layers.7.norms.1.weight, decode_head.transformer_decoder.layers.7.norms.1.bias, decode_head.transformer_decoder.layers.7.norms.2.weight, decode_head.transformer_decoder.layers.7.norms.2.bias, decode_head.transformer_decoder.layers.8.attentions.0.attn.in_proj_weight, decode_head.transformer_decoder.layers.8.attentions.0.attn.in_proj_bias, decode_head.transformer_decoder.layers.8.attentions.0.attn.out_proj.weight, decode_head.transformer_decoder.layers.8.attentions.0.attn.out_proj.bias, decode_head.transformer_decoder.layers.8.attentions.1.attn.in_proj_weight, decode_head.transformer_decoder.layers.8.attentions.1.attn.in_proj_bias, decode_head.transformer_decoder.layers.8.attentions.1.attn.out_proj.weight, decode_head.transformer_decoder.layers.8.attentions.1.attn.out_proj.bias, decode_head.transformer_decoder.layers.8.ffns.0.layers.0.0.weight, decode_head.transformer_decoder.layers.8.ffns.0.layers.0.0.bias, decode_head.transformer_decoder.layers.8.ffns.0.layers.1.weight, decode_head.transformer_decoder.layers.8.ffns.0.layers.1.bias, decode_head.transformer_decoder.layers.8.norms.0.weight, decode_head.transformer_decoder.layers.8.norms.0.bias, decode_head.transformer_decoder.layers.8.norms.1.weight, decode_head.transformer_decoder.layers.8.norms.1.bias, decode_head.transformer_decoder.layers.8.norms.2.weight, decode_head.transformer_decoder.layers.8.norms.2.bias, decode_head.transformer_decoder.post_norm.weight, decode_head.transformer_decoder.post_norm.bias, decode_head.query_embed.weight, decode_head.query_feat.weight, decode_head.level_embed.weight, decode_head.cls_embed.weight, decode_head.cls_embed.bias, decode_head.mask_embed.0.weight, decode_head.mask_embed.0.bias, decode_head.mask_embed.2.weight, decode_head.mask_embed.2.bias, decode_head.mask_embed.4.weight, decode_head.mask_embed.4.bias\n",
      "\n",
      "missing keys in source state_dict: cls_token, patch_embed.proj.weight, patch_embed.proj.bias, blocks.0.gamma_1, blocks.0.gamma_2, blocks.0.norm1.weight, blocks.0.norm1.bias, blocks.0.attn.q_bias, blocks.0.attn.v_bias, blocks.0.attn.relative_position_bias_table, blocks.0.attn.relative_position_index, blocks.0.attn.qkv.weight, blocks.0.attn.proj.weight, blocks.0.attn.proj.bias, blocks.0.norm2.weight, blocks.0.norm2.bias, blocks.0.mlp.fc1.weight, blocks.0.mlp.fc1.bias, blocks.0.mlp.fc2.weight, blocks.0.mlp.fc2.bias, blocks.1.gamma_1, blocks.1.gamma_2, blocks.1.norm1.weight, blocks.1.norm1.bias, blocks.1.attn.q_bias, blocks.1.attn.v_bias, blocks.1.attn.relative_position_bias_table, blocks.1.attn.relative_position_index, blocks.1.attn.qkv.weight, blocks.1.attn.proj.weight, blocks.1.attn.proj.bias, blocks.1.norm2.weight, blocks.1.norm2.bias, blocks.1.mlp.fc1.weight, blocks.1.mlp.fc1.bias, blocks.1.mlp.fc2.weight, blocks.1.mlp.fc2.bias, blocks.2.gamma_1, blocks.2.gamma_2, blocks.2.norm1.weight, blocks.2.norm1.bias, blocks.2.attn.q_bias, blocks.2.attn.v_bias, blocks.2.attn.relative_position_bias_table, blocks.2.attn.relative_position_index, blocks.2.attn.qkv.weight, blocks.2.attn.proj.weight, blocks.2.attn.proj.bias, blocks.2.norm2.weight, blocks.2.norm2.bias, blocks.2.mlp.fc1.weight, blocks.2.mlp.fc1.bias, blocks.2.mlp.fc2.weight, blocks.2.mlp.fc2.bias, blocks.3.gamma_1, blocks.3.gamma_2, blocks.3.norm1.weight, blocks.3.norm1.bias, blocks.3.attn.q_bias, blocks.3.attn.v_bias, blocks.3.attn.relative_position_bias_table, blocks.3.attn.relative_position_index, blocks.3.attn.qkv.weight, blocks.3.attn.proj.weight, blocks.3.attn.proj.bias, blocks.3.norm2.weight, blocks.3.norm2.bias, blocks.3.mlp.fc1.weight, blocks.3.mlp.fc1.bias, blocks.3.mlp.fc2.weight, blocks.3.mlp.fc2.bias, blocks.4.gamma_1, blocks.4.gamma_2, blocks.4.norm1.weight, blocks.4.norm1.bias, blocks.4.attn.q_bias, blocks.4.attn.v_bias, blocks.4.attn.relative_position_bias_table, blocks.4.attn.relative_position_index, blocks.4.attn.qkv.weight, blocks.4.attn.proj.weight, blocks.4.attn.proj.bias, blocks.4.norm2.weight, blocks.4.norm2.bias, blocks.4.mlp.fc1.weight, blocks.4.mlp.fc1.bias, blocks.4.mlp.fc2.weight, blocks.4.mlp.fc2.bias, blocks.5.gamma_1, blocks.5.gamma_2, blocks.5.norm1.weight, blocks.5.norm1.bias, blocks.5.attn.q_bias, blocks.5.attn.v_bias, blocks.5.attn.relative_position_bias_table, blocks.5.attn.relative_position_index, blocks.5.attn.qkv.weight, blocks.5.attn.proj.weight, blocks.5.attn.proj.bias, blocks.5.norm2.weight, blocks.5.norm2.bias, blocks.5.mlp.fc1.weight, blocks.5.mlp.fc1.bias, blocks.5.mlp.fc2.weight, blocks.5.mlp.fc2.bias, blocks.6.gamma_1, blocks.6.gamma_2, blocks.6.norm1.weight, blocks.6.norm1.bias, blocks.6.attn.q_bias, blocks.6.attn.v_bias, blocks.6.attn.relative_position_bias_table, blocks.6.attn.relative_position_index, blocks.6.attn.qkv.weight, blocks.6.attn.proj.weight, blocks.6.attn.proj.bias, blocks.6.norm2.weight, blocks.6.norm2.bias, blocks.6.mlp.fc1.weight, blocks.6.mlp.fc1.bias, blocks.6.mlp.fc2.weight, blocks.6.mlp.fc2.bias, blocks.7.gamma_1, blocks.7.gamma_2, blocks.7.norm1.weight, blocks.7.norm1.bias, blocks.7.attn.q_bias, blocks.7.attn.v_bias, blocks.7.attn.relative_position_bias_table, blocks.7.attn.relative_position_index, blocks.7.attn.qkv.weight, blocks.7.attn.proj.weight, blocks.7.attn.proj.bias, blocks.7.norm2.weight, blocks.7.norm2.bias, blocks.7.mlp.fc1.weight, blocks.7.mlp.fc1.bias, blocks.7.mlp.fc2.weight, blocks.7.mlp.fc2.bias, blocks.8.gamma_1, blocks.8.gamma_2, blocks.8.norm1.weight, blocks.8.norm1.bias, blocks.8.attn.q_bias, blocks.8.attn.v_bias, blocks.8.attn.relative_position_bias_table, blocks.8.attn.relative_position_index, blocks.8.attn.qkv.weight, blocks.8.attn.proj.weight, blocks.8.attn.proj.bias, blocks.8.norm2.weight, blocks.8.norm2.bias, blocks.8.mlp.fc1.weight, blocks.8.mlp.fc1.bias, blocks.8.mlp.fc2.weight, blocks.8.mlp.fc2.bias, blocks.9.gamma_1, blocks.9.gamma_2, blocks.9.norm1.weight, blocks.9.norm1.bias, blocks.9.attn.q_bias, blocks.9.attn.v_bias, blocks.9.attn.relative_position_bias_table, blocks.9.attn.relative_position_index, blocks.9.attn.qkv.weight, blocks.9.attn.proj.weight, blocks.9.attn.proj.bias, blocks.9.norm2.weight, blocks.9.norm2.bias, blocks.9.mlp.fc1.weight, blocks.9.mlp.fc1.bias, blocks.9.mlp.fc2.weight, blocks.9.mlp.fc2.bias, blocks.10.gamma_1, blocks.10.gamma_2, blocks.10.norm1.weight, blocks.10.norm1.bias, blocks.10.attn.q_bias, blocks.10.attn.v_bias, blocks.10.attn.relative_position_bias_table, blocks.10.attn.relative_position_index, blocks.10.attn.qkv.weight, blocks.10.attn.proj.weight, blocks.10.attn.proj.bias, blocks.10.norm2.weight, blocks.10.norm2.bias, blocks.10.mlp.fc1.weight, blocks.10.mlp.fc1.bias, blocks.10.mlp.fc2.weight, blocks.10.mlp.fc2.bias, blocks.11.gamma_1, blocks.11.gamma_2, blocks.11.norm1.weight, blocks.11.norm1.bias, blocks.11.attn.q_bias, blocks.11.attn.v_bias, blocks.11.attn.relative_position_bias_table, blocks.11.attn.relative_position_index, blocks.11.attn.qkv.weight, blocks.11.attn.proj.weight, blocks.11.attn.proj.bias, blocks.11.norm2.weight, blocks.11.norm2.bias, blocks.11.mlp.fc1.weight, blocks.11.mlp.fc1.bias, blocks.11.mlp.fc2.weight, blocks.11.mlp.fc2.bias, blocks.12.gamma_1, blocks.12.gamma_2, blocks.12.norm1.weight, blocks.12.norm1.bias, blocks.12.attn.q_bias, blocks.12.attn.v_bias, blocks.12.attn.relative_position_bias_table, blocks.12.attn.relative_position_index, blocks.12.attn.qkv.weight, blocks.12.attn.proj.weight, blocks.12.attn.proj.bias, blocks.12.norm2.weight, blocks.12.norm2.bias, blocks.12.mlp.fc1.weight, blocks.12.mlp.fc1.bias, blocks.12.mlp.fc2.weight, blocks.12.mlp.fc2.bias, blocks.13.gamma_1, blocks.13.gamma_2, blocks.13.norm1.weight, blocks.13.norm1.bias, blocks.13.attn.q_bias, blocks.13.attn.v_bias, blocks.13.attn.relative_position_bias_table, blocks.13.attn.relative_position_index, blocks.13.attn.qkv.weight, blocks.13.attn.proj.weight, blocks.13.attn.proj.bias, blocks.13.norm2.weight, blocks.13.norm2.bias, blocks.13.mlp.fc1.weight, blocks.13.mlp.fc1.bias, blocks.13.mlp.fc2.weight, blocks.13.mlp.fc2.bias, blocks.14.gamma_1, blocks.14.gamma_2, blocks.14.norm1.weight, blocks.14.norm1.bias, blocks.14.attn.q_bias, blocks.14.attn.v_bias, blocks.14.attn.relative_position_bias_table, blocks.14.attn.relative_position_index, blocks.14.attn.qkv.weight, blocks.14.attn.proj.weight, blocks.14.attn.proj.bias, blocks.14.norm2.weight, blocks.14.norm2.bias, blocks.14.mlp.fc1.weight, blocks.14.mlp.fc1.bias, blocks.14.mlp.fc2.weight, blocks.14.mlp.fc2.bias, blocks.15.gamma_1, blocks.15.gamma_2, blocks.15.norm1.weight, blocks.15.norm1.bias, blocks.15.attn.q_bias, blocks.15.attn.v_bias, blocks.15.attn.relative_position_bias_table, blocks.15.attn.relative_position_index, blocks.15.attn.qkv.weight, blocks.15.attn.proj.weight, blocks.15.attn.proj.bias, blocks.15.norm2.weight, blocks.15.norm2.bias, blocks.15.mlp.fc1.weight, blocks.15.mlp.fc1.bias, blocks.15.mlp.fc2.weight, blocks.15.mlp.fc2.bias, blocks.16.gamma_1, blocks.16.gamma_2, blocks.16.norm1.weight, blocks.16.norm1.bias, blocks.16.attn.q_bias, blocks.16.attn.v_bias, blocks.16.attn.relative_position_bias_table, blocks.16.attn.relative_position_index, blocks.16.attn.qkv.weight, blocks.16.attn.proj.weight, blocks.16.attn.proj.bias, blocks.16.norm2.weight, blocks.16.norm2.bias, blocks.16.mlp.fc1.weight, blocks.16.mlp.fc1.bias, blocks.16.mlp.fc2.weight, blocks.16.mlp.fc2.bias, blocks.17.gamma_1, blocks.17.gamma_2, blocks.17.norm1.weight, blocks.17.norm1.bias, blocks.17.attn.q_bias, blocks.17.attn.v_bias, blocks.17.attn.relative_position_bias_table, blocks.17.attn.relative_position_index, blocks.17.attn.qkv.weight, blocks.17.attn.proj.weight, blocks.17.attn.proj.bias, blocks.17.norm2.weight, blocks.17.norm2.bias, blocks.17.mlp.fc1.weight, blocks.17.mlp.fc1.bias, blocks.17.mlp.fc2.weight, blocks.17.mlp.fc2.bias, blocks.18.gamma_1, blocks.18.gamma_2, blocks.18.norm1.weight, blocks.18.norm1.bias, blocks.18.attn.q_bias, blocks.18.attn.v_bias, blocks.18.attn.relative_position_bias_table, blocks.18.attn.relative_position_index, blocks.18.attn.qkv.weight, blocks.18.attn.proj.weight, blocks.18.attn.proj.bias, blocks.18.norm2.weight, blocks.18.norm2.bias, blocks.18.mlp.fc1.weight, blocks.18.mlp.fc1.bias, blocks.18.mlp.fc2.weight, blocks.18.mlp.fc2.bias, blocks.19.gamma_1, blocks.19.gamma_2, blocks.19.norm1.weight, blocks.19.norm1.bias, blocks.19.attn.q_bias, blocks.19.attn.v_bias, blocks.19.attn.relative_position_bias_table, blocks.19.attn.relative_position_index, blocks.19.attn.qkv.weight, blocks.19.attn.proj.weight, blocks.19.attn.proj.bias, blocks.19.norm2.weight, blocks.19.norm2.bias, blocks.19.mlp.fc1.weight, blocks.19.mlp.fc1.bias, blocks.19.mlp.fc2.weight, blocks.19.mlp.fc2.bias, blocks.20.gamma_1, blocks.20.gamma_2, blocks.20.norm1.weight, blocks.20.norm1.bias, blocks.20.attn.q_bias, blocks.20.attn.v_bias, blocks.20.attn.relative_position_bias_table, blocks.20.attn.relative_position_index, blocks.20.attn.qkv.weight, blocks.20.attn.proj.weight, blocks.20.attn.proj.bias, blocks.20.norm2.weight, blocks.20.norm2.bias, blocks.20.mlp.fc1.weight, blocks.20.mlp.fc1.bias, blocks.20.mlp.fc2.weight, blocks.20.mlp.fc2.bias, blocks.21.gamma_1, blocks.21.gamma_2, blocks.21.norm1.weight, blocks.21.norm1.bias, blocks.21.attn.q_bias, blocks.21.attn.v_bias, blocks.21.attn.relative_position_bias_table, blocks.21.attn.relative_position_index, blocks.21.attn.qkv.weight, blocks.21.attn.proj.weight, blocks.21.attn.proj.bias, blocks.21.norm2.weight, blocks.21.norm2.bias, blocks.21.mlp.fc1.weight, blocks.21.mlp.fc1.bias, blocks.21.mlp.fc2.weight, blocks.21.mlp.fc2.bias, blocks.22.gamma_1, blocks.22.gamma_2, blocks.22.norm1.weight, blocks.22.norm1.bias, blocks.22.attn.q_bias, blocks.22.attn.v_bias, blocks.22.attn.relative_position_bias_table, blocks.22.attn.relative_position_index, blocks.22.attn.qkv.weight, blocks.22.attn.proj.weight, blocks.22.attn.proj.bias, blocks.22.norm2.weight, blocks.22.norm2.bias, blocks.22.mlp.fc1.weight, blocks.22.mlp.fc1.bias, blocks.22.mlp.fc2.weight, blocks.22.mlp.fc2.bias, blocks.23.gamma_1, blocks.23.gamma_2, blocks.23.norm1.weight, blocks.23.norm1.bias, blocks.23.attn.q_bias, blocks.23.attn.v_bias, blocks.23.attn.relative_position_bias_table, blocks.23.attn.relative_position_index, blocks.23.attn.qkv.weight, blocks.23.attn.proj.weight, blocks.23.attn.proj.bias, blocks.23.norm2.weight, blocks.23.norm2.bias, blocks.23.mlp.fc1.weight, blocks.23.mlp.fc1.bias, blocks.23.mlp.fc2.weight, blocks.23.mlp.fc2.bias\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/ViT-Adapter/segmentation/mmseg_custom/models/losses/cross_entropy_loss.py:231: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n",
      "  'Default ``avg_non_ignore`` is False, if you would like to '\n",
      "/workspace/ViT-Adapter/segmentation/mmseg_custom/models/losses/cross_entropy_loss.py:231: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n",
      "  'Default ``avg_non_ignore`` is False, if you would like to '\n",
      "/workspace/ViT-Adapter/segmentation/mmseg_custom/models/losses/cross_entropy_loss.py:231: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n",
      "  'Default ``avg_non_ignore`` is False, if you would like to '\n",
      "/workspace/ViT-Adapter/segmentation/mmseg_custom/models/losses/cross_entropy_loss.py:231: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n",
      "  'Default ``avg_non_ignore`` is False, if you would like to '\n",
      "2024-02-14 13:32:23,668 - mmseg - INFO - EncoderDecoderMask2Former(\n",
      "  (backbone): BEiTAdapter(\n",
      "    (patch_embed): PatchEmbed(\n",
      "      (proj): Conv2d(3, 1024, kernel_size=(16, 16), stride=(16, 16))\n",
      "    )\n",
      "    (pos_drop): Dropout(p=0.0, inplace=False)\n",
      "    (blocks): ModuleList(\n",
      "      (0): Block(\n",
      "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=1024, out_features=3072, bias=False)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (act): GELU()\n",
      "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (1): Block(\n",
      "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=1024, out_features=3072, bias=False)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (drop_path): DropPath(p=0.013043479062616825)\n",
      "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (act): GELU()\n",
      "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (2): Block(\n",
      "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=1024, out_features=3072, bias=False)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (drop_path): DropPath(p=0.02608695812523365)\n",
      "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (act): GELU()\n",
      "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (3): Block(\n",
      "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=1024, out_features=3072, bias=False)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (drop_path): DropPath(p=0.03913043811917305)\n",
      "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (act): GELU()\n",
      "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (4): Block(\n",
      "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=1024, out_features=3072, bias=False)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (drop_path): DropPath(p=0.0521739162504673)\n",
      "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (act): GELU()\n",
      "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (5): Block(\n",
      "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=1024, out_features=3072, bias=False)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (drop_path): DropPath(p=0.06521739810705185)\n",
      "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (act): GELU()\n",
      "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (6): Block(\n",
      "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=1024, out_features=3072, bias=False)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (drop_path): DropPath(p=0.0782608762383461)\n",
      "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (act): GELU()\n",
      "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (7): Block(\n",
      "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=1024, out_features=3072, bias=False)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (drop_path): DropPath(p=0.09130435436964035)\n",
      "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (act): GELU()\n",
      "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (8): Block(\n",
      "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=1024, out_features=3072, bias=False)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (drop_path): DropPath(p=0.1043478325009346)\n",
      "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (act): GELU()\n",
      "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (9): Block(\n",
      "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=1024, out_features=3072, bias=False)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (drop_path): DropPath(p=0.11739131063222885)\n",
      "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (act): GELU()\n",
      "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (10): Block(\n",
      "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=1024, out_features=3072, bias=False)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (drop_path): DropPath(p=0.1304347962141037)\n",
      "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (act): GELU()\n",
      "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (11): Block(\n",
      "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=1024, out_features=3072, bias=False)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (drop_path): DropPath(p=0.14347827434539795)\n",
      "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (act): GELU()\n",
      "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (12): Block(\n",
      "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=1024, out_features=3072, bias=False)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (drop_path): DropPath(p=0.1565217524766922)\n",
      "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (act): GELU()\n",
      "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (13): Block(\n",
      "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=1024, out_features=3072, bias=False)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (drop_path): DropPath(p=0.16956523060798645)\n",
      "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (act): GELU()\n",
      "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (14): Block(\n",
      "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=1024, out_features=3072, bias=False)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (drop_path): DropPath(p=0.1826087087392807)\n",
      "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (act): GELU()\n",
      "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (15): Block(\n",
      "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=1024, out_features=3072, bias=False)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (drop_path): DropPath(p=0.19565218687057495)\n",
      "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (act): GELU()\n",
      "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (16): Block(\n",
      "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=1024, out_features=3072, bias=False)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (drop_path): DropPath(p=0.2086956650018692)\n",
      "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (act): GELU()\n",
      "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (17): Block(\n",
      "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=1024, out_features=3072, bias=False)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (drop_path): DropPath(p=0.22173914313316345)\n",
      "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (act): GELU()\n",
      "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (18): Block(\n",
      "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=1024, out_features=3072, bias=False)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (drop_path): DropPath(p=0.2347826212644577)\n",
      "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (act): GELU()\n",
      "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (19): Block(\n",
      "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=1024, out_features=3072, bias=False)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (drop_path): DropPath(p=0.24782609939575195)\n",
      "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (act): GELU()\n",
      "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (20): Block(\n",
      "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=1024, out_features=3072, bias=False)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (drop_path): DropPath(p=0.260869562625885)\n",
      "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (act): GELU()\n",
      "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (21): Block(\n",
      "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=1024, out_features=3072, bias=False)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (drop_path): DropPath(p=0.27391305565834045)\n",
      "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (act): GELU()\n",
      "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (22): Block(\n",
      "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=1024, out_features=3072, bias=False)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (drop_path): DropPath(p=0.2869565188884735)\n",
      "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (act): GELU()\n",
      "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (23): Block(\n",
      "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=1024, out_features=3072, bias=False)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (drop_path): DropPath(p=0.30000001192092896)\n",
      "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (act): GELU()\n",
      "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (spm): SpatialPriorModule(\n",
      "      (stem): Sequential(\n",
      "        (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (4): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): ReLU(inplace=True)\n",
      "        (6): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (7): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (8): ReLU(inplace=True)\n",
      "        (9): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "      )\n",
      "      (conv2): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "      )\n",
      "      (conv3): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "      )\n",
      "      (conv4): Sequential(\n",
      "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "      )\n",
      "      (fc1): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (fc2): Conv2d(128, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (fc3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (fc4): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (interactions): Sequential(\n",
      "      (0): InteractionBlockWithCls(\n",
      "        (injector): Injector(\n",
      "          (query_norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "          (feat_norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "          (attn): MSDeformAttn(\n",
      "            (sampling_offsets): Linear(in_features=1024, out_features=384, bias=True)\n",
      "            (attention_weights): Linear(in_features=1024, out_features=192, bias=True)\n",
      "            (value_proj): Linear(in_features=1024, out_features=512, bias=True)\n",
      "            (output_proj): Linear(in_features=512, out_features=1024, bias=True)\n",
      "          )\n",
      "        )\n",
      "        (extractor): Extractor(\n",
      "          (query_norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "          (feat_norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "          (attn): MSDeformAttn(\n",
      "            (sampling_offsets): Linear(in_features=1024, out_features=128, bias=True)\n",
      "            (attention_weights): Linear(in_features=1024, out_features=64, bias=True)\n",
      "            (value_proj): Linear(in_features=1024, out_features=512, bias=True)\n",
      "            (output_proj): Linear(in_features=512, out_features=1024, bias=True)\n",
      "          )\n",
      "          (ffn): ConvFFN(\n",
      "            (fc1): Linear(in_features=1024, out_features=256, bias=True)\n",
      "            (dwconv): DWConv(\n",
      "              (dwconv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
      "            )\n",
      "            (act): GELU()\n",
      "            (fc2): Linear(in_features=256, out_features=1024, bias=True)\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ffn_norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "          (drop_path): DropPath()\n",
      "        )\n",
      "      )\n",
      "      (1): InteractionBlockWithCls(\n",
      "        (injector): Injector(\n",
      "          (query_norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "          (feat_norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "          (attn): MSDeformAttn(\n",
      "            (sampling_offsets): Linear(in_features=1024, out_features=384, bias=True)\n",
      "            (attention_weights): Linear(in_features=1024, out_features=192, bias=True)\n",
      "            (value_proj): Linear(in_features=1024, out_features=512, bias=True)\n",
      "            (output_proj): Linear(in_features=512, out_features=1024, bias=True)\n",
      "          )\n",
      "        )\n",
      "        (extractor): Extractor(\n",
      "          (query_norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "          (feat_norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "          (attn): MSDeformAttn(\n",
      "            (sampling_offsets): Linear(in_features=1024, out_features=128, bias=True)\n",
      "            (attention_weights): Linear(in_features=1024, out_features=64, bias=True)\n",
      "            (value_proj): Linear(in_features=1024, out_features=512, bias=True)\n",
      "            (output_proj): Linear(in_features=512, out_features=1024, bias=True)\n",
      "          )\n",
      "          (ffn): ConvFFN(\n",
      "            (fc1): Linear(in_features=1024, out_features=256, bias=True)\n",
      "            (dwconv): DWConv(\n",
      "              (dwconv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
      "            )\n",
      "            (act): GELU()\n",
      "            (fc2): Linear(in_features=256, out_features=1024, bias=True)\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ffn_norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "          (drop_path): DropPath()\n",
      "        )\n",
      "      )\n",
      "      (2): InteractionBlockWithCls(\n",
      "        (injector): Injector(\n",
      "          (query_norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "          (feat_norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "          (attn): MSDeformAttn(\n",
      "            (sampling_offsets): Linear(in_features=1024, out_features=384, bias=True)\n",
      "            (attention_weights): Linear(in_features=1024, out_features=192, bias=True)\n",
      "            (value_proj): Linear(in_features=1024, out_features=512, bias=True)\n",
      "            (output_proj): Linear(in_features=512, out_features=1024, bias=True)\n",
      "          )\n",
      "        )\n",
      "        (extractor): Extractor(\n",
      "          (query_norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "          (feat_norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "          (attn): MSDeformAttn(\n",
      "            (sampling_offsets): Linear(in_features=1024, out_features=128, bias=True)\n",
      "            (attention_weights): Linear(in_features=1024, out_features=64, bias=True)\n",
      "            (value_proj): Linear(in_features=1024, out_features=512, bias=True)\n",
      "            (output_proj): Linear(in_features=512, out_features=1024, bias=True)\n",
      "          )\n",
      "          (ffn): ConvFFN(\n",
      "            (fc1): Linear(in_features=1024, out_features=256, bias=True)\n",
      "            (dwconv): DWConv(\n",
      "              (dwconv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
      "            )\n",
      "            (act): GELU()\n",
      "            (fc2): Linear(in_features=256, out_features=1024, bias=True)\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ffn_norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "          (drop_path): DropPath()\n",
      "        )\n",
      "      )\n",
      "      (3): InteractionBlockWithCls(\n",
      "        (injector): Injector(\n",
      "          (query_norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "          (feat_norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "          (attn): MSDeformAttn(\n",
      "            (sampling_offsets): Linear(in_features=1024, out_features=384, bias=True)\n",
      "            (attention_weights): Linear(in_features=1024, out_features=192, bias=True)\n",
      "            (value_proj): Linear(in_features=1024, out_features=512, bias=True)\n",
      "            (output_proj): Linear(in_features=512, out_features=1024, bias=True)\n",
      "          )\n",
      "        )\n",
      "        (extractor): Extractor(\n",
      "          (query_norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "          (feat_norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "          (attn): MSDeformAttn(\n",
      "            (sampling_offsets): Linear(in_features=1024, out_features=128, bias=True)\n",
      "            (attention_weights): Linear(in_features=1024, out_features=64, bias=True)\n",
      "            (value_proj): Linear(in_features=1024, out_features=512, bias=True)\n",
      "            (output_proj): Linear(in_features=512, out_features=1024, bias=True)\n",
      "          )\n",
      "          (ffn): ConvFFN(\n",
      "            (fc1): Linear(in_features=1024, out_features=256, bias=True)\n",
      "            (dwconv): DWConv(\n",
      "              (dwconv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
      "            )\n",
      "            (act): GELU()\n",
      "            (fc2): Linear(in_features=256, out_features=1024, bias=True)\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ffn_norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "          (drop_path): DropPath()\n",
      "        )\n",
      "        (extra_extractors): Sequential(\n",
      "          (0): Extractor(\n",
      "            (query_norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "            (feat_norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "            (attn): MSDeformAttn(\n",
      "              (sampling_offsets): Linear(in_features=1024, out_features=128, bias=True)\n",
      "              (attention_weights): Linear(in_features=1024, out_features=64, bias=True)\n",
      "              (value_proj): Linear(in_features=1024, out_features=512, bias=True)\n",
      "              (output_proj): Linear(in_features=512, out_features=1024, bias=True)\n",
      "            )\n",
      "            (ffn): ConvFFN(\n",
      "              (fc1): Linear(in_features=1024, out_features=256, bias=True)\n",
      "              (dwconv): DWConv(\n",
      "                (dwconv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
      "              )\n",
      "              (act): GELU()\n",
      "              (fc2): Linear(in_features=256, out_features=1024, bias=True)\n",
      "              (drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (ffn_norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "            (drop_path): DropPath()\n",
      "          )\n",
      "          (1): Extractor(\n",
      "            (query_norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "            (feat_norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "            (attn): MSDeformAttn(\n",
      "              (sampling_offsets): Linear(in_features=1024, out_features=128, bias=True)\n",
      "              (attention_weights): Linear(in_features=1024, out_features=64, bias=True)\n",
      "              (value_proj): Linear(in_features=1024, out_features=512, bias=True)\n",
      "              (output_proj): Linear(in_features=512, out_features=1024, bias=True)\n",
      "            )\n",
      "            (ffn): ConvFFN(\n",
      "              (fc1): Linear(in_features=1024, out_features=256, bias=True)\n",
      "              (dwconv): DWConv(\n",
      "                (dwconv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
      "              )\n",
      "              (act): GELU()\n",
      "              (fc2): Linear(in_features=256, out_features=1024, bias=True)\n",
      "              (drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (ffn_norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "            (drop_path): DropPath()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (up): ConvTranspose2d(1024, 1024, kernel_size=(2, 2), stride=(2, 2))\n",
      "    (norm1): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (norm2): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (norm3): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (norm4): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (decode_head): Mask2FormerHead(\n",
      "    input_transform=multiple_select, ignore_index=255, align_corners=False\n",
      "    (loss_decode): CrossEntropyLoss(avg_non_ignore=False)\n",
      "    (conv_seg): None\n",
      "    (dropout): Dropout2d(p=0.1, inplace=False)\n",
      "    (pixel_decoder): MSDeformAttnPixelDecoder(\n",
      "      (input_convs): ModuleList(\n",
      "        (0): ConvModule(\n",
      "          (conv): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (gn): GroupNorm(32, 1024, eps=1e-05, affine=True)\n",
      "        )\n",
      "        (1): ConvModule(\n",
      "          (conv): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (gn): GroupNorm(32, 1024, eps=1e-05, affine=True)\n",
      "        )\n",
      "        (2): ConvModule(\n",
      "          (conv): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (gn): GroupNorm(32, 1024, eps=1e-05, affine=True)\n",
      "        )\n",
      "      )\n",
      "      (encoder): DetrTransformerEncoder(\n",
      "        (layers): ModuleList(\n",
      "          (0): BaseTransformerLayer(\n",
      "            (attentions): ModuleList(\n",
      "              (0): MultiScaleDeformableAttention(\n",
      "                (dropout): Dropout(p=0.0, inplace=False)\n",
      "                (sampling_offsets): Linear(in_features=1024, out_features=768, bias=True)\n",
      "                (attention_weights): Linear(in_features=1024, out_features=384, bias=True)\n",
      "                (value_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                (output_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              )\n",
      "            )\n",
      "            (ffns): ModuleList(\n",
      "              (0): FFN(\n",
      "                (activate): ReLU(inplace=True)\n",
      "                (layers): Sequential(\n",
      "                  (0): Sequential(\n",
      "                    (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "                    (1): ReLU(inplace=True)\n",
      "                    (2): Dropout(p=0.0, inplace=False)\n",
      "                  )\n",
      "                  (1): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "                  (2): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "                (dropout_layer): Identity()\n",
      "              )\n",
      "            )\n",
      "            (norms): ModuleList(\n",
      "              (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "              (1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            )\n",
      "          )\n",
      "          (1): BaseTransformerLayer(\n",
      "            (attentions): ModuleList(\n",
      "              (0): MultiScaleDeformableAttention(\n",
      "                (dropout): Dropout(p=0.0, inplace=False)\n",
      "                (sampling_offsets): Linear(in_features=1024, out_features=768, bias=True)\n",
      "                (attention_weights): Linear(in_features=1024, out_features=384, bias=True)\n",
      "                (value_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                (output_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              )\n",
      "            )\n",
      "            (ffns): ModuleList(\n",
      "              (0): FFN(\n",
      "                (activate): ReLU(inplace=True)\n",
      "                (layers): Sequential(\n",
      "                  (0): Sequential(\n",
      "                    (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "                    (1): ReLU(inplace=True)\n",
      "                    (2): Dropout(p=0.0, inplace=False)\n",
      "                  )\n",
      "                  (1): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "                  (2): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "                (dropout_layer): Identity()\n",
      "              )\n",
      "            )\n",
      "            (norms): ModuleList(\n",
      "              (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "              (1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            )\n",
      "          )\n",
      "          (2): BaseTransformerLayer(\n",
      "            (attentions): ModuleList(\n",
      "              (0): MultiScaleDeformableAttention(\n",
      "                (dropout): Dropout(p=0.0, inplace=False)\n",
      "                (sampling_offsets): Linear(in_features=1024, out_features=768, bias=True)\n",
      "                (attention_weights): Linear(in_features=1024, out_features=384, bias=True)\n",
      "                (value_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                (output_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              )\n",
      "            )\n",
      "            (ffns): ModuleList(\n",
      "              (0): FFN(\n",
      "                (activate): ReLU(inplace=True)\n",
      "                (layers): Sequential(\n",
      "                  (0): Sequential(\n",
      "                    (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "                    (1): ReLU(inplace=True)\n",
      "                    (2): Dropout(p=0.0, inplace=False)\n",
      "                  )\n",
      "                  (1): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "                  (2): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "                (dropout_layer): Identity()\n",
      "              )\n",
      "            )\n",
      "            (norms): ModuleList(\n",
      "              (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "              (1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            )\n",
      "          )\n",
      "          (3): BaseTransformerLayer(\n",
      "            (attentions): ModuleList(\n",
      "              (0): MultiScaleDeformableAttention(\n",
      "                (dropout): Dropout(p=0.0, inplace=False)\n",
      "                (sampling_offsets): Linear(in_features=1024, out_features=768, bias=True)\n",
      "                (attention_weights): Linear(in_features=1024, out_features=384, bias=True)\n",
      "                (value_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                (output_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              )\n",
      "            )\n",
      "            (ffns): ModuleList(\n",
      "              (0): FFN(\n",
      "                (activate): ReLU(inplace=True)\n",
      "                (layers): Sequential(\n",
      "                  (0): Sequential(\n",
      "                    (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "                    (1): ReLU(inplace=True)\n",
      "                    (2): Dropout(p=0.0, inplace=False)\n",
      "                  )\n",
      "                  (1): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "                  (2): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "                (dropout_layer): Identity()\n",
      "              )\n",
      "            )\n",
      "            (norms): ModuleList(\n",
      "              (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "              (1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            )\n",
      "          )\n",
      "          (4): BaseTransformerLayer(\n",
      "            (attentions): ModuleList(\n",
      "              (0): MultiScaleDeformableAttention(\n",
      "                (dropout): Dropout(p=0.0, inplace=False)\n",
      "                (sampling_offsets): Linear(in_features=1024, out_features=768, bias=True)\n",
      "                (attention_weights): Linear(in_features=1024, out_features=384, bias=True)\n",
      "                (value_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                (output_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              )\n",
      "            )\n",
      "            (ffns): ModuleList(\n",
      "              (0): FFN(\n",
      "                (activate): ReLU(inplace=True)\n",
      "                (layers): Sequential(\n",
      "                  (0): Sequential(\n",
      "                    (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "                    (1): ReLU(inplace=True)\n",
      "                    (2): Dropout(p=0.0, inplace=False)\n",
      "                  )\n",
      "                  (1): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "                  (2): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "                (dropout_layer): Identity()\n",
      "              )\n",
      "            )\n",
      "            (norms): ModuleList(\n",
      "              (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "              (1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            )\n",
      "          )\n",
      "          (5): BaseTransformerLayer(\n",
      "            (attentions): ModuleList(\n",
      "              (0): MultiScaleDeformableAttention(\n",
      "                (dropout): Dropout(p=0.0, inplace=False)\n",
      "                (sampling_offsets): Linear(in_features=1024, out_features=768, bias=True)\n",
      "                (attention_weights): Linear(in_features=1024, out_features=384, bias=True)\n",
      "                (value_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                (output_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              )\n",
      "            )\n",
      "            (ffns): ModuleList(\n",
      "              (0): FFN(\n",
      "                (activate): ReLU(inplace=True)\n",
      "                (layers): Sequential(\n",
      "                  (0): Sequential(\n",
      "                    (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "                    (1): ReLU(inplace=True)\n",
      "                    (2): Dropout(p=0.0, inplace=False)\n",
      "                  )\n",
      "                  (1): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "                  (2): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "                (dropout_layer): Identity()\n",
      "              )\n",
      "            )\n",
      "            (norms): ModuleList(\n",
      "              (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "              (1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (postional_encoding): SinePositionalEncoding(num_feats=512, temperature=10000, normalize=True, scale=6.283185307179586, eps=1e-06)\n",
      "      (level_encoding): Embedding(3, 1024)\n",
      "      (lateral_convs): ModuleList(\n",
      "        (0): ConvModule(\n",
      "          (conv): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (gn): GroupNorm(32, 1024, eps=1e-05, affine=True)\n",
      "        )\n",
      "      )\n",
      "      (output_convs): ModuleList(\n",
      "        (0): ConvModule(\n",
      "          (conv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (gn): GroupNorm(32, 1024, eps=1e-05, affine=True)\n",
      "          (activate): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (mask_feature): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (transformer_decoder): DetrTransformerDecoder(\n",
      "      (layers): ModuleList(\n",
      "        (0): DetrTransformerDecoderLayer(\n",
      "          (attentions): ModuleList(\n",
      "            (0): MultiheadAttention(\n",
      "              (attn): MultiheadAttention(\n",
      "                (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
      "              )\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (dropout_layer): Identity()\n",
      "            )\n",
      "            (1): MultiheadAttention(\n",
      "              (attn): MultiheadAttention(\n",
      "                (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
      "              )\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (dropout_layer): Identity()\n",
      "            )\n",
      "          )\n",
      "          (ffns): ModuleList(\n",
      "            (0): FFN(\n",
      "              (activate): ReLU(inplace=True)\n",
      "              (layers): Sequential(\n",
      "                (0): Sequential(\n",
      "                  (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "                  (1): ReLU(inplace=True)\n",
      "                  (2): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "                (1): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "                (2): Dropout(p=0.0, inplace=False)\n",
      "              )\n",
      "              (dropout_layer): Identity()\n",
      "            )\n",
      "          )\n",
      "          (norms): ModuleList(\n",
      "            (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "        )\n",
      "        (1): DetrTransformerDecoderLayer(\n",
      "          (attentions): ModuleList(\n",
      "            (0): MultiheadAttention(\n",
      "              (attn): MultiheadAttention(\n",
      "                (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
      "              )\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (dropout_layer): Identity()\n",
      "            )\n",
      "            (1): MultiheadAttention(\n",
      "              (attn): MultiheadAttention(\n",
      "                (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
      "              )\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (dropout_layer): Identity()\n",
      "            )\n",
      "          )\n",
      "          (ffns): ModuleList(\n",
      "            (0): FFN(\n",
      "              (activate): ReLU(inplace=True)\n",
      "              (layers): Sequential(\n",
      "                (0): Sequential(\n",
      "                  (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "                  (1): ReLU(inplace=True)\n",
      "                  (2): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "                (1): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "                (2): Dropout(p=0.0, inplace=False)\n",
      "              )\n",
      "              (dropout_layer): Identity()\n",
      "            )\n",
      "          )\n",
      "          (norms): ModuleList(\n",
      "            (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "        )\n",
      "        (2): DetrTransformerDecoderLayer(\n",
      "          (attentions): ModuleList(\n",
      "            (0): MultiheadAttention(\n",
      "              (attn): MultiheadAttention(\n",
      "                (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
      "              )\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (dropout_layer): Identity()\n",
      "            )\n",
      "            (1): MultiheadAttention(\n",
      "              (attn): MultiheadAttention(\n",
      "                (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
      "              )\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (dropout_layer): Identity()\n",
      "            )\n",
      "          )\n",
      "          (ffns): ModuleList(\n",
      "            (0): FFN(\n",
      "              (activate): ReLU(inplace=True)\n",
      "              (layers): Sequential(\n",
      "                (0): Sequential(\n",
      "                  (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "                  (1): ReLU(inplace=True)\n",
      "                  (2): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "                (1): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "                (2): Dropout(p=0.0, inplace=False)\n",
      "              )\n",
      "              (dropout_layer): Identity()\n",
      "            )\n",
      "          )\n",
      "          (norms): ModuleList(\n",
      "            (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "        )\n",
      "        (3): DetrTransformerDecoderLayer(\n",
      "          (attentions): ModuleList(\n",
      "            (0): MultiheadAttention(\n",
      "              (attn): MultiheadAttention(\n",
      "                (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
      "              )\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (dropout_layer): Identity()\n",
      "            )\n",
      "            (1): MultiheadAttention(\n",
      "              (attn): MultiheadAttention(\n",
      "                (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
      "              )\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (dropout_layer): Identity()\n",
      "            )\n",
      "          )\n",
      "          (ffns): ModuleList(\n",
      "            (0): FFN(\n",
      "              (activate): ReLU(inplace=True)\n",
      "              (layers): Sequential(\n",
      "                (0): Sequential(\n",
      "                  (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "                  (1): ReLU(inplace=True)\n",
      "                  (2): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "                (1): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "                (2): Dropout(p=0.0, inplace=False)\n",
      "              )\n",
      "              (dropout_layer): Identity()\n",
      "            )\n",
      "          )\n",
      "          (norms): ModuleList(\n",
      "            (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "        )\n",
      "        (4): DetrTransformerDecoderLayer(\n",
      "          (attentions): ModuleList(\n",
      "            (0): MultiheadAttention(\n",
      "              (attn): MultiheadAttention(\n",
      "                (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
      "              )\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (dropout_layer): Identity()\n",
      "            )\n",
      "            (1): MultiheadAttention(\n",
      "              (attn): MultiheadAttention(\n",
      "                (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
      "              )\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (dropout_layer): Identity()\n",
      "            )\n",
      "          )\n",
      "          (ffns): ModuleList(\n",
      "            (0): FFN(\n",
      "              (activate): ReLU(inplace=True)\n",
      "              (layers): Sequential(\n",
      "                (0): Sequential(\n",
      "                  (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "                  (1): ReLU(inplace=True)\n",
      "                  (2): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "                (1): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "                (2): Dropout(p=0.0, inplace=False)\n",
      "              )\n",
      "              (dropout_layer): Identity()\n",
      "            )\n",
      "          )\n",
      "          (norms): ModuleList(\n",
      "            (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "        )\n",
      "        (5): DetrTransformerDecoderLayer(\n",
      "          (attentions): ModuleList(\n",
      "            (0): MultiheadAttention(\n",
      "              (attn): MultiheadAttention(\n",
      "                (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
      "              )\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (dropout_layer): Identity()\n",
      "            )\n",
      "            (1): MultiheadAttention(\n",
      "              (attn): MultiheadAttention(\n",
      "                (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
      "              )\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (dropout_layer): Identity()\n",
      "            )\n",
      "          )\n",
      "          (ffns): ModuleList(\n",
      "            (0): FFN(\n",
      "              (activate): ReLU(inplace=True)\n",
      "              (layers): Sequential(\n",
      "                (0): Sequential(\n",
      "                  (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "                  (1): ReLU(inplace=True)\n",
      "                  (2): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "                (1): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "                (2): Dropout(p=0.0, inplace=False)\n",
      "              )\n",
      "              (dropout_layer): Identity()\n",
      "            )\n",
      "          )\n",
      "          (norms): ModuleList(\n",
      "            (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "        )\n",
      "        (6): DetrTransformerDecoderLayer(\n",
      "          (attentions): ModuleList(\n",
      "            (0): MultiheadAttention(\n",
      "              (attn): MultiheadAttention(\n",
      "                (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
      "              )\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (dropout_layer): Identity()\n",
      "            )\n",
      "            (1): MultiheadAttention(\n",
      "              (attn): MultiheadAttention(\n",
      "                (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
      "              )\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (dropout_layer): Identity()\n",
      "            )\n",
      "          )\n",
      "          (ffns): ModuleList(\n",
      "            (0): FFN(\n",
      "              (activate): ReLU(inplace=True)\n",
      "              (layers): Sequential(\n",
      "                (0): Sequential(\n",
      "                  (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "                  (1): ReLU(inplace=True)\n",
      "                  (2): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "                (1): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "                (2): Dropout(p=0.0, inplace=False)\n",
      "              )\n",
      "              (dropout_layer): Identity()\n",
      "            )\n",
      "          )\n",
      "          (norms): ModuleList(\n",
      "            (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "        )\n",
      "        (7): DetrTransformerDecoderLayer(\n",
      "          (attentions): ModuleList(\n",
      "            (0): MultiheadAttention(\n",
      "              (attn): MultiheadAttention(\n",
      "                (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
      "              )\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (dropout_layer): Identity()\n",
      "            )\n",
      "            (1): MultiheadAttention(\n",
      "              (attn): MultiheadAttention(\n",
      "                (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
      "              )\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (dropout_layer): Identity()\n",
      "            )\n",
      "          )\n",
      "          (ffns): ModuleList(\n",
      "            (0): FFN(\n",
      "              (activate): ReLU(inplace=True)\n",
      "              (layers): Sequential(\n",
      "                (0): Sequential(\n",
      "                  (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "                  (1): ReLU(inplace=True)\n",
      "                  (2): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "                (1): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "                (2): Dropout(p=0.0, inplace=False)\n",
      "              )\n",
      "              (dropout_layer): Identity()\n",
      "            )\n",
      "          )\n",
      "          (norms): ModuleList(\n",
      "            (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "        )\n",
      "        (8): DetrTransformerDecoderLayer(\n",
      "          (attentions): ModuleList(\n",
      "            (0): MultiheadAttention(\n",
      "              (attn): MultiheadAttention(\n",
      "                (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
      "              )\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (dropout_layer): Identity()\n",
      "            )\n",
      "            (1): MultiheadAttention(\n",
      "              (attn): MultiheadAttention(\n",
      "                (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
      "              )\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (dropout_layer): Identity()\n",
      "            )\n",
      "          )\n",
      "          (ffns): ModuleList(\n",
      "            (0): FFN(\n",
      "              (activate): ReLU(inplace=True)\n",
      "              (layers): Sequential(\n",
      "                (0): Sequential(\n",
      "                  (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "                  (1): ReLU(inplace=True)\n",
      "                  (2): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "                (1): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "                (2): Dropout(p=0.0, inplace=False)\n",
      "              )\n",
      "              (dropout_layer): Identity()\n",
      "            )\n",
      "          )\n",
      "          (norms): ModuleList(\n",
      "            (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (post_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (decoder_input_projs): ModuleList(\n",
      "      (0): Identity()\n",
      "      (1): Identity()\n",
      "      (2): Identity()\n",
      "    )\n",
      "    (decoder_positional_encoding): SinePositionalEncoding(num_feats=512, temperature=10000, normalize=True, scale=6.283185307179586, eps=1e-06)\n",
      "    (query_embed): Embedding(200, 1024)\n",
      "    (query_feat): Embedding(200, 1024)\n",
      "    (level_embed): Embedding(3, 1024)\n",
      "    (cls_embed): Linear(in_features=1024, out_features=7, bias=True)\n",
      "    (mask_embed): Sequential(\n",
      "      (0): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (3): ReLU(inplace=True)\n",
      "      (4): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "    )\n",
      "    (loss_cls): CrossEntropyLoss(avg_non_ignore=False)\n",
      "    (loss_mask): CrossEntropyLoss(avg_non_ignore=False)\n",
      "    (loss_dice): DiceLoss()\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-14 13:32:23,714 - mmseg - INFO - Loaded 1280 images\n",
      "{'num_layers': 24, 'layer_decay_rate': 0.9}\n",
      "Build LayerDecayOptimizerConstructor 0.900000 - 26\n",
      "{'num_layers': 24, 'layer_decay_rate': 0.9}\n",
      "Build LayerDecayOptimizerConstructor 0.900000 - 26\n",
      "{'num_layers': 24, 'layer_decay_rate': 0.9}\n",
      "Build LayerDecayOptimizerConstructor 0.900000 - 26\n",
      "Param groups = {\n",
      "  \"layer_0_decay\": {\n",
      "    \"param_names\": [\n",
      "      \"backbone.cls_token\",\n",
      "      \"backbone.patch_embed.proj.weight\",\n",
      "      \"decode_head.query_embed.weight\",\n",
      "      \"decode_head.query_feat.weight\",\n",
      "      \"decode_head.level_embed.weight\",\n",
      "      \"decode_head.cls_embed.weight\",\n",
      "      \"decode_head.mask_embed.0.weight\",\n",
      "      \"decode_head.mask_embed.2.weight\",\n",
      "      \"decode_head.mask_embed.4.weight\"\n",
      "    ],\n",
      "    \"lr_scale\": 0.0717897987691853,\n",
      "    \"lr\": 1.4357959753837061e-06,\n",
      "    \"weight_decay\": 0.05\n",
      "  },\n",
      "  \"layer_25_decay\": {\n",
      "    \"param_names\": [\n",
      "      \"backbone.level_embed\",\n",
      "      \"backbone.spm.stem.0.weight\",\n",
      "      \"backbone.spm.stem.3.weight\",\n",
      "      \"backbone.spm.stem.6.weight\",\n",
      "      \"backbone.spm.conv2.0.weight\",\n",
      "      \"backbone.spm.conv3.0.weight\",\n",
      "      \"backbone.spm.conv4.0.weight\",\n",
      "      \"backbone.spm.fc1.weight\",\n",
      "      \"backbone.spm.fc2.weight\",\n",
      "      \"backbone.spm.fc3.weight\",\n",
      "      \"backbone.spm.fc4.weight\",\n",
      "      \"backbone.interactions.0.injector.attn.sampling_offsets.weight\",\n",
      "      \"backbone.interactions.0.injector.attn.attention_weights.weight\",\n",
      "      \"backbone.interactions.0.injector.attn.value_proj.weight\",\n",
      "      \"backbone.interactions.0.injector.attn.output_proj.weight\",\n",
      "      \"backbone.interactions.0.extractor.attn.sampling_offsets.weight\",\n",
      "      \"backbone.interactions.0.extractor.attn.attention_weights.weight\",\n",
      "      \"backbone.interactions.0.extractor.attn.value_proj.weight\",\n",
      "      \"backbone.interactions.0.extractor.attn.output_proj.weight\",\n",
      "      \"backbone.interactions.0.extractor.ffn.fc1.weight\",\n",
      "      \"backbone.interactions.0.extractor.ffn.dwconv.dwconv.weight\",\n",
      "      \"backbone.interactions.0.extractor.ffn.fc2.weight\",\n",
      "      \"backbone.interactions.1.injector.attn.sampling_offsets.weight\",\n",
      "      \"backbone.interactions.1.injector.attn.attention_weights.weight\",\n",
      "      \"backbone.interactions.1.injector.attn.value_proj.weight\",\n",
      "      \"backbone.interactions.1.injector.attn.output_proj.weight\",\n",
      "      \"backbone.interactions.1.extractor.attn.sampling_offsets.weight\",\n",
      "      \"backbone.interactions.1.extractor.attn.attention_weights.weight\",\n",
      "      \"backbone.interactions.1.extractor.attn.value_proj.weight\",\n",
      "      \"backbone.interactions.1.extractor.attn.output_proj.weight\",\n",
      "      \"backbone.interactions.1.extractor.ffn.fc1.weight\",\n",
      "      \"backbone.interactions.1.extractor.ffn.dwconv.dwconv.weight\",\n",
      "      \"backbone.interactions.1.extractor.ffn.fc2.weight\",\n",
      "      \"backbone.interactions.2.injector.attn.sampling_offsets.weight\",\n",
      "      \"backbone.interactions.2.injector.attn.attention_weights.weight\",\n",
      "      \"backbone.interactions.2.injector.attn.value_proj.weight\",\n",
      "      \"backbone.interactions.2.injector.attn.output_proj.weight\",\n",
      "      \"backbone.interactions.2.extractor.attn.sampling_offsets.weight\",\n",
      "      \"backbone.interactions.2.extractor.attn.attention_weights.weight\",\n",
      "      \"backbone.interactions.2.extractor.attn.value_proj.weight\",\n",
      "      \"backbone.interactions.2.extractor.attn.output_proj.weight\",\n",
      "      \"backbone.interactions.2.extractor.ffn.fc1.weight\",\n",
      "      \"backbone.interactions.2.extractor.ffn.dwconv.dwconv.weight\",\n",
      "      \"backbone.interactions.2.extractor.ffn.fc2.weight\",\n",
      "      \"backbone.interactions.3.injector.attn.sampling_offsets.weight\",\n",
      "      \"backbone.interactions.3.injector.attn.attention_weights.weight\",\n",
      "      \"backbone.interactions.3.injector.attn.value_proj.weight\",\n",
      "      \"backbone.interactions.3.injector.attn.output_proj.weight\",\n",
      "      \"backbone.interactions.3.extractor.attn.sampling_offsets.weight\",\n",
      "      \"backbone.interactions.3.extractor.attn.attention_weights.weight\",\n",
      "      \"backbone.interactions.3.extractor.attn.value_proj.weight\",\n",
      "      \"backbone.interactions.3.extractor.attn.output_proj.weight\",\n",
      "      \"backbone.interactions.3.extractor.ffn.fc1.weight\",\n",
      "      \"backbone.interactions.3.extractor.ffn.dwconv.dwconv.weight\",\n",
      "      \"backbone.interactions.3.extractor.ffn.fc2.weight\",\n",
      "      \"backbone.interactions.3.extra_extractors.0.attn.sampling_offsets.weight\",\n",
      "      \"backbone.interactions.3.extra_extractors.0.attn.attention_weights.weight\",\n",
      "      \"backbone.interactions.3.extra_extractors.0.attn.value_proj.weight\",\n",
      "      \"backbone.interactions.3.extra_extractors.0.attn.output_proj.weight\",\n",
      "      \"backbone.interactions.3.extra_extractors.0.ffn.fc1.weight\",\n",
      "      \"backbone.interactions.3.extra_extractors.0.ffn.dwconv.dwconv.weight\",\n",
      "      \"backbone.interactions.3.extra_extractors.0.ffn.fc2.weight\",\n",
      "      \"backbone.interactions.3.extra_extractors.1.attn.sampling_offsets.weight\",\n",
      "      \"backbone.interactions.3.extra_extractors.1.attn.attention_weights.weight\",\n",
      "      \"backbone.interactions.3.extra_extractors.1.attn.value_proj.weight\",\n",
      "      \"backbone.interactions.3.extra_extractors.1.attn.output_proj.weight\",\n",
      "      \"backbone.interactions.3.extra_extractors.1.ffn.fc1.weight\",\n",
      "      \"backbone.interactions.3.extra_extractors.1.ffn.dwconv.dwconv.weight\",\n",
      "      \"backbone.interactions.3.extra_extractors.1.ffn.fc2.weight\",\n",
      "      \"backbone.up.weight\",\n",
      "      \"decode_head.pixel_decoder.input_convs.0.conv.weight\",\n",
      "      \"decode_head.pixel_decoder.input_convs.1.conv.weight\",\n",
      "      \"decode_head.pixel_decoder.input_convs.2.conv.weight\",\n",
      "      \"decode_head.pixel_decoder.encoder.layers.0.attentions.0.sampling_offsets.weight\",\n",
      "      \"decode_head.pixel_decoder.encoder.layers.0.attentions.0.attention_weights.weight\",\n",
      "      \"decode_head.pixel_decoder.encoder.layers.0.attentions.0.value_proj.weight\",\n",
      "      \"decode_head.pixel_decoder.encoder.layers.0.attentions.0.output_proj.weight\",\n",
      "      \"decode_head.pixel_decoder.encoder.layers.0.ffns.0.layers.0.0.weight\",\n",
      "      \"decode_head.pixel_decoder.encoder.layers.0.ffns.0.layers.1.weight\",\n",
      "      \"decode_head.pixel_decoder.encoder.layers.1.attentions.0.sampling_offsets.weight\",\n",
      "      \"decode_head.pixel_decoder.encoder.layers.1.attentions.0.attention_weights.weight\",\n",
      "      \"decode_head.pixel_decoder.encoder.layers.1.attentions.0.value_proj.weight\",\n",
      "      \"decode_head.pixel_decoder.encoder.layers.1.attentions.0.output_proj.weight\",\n",
      "      \"decode_head.pixel_decoder.encoder.layers.1.ffns.0.layers.0.0.weight\",\n",
      "      \"decode_head.pixel_decoder.encoder.layers.1.ffns.0.layers.1.weight\",\n",
      "      \"decode_head.pixel_decoder.encoder.layers.2.attentions.0.sampling_offsets.weight\",\n",
      "      \"decode_head.pixel_decoder.encoder.layers.2.attentions.0.attention_weights.weight\",\n",
      "      \"decode_head.pixel_decoder.encoder.layers.2.attentions.0.value_proj.weight\",\n",
      "      \"decode_head.pixel_decoder.encoder.layers.2.attentions.0.output_proj.weight\",\n",
      "      \"decode_head.pixel_decoder.encoder.layers.2.ffns.0.layers.0.0.weight\",\n",
      "      \"decode_head.pixel_decoder.encoder.layers.2.ffns.0.layers.1.weight\",\n",
      "      \"decode_head.pixel_decoder.encoder.layers.3.attentions.0.sampling_offsets.weight\",\n",
      "      \"decode_head.pixel_decoder.encoder.layers.3.attentions.0.attention_weights.weight\",\n",
      "      \"decode_head.pixel_decoder.encoder.layers.3.attentions.0.value_proj.weight\",\n",
      "      \"decode_head.pixel_decoder.encoder.layers.3.attentions.0.output_proj.weight\",\n",
      "      \"decode_head.pixel_decoder.encoder.layers.3.ffns.0.layers.0.0.weight\",\n",
      "      \"decode_head.pixel_decoder.encoder.layers.3.ffns.0.layers.1.weight\",\n",
      "      \"decode_head.pixel_decoder.encoder.layers.4.attentions.0.sampling_offsets.weight\",\n",
      "      \"decode_head.pixel_decoder.encoder.layers.4.attentions.0.attention_weights.weight\",\n",
      "      \"decode_head.pixel_decoder.encoder.layers.4.attentions.0.value_proj.weight\",\n",
      "      \"decode_head.pixel_decoder.encoder.layers.4.attentions.0.output_proj.weight\",\n",
      "      \"decode_head.pixel_decoder.encoder.layers.4.ffns.0.layers.0.0.weight\",\n",
      "      \"decode_head.pixel_decoder.encoder.layers.4.ffns.0.layers.1.weight\",\n",
      "      \"decode_head.pixel_decoder.encoder.layers.5.attentions.0.sampling_offsets.weight\",\n",
      "      \"decode_head.pixel_decoder.encoder.layers.5.attentions.0.attention_weights.weight\",\n",
      "      \"decode_head.pixel_decoder.encoder.layers.5.attentions.0.value_proj.weight\",\n",
      "      \"decode_head.pixel_decoder.encoder.layers.5.attentions.0.output_proj.weight\",\n",
      "      \"decode_head.pixel_decoder.encoder.layers.5.ffns.0.layers.0.0.weight\",\n",
      "      \"decode_head.pixel_decoder.encoder.layers.5.ffns.0.layers.1.weight\",\n",
      "      \"decode_head.pixel_decoder.level_encoding.weight\",\n",
      "      \"decode_head.pixel_decoder.lateral_convs.0.conv.weight\",\n",
      "      \"decode_head.pixel_decoder.output_convs.0.conv.weight\",\n",
      "      \"decode_head.pixel_decoder.mask_feature.weight\",\n",
      "      \"decode_head.transformer_decoder.layers.0.attentions.0.attn.in_proj_weight\",\n",
      "      \"decode_head.transformer_decoder.layers.0.attentions.0.attn.out_proj.weight\",\n",
      "      \"decode_head.transformer_decoder.layers.0.attentions.1.attn.in_proj_weight\",\n",
      "      \"decode_head.transformer_decoder.layers.0.attentions.1.attn.out_proj.weight\",\n",
      "      \"decode_head.transformer_decoder.layers.0.ffns.0.layers.0.0.weight\",\n",
      "      \"decode_head.transformer_decoder.layers.0.ffns.0.layers.1.weight\",\n",
      "      \"decode_head.transformer_decoder.layers.1.attentions.0.attn.in_proj_weight\",\n",
      "      \"decode_head.transformer_decoder.layers.1.attentions.0.attn.out_proj.weight\",\n",
      "      \"decode_head.transformer_decoder.layers.1.attentions.1.attn.in_proj_weight\",\n",
      "      \"decode_head.transformer_decoder.layers.1.attentions.1.attn.out_proj.weight\",\n",
      "      \"decode_head.transformer_decoder.layers.1.ffns.0.layers.0.0.weight\",\n",
      "      \"decode_head.transformer_decoder.layers.1.ffns.0.layers.1.weight\",\n",
      "      \"decode_head.transformer_decoder.layers.2.attentions.0.attn.in_proj_weight\",\n",
      "      \"decode_head.transformer_decoder.layers.2.attentions.0.attn.out_proj.weight\",\n",
      "      \"decode_head.transformer_decoder.layers.2.attentions.1.attn.in_proj_weight\",\n",
      "      \"decode_head.transformer_decoder.layers.2.attentions.1.attn.out_proj.weight\",\n",
      "      \"decode_head.transformer_decoder.layers.2.ffns.0.layers.0.0.weight\",\n",
      "      \"decode_head.transformer_decoder.layers.2.ffns.0.layers.1.weight\",\n",
      "      \"decode_head.transformer_decoder.layers.3.attentions.0.attn.in_proj_weight\",\n",
      "      \"decode_head.transformer_decoder.layers.3.attentions.0.attn.out_proj.weight\",\n",
      "      \"decode_head.transformer_decoder.layers.3.attentions.1.attn.in_proj_weight\",\n",
      "      \"decode_head.transformer_decoder.layers.3.attentions.1.attn.out_proj.weight\",\n",
      "      \"decode_head.transformer_decoder.layers.3.ffns.0.layers.0.0.weight\",\n",
      "      \"decode_head.transformer_decoder.layers.3.ffns.0.layers.1.weight\",\n",
      "      \"decode_head.transformer_decoder.layers.4.attentions.0.attn.in_proj_weight\",\n",
      "      \"decode_head.transformer_decoder.layers.4.attentions.0.attn.out_proj.weight\",\n",
      "      \"decode_head.transformer_decoder.layers.4.attentions.1.attn.in_proj_weight\",\n",
      "      \"decode_head.transformer_decoder.layers.4.attentions.1.attn.out_proj.weight\",\n",
      "      \"decode_head.transformer_decoder.layers.4.ffns.0.layers.0.0.weight\",\n",
      "      \"decode_head.transformer_decoder.layers.4.ffns.0.layers.1.weight\",\n",
      "      \"decode_head.transformer_decoder.layers.5.attentions.0.attn.in_proj_weight\",\n",
      "      \"decode_head.transformer_decoder.layers.5.attentions.0.attn.out_proj.weight\",\n",
      "      \"decode_head.transformer_decoder.layers.5.attentions.1.attn.in_proj_weight\",\n",
      "      \"decode_head.transformer_decoder.layers.5.attentions.1.attn.out_proj.weight\",\n",
      "      \"decode_head.transformer_decoder.layers.5.ffns.0.layers.0.0.weight\",\n",
      "      \"decode_head.transformer_decoder.layers.5.ffns.0.layers.1.weight\",\n",
      "      \"decode_head.transformer_decoder.layers.6.attentions.0.attn.in_proj_weight\",\n",
      "      \"decode_head.transformer_decoder.layers.6.attentions.0.attn.out_proj.weight\",\n",
      "      \"decode_head.transformer_decoder.layers.6.attentions.1.attn.in_proj_weight\",\n",
      "      \"decode_head.transformer_decoder.layers.6.attentions.1.attn.out_proj.weight\",\n",
      "      \"decode_head.transformer_decoder.layers.6.ffns.0.layers.0.0.weight\",\n",
      "      \"decode_head.transformer_decoder.layers.6.ffns.0.layers.1.weight\",\n",
      "      \"decode_head.transformer_decoder.layers.7.attentions.0.attn.in_proj_weight\",\n",
      "      \"decode_head.transformer_decoder.layers.7.attentions.0.attn.out_proj.weight\",\n",
      "      \"decode_head.transformer_decoder.layers.7.attentions.1.attn.in_proj_weight\",\n",
      "      \"decode_head.transformer_decoder.layers.7.attentions.1.attn.out_proj.weight\",\n",
      "      \"decode_head.transformer_decoder.layers.7.ffns.0.layers.0.0.weight\",\n",
      "      \"decode_head.transformer_decoder.layers.7.ffns.0.layers.1.weight\",\n",
      "      \"decode_head.transformer_decoder.layers.8.attentions.0.attn.in_proj_weight\",\n",
      "      \"decode_head.transformer_decoder.layers.8.attentions.0.attn.out_proj.weight\",\n",
      "      \"decode_head.transformer_decoder.layers.8.attentions.1.attn.in_proj_weight\",\n",
      "      \"decode_head.transformer_decoder.layers.8.attentions.1.attn.out_proj.weight\",\n",
      "      \"decode_head.transformer_decoder.layers.8.ffns.0.layers.0.0.weight\",\n",
      "      \"decode_head.transformer_decoder.layers.8.ffns.0.layers.1.weight\"\n",
      "    ],\n",
      "    \"lr_scale\": 1.0,\n",
      "    \"lr\": 2e-05,\n",
      "    \"weight_decay\": 0.05\n",
      "  },\n",
      "  \"layer_0_no_decay\": {\n",
      "    \"param_names\": [\n",
      "      \"backbone.patch_embed.proj.bias\",\n",
      "      \"decode_head.cls_embed.bias\",\n",
      "      \"decode_head.mask_embed.0.bias\",\n",
      "      \"decode_head.mask_embed.2.bias\",\n",
      "      \"decode_head.mask_embed.4.bias\"\n",
      "    ],\n",
      "    \"lr_scale\": 0.0717897987691853,\n",
      "    \"lr\": 1.4357959753837061e-06,\n",
      "    \"weight_decay\": 0.0\n",
      "  },\n",
      "  \"layer_1_no_decay\": {\n",
      "    \"param_names\": [\n",
      "      \"backbone.blocks.0.gamma_1\",\n",
      "      \"backbone.blocks.0.gamma_2\",\n",
      "      \"backbone.blocks.0.norm1.weight\",\n",
      "      \"backbone.blocks.0.norm1.bias\",\n",
      "      \"backbone.blocks.0.attn.q_bias\",\n",
      "      \"backbone.blocks.0.attn.v_bias\",\n",
      "      \"backbone.blocks.0.attn.proj.bias\",\n",
      "      \"backbone.blocks.0.norm2.weight\",\n",
      "      \"backbone.blocks.0.norm2.bias\",\n",
      "      \"backbone.blocks.0.mlp.fc1.bias\",\n",
      "      \"backbone.blocks.0.mlp.fc2.bias\"\n",
      "    ],\n",
      "    \"lr_scale\": 0.07976644307687256,\n",
      "    \"lr\": 1.5953288615374513e-06,\n",
      "    \"weight_decay\": 0.0\n",
      "  },\n",
      "  \"layer_1_decay\": {\n",
      "    \"param_names\": [\n",
      "      \"backbone.blocks.0.attn.relative_position_bias_table\",\n",
      "      \"backbone.blocks.0.attn.qkv.weight\",\n",
      "      \"backbone.blocks.0.attn.proj.weight\",\n",
      "      \"backbone.blocks.0.mlp.fc1.weight\",\n",
      "      \"backbone.blocks.0.mlp.fc2.weight\"\n",
      "    ],\n",
      "    \"lr_scale\": 0.07976644307687256,\n",
      "    \"lr\": 1.5953288615374513e-06,\n",
      "    \"weight_decay\": 0.05\n",
      "  },\n",
      "  \"layer_2_no_decay\": {\n",
      "    \"param_names\": [\n",
      "      \"backbone.blocks.1.gamma_1\",\n",
      "      \"backbone.blocks.1.gamma_2\",\n",
      "      \"backbone.blocks.1.norm1.weight\",\n",
      "      \"backbone.blocks.1.norm1.bias\",\n",
      "      \"backbone.blocks.1.attn.q_bias\",\n",
      "      \"backbone.blocks.1.attn.v_bias\",\n",
      "      \"backbone.blocks.1.attn.proj.bias\",\n",
      "      \"backbone.blocks.1.norm2.weight\",\n",
      "      \"backbone.blocks.1.norm2.bias\",\n",
      "      \"backbone.blocks.1.mlp.fc1.bias\",\n",
      "      \"backbone.blocks.1.mlp.fc2.bias\"\n",
      "    ],\n",
      "    \"lr_scale\": 0.08862938119652507,\n",
      "    \"lr\": 1.7725876239305016e-06,\n",
      "    \"weight_decay\": 0.0\n",
      "  },\n",
      "  \"layer_2_decay\": {\n",
      "    \"param_names\": [\n",
      "      \"backbone.blocks.1.attn.relative_position_bias_table\",\n",
      "      \"backbone.blocks.1.attn.qkv.weight\",\n",
      "      \"backbone.blocks.1.attn.proj.weight\",\n",
      "      \"backbone.blocks.1.mlp.fc1.weight\",\n",
      "      \"backbone.blocks.1.mlp.fc2.weight\"\n",
      "    ],\n",
      "    \"lr_scale\": 0.08862938119652507,\n",
      "    \"lr\": 1.7725876239305016e-06,\n",
      "    \"weight_decay\": 0.05\n",
      "  },\n",
      "  \"layer_3_no_decay\": {\n",
      "    \"param_names\": [\n",
      "      \"backbone.blocks.2.gamma_1\",\n",
      "      \"backbone.blocks.2.gamma_2\",\n",
      "      \"backbone.blocks.2.norm1.weight\",\n",
      "      \"backbone.blocks.2.norm1.bias\",\n",
      "      \"backbone.blocks.2.attn.q_bias\",\n",
      "      \"backbone.blocks.2.attn.v_bias\",\n",
      "      \"backbone.blocks.2.attn.proj.bias\",\n",
      "      \"backbone.blocks.2.norm2.weight\",\n",
      "      \"backbone.blocks.2.norm2.bias\",\n",
      "      \"backbone.blocks.2.mlp.fc1.bias\",\n",
      "      \"backbone.blocks.2.mlp.fc2.bias\"\n",
      "    ],\n",
      "    \"lr_scale\": 0.09847709021836118,\n",
      "    \"lr\": 1.969541804367224e-06,\n",
      "    \"weight_decay\": 0.0\n",
      "  },\n",
      "  \"layer_3_decay\": {\n",
      "    \"param_names\": [\n",
      "      \"backbone.blocks.2.attn.relative_position_bias_table\",\n",
      "      \"backbone.blocks.2.attn.qkv.weight\",\n",
      "      \"backbone.blocks.2.attn.proj.weight\",\n",
      "      \"backbone.blocks.2.mlp.fc1.weight\",\n",
      "      \"backbone.blocks.2.mlp.fc2.weight\"\n",
      "    ],\n",
      "    \"lr_scale\": 0.09847709021836118,\n",
      "    \"lr\": 1.969541804367224e-06,\n",
      "    \"weight_decay\": 0.05\n",
      "  },\n",
      "  \"layer_4_no_decay\": {\n",
      "    \"param_names\": [\n",
      "      \"backbone.blocks.3.gamma_1\",\n",
      "      \"backbone.blocks.3.gamma_2\",\n",
      "      \"backbone.blocks.3.norm1.weight\",\n",
      "      \"backbone.blocks.3.norm1.bias\",\n",
      "      \"backbone.blocks.3.attn.q_bias\",\n",
      "      \"backbone.blocks.3.attn.v_bias\",\n",
      "      \"backbone.blocks.3.attn.proj.bias\",\n",
      "      \"backbone.blocks.3.norm2.weight\",\n",
      "      \"backbone.blocks.3.norm2.bias\",\n",
      "      \"backbone.blocks.3.mlp.fc1.bias\",\n",
      "      \"backbone.blocks.3.mlp.fc2.bias\"\n",
      "    ],\n",
      "    \"lr_scale\": 0.10941898913151242,\n",
      "    \"lr\": 2.1883797826302486e-06,\n",
      "    \"weight_decay\": 0.0\n",
      "  },\n",
      "  \"layer_4_decay\": {\n",
      "    \"param_names\": [\n",
      "      \"backbone.blocks.3.attn.relative_position_bias_table\",\n",
      "      \"backbone.blocks.3.attn.qkv.weight\",\n",
      "      \"backbone.blocks.3.attn.proj.weight\",\n",
      "      \"backbone.blocks.3.mlp.fc1.weight\",\n",
      "      \"backbone.blocks.3.mlp.fc2.weight\"\n",
      "    ],\n",
      "    \"lr_scale\": 0.10941898913151242,\n",
      "    \"lr\": 2.1883797826302486e-06,\n",
      "    \"weight_decay\": 0.05\n",
      "  },\n",
      "  \"layer_5_no_decay\": {\n",
      "    \"param_names\": [\n",
      "      \"backbone.blocks.4.gamma_1\",\n",
      "      \"backbone.blocks.4.gamma_2\",\n",
      "      \"backbone.blocks.4.norm1.weight\",\n",
      "      \"backbone.blocks.4.norm1.bias\",\n",
      "      \"backbone.blocks.4.attn.q_bias\",\n",
      "      \"backbone.blocks.4.attn.v_bias\",\n",
      "      \"backbone.blocks.4.attn.proj.bias\",\n",
      "      \"backbone.blocks.4.norm2.weight\",\n",
      "      \"backbone.blocks.4.norm2.bias\",\n",
      "      \"backbone.blocks.4.mlp.fc1.bias\",\n",
      "      \"backbone.blocks.4.mlp.fc2.bias\"\n",
      "    ],\n",
      "    \"lr_scale\": 0.12157665459056935,\n",
      "    \"lr\": 2.431533091811387e-06,\n",
      "    \"weight_decay\": 0.0\n",
      "  },\n",
      "  \"layer_5_decay\": {\n",
      "    \"param_names\": [\n",
      "      \"backbone.blocks.4.attn.relative_position_bias_table\",\n",
      "      \"backbone.blocks.4.attn.qkv.weight\",\n",
      "      \"backbone.blocks.4.attn.proj.weight\",\n",
      "      \"backbone.blocks.4.mlp.fc1.weight\",\n",
      "      \"backbone.blocks.4.mlp.fc2.weight\"\n",
      "    ],\n",
      "    \"lr_scale\": 0.12157665459056935,\n",
      "    \"lr\": 2.431533091811387e-06,\n",
      "    \"weight_decay\": 0.05\n",
      "  },\n",
      "  \"layer_6_no_decay\": {\n",
      "    \"param_names\": [\n",
      "      \"backbone.blocks.5.gamma_1\",\n",
      "      \"backbone.blocks.5.gamma_2\",\n",
      "      \"backbone.blocks.5.norm1.weight\",\n",
      "      \"backbone.blocks.5.norm1.bias\",\n",
      "      \"backbone.blocks.5.attn.q_bias\",\n",
      "      \"backbone.blocks.5.attn.v_bias\",\n",
      "      \"backbone.blocks.5.attn.proj.bias\",\n",
      "      \"backbone.blocks.5.norm2.weight\",\n",
      "      \"backbone.blocks.5.norm2.bias\",\n",
      "      \"backbone.blocks.5.mlp.fc1.bias\",\n",
      "      \"backbone.blocks.5.mlp.fc2.bias\"\n",
      "    ],\n",
      "    \"lr_scale\": 0.13508517176729928,\n",
      "    \"lr\": 2.701703435345986e-06,\n",
      "    \"weight_decay\": 0.0\n",
      "  },\n",
      "  \"layer_6_decay\": {\n",
      "    \"param_names\": [\n",
      "      \"backbone.blocks.5.attn.relative_position_bias_table\",\n",
      "      \"backbone.blocks.5.attn.qkv.weight\",\n",
      "      \"backbone.blocks.5.attn.proj.weight\",\n",
      "      \"backbone.blocks.5.mlp.fc1.weight\",\n",
      "      \"backbone.blocks.5.mlp.fc2.weight\"\n",
      "    ],\n",
      "    \"lr_scale\": 0.13508517176729928,\n",
      "    \"lr\": 2.701703435345986e-06,\n",
      "    \"weight_decay\": 0.05\n",
      "  },\n",
      "  \"layer_7_no_decay\": {\n",
      "    \"param_names\": [\n",
      "      \"backbone.blocks.6.gamma_1\",\n",
      "      \"backbone.blocks.6.gamma_2\",\n",
      "      \"backbone.blocks.6.norm1.weight\",\n",
      "      \"backbone.blocks.6.norm1.bias\",\n",
      "      \"backbone.blocks.6.attn.q_bias\",\n",
      "      \"backbone.blocks.6.attn.v_bias\",\n",
      "      \"backbone.blocks.6.attn.proj.bias\",\n",
      "      \"backbone.blocks.6.norm2.weight\",\n",
      "      \"backbone.blocks.6.norm2.bias\",\n",
      "      \"backbone.blocks.6.mlp.fc1.bias\",\n",
      "      \"backbone.blocks.6.mlp.fc2.bias\"\n",
      "    ],\n",
      "    \"lr_scale\": 0.15009463529699918,\n",
      "    \"lr\": 3.001892705939984e-06,\n",
      "    \"weight_decay\": 0.0\n",
      "  },\n",
      "  \"layer_7_decay\": {\n",
      "    \"param_names\": [\n",
      "      \"backbone.blocks.6.attn.relative_position_bias_table\",\n",
      "      \"backbone.blocks.6.attn.qkv.weight\",\n",
      "      \"backbone.blocks.6.attn.proj.weight\",\n",
      "      \"backbone.blocks.6.mlp.fc1.weight\",\n",
      "      \"backbone.blocks.6.mlp.fc2.weight\"\n",
      "    ],\n",
      "    \"lr_scale\": 0.15009463529699918,\n",
      "    \"lr\": 3.001892705939984e-06,\n",
      "    \"weight_decay\": 0.05\n",
      "  },\n",
      "  \"layer_8_no_decay\": {\n",
      "    \"param_names\": [\n",
      "      \"backbone.blocks.7.gamma_1\",\n",
      "      \"backbone.blocks.7.gamma_2\",\n",
      "      \"backbone.blocks.7.norm1.weight\",\n",
      "      \"backbone.blocks.7.norm1.bias\",\n",
      "      \"backbone.blocks.7.attn.q_bias\",\n",
      "      \"backbone.blocks.7.attn.v_bias\",\n",
      "      \"backbone.blocks.7.attn.proj.bias\",\n",
      "      \"backbone.blocks.7.norm2.weight\",\n",
      "      \"backbone.blocks.7.norm2.bias\",\n",
      "      \"backbone.blocks.7.mlp.fc1.bias\",\n",
      "      \"backbone.blocks.7.mlp.fc2.bias\"\n",
      "    ],\n",
      "    \"lr_scale\": 0.16677181699666577,\n",
      "    \"lr\": 3.3354363399333156e-06,\n",
      "    \"weight_decay\": 0.0\n",
      "  },\n",
      "  \"layer_8_decay\": {\n",
      "    \"param_names\": [\n",
      "      \"backbone.blocks.7.attn.relative_position_bias_table\",\n",
      "      \"backbone.blocks.7.attn.qkv.weight\",\n",
      "      \"backbone.blocks.7.attn.proj.weight\",\n",
      "      \"backbone.blocks.7.mlp.fc1.weight\",\n",
      "      \"backbone.blocks.7.mlp.fc2.weight\"\n",
      "    ],\n",
      "    \"lr_scale\": 0.16677181699666577,\n",
      "    \"lr\": 3.3354363399333156e-06,\n",
      "    \"weight_decay\": 0.05\n",
      "  },\n",
      "  \"layer_9_no_decay\": {\n",
      "    \"param_names\": [\n",
      "      \"backbone.blocks.8.gamma_1\",\n",
      "      \"backbone.blocks.8.gamma_2\",\n",
      "      \"backbone.blocks.8.norm1.weight\",\n",
      "      \"backbone.blocks.8.norm1.bias\",\n",
      "      \"backbone.blocks.8.attn.q_bias\",\n",
      "      \"backbone.blocks.8.attn.v_bias\",\n",
      "      \"backbone.blocks.8.attn.proj.bias\",\n",
      "      \"backbone.blocks.8.norm2.weight\",\n",
      "      \"backbone.blocks.8.norm2.bias\",\n",
      "      \"backbone.blocks.8.mlp.fc1.bias\",\n",
      "      \"backbone.blocks.8.mlp.fc2.bias\"\n",
      "    ],\n",
      "    \"lr_scale\": 0.18530201888518416,\n",
      "    \"lr\": 3.7060403777036836e-06,\n",
      "    \"weight_decay\": 0.0\n",
      "  },\n",
      "  \"layer_9_decay\": {\n",
      "    \"param_names\": [\n",
      "      \"backbone.blocks.8.attn.relative_position_bias_table\",\n",
      "      \"backbone.blocks.8.attn.qkv.weight\",\n",
      "      \"backbone.blocks.8.attn.proj.weight\",\n",
      "      \"backbone.blocks.8.mlp.fc1.weight\",\n",
      "      \"backbone.blocks.8.mlp.fc2.weight\"\n",
      "    ],\n",
      "    \"lr_scale\": 0.18530201888518416,\n",
      "    \"lr\": 3.7060403777036836e-06,\n",
      "    \"weight_decay\": 0.05\n",
      "  },\n",
      "  \"layer_10_no_decay\": {\n",
      "    \"param_names\": [\n",
      "      \"backbone.blocks.9.gamma_1\",\n",
      "      \"backbone.blocks.9.gamma_2\",\n",
      "      \"backbone.blocks.9.norm1.weight\",\n",
      "      \"backbone.blocks.9.norm1.bias\",\n",
      "      \"backbone.blocks.9.attn.q_bias\",\n",
      "      \"backbone.blocks.9.attn.v_bias\",\n",
      "      \"backbone.blocks.9.attn.proj.bias\",\n",
      "      \"backbone.blocks.9.norm2.weight\",\n",
      "      \"backbone.blocks.9.norm2.bias\",\n",
      "      \"backbone.blocks.9.mlp.fc1.bias\",\n",
      "      \"backbone.blocks.9.mlp.fc2.bias\"\n",
      "    ],\n",
      "    \"lr_scale\": 0.20589113209464907,\n",
      "    \"lr\": 4.117822641892982e-06,\n",
      "    \"weight_decay\": 0.0\n",
      "  },\n",
      "  \"layer_10_decay\": {\n",
      "    \"param_names\": [\n",
      "      \"backbone.blocks.9.attn.relative_position_bias_table\",\n",
      "      \"backbone.blocks.9.attn.qkv.weight\",\n",
      "      \"backbone.blocks.9.attn.proj.weight\",\n",
      "      \"backbone.blocks.9.mlp.fc1.weight\",\n",
      "      \"backbone.blocks.9.mlp.fc2.weight\"\n",
      "    ],\n",
      "    \"lr_scale\": 0.20589113209464907,\n",
      "    \"lr\": 4.117822641892982e-06,\n",
      "    \"weight_decay\": 0.05\n",
      "  },\n",
      "  \"layer_11_no_decay\": {\n",
      "    \"param_names\": [\n",
      "      \"backbone.blocks.10.gamma_1\",\n",
      "      \"backbone.blocks.10.gamma_2\",\n",
      "      \"backbone.blocks.10.norm1.weight\",\n",
      "      \"backbone.blocks.10.norm1.bias\",\n",
      "      \"backbone.blocks.10.attn.q_bias\",\n",
      "      \"backbone.blocks.10.attn.v_bias\",\n",
      "      \"backbone.blocks.10.attn.proj.bias\",\n",
      "      \"backbone.blocks.10.norm2.weight\",\n",
      "      \"backbone.blocks.10.norm2.bias\",\n",
      "      \"backbone.blocks.10.mlp.fc1.bias\",\n",
      "      \"backbone.blocks.10.mlp.fc2.bias\"\n",
      "    ],\n",
      "    \"lr_scale\": 0.2287679245496101,\n",
      "    \"lr\": 4.575358490992202e-06,\n",
      "    \"weight_decay\": 0.0\n",
      "  },\n",
      "  \"layer_11_decay\": {\n",
      "    \"param_names\": [\n",
      "      \"backbone.blocks.10.attn.relative_position_bias_table\",\n",
      "      \"backbone.blocks.10.attn.qkv.weight\",\n",
      "      \"backbone.blocks.10.attn.proj.weight\",\n",
      "      \"backbone.blocks.10.mlp.fc1.weight\",\n",
      "      \"backbone.blocks.10.mlp.fc2.weight\"\n",
      "    ],\n",
      "    \"lr_scale\": 0.2287679245496101,\n",
      "    \"lr\": 4.575358490992202e-06,\n",
      "    \"weight_decay\": 0.05\n",
      "  },\n",
      "  \"layer_12_no_decay\": {\n",
      "    \"param_names\": [\n",
      "      \"backbone.blocks.11.gamma_1\",\n",
      "      \"backbone.blocks.11.gamma_2\",\n",
      "      \"backbone.blocks.11.norm1.weight\",\n",
      "      \"backbone.blocks.11.norm1.bias\",\n",
      "      \"backbone.blocks.11.attn.q_bias\",\n",
      "      \"backbone.blocks.11.attn.v_bias\",\n",
      "      \"backbone.blocks.11.attn.proj.bias\",\n",
      "      \"backbone.blocks.11.norm2.weight\",\n",
      "      \"backbone.blocks.11.norm2.bias\",\n",
      "      \"backbone.blocks.11.mlp.fc1.bias\",\n",
      "      \"backbone.blocks.11.mlp.fc2.bias\"\n",
      "    ],\n",
      "    \"lr_scale\": 0.2541865828329001,\n",
      "    \"lr\": 5.083731656658002e-06,\n",
      "    \"weight_decay\": 0.0\n",
      "  },\n",
      "  \"layer_12_decay\": {\n",
      "    \"param_names\": [\n",
      "      \"backbone.blocks.11.attn.relative_position_bias_table\",\n",
      "      \"backbone.blocks.11.attn.qkv.weight\",\n",
      "      \"backbone.blocks.11.attn.proj.weight\",\n",
      "      \"backbone.blocks.11.mlp.fc1.weight\",\n",
      "      \"backbone.blocks.11.mlp.fc2.weight\"\n",
      "    ],\n",
      "    \"lr_scale\": 0.2541865828329001,\n",
      "    \"lr\": 5.083731656658002e-06,\n",
      "    \"weight_decay\": 0.05\n",
      "  },\n",
      "  \"layer_13_no_decay\": {\n",
      "    \"param_names\": [\n",
      "      \"backbone.blocks.12.gamma_1\",\n",
      "      \"backbone.blocks.12.gamma_2\",\n",
      "      \"backbone.blocks.12.norm1.weight\",\n",
      "      \"backbone.blocks.12.norm1.bias\",\n",
      "      \"backbone.blocks.12.attn.q_bias\",\n",
      "      \"backbone.blocks.12.attn.v_bias\",\n",
      "      \"backbone.blocks.12.attn.proj.bias\",\n",
      "      \"backbone.blocks.12.norm2.weight\",\n",
      "      \"backbone.blocks.12.norm2.bias\",\n",
      "      \"backbone.blocks.12.mlp.fc1.bias\",\n",
      "      \"backbone.blocks.12.mlp.fc2.bias\"\n",
      "    ],\n",
      "    \"lr_scale\": 0.2824295364810001,\n",
      "    \"lr\": 5.648590729620003e-06,\n",
      "    \"weight_decay\": 0.0\n",
      "  },\n",
      "  \"layer_13_decay\": {\n",
      "    \"param_names\": [\n",
      "      \"backbone.blocks.12.attn.relative_position_bias_table\",\n",
      "      \"backbone.blocks.12.attn.qkv.weight\",\n",
      "      \"backbone.blocks.12.attn.proj.weight\",\n",
      "      \"backbone.blocks.12.mlp.fc1.weight\",\n",
      "      \"backbone.blocks.12.mlp.fc2.weight\"\n",
      "    ],\n",
      "    \"lr_scale\": 0.2824295364810001,\n",
      "    \"lr\": 5.648590729620003e-06,\n",
      "    \"weight_decay\": 0.05\n",
      "  },\n",
      "  \"layer_14_no_decay\": {\n",
      "    \"param_names\": [\n",
      "      \"backbone.blocks.13.gamma_1\",\n",
      "      \"backbone.blocks.13.gamma_2\",\n",
      "      \"backbone.blocks.13.norm1.weight\",\n",
      "      \"backbone.blocks.13.norm1.bias\",\n",
      "      \"backbone.blocks.13.attn.q_bias\",\n",
      "      \"backbone.blocks.13.attn.v_bias\",\n",
      "      \"backbone.blocks.13.attn.proj.bias\",\n",
      "      \"backbone.blocks.13.norm2.weight\",\n",
      "      \"backbone.blocks.13.norm2.bias\",\n",
      "      \"backbone.blocks.13.mlp.fc1.bias\",\n",
      "      \"backbone.blocks.13.mlp.fc2.bias\"\n",
      "    ],\n",
      "    \"lr_scale\": 0.31381059609000006,\n",
      "    \"lr\": 6.276211921800002e-06,\n",
      "    \"weight_decay\": 0.0\n",
      "  },\n",
      "  \"layer_14_decay\": {\n",
      "    \"param_names\": [\n",
      "      \"backbone.blocks.13.attn.relative_position_bias_table\",\n",
      "      \"backbone.blocks.13.attn.qkv.weight\",\n",
      "      \"backbone.blocks.13.attn.proj.weight\",\n",
      "      \"backbone.blocks.13.mlp.fc1.weight\",\n",
      "      \"backbone.blocks.13.mlp.fc2.weight\"\n",
      "    ],\n",
      "    \"lr_scale\": 0.31381059609000006,\n",
      "    \"lr\": 6.276211921800002e-06,\n",
      "    \"weight_decay\": 0.05\n",
      "  },\n",
      "  \"layer_15_no_decay\": {\n",
      "    \"param_names\": [\n",
      "      \"backbone.blocks.14.gamma_1\",\n",
      "      \"backbone.blocks.14.gamma_2\",\n",
      "      \"backbone.blocks.14.norm1.weight\",\n",
      "      \"backbone.blocks.14.norm1.bias\",\n",
      "      \"backbone.blocks.14.attn.q_bias\",\n",
      "      \"backbone.blocks.14.attn.v_bias\",\n",
      "      \"backbone.blocks.14.attn.proj.bias\",\n",
      "      \"backbone.blocks.14.norm2.weight\",\n",
      "      \"backbone.blocks.14.norm2.bias\",\n",
      "      \"backbone.blocks.14.mlp.fc1.bias\",\n",
      "      \"backbone.blocks.14.mlp.fc2.bias\"\n",
      "    ],\n",
      "    \"lr_scale\": 0.3486784401000001,\n",
      "    \"lr\": 6.973568802000002e-06,\n",
      "    \"weight_decay\": 0.0\n",
      "  },\n",
      "  \"layer_15_decay\": {\n",
      "    \"param_names\": [\n",
      "      \"backbone.blocks.14.attn.relative_position_bias_table\",\n",
      "      \"backbone.blocks.14.attn.qkv.weight\",\n",
      "      \"backbone.blocks.14.attn.proj.weight\",\n",
      "      \"backbone.blocks.14.mlp.fc1.weight\",\n",
      "      \"backbone.blocks.14.mlp.fc2.weight\"\n",
      "    ],\n",
      "    \"lr_scale\": 0.3486784401000001,\n",
      "    \"lr\": 6.973568802000002e-06,\n",
      "    \"weight_decay\": 0.05\n",
      "  },\n",
      "  \"layer_16_no_decay\": {\n",
      "    \"param_names\": [\n",
      "      \"backbone.blocks.15.gamma_1\",\n",
      "      \"backbone.blocks.15.gamma_2\",\n",
      "      \"backbone.blocks.15.norm1.weight\",\n",
      "      \"backbone.blocks.15.norm1.bias\",\n",
      "      \"backbone.blocks.15.attn.q_bias\",\n",
      "      \"backbone.blocks.15.attn.v_bias\",\n",
      "      \"backbone.blocks.15.attn.proj.bias\",\n",
      "      \"backbone.blocks.15.norm2.weight\",\n",
      "      \"backbone.blocks.15.norm2.bias\",\n",
      "      \"backbone.blocks.15.mlp.fc1.bias\",\n",
      "      \"backbone.blocks.15.mlp.fc2.bias\"\n",
      "    ],\n",
      "    \"lr_scale\": 0.3874204890000001,\n",
      "    \"lr\": 7.748409780000003e-06,\n",
      "    \"weight_decay\": 0.0\n",
      "  },\n",
      "  \"layer_16_decay\": {\n",
      "    \"param_names\": [\n",
      "      \"backbone.blocks.15.attn.relative_position_bias_table\",\n",
      "      \"backbone.blocks.15.attn.qkv.weight\",\n",
      "      \"backbone.blocks.15.attn.proj.weight\",\n",
      "      \"backbone.blocks.15.mlp.fc1.weight\",\n",
      "      \"backbone.blocks.15.mlp.fc2.weight\"\n",
      "    ],\n",
      "    \"lr_scale\": 0.3874204890000001,\n",
      "    \"lr\": 7.748409780000003e-06,\n",
      "    \"weight_decay\": 0.05\n",
      "  },\n",
      "  \"layer_17_no_decay\": {\n",
      "    \"param_names\": [\n",
      "      \"backbone.blocks.16.gamma_1\",\n",
      "      \"backbone.blocks.16.gamma_2\",\n",
      "      \"backbone.blocks.16.norm1.weight\",\n",
      "      \"backbone.blocks.16.norm1.bias\",\n",
      "      \"backbone.blocks.16.attn.q_bias\",\n",
      "      \"backbone.blocks.16.attn.v_bias\",\n",
      "      \"backbone.blocks.16.attn.proj.bias\",\n",
      "      \"backbone.blocks.16.norm2.weight\",\n",
      "      \"backbone.blocks.16.norm2.bias\",\n",
      "      \"backbone.blocks.16.mlp.fc1.bias\",\n",
      "      \"backbone.blocks.16.mlp.fc2.bias\"\n",
      "    ],\n",
      "    \"lr_scale\": 0.4304672100000001,\n",
      "    \"lr\": 8.609344200000003e-06,\n",
      "    \"weight_decay\": 0.0\n",
      "  },\n",
      "  \"layer_17_decay\": {\n",
      "    \"param_names\": [\n",
      "      \"backbone.blocks.16.attn.relative_position_bias_table\",\n",
      "      \"backbone.blocks.16.attn.qkv.weight\",\n",
      "      \"backbone.blocks.16.attn.proj.weight\",\n",
      "      \"backbone.blocks.16.mlp.fc1.weight\",\n",
      "      \"backbone.blocks.16.mlp.fc2.weight\"\n",
      "    ],\n",
      "    \"lr_scale\": 0.4304672100000001,\n",
      "    \"lr\": 8.609344200000003e-06,\n",
      "    \"weight_decay\": 0.05\n",
      "  },\n",
      "  \"layer_18_no_decay\": {\n",
      "    \"param_names\": [\n",
      "      \"backbone.blocks.17.gamma_1\",\n",
      "      \"backbone.blocks.17.gamma_2\",\n",
      "      \"backbone.blocks.17.norm1.weight\",\n",
      "      \"backbone.blocks.17.norm1.bias\",\n",
      "      \"backbone.blocks.17.attn.q_bias\",\n",
      "      \"backbone.blocks.17.attn.v_bias\",\n",
      "      \"backbone.blocks.17.attn.proj.bias\",\n",
      "      \"backbone.blocks.17.norm2.weight\",\n",
      "      \"backbone.blocks.17.norm2.bias\",\n",
      "      \"backbone.blocks.17.mlp.fc1.bias\",\n",
      "      \"backbone.blocks.17.mlp.fc2.bias\"\n",
      "    ],\n",
      "    \"lr_scale\": 0.4782969000000001,\n",
      "    \"lr\": 9.565938000000002e-06,\n",
      "    \"weight_decay\": 0.0\n",
      "  },\n",
      "  \"layer_18_decay\": {\n",
      "    \"param_names\": [\n",
      "      \"backbone.blocks.17.attn.relative_position_bias_table\",\n",
      "      \"backbone.blocks.17.attn.qkv.weight\",\n",
      "      \"backbone.blocks.17.attn.proj.weight\",\n",
      "      \"backbone.blocks.17.mlp.fc1.weight\",\n",
      "      \"backbone.blocks.17.mlp.fc2.weight\"\n",
      "    ],\n",
      "    \"lr_scale\": 0.4782969000000001,\n",
      "    \"lr\": 9.565938000000002e-06,\n",
      "    \"weight_decay\": 0.05\n",
      "  },\n",
      "  \"layer_19_no_decay\": {\n",
      "    \"param_names\": [\n",
      "      \"backbone.blocks.18.gamma_1\",\n",
      "      \"backbone.blocks.18.gamma_2\",\n",
      "      \"backbone.blocks.18.norm1.weight\",\n",
      "      \"backbone.blocks.18.norm1.bias\",\n",
      "      \"backbone.blocks.18.attn.q_bias\",\n",
      "      \"backbone.blocks.18.attn.v_bias\",\n",
      "      \"backbone.blocks.18.attn.proj.bias\",\n",
      "      \"backbone.blocks.18.norm2.weight\",\n",
      "      \"backbone.blocks.18.norm2.bias\",\n",
      "      \"backbone.blocks.18.mlp.fc1.bias\",\n",
      "      \"backbone.blocks.18.mlp.fc2.bias\"\n",
      "    ],\n",
      "    \"lr_scale\": 0.531441,\n",
      "    \"lr\": 1.0628820000000002e-05,\n",
      "    \"weight_decay\": 0.0\n",
      "  },\n",
      "  \"layer_19_decay\": {\n",
      "    \"param_names\": [\n",
      "      \"backbone.blocks.18.attn.relative_position_bias_table\",\n",
      "      \"backbone.blocks.18.attn.qkv.weight\",\n",
      "      \"backbone.blocks.18.attn.proj.weight\",\n",
      "      \"backbone.blocks.18.mlp.fc1.weight\",\n",
      "      \"backbone.blocks.18.mlp.fc2.weight\"\n",
      "    ],\n",
      "    \"lr_scale\": 0.531441,\n",
      "    \"lr\": 1.0628820000000002e-05,\n",
      "    \"weight_decay\": 0.05\n",
      "  },\n",
      "  \"layer_20_no_decay\": {\n",
      "    \"param_names\": [\n",
      "      \"backbone.blocks.19.gamma_1\",\n",
      "      \"backbone.blocks.19.gamma_2\",\n",
      "      \"backbone.blocks.19.norm1.weight\",\n",
      "      \"backbone.blocks.19.norm1.bias\",\n",
      "      \"backbone.blocks.19.attn.q_bias\",\n",
      "      \"backbone.blocks.19.attn.v_bias\",\n",
      "      \"backbone.blocks.19.attn.proj.bias\",\n",
      "      \"backbone.blocks.19.norm2.weight\",\n",
      "      \"backbone.blocks.19.norm2.bias\",\n",
      "      \"backbone.blocks.19.mlp.fc1.bias\",\n",
      "      \"backbone.blocks.19.mlp.fc2.bias\"\n",
      "    ],\n",
      "    \"lr_scale\": 0.5904900000000001,\n",
      "    \"lr\": 1.1809800000000002e-05,\n",
      "    \"weight_decay\": 0.0\n",
      "  },\n",
      "  \"layer_20_decay\": {\n",
      "    \"param_names\": [\n",
      "      \"backbone.blocks.19.attn.relative_position_bias_table\",\n",
      "      \"backbone.blocks.19.attn.qkv.weight\",\n",
      "      \"backbone.blocks.19.attn.proj.weight\",\n",
      "      \"backbone.blocks.19.mlp.fc1.weight\",\n",
      "      \"backbone.blocks.19.mlp.fc2.weight\"\n",
      "    ],\n",
      "    \"lr_scale\": 0.5904900000000001,\n",
      "    \"lr\": 1.1809800000000002e-05,\n",
      "    \"weight_decay\": 0.05\n",
      "  },\n",
      "  \"layer_21_no_decay\": {\n",
      "    \"param_names\": [\n",
      "      \"backbone.blocks.20.gamma_1\",\n",
      "      \"backbone.blocks.20.gamma_2\",\n",
      "      \"backbone.blocks.20.norm1.weight\",\n",
      "      \"backbone.blocks.20.norm1.bias\",\n",
      "      \"backbone.blocks.20.attn.q_bias\",\n",
      "      \"backbone.blocks.20.attn.v_bias\",\n",
      "      \"backbone.blocks.20.attn.proj.bias\",\n",
      "      \"backbone.blocks.20.norm2.weight\",\n",
      "      \"backbone.blocks.20.norm2.bias\",\n",
      "      \"backbone.blocks.20.mlp.fc1.bias\",\n",
      "      \"backbone.blocks.20.mlp.fc2.bias\"\n",
      "    ],\n",
      "    \"lr_scale\": 0.6561,\n",
      "    \"lr\": 1.3122e-05,\n",
      "    \"weight_decay\": 0.0\n",
      "  },\n",
      "  \"layer_21_decay\": {\n",
      "    \"param_names\": [\n",
      "      \"backbone.blocks.20.attn.relative_position_bias_table\",\n",
      "      \"backbone.blocks.20.attn.qkv.weight\",\n",
      "      \"backbone.blocks.20.attn.proj.weight\",\n",
      "      \"backbone.blocks.20.mlp.fc1.weight\",\n",
      "      \"backbone.blocks.20.mlp.fc2.weight\"\n",
      "    ],\n",
      "    \"lr_scale\": 0.6561,\n",
      "    \"lr\": 1.3122e-05,\n",
      "    \"weight_decay\": 0.05\n",
      "  },\n",
      "  \"layer_22_no_decay\": {\n",
      "    \"param_names\": [\n",
      "      \"backbone.blocks.21.gamma_1\",\n",
      "      \"backbone.blocks.21.gamma_2\",\n",
      "      \"backbone.blocks.21.norm1.weight\",\n",
      "      \"backbone.blocks.21.norm1.bias\",\n",
      "      \"backbone.blocks.21.attn.q_bias\",\n",
      "      \"backbone.blocks.21.attn.v_bias\",\n",
      "      \"backbone.blocks.21.attn.proj.bias\",\n",
      "      \"backbone.blocks.21.norm2.weight\",\n",
      "      \"backbone.blocks.21.norm2.bias\",\n",
      "      \"backbone.blocks.21.mlp.fc1.bias\",\n",
      "      \"backbone.blocks.21.mlp.fc2.bias\"\n",
      "    ],\n",
      "    \"lr_scale\": 0.7290000000000001,\n",
      "    \"lr\": 1.4580000000000003e-05,\n",
      "    \"weight_decay\": 0.0\n",
      "  },\n",
      "  \"layer_22_decay\": {\n",
      "    \"param_names\": [\n",
      "      \"backbone.blocks.21.attn.relative_position_bias_table\",\n",
      "      \"backbone.blocks.21.attn.qkv.weight\",\n",
      "      \"backbone.blocks.21.attn.proj.weight\",\n",
      "      \"backbone.blocks.21.mlp.fc1.weight\",\n",
      "      \"backbone.blocks.21.mlp.fc2.weight\"\n",
      "    ],\n",
      "    \"lr_scale\": 0.7290000000000001,\n",
      "    \"lr\": 1.4580000000000003e-05,\n",
      "    \"weight_decay\": 0.05\n",
      "  },\n",
      "  \"layer_23_no_decay\": {\n",
      "    \"param_names\": [\n",
      "      \"backbone.blocks.22.gamma_1\",\n",
      "      \"backbone.blocks.22.gamma_2\",\n",
      "      \"backbone.blocks.22.norm1.weight\",\n",
      "      \"backbone.blocks.22.norm1.bias\",\n",
      "      \"backbone.blocks.22.attn.q_bias\",\n",
      "      \"backbone.blocks.22.attn.v_bias\",\n",
      "      \"backbone.blocks.22.attn.proj.bias\",\n",
      "      \"backbone.blocks.22.norm2.weight\",\n",
      "      \"backbone.blocks.22.norm2.bias\",\n",
      "      \"backbone.blocks.22.mlp.fc1.bias\",\n",
      "      \"backbone.blocks.22.mlp.fc2.bias\"\n",
      "    ],\n",
      "    \"lr_scale\": 0.81,\n",
      "    \"lr\": 1.62e-05,\n",
      "    \"weight_decay\": 0.0\n",
      "  },\n",
      "  \"layer_23_decay\": {\n",
      "    \"param_names\": [\n",
      "      \"backbone.blocks.22.attn.relative_position_bias_table\",\n",
      "      \"backbone.blocks.22.attn.qkv.weight\",\n",
      "      \"backbone.blocks.22.attn.proj.weight\",\n",
      "      \"backbone.blocks.22.mlp.fc1.weight\",\n",
      "      \"backbone.blocks.22.mlp.fc2.weight\"\n",
      "    ],\n",
      "    \"lr_scale\": 0.81,\n",
      "    \"lr\": 1.62e-05,\n",
      "    \"weight_decay\": 0.05\n",
      "  },\n",
      "  \"layer_24_no_decay\": {\n",
      "    \"param_names\": [\n",
      "      \"backbone.blocks.23.gamma_1\",\n",
      "      \"backbone.blocks.23.gamma_2\",\n",
      "      \"backbone.blocks.23.norm1.weight\",\n",
      "      \"backbone.blocks.23.norm1.bias\",\n",
      "      \"backbone.blocks.23.attn.q_bias\",\n",
      "      \"backbone.blocks.23.attn.v_bias\",\n",
      "      \"backbone.blocks.23.attn.proj.bias\",\n",
      "      \"backbone.blocks.23.norm2.weight\",\n",
      "      \"backbone.blocks.23.norm2.bias\",\n",
      "      \"backbone.blocks.23.mlp.fc1.bias\",\n",
      "      \"backbone.blocks.23.mlp.fc2.bias\"\n",
      "    ],\n",
      "    \"lr_scale\": 0.9,\n",
      "    \"lr\": 1.8e-05,\n",
      "    \"weight_decay\": 0.0\n",
      "  },\n",
      "  \"layer_24_decay\": {\n",
      "    \"param_names\": [\n",
      "      \"backbone.blocks.23.attn.relative_position_bias_table\",\n",
      "      \"backbone.blocks.23.attn.qkv.weight\",\n",
      "      \"backbone.blocks.23.attn.proj.weight\",\n",
      "      \"backbone.blocks.23.mlp.fc1.weight\",\n",
      "      \"backbone.blocks.23.mlp.fc2.weight\"\n",
      "    ],\n",
      "    \"lr_scale\": 0.9,\n",
      "    \"lr\": 1.8e-05,\n",
      "    \"weight_decay\": 0.05\n",
      "  },\n",
      "  \"layer_25_no_decay\": {\n",
      "    \"param_names\": [\n",
      "      \"backbone.spm.stem.1.weight\",\n",
      "      \"backbone.spm.stem.1.bias\",\n",
      "      \"backbone.spm.stem.4.weight\",\n",
      "      \"backbone.spm.stem.4.bias\",\n",
      "      \"backbone.spm.stem.7.weight\",\n",
      "      \"backbone.spm.stem.7.bias\",\n",
      "      \"backbone.spm.conv2.1.weight\",\n",
      "      \"backbone.spm.conv2.1.bias\",\n",
      "      \"backbone.spm.conv3.1.weight\",\n",
      "      \"backbone.spm.conv3.1.bias\",\n",
      "      \"backbone.spm.conv4.1.weight\",\n",
      "      \"backbone.spm.conv4.1.bias\",\n",
      "      \"backbone.spm.fc1.bias\",\n",
      "      \"backbone.spm.fc2.bias\",\n",
      "      \"backbone.spm.fc3.bias\",\n",
      "      \"backbone.spm.fc4.bias\",\n",
      "      \"backbone.interactions.0.injector.gamma\",\n",
      "      \"backbone.interactions.0.injector.query_norm.weight\",\n",
      "      \"backbone.interactions.0.injector.query_norm.bias\",\n",
      "      \"backbone.interactions.0.injector.feat_norm.weight\",\n",
      "      \"backbone.interactions.0.injector.feat_norm.bias\",\n",
      "      \"backbone.interactions.0.injector.attn.sampling_offsets.bias\",\n",
      "      \"backbone.interactions.0.injector.attn.attention_weights.bias\",\n",
      "      \"backbone.interactions.0.injector.attn.value_proj.bias\",\n",
      "      \"backbone.interactions.0.injector.attn.output_proj.bias\",\n",
      "      \"backbone.interactions.0.extractor.query_norm.weight\",\n",
      "      \"backbone.interactions.0.extractor.query_norm.bias\",\n",
      "      \"backbone.interactions.0.extractor.feat_norm.weight\",\n",
      "      \"backbone.interactions.0.extractor.feat_norm.bias\",\n",
      "      \"backbone.interactions.0.extractor.attn.sampling_offsets.bias\",\n",
      "      \"backbone.interactions.0.extractor.attn.attention_weights.bias\",\n",
      "      \"backbone.interactions.0.extractor.attn.value_proj.bias\",\n",
      "      \"backbone.interactions.0.extractor.attn.output_proj.bias\",\n",
      "      \"backbone.interactions.0.extractor.ffn.fc1.bias\",\n",
      "      \"backbone.interactions.0.extractor.ffn.dwconv.dwconv.bias\",\n",
      "      \"backbone.interactions.0.extractor.ffn.fc2.bias\",\n",
      "      \"backbone.interactions.0.extractor.ffn_norm.weight\",\n",
      "      \"backbone.interactions.0.extractor.ffn_norm.bias\",\n",
      "      \"backbone.interactions.1.injector.gamma\",\n",
      "      \"backbone.interactions.1.injector.query_norm.weight\",\n",
      "      \"backbone.interactions.1.injector.query_norm.bias\",\n",
      "      \"backbone.interactions.1.injector.feat_norm.weight\",\n",
      "      \"backbone.interactions.1.injector.feat_norm.bias\",\n",
      "      \"backbone.interactions.1.injector.attn.sampling_offsets.bias\",\n",
      "      \"backbone.interactions.1.injector.attn.attention_weights.bias\",\n",
      "      \"backbone.interactions.1.injector.attn.value_proj.bias\",\n",
      "      \"backbone.interactions.1.injector.attn.output_proj.bias\",\n",
      "      \"backbone.interactions.1.extractor.query_norm.weight\",\n",
      "      \"backbone.interactions.1.extractor.query_norm.bias\",\n",
      "      \"backbone.interactions.1.extractor.feat_norm.weight\",\n",
      "      \"backbone.interactions.1.extractor.feat_norm.bias\",\n",
      "      \"backbone.interactions.1.extractor.attn.sampling_offsets.bias\",\n",
      "      \"backbone.interactions.1.extractor.attn.attention_weights.bias\",\n",
      "      \"backbone.interactions.1.extractor.attn.value_proj.bias\",\n",
      "      \"backbone.interactions.1.extractor.attn.output_proj.bias\",\n",
      "      \"backbone.interactions.1.extractor.ffn.fc1.bias\",\n",
      "      \"backbone.interactions.1.extractor.ffn.dwconv.dwconv.bias\",\n",
      "      \"backbone.interactions.1.extractor.ffn.fc2.bias\",\n",
      "      \"backbone.interactions.1.extractor.ffn_norm.weight\",\n",
      "      \"backbone.interactions.1.extractor.ffn_norm.bias\",\n",
      "      \"backbone.interactions.2.injector.gamma\",\n",
      "      \"backbone.interactions.2.injector.query_norm.weight\",\n",
      "      \"backbone.interactions.2.injector.query_norm.bias\",\n",
      "      \"backbone.interactions.2.injector.feat_norm.weight\",\n",
      "      \"backbone.interactions.2.injector.feat_norm.bias\",\n",
      "      \"backbone.interactions.2.injector.attn.sampling_offsets.bias\",\n",
      "      \"backbone.interactions.2.injector.attn.attention_weights.bias\",\n",
      "      \"backbone.interactions.2.injector.attn.value_proj.bias\",\n",
      "      \"backbone.interactions.2.injector.attn.output_proj.bias\",\n",
      "      \"backbone.interactions.2.extractor.query_norm.weight\",\n",
      "      \"backbone.interactions.2.extractor.query_norm.bias\",\n",
      "      \"backbone.interactions.2.extractor.feat_norm.weight\",\n",
      "      \"backbone.interactions.2.extractor.feat_norm.bias\",\n",
      "      \"backbone.interactions.2.extractor.attn.sampling_offsets.bias\",\n",
      "      \"backbone.interactions.2.extractor.attn.attention_weights.bias\",\n",
      "      \"backbone.interactions.2.extractor.attn.value_proj.bias\",\n",
      "      \"backbone.interactions.2.extractor.attn.output_proj.bias\",\n",
      "      \"backbone.interactions.2.extractor.ffn.fc1.bias\",\n",
      "      \"backbone.interactions.2.extractor.ffn.dwconv.dwconv.bias\",\n",
      "      \"backbone.interactions.2.extractor.ffn.fc2.bias\",\n",
      "      \"backbone.interactions.2.extractor.ffn_norm.weight\",\n",
      "      \"backbone.interactions.2.extractor.ffn_norm.bias\",\n",
      "      \"backbone.interactions.3.injector.gamma\",\n",
      "      \"backbone.interactions.3.injector.query_norm.weight\",\n",
      "      \"backbone.interactions.3.injector.query_norm.bias\",\n",
      "      \"backbone.interactions.3.injector.feat_norm.weight\",\n",
      "      \"backbone.interactions.3.injector.feat_norm.bias\",\n",
      "      \"backbone.interactions.3.injector.attn.sampling_offsets.bias\",\n",
      "      \"backbone.interactions.3.injector.attn.attention_weights.bias\",\n",
      "      \"backbone.interactions.3.injector.attn.value_proj.bias\",\n",
      "      \"backbone.interactions.3.injector.attn.output_proj.bias\",\n",
      "      \"backbone.interactions.3.extractor.query_norm.weight\",\n",
      "      \"backbone.interactions.3.extractor.query_norm.bias\",\n",
      "      \"backbone.interactions.3.extractor.feat_norm.weight\",\n",
      "      \"backbone.interactions.3.extractor.feat_norm.bias\",\n",
      "      \"backbone.interactions.3.extractor.attn.sampling_offsets.bias\",\n",
      "      \"backbone.interactions.3.extractor.attn.attention_weights.bias\",\n",
      "      \"backbone.interactions.3.extractor.attn.value_proj.bias\",\n",
      "      \"backbone.interactions.3.extractor.attn.output_proj.bias\",\n",
      "      \"backbone.interactions.3.extractor.ffn.fc1.bias\",\n",
      "      \"backbone.interactions.3.extractor.ffn.dwconv.dwconv.bias\",\n",
      "      \"backbone.interactions.3.extractor.ffn.fc2.bias\",\n",
      "      \"backbone.interactions.3.extractor.ffn_norm.weight\",\n",
      "      \"backbone.interactions.3.extractor.ffn_norm.bias\",\n",
      "      \"backbone.interactions.3.extra_extractors.0.query_norm.weight\",\n",
      "      \"backbone.interactions.3.extra_extractors.0.query_norm.bias\",\n",
      "      \"backbone.interactions.3.extra_extractors.0.feat_norm.weight\",\n",
      "      \"backbone.interactions.3.extra_extractors.0.feat_norm.bias\",\n",
      "      \"backbone.interactions.3.extra_extractors.0.attn.sampling_offsets.bias\",\n",
      "      \"backbone.interactions.3.extra_extractors.0.attn.attention_weights.bias\",\n",
      "      \"backbone.interactions.3.extra_extractors.0.attn.value_proj.bias\",\n",
      "      \"backbone.interactions.3.extra_extractors.0.attn.output_proj.bias\",\n",
      "      \"backbone.interactions.3.extra_extractors.0.ffn.fc1.bias\",\n",
      "      \"backbone.interactions.3.extra_extractors.0.ffn.dwconv.dwconv.bias\",\n",
      "      \"backbone.interactions.3.extra_extractors.0.ffn.fc2.bias\",\n",
      "      \"backbone.interactions.3.extra_extractors.0.ffn_norm.weight\",\n",
      "      \"backbone.interactions.3.extra_extractors.0.ffn_norm.bias\",\n",
      "      \"backbone.interactions.3.extra_extractors.1.query_norm.weight\",\n",
      "      \"backbone.interactions.3.extra_extractors.1.query_norm.bias\",\n",
      "      \"backbone.interactions.3.extra_extractors.1.feat_norm.weight\",\n",
      "      \"backbone.interactions.3.extra_extractors.1.feat_norm.bias\",\n",
      "      \"backbone.interactions.3.extra_extractors.1.attn.sampling_offsets.bias\",\n",
      "      \"backbone.interactions.3.extra_extractors.1.attn.attention_weights.bias\",\n",
      "      \"backbone.interactions.3.extra_extractors.1.attn.value_proj.bias\",\n",
      "      \"backbone.interactions.3.extra_extractors.1.attn.output_proj.bias\",\n",
      "      \"backbone.interactions.3.extra_extractors.1.ffn.fc1.bias\",\n",
      "      \"backbone.interactions.3.extra_extractors.1.ffn.dwconv.dwconv.bias\",\n",
      "      \"backbone.interactions.3.extra_extractors.1.ffn.fc2.bias\",\n",
      "      \"backbone.interactions.3.extra_extractors.1.ffn_norm.weight\",\n",
      "      \"backbone.interactions.3.extra_extractors.1.ffn_norm.bias\",\n",
      "      \"backbone.up.bias\",\n",
      "      \"backbone.norm1.weight\",\n",
      "      \"backbone.norm1.bias\",\n",
      "      \"backbone.norm2.weight\",\n",
      "      \"backbone.norm2.bias\",\n",
      "      \"backbone.norm3.weight\",\n",
      "      \"backbone.norm3.bias\",\n",
      "      \"backbone.norm4.weight\",\n",
      "      \"backbone.norm4.bias\",\n",
      "      \"decode_head.pixel_decoder.input_convs.0.conv.bias\",\n",
      "      \"decode_head.pixel_decoder.input_convs.0.gn.weight\",\n",
      "      \"decode_head.pixel_decoder.input_convs.0.gn.bias\",\n",
      "      \"decode_head.pixel_decoder.input_convs.1.conv.bias\",\n",
      "      \"decode_head.pixel_decoder.input_convs.1.gn.weight\",\n",
      "      \"decode_head.pixel_decoder.input_convs.1.gn.bias\",\n",
      "      \"decode_head.pixel_decoder.input_convs.2.conv.bias\",\n",
      "      \"decode_head.pixel_decoder.input_convs.2.gn.weight\",\n",
      "      \"decode_head.pixel_decoder.input_convs.2.gn.bias\",\n",
      "      \"decode_head.pixel_decoder.encoder.layers.0.attentions.0.sampling_offsets.bias\",\n",
      "      \"decode_head.pixel_decoder.encoder.layers.0.attentions.0.attention_weights.bias\",\n",
      "      \"decode_head.pixel_decoder.encoder.layers.0.attentions.0.value_proj.bias\",\n",
      "      \"decode_head.pixel_decoder.encoder.layers.0.attentions.0.output_proj.bias\",\n",
      "      \"decode_head.pixel_decoder.encoder.layers.0.ffns.0.layers.0.0.bias\",\n",
      "      \"decode_head.pixel_decoder.encoder.layers.0.ffns.0.layers.1.bias\",\n",
      "      \"decode_head.pixel_decoder.encoder.layers.0.norms.0.weight\",\n",
      "      \"decode_head.pixel_decoder.encoder.layers.0.norms.0.bias\",\n",
      "      \"decode_head.pixel_decoder.encoder.layers.0.norms.1.weight\",\n",
      "      \"decode_head.pixel_decoder.encoder.layers.0.norms.1.bias\",\n",
      "      \"decode_head.pixel_decoder.encoder.layers.1.attentions.0.sampling_offsets.bias\",\n",
      "      \"decode_head.pixel_decoder.encoder.layers.1.attentions.0.attention_weights.bias\",\n",
      "      \"decode_head.pixel_decoder.encoder.layers.1.attentions.0.value_proj.bias\",\n",
      "      \"decode_head.pixel_decoder.encoder.layers.1.attentions.0.output_proj.bias\",\n",
      "      \"decode_head.pixel_decoder.encoder.layers.1.ffns.0.layers.0.0.bias\",\n",
      "      \"decode_head.pixel_decoder.encoder.layers.1.ffns.0.layers.1.bias\",\n",
      "      \"decode_head.pixel_decoder.encoder.layers.1.norms.0.weight\",\n",
      "      \"decode_head.pixel_decoder.encoder.layers.1.norms.0.bias\",\n",
      "      \"decode_head.pixel_decoder.encoder.layers.1.norms.1.weight\",\n",
      "      \"decode_head.pixel_decoder.encoder.layers.1.norms.1.bias\",\n",
      "      \"decode_head.pixel_decoder.encoder.layers.2.attentions.0.sampling_offsets.bias\",\n",
      "      \"decode_head.pixel_decoder.encoder.layers.2.attentions.0.attention_weights.bias\",\n",
      "      \"decode_head.pixel_decoder.encoder.layers.2.attentions.0.value_proj.bias\",\n",
      "      \"decode_head.pixel_decoder.encoder.layers.2.attentions.0.output_proj.bias\",\n",
      "      \"decode_head.pixel_decoder.encoder.layers.2.ffns.0.layers.0.0.bias\",\n",
      "      \"decode_head.pixel_decoder.encoder.layers.2.ffns.0.layers.1.bias\",\n",
      "      \"decode_head.pixel_decoder.encoder.layers.2.norms.0.weight\",\n",
      "      \"decode_head.pixel_decoder.encoder.layers.2.norms.0.bias\",\n",
      "      \"decode_head.pixel_decoder.encoder.layers.2.norms.1.weight\",\n",
      "      \"decode_head.pixel_decoder.encoder.layers.2.norms.1.bias\",\n",
      "      \"decode_head.pixel_decoder.encoder.layers.3.attentions.0.sampling_offsets.bias\",\n",
      "      \"decode_head.pixel_decoder.encoder.layers.3.attentions.0.attention_weights.bias\",\n",
      "      \"decode_head.pixel_decoder.encoder.layers.3.attentions.0.value_proj.bias\",\n",
      "      \"decode_head.pixel_decoder.encoder.layers.3.attentions.0.output_proj.bias\",\n",
      "      \"decode_head.pixel_decoder.encoder.layers.3.ffns.0.layers.0.0.bias\",\n",
      "      \"decode_head.pixel_decoder.encoder.layers.3.ffns.0.layers.1.bias\",\n",
      "      \"decode_head.pixel_decoder.encoder.layers.3.norms.0.weight\",\n",
      "      \"decode_head.pixel_decoder.encoder.layers.3.norms.0.bias\",\n",
      "      \"decode_head.pixel_decoder.encoder.layers.3.norms.1.weight\",\n",
      "      \"decode_head.pixel_decoder.encoder.layers.3.norms.1.bias\",\n",
      "      \"decode_head.pixel_decoder.encoder.layers.4.attentions.0.sampling_offsets.bias\",\n",
      "      \"decode_head.pixel_decoder.encoder.layers.4.attentions.0.attention_weights.bias\",\n",
      "      \"decode_head.pixel_decoder.encoder.layers.4.attentions.0.value_proj.bias\",\n",
      "      \"decode_head.pixel_decoder.encoder.layers.4.attentions.0.output_proj.bias\",\n",
      "      \"decode_head.pixel_decoder.encoder.layers.4.ffns.0.layers.0.0.bias\",\n",
      "      \"decode_head.pixel_decoder.encoder.layers.4.ffns.0.layers.1.bias\",\n",
      "      \"decode_head.pixel_decoder.encoder.layers.4.norms.0.weight\",\n",
      "      \"decode_head.pixel_decoder.encoder.layers.4.norms.0.bias\",\n",
      "      \"decode_head.pixel_decoder.encoder.layers.4.norms.1.weight\",\n",
      "      \"decode_head.pixel_decoder.encoder.layers.4.norms.1.bias\",\n",
      "      \"decode_head.pixel_decoder.encoder.layers.5.attentions.0.sampling_offsets.bias\",\n",
      "      \"decode_head.pixel_decoder.encoder.layers.5.attentions.0.attention_weights.bias\",\n",
      "      \"decode_head.pixel_decoder.encoder.layers.5.attentions.0.value_proj.bias\",\n",
      "      \"decode_head.pixel_decoder.encoder.layers.5.attentions.0.output_proj.bias\",\n",
      "      \"decode_head.pixel_decoder.encoder.layers.5.ffns.0.layers.0.0.bias\",\n",
      "      \"decode_head.pixel_decoder.encoder.layers.5.ffns.0.layers.1.bias\",\n",
      "      \"decode_head.pixel_decoder.encoder.layers.5.norms.0.weight\",\n",
      "      \"decode_head.pixel_decoder.encoder.layers.5.norms.0.bias\",\n",
      "      \"decode_head.pixel_decoder.encoder.layers.5.norms.1.weight\",\n",
      "      \"decode_head.pixel_decoder.encoder.layers.5.norms.1.bias\",\n",
      "      \"decode_head.pixel_decoder.lateral_convs.0.gn.weight\",\n",
      "      \"decode_head.pixel_decoder.lateral_convs.0.gn.bias\",\n",
      "      \"decode_head.pixel_decoder.output_convs.0.gn.weight\",\n",
      "      \"decode_head.pixel_decoder.output_convs.0.gn.bias\",\n",
      "      \"decode_head.pixel_decoder.mask_feature.bias\",\n",
      "      \"decode_head.transformer_decoder.layers.0.attentions.0.attn.in_proj_bias\",\n",
      "      \"decode_head.transformer_decoder.layers.0.attentions.0.attn.out_proj.bias\",\n",
      "      \"decode_head.transformer_decoder.layers.0.attentions.1.attn.in_proj_bias\",\n",
      "      \"decode_head.transformer_decoder.layers.0.attentions.1.attn.out_proj.bias\",\n",
      "      \"decode_head.transformer_decoder.layers.0.ffns.0.layers.0.0.bias\",\n",
      "      \"decode_head.transformer_decoder.layers.0.ffns.0.layers.1.bias\",\n",
      "      \"decode_head.transformer_decoder.layers.0.norms.0.weight\",\n",
      "      \"decode_head.transformer_decoder.layers.0.norms.0.bias\",\n",
      "      \"decode_head.transformer_decoder.layers.0.norms.1.weight\",\n",
      "      \"decode_head.transformer_decoder.layers.0.norms.1.bias\",\n",
      "      \"decode_head.transformer_decoder.layers.0.norms.2.weight\",\n",
      "      \"decode_head.transformer_decoder.layers.0.norms.2.bias\",\n",
      "      \"decode_head.transformer_decoder.layers.1.attentions.0.attn.in_proj_bias\",\n",
      "      \"decode_head.transformer_decoder.layers.1.attentions.0.attn.out_proj.bias\",\n",
      "      \"decode_head.transformer_decoder.layers.1.attentions.1.attn.in_proj_bias\",\n",
      "      \"decode_head.transformer_decoder.layers.1.attentions.1.attn.out_proj.bias\",\n",
      "      \"decode_head.transformer_decoder.layers.1.ffns.0.layers.0.0.bias\",\n",
      "      \"decode_head.transformer_decoder.layers.1.ffns.0.layers.1.bias\",\n",
      "      \"decode_head.transformer_decoder.layers.1.norms.0.weight\",\n",
      "      \"decode_head.transformer_decoder.layers.1.norms.0.bias\",\n",
      "      \"decode_head.transformer_decoder.layers.1.norms.1.weight\",\n",
      "      \"decode_head.transformer_decoder.layers.1.norms.1.bias\",\n",
      "      \"decode_head.transformer_decoder.layers.1.norms.2.weight\",\n",
      "      \"decode_head.transformer_decoder.layers.1.norms.2.bias\",\n",
      "      \"decode_head.transformer_decoder.layers.2.attentions.0.attn.in_proj_bias\",\n",
      "      \"decode_head.transformer_decoder.layers.2.attentions.0.attn.out_proj.bias\",\n",
      "      \"decode_head.transformer_decoder.layers.2.attentions.1.attn.in_proj_bias\",\n",
      "      \"decode_head.transformer_decoder.layers.2.attentions.1.attn.out_proj.bias\",\n",
      "      \"decode_head.transformer_decoder.layers.2.ffns.0.layers.0.0.bias\",\n",
      "      \"decode_head.transformer_decoder.layers.2.ffns.0.layers.1.bias\",\n",
      "      \"decode_head.transformer_decoder.layers.2.norms.0.weight\",\n",
      "      \"decode_head.transformer_decoder.layers.2.norms.0.bias\",\n",
      "      \"decode_head.transformer_decoder.layers.2.norms.1.weight\",\n",
      "      \"decode_head.transformer_decoder.layers.2.norms.1.bias\",\n",
      "      \"decode_head.transformer_decoder.layers.2.norms.2.weight\",\n",
      "      \"decode_head.transformer_decoder.layers.2.norms.2.bias\",\n",
      "      \"decode_head.transformer_decoder.layers.3.attentions.0.attn.in_proj_bias\",\n",
      "      \"decode_head.transformer_decoder.layers.3.attentions.0.attn.out_proj.bias\",\n",
      "      \"decode_head.transformer_decoder.layers.3.attentions.1.attn.in_proj_bias\",\n",
      "      \"decode_head.transformer_decoder.layers.3.attentions.1.attn.out_proj.bias\",\n",
      "      \"decode_head.transformer_decoder.layers.3.ffns.0.layers.0.0.bias\",\n",
      "      \"decode_head.transformer_decoder.layers.3.ffns.0.layers.1.bias\",\n",
      "      \"decode_head.transformer_decoder.layers.3.norms.0.weight\",\n",
      "      \"decode_head.transformer_decoder.layers.3.norms.0.bias\",\n",
      "      \"decode_head.transformer_decoder.layers.3.norms.1.weight\",\n",
      "      \"decode_head.transformer_decoder.layers.3.norms.1.bias\",\n",
      "      \"decode_head.transformer_decoder.layers.3.norms.2.weight\",\n",
      "      \"decode_head.transformer_decoder.layers.3.norms.2.bias\",\n",
      "      \"decode_head.transformer_decoder.layers.4.attentions.0.attn.in_proj_bias\",\n",
      "      \"decode_head.transformer_decoder.layers.4.attentions.0.attn.out_proj.bias\",\n",
      "      \"decode_head.transformer_decoder.layers.4.attentions.1.attn.in_proj_bias\",\n",
      "      \"decode_head.transformer_decoder.layers.4.attentions.1.attn.out_proj.bias\",\n",
      "      \"decode_head.transformer_decoder.layers.4.ffns.0.layers.0.0.bias\",\n",
      "      \"decode_head.transformer_decoder.layers.4.ffns.0.layers.1.bias\",\n",
      "      \"decode_head.transformer_decoder.layers.4.norms.0.weight\",\n",
      "      \"decode_head.transformer_decoder.layers.4.norms.0.bias\",\n",
      "      \"decode_head.transformer_decoder.layers.4.norms.1.weight\",\n",
      "      \"decode_head.transformer_decoder.layers.4.norms.1.bias\",\n",
      "      \"decode_head.transformer_decoder.layers.4.norms.2.weight\",\n",
      "      \"decode_head.transformer_decoder.layers.4.norms.2.bias\",\n",
      "      \"decode_head.transformer_decoder.layers.5.attentions.0.attn.in_proj_bias\",\n",
      "      \"decode_head.transformer_decoder.layers.5.attentions.0.attn.out_proj.bias\",\n",
      "      \"decode_head.transformer_decoder.layers.5.attentions.1.attn.in_proj_bias\",\n",
      "      \"decode_head.transformer_decoder.layers.5.attentions.1.attn.out_proj.bias\",\n",
      "      \"decode_head.transformer_decoder.layers.5.ffns.0.layers.0.0.bias\",\n",
      "      \"decode_head.transformer_decoder.layers.5.ffns.0.layers.1.bias\",\n",
      "      \"decode_head.transformer_decoder.layers.5.norms.0.weight\",\n",
      "      \"decode_head.transformer_decoder.layers.5.norms.0.bias\",\n",
      "      \"decode_head.transformer_decoder.layers.5.norms.1.weight\",\n",
      "      \"decode_head.transformer_decoder.layers.5.norms.1.bias\",\n",
      "      \"decode_head.transformer_decoder.layers.5.norms.2.weight\",\n",
      "      \"decode_head.transformer_decoder.layers.5.norms.2.bias\",\n",
      "      \"decode_head.transformer_decoder.layers.6.attentions.0.attn.in_proj_bias\",\n",
      "      \"decode_head.transformer_decoder.layers.6.attentions.0.attn.out_proj.bias\",\n",
      "      \"decode_head.transformer_decoder.layers.6.attentions.1.attn.in_proj_bias\",\n",
      "      \"decode_head.transformer_decoder.layers.6.attentions.1.attn.out_proj.bias\",\n",
      "      \"decode_head.transformer_decoder.layers.6.ffns.0.layers.0.0.bias\",\n",
      "      \"decode_head.transformer_decoder.layers.6.ffns.0.layers.1.bias\",\n",
      "      \"decode_head.transformer_decoder.layers.6.norms.0.weight\",\n",
      "      \"decode_head.transformer_decoder.layers.6.norms.0.bias\",\n",
      "      \"decode_head.transformer_decoder.layers.6.norms.1.weight\",\n",
      "      \"decode_head.transformer_decoder.layers.6.norms.1.bias\",\n",
      "      \"decode_head.transformer_decoder.layers.6.norms.2.weight\",\n",
      "      \"decode_head.transformer_decoder.layers.6.norms.2.bias\",\n",
      "      \"decode_head.transformer_decoder.layers.7.attentions.0.attn.in_proj_bias\",\n",
      "      \"decode_head.transformer_decoder.layers.7.attentions.0.attn.out_proj.bias\",\n",
      "      \"decode_head.transformer_decoder.layers.7.attentions.1.attn.in_proj_bias\",\n",
      "      \"decode_head.transformer_decoder.layers.7.attentions.1.attn.out_proj.bias\",\n",
      "      \"decode_head.transformer_decoder.layers.7.ffns.0.layers.0.0.bias\",\n",
      "      \"decode_head.transformer_decoder.layers.7.ffns.0.layers.1.bias\",\n",
      "      \"decode_head.transformer_decoder.layers.7.norms.0.weight\",\n",
      "      \"decode_head.transformer_decoder.layers.7.norms.0.bias\",\n",
      "      \"decode_head.transformer_decoder.layers.7.norms.1.weight\",\n",
      "      \"decode_head.transformer_decoder.layers.7.norms.1.bias\",\n",
      "      \"decode_head.transformer_decoder.layers.7.norms.2.weight\",\n",
      "      \"decode_head.transformer_decoder.layers.7.norms.2.bias\",\n",
      "      \"decode_head.transformer_decoder.layers.8.attentions.0.attn.in_proj_bias\",\n",
      "      \"decode_head.transformer_decoder.layers.8.attentions.0.attn.out_proj.bias\",\n",
      "      \"decode_head.transformer_decoder.layers.8.attentions.1.attn.in_proj_bias\",\n",
      "      \"decode_head.transformer_decoder.layers.8.attentions.1.attn.out_proj.bias\",\n",
      "      \"decode_head.transformer_decoder.layers.8.ffns.0.layers.0.0.bias\",\n",
      "      \"decode_head.transformer_decoder.layers.8.ffns.0.layers.1.bias\",\n",
      "      \"decode_head.transformer_decoder.layers.8.norms.0.weight\",\n",
      "      \"decode_head.transformer_decoder.layers.8.norms.0.bias\",\n",
      "      \"decode_head.transformer_decoder.layers.8.norms.1.weight\",\n",
      "      \"decode_head.transformer_decoder.layers.8.norms.1.bias\",\n",
      "      \"decode_head.transformer_decoder.layers.8.norms.2.weight\",\n",
      "      \"decode_head.transformer_decoder.layers.8.norms.2.bias\",\n",
      "      \"decode_head.transformer_decoder.post_norm.weight\",\n",
      "      \"decode_head.transformer_decoder.post_norm.bias\"\n",
      "    ],\n",
      "    \"lr_scale\": 1.0,\n",
      "    \"lr\": 2e-05,\n",
      "    \"weight_decay\": 0.0\n",
      "  }\n",
      "}\n",
      "{'num_layers': 24, 'layer_decay_rate': 0.9}\n",
      "Build LayerDecayOptimizerConstructor 0.900000 - 26\n",
      "2024-02-14 13:32:25,743 - mmseg - INFO - Loaded 40 images\n",
      "2024-02-14 13:32:25,744 - mmseg - INFO - load checkpoint from local path: /workspace/ViT-Adapter/segmentation/mask2former_beit_adapter_large_896_80k_ade20k.pth.tar\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-14 13:32:27,091 - mmseg - WARNING - The model and loaded state dict do not match exactly\n",
      "\n",
      "size mismatch for decode_head.cls_embed.weight: copying a param with shape torch.Size([151, 1024]) from checkpoint, the shape in current model is torch.Size([7, 1024]).\n",
      "size mismatch for decode_head.cls_embed.bias: copying a param with shape torch.Size([151]) from checkpoint, the shape in current model is torch.Size([7]).\n",
      "missing keys in source state_dict: backbone.blocks.0.attn.relative_position_index, backbone.blocks.1.attn.relative_position_index, backbone.blocks.2.attn.relative_position_index, backbone.blocks.3.attn.relative_position_index, backbone.blocks.4.attn.relative_position_index, backbone.blocks.5.attn.relative_position_index, backbone.blocks.6.attn.relative_position_index, backbone.blocks.7.attn.relative_position_index, backbone.blocks.8.attn.relative_position_index, backbone.blocks.9.attn.relative_position_index, backbone.blocks.10.attn.relative_position_index, backbone.blocks.11.attn.relative_position_index, backbone.blocks.12.attn.relative_position_index, backbone.blocks.13.attn.relative_position_index, backbone.blocks.14.attn.relative_position_index, backbone.blocks.15.attn.relative_position_index, backbone.blocks.16.attn.relative_position_index, backbone.blocks.17.attn.relative_position_index, backbone.blocks.18.attn.relative_position_index, backbone.blocks.19.attn.relative_position_index, backbone.blocks.20.attn.relative_position_index, backbone.blocks.21.attn.relative_position_index, backbone.blocks.22.attn.relative_position_index, backbone.blocks.23.attn.relative_position_index\n",
      "\n",
      "2024-02-14 13:32:27,102 - mmseg - INFO - Start running, host: root@eeab1feafb63, work_dir: /workspace/ViT-Adapter/segmentation/work_dirs/pizze_training_large\n",
      "2024-02-14 13:32:27,103 - mmseg - INFO - Hooks will be executed in the following order:\n",
      "before_run:\n",
      "(VERY_HIGH   ) PolyLrUpdaterHook                  \n",
      "(NORMAL      ) CheckpointHook                     \n",
      "(LOW         ) DistEvalHook                       \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "before_train_epoch:\n",
      "(VERY_HIGH   ) PolyLrUpdaterHook                  \n",
      "(LOW         ) IterTimerHook                      \n",
      "(LOW         ) DistEvalHook                       \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "before_train_iter:\n",
      "(VERY_HIGH   ) PolyLrUpdaterHook                  \n",
      "(LOW         ) IterTimerHook                      \n",
      "(LOW         ) DistEvalHook                       \n",
      " -------------------- \n",
      "after_train_iter:\n",
      "(ABOVE_NORMAL) OptimizerHook                      \n",
      "(NORMAL      ) CheckpointHook                     \n",
      "(LOW         ) IterTimerHook                      \n",
      "(LOW         ) DistEvalHook                       \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "after_train_epoch:\n",
      "(NORMAL      ) CheckpointHook                     \n",
      "(LOW         ) DistEvalHook                       \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "before_val_epoch:\n",
      "(LOW         ) IterTimerHook                      \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "before_val_iter:\n",
      "(LOW         ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_iter:\n",
      "(LOW         ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_epoch:\n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "after_run:\n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "2024-02-14 13:32:27,103 - mmseg - INFO - workflow: [('train', 1)], max: 80000 iters\n",
      "2024-02-14 13:32:27,103 - mmseg - INFO - Checkpoints will be saved to /workspace/ViT-Adapter/segmentation/work_dirs/pizze_training_large by HardDiskBackend.\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:3658: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and now uses scale_factor directly, instead of relying on the computed output size. If you wish to restore the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
      "  \"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:3658: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and now uses scale_factor directly, instead of relying on the computed output size. If you wish to restore the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
      "  \"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:3658: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and now uses scale_factor directly, instead of relying on the computed output size. If you wish to restore the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
      "  \"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:3658: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and now uses scale_factor directly, instead of relying on the computed output size. If you wish to restore the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
      "  \"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
      "/opt/conda/lib/python3.7/site-packages/torch/_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.\n",
      "To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /pytorch/aten/src/ATen/native/BinaryOps.cpp:467.)\n",
      "  return torch.floor_divide(self, other)\n",
      "/opt/conda/lib/python3.7/site-packages/torch/_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.\n",
      "To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /pytorch/aten/src/ATen/native/BinaryOps.cpp:467.)\n",
      "  return torch.floor_divide(self, other)\n",
      "/opt/conda/lib/python3.7/site-packages/torch/_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.\n",
      "To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /pytorch/aten/src/ATen/native/BinaryOps.cpp:467.)\n",
      "  return torch.floor_divide(self, other)\n",
      "/opt/conda/lib/python3.7/site-packages/torch/_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.\n",
      "To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /pytorch/aten/src/ATen/native/BinaryOps.cpp:467.)\n",
      "  return torch.floor_divide(self, other)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-14 13:32:55,318 - mmcv - INFO - Reducer buckets have been rebuilt in this iteration.\n",
      "2024-02-14 13:33:14,486 - mmseg - INFO - Iter [10/80000]\tlr: 8.615e-09, eta: 2 days, 0:20:57, time: 2.176, data_time: 0.020, memory: 23505, decode.loss_cls: 4.5663, decode.loss_mask: 3.1641, decode.loss_dice: 2.6144, decode.d0.loss_cls: 4.2356, decode.d0.loss_mask: 3.0886, decode.d0.loss_dice: 2.9533, decode.d1.loss_cls: 5.4528, decode.d1.loss_mask: 2.7100, decode.d1.loss_dice: 2.6706, decode.d2.loss_cls: 5.2882, decode.d2.loss_mask: 2.7008, decode.d2.loss_dice: 2.6443, decode.d3.loss_cls: 4.7237, decode.d3.loss_mask: 2.7771, decode.d3.loss_dice: 2.6473, decode.d4.loss_cls: 4.4830, decode.d4.loss_mask: 2.9702, decode.d4.loss_dice: 2.6266, decode.d5.loss_cls: 5.3573, decode.d5.loss_mask: 2.7990, decode.d5.loss_dice: 2.6632, decode.d6.loss_cls: 4.8306, decode.d6.loss_mask: 2.8751, decode.d6.loss_dice: 2.6938, decode.d7.loss_cls: 4.5622, decode.d7.loss_mask: 2.9696, decode.d7.loss_dice: 2.6682, decode.d8.loss_cls: 4.6469, decode.d8.loss_mask: 3.1053, decode.d8.loss_dice: 2.6323, loss: 104.1202\n",
      "2024-02-14 13:33:35,712 - mmseg - INFO - Iter [20/80000]\tlr: 1.818e-08, eta: 1 day, 23:44:57, time: 2.123, data_time: 0.013, memory: 23505, decode.loss_cls: 4.4912, decode.loss_mask: 2.0893, decode.loss_dice: 2.2449, decode.d0.loss_cls: 4.2136, decode.d0.loss_mask: 2.6780, decode.d0.loss_dice: 2.8424, decode.d1.loss_cls: 5.3531, decode.d1.loss_mask: 2.2364, decode.d1.loss_dice: 2.4956, decode.d2.loss_cls: 5.2715, decode.d2.loss_mask: 2.2003, decode.d2.loss_dice: 2.4468, decode.d3.loss_cls: 4.6354, decode.d3.loss_mask: 2.1215, decode.d3.loss_dice: 2.4276, decode.d4.loss_cls: 4.3994, decode.d4.loss_mask: 2.1332, decode.d4.loss_dice: 2.3834, decode.d5.loss_cls: 5.1805, decode.d5.loss_mask: 1.9685, decode.d5.loss_dice: 2.3378, decode.d6.loss_cls: 4.7038, decode.d6.loss_mask: 2.0549, decode.d6.loss_dice: 2.3607, decode.d7.loss_cls: 4.5283, decode.d7.loss_mask: 2.1213, decode.d7.loss_dice: 2.3616, decode.d8.loss_cls: 4.5757, decode.d8.loss_mask: 2.1568, decode.d8.loss_dice: 2.2943, loss: 93.3080\n",
      "2024-02-14 13:33:56,966 - mmseg - INFO - Iter [30/80000]\tlr: 2.775e-08, eta: 1 day, 23:34:00, time: 2.125, data_time: 0.013, memory: 23505, decode.loss_cls: 4.1230, decode.loss_mask: 1.9880, decode.loss_dice: 2.2664, decode.d0.loss_cls: 4.1983, decode.d0.loss_mask: 2.5307, decode.d0.loss_dice: 2.7972, decode.d1.loss_cls: 5.1501, decode.d1.loss_mask: 2.0553, decode.d1.loss_dice: 2.4487, decode.d2.loss_cls: 5.0243, decode.d2.loss_mask: 2.1041, decode.d2.loss_dice: 2.4407, decode.d3.loss_cls: 4.4193, decode.d3.loss_mask: 2.0865, decode.d3.loss_dice: 2.3991, decode.d4.loss_cls: 4.2020, decode.d4.loss_mask: 2.0708, decode.d4.loss_dice: 2.3647, decode.d5.loss_cls: 4.9028, decode.d5.loss_mask: 1.8927, decode.d5.loss_dice: 2.3251, decode.d6.loss_cls: 4.4455, decode.d6.loss_mask: 1.8990, decode.d6.loss_dice: 2.3105, decode.d7.loss_cls: 4.2181, decode.d7.loss_mask: 1.9891, decode.d7.loss_dice: 2.3511, decode.d8.loss_cls: 4.2571, decode.d8.loss_mask: 1.9666, decode.d8.loss_dice: 2.2989, loss: 89.5258\n",
      "2024-02-14 13:34:18,192 - mmseg - INFO - Iter [40/80000]\tlr: 3.731e-08, eta: 1 day, 23:27:26, time: 2.123, data_time: 0.013, memory: 23505, decode.loss_cls: 3.6571, decode.loss_mask: 1.7317, decode.loss_dice: 2.1164, decode.d0.loss_cls: 4.1943, decode.d0.loss_mask: 2.1617, decode.d0.loss_dice: 2.7807, decode.d1.loss_cls: 4.9730, decode.d1.loss_mask: 1.8107, decode.d1.loss_dice: 2.3660, decode.d2.loss_cls: 4.7189, decode.d2.loss_mask: 1.8027, decode.d2.loss_dice: 2.3069, decode.d3.loss_cls: 4.0579, decode.d3.loss_mask: 1.8501, decode.d3.loss_dice: 2.2358, decode.d4.loss_cls: 3.8344, decode.d4.loss_mask: 1.8001, decode.d4.loss_dice: 2.2317, decode.d5.loss_cls: 4.4560, decode.d5.loss_mask: 1.7132, decode.d5.loss_dice: 2.1995, decode.d6.loss_cls: 4.0033, decode.d6.loss_mask: 1.6949, decode.d6.loss_dice: 2.1833, decode.d7.loss_cls: 3.8030, decode.d7.loss_mask: 1.7471, decode.d7.loss_dice: 2.1772, decode.d8.loss_cls: 3.7682, decode.d8.loss_mask: 1.6896, decode.d8.loss_dice: 2.1187, loss: 82.1843\n",
      "2024-02-14 13:34:39,475 - mmseg - INFO - Iter [50/80000]\tlr: 4.688e-08, eta: 1 day, 23:24:52, time: 2.128, data_time: 0.013, memory: 23505, decode.loss_cls: 3.0794, decode.loss_mask: 1.5979, decode.loss_dice: 2.1343, decode.d0.loss_cls: 4.1934, decode.d0.loss_mask: 2.0382, decode.d0.loss_dice: 2.7467, decode.d1.loss_cls: 4.6364, decode.d1.loss_mask: 1.8608, decode.d1.loss_dice: 2.3692, decode.d2.loss_cls: 4.2412, decode.d2.loss_mask: 1.7470, decode.d2.loss_dice: 2.2745, decode.d3.loss_cls: 3.5705, decode.d3.loss_mask: 1.7342, decode.d3.loss_dice: 2.2561, decode.d4.loss_cls: 3.3822, decode.d4.loss_mask: 1.7254, decode.d4.loss_dice: 2.2196, decode.d5.loss_cls: 3.9468, decode.d5.loss_mask: 1.6884, decode.d5.loss_dice: 2.2105, decode.d6.loss_cls: 3.4302, decode.d6.loss_mask: 1.6845, decode.d6.loss_dice: 2.2220, decode.d7.loss_cls: 3.1598, decode.d7.loss_mask: 1.6877, decode.d7.loss_dice: 2.2140, decode.d8.loss_cls: 3.1737, decode.d8.loss_mask: 1.6221, decode.d8.loss_dice: 2.1316, loss: 76.9782\n",
      "2024-02-14 13:35:00,783 - mmseg - INFO - Iter [60/80000]\tlr: 5.643e-08, eta: 1 day, 23:23:34, time: 2.131, data_time: 0.016, memory: 23505, decode.loss_cls: 2.4645, decode.loss_mask: 1.2671, decode.loss_dice: 1.9953, decode.d0.loss_cls: 4.2278, decode.d0.loss_mask: 1.5492, decode.d0.loss_dice: 2.6384, decode.d1.loss_cls: 4.2187, decode.d1.loss_mask: 1.4781, decode.d1.loss_dice: 2.2104, decode.d2.loss_cls: 3.7331, decode.d2.loss_mask: 1.4028, decode.d2.loss_dice: 2.0957, decode.d3.loss_cls: 3.0355, decode.d3.loss_mask: 1.3795, decode.d3.loss_dice: 2.0375, decode.d4.loss_cls: 2.8192, decode.d4.loss_mask: 1.4131, decode.d4.loss_dice: 2.0195, decode.d5.loss_cls: 3.2475, decode.d5.loss_mask: 1.3237, decode.d5.loss_dice: 2.0454, decode.d6.loss_cls: 2.8111, decode.d6.loss_mask: 1.2928, decode.d6.loss_dice: 2.0554, decode.d7.loss_cls: 2.6479, decode.d7.loss_mask: 1.3438, decode.d7.loss_dice: 2.0221, decode.d8.loss_cls: 2.6259, decode.d8.loss_mask: 1.2606, decode.d8.loss_dice: 2.0064, loss: 66.6679\n",
      "2024-02-14 13:35:22,109 - mmseg - INFO - Iter [70/80000]\tlr: 6.599e-08, eta: 1 day, 23:22:53, time: 2.133, data_time: 0.016, memory: 23505, decode.loss_cls: 1.9866, decode.loss_mask: 0.9720, decode.loss_dice: 1.8619, decode.d0.loss_cls: 4.1980, decode.d0.loss_mask: 1.3710, decode.d0.loss_dice: 2.5201, decode.d1.loss_cls: 3.8636, decode.d1.loss_mask: 1.1588, decode.d1.loss_dice: 2.0577, decode.d2.loss_cls: 3.2341, decode.d2.loss_mask: 1.0473, decode.d2.loss_dice: 1.9880, decode.d3.loss_cls: 2.5470, decode.d3.loss_mask: 1.0141, decode.d3.loss_dice: 1.8774, decode.d4.loss_cls: 2.3090, decode.d4.loss_mask: 1.0226, decode.d4.loss_dice: 1.9123, decode.d5.loss_cls: 2.6055, decode.d5.loss_mask: 0.9479, decode.d5.loss_dice: 1.9140, decode.d6.loss_cls: 2.3008, decode.d6.loss_mask: 0.9438, decode.d6.loss_dice: 1.8977, decode.d7.loss_cls: 2.1292, decode.d7.loss_mask: 0.9587, decode.d7.loss_dice: 1.8972, decode.d8.loss_cls: 2.0720, decode.d8.loss_mask: 0.9735, decode.d8.loss_dice: 1.8569, loss: 57.4388\n",
      "2024-02-14 13:35:43,437 - mmseg - INFO - Iter [80/80000]\tlr: 7.555e-08, eta: 1 day, 23:22:19, time: 2.133, data_time: 0.017, memory: 23505, decode.loss_cls: 1.6853, decode.loss_mask: 0.8513, decode.loss_dice: 1.6764, decode.d0.loss_cls: 4.2180, decode.d0.loss_mask: 1.2957, decode.d0.loss_dice: 2.3268, decode.d1.loss_cls: 3.4326, decode.d1.loss_mask: 1.0344, decode.d1.loss_dice: 1.8787, decode.d2.loss_cls: 2.7382, decode.d2.loss_mask: 0.9604, decode.d2.loss_dice: 1.7498, decode.d3.loss_cls: 2.1393, decode.d3.loss_mask: 0.8999, decode.d3.loss_dice: 1.7275, decode.d4.loss_cls: 1.9761, decode.d4.loss_mask: 0.9274, decode.d4.loss_dice: 1.7361, decode.d5.loss_cls: 2.1755, decode.d5.loss_mask: 0.8559, decode.d5.loss_dice: 1.7349, decode.d6.loss_cls: 1.9010, decode.d6.loss_mask: 0.8592, decode.d6.loss_dice: 1.7416, decode.d7.loss_cls: 1.7962, decode.d7.loss_mask: 0.8620, decode.d7.loss_dice: 1.7210, decode.d8.loss_cls: 1.7466, decode.d8.loss_mask: 0.8570, decode.d8.loss_dice: 1.7076, loss: 51.2124\n",
      "2024-02-14 13:36:04,950 - mmseg - INFO - Iter [90/80000]\tlr: 8.510e-08, eta: 1 day, 23:24:33, time: 2.151, data_time: 0.017, memory: 23505, decode.loss_cls: 1.5127, decode.loss_mask: 0.8012, decode.loss_dice: 1.5923, decode.d0.loss_cls: 4.2035, decode.d0.loss_mask: 1.1394, decode.d0.loss_dice: 2.1993, decode.d1.loss_cls: 3.0140, decode.d1.loss_mask: 0.9567, decode.d1.loss_dice: 1.7694, decode.d2.loss_cls: 2.2933, decode.d2.loss_mask: 0.8796, decode.d2.loss_dice: 1.6526, decode.d3.loss_cls: 1.7775, decode.d3.loss_mask: 0.8068, decode.d3.loss_dice: 1.6238, decode.d4.loss_cls: 1.6878, decode.d4.loss_mask: 0.8259, decode.d4.loss_dice: 1.6273, decode.d5.loss_cls: 1.8322, decode.d5.loss_mask: 0.7735, decode.d5.loss_dice: 1.6205, decode.d6.loss_cls: 1.6024, decode.d6.loss_mask: 0.7878, decode.d6.loss_dice: 1.6400, decode.d7.loss_cls: 1.5444, decode.d7.loss_mask: 0.7980, decode.d7.loss_dice: 1.5999, decode.d8.loss_cls: 1.5256, decode.d8.loss_mask: 0.7841, decode.d8.loss_dice: 1.5955, loss: 46.4666\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-14 13:36:26,279 - mmseg - INFO - Iter [100/80000]\tlr: 9.465e-08, eta: 1 day, 23:23:45, time: 2.133, data_time: 0.016, memory: 23505, decode.loss_cls: 1.4108, decode.loss_mask: 0.6568, decode.loss_dice: 1.3893, decode.d0.loss_cls: 4.2249, decode.d0.loss_mask: 1.0393, decode.d0.loss_dice: 1.9450, decode.d1.loss_cls: 2.5836, decode.d1.loss_mask: 0.8478, decode.d1.loss_dice: 1.5585, decode.d2.loss_cls: 1.9151, decode.d2.loss_mask: 0.7320, decode.d2.loss_dice: 1.4585, decode.d3.loss_cls: 1.5481, decode.d3.loss_mask: 0.6739, decode.d3.loss_dice: 1.4503, decode.d4.loss_cls: 1.4885, decode.d4.loss_mask: 0.6628, decode.d4.loss_dice: 1.4254, decode.d5.loss_cls: 1.5643, decode.d5.loss_mask: 0.6569, decode.d5.loss_dice: 1.4145, decode.d6.loss_cls: 1.4415, decode.d6.loss_mask: 0.6439, decode.d6.loss_dice: 1.4317, decode.d7.loss_cls: 1.4340, decode.d7.loss_mask: 0.6389, decode.d7.loss_dice: 1.3929, decode.d8.loss_cls: 1.4121, decode.d8.loss_mask: 0.6363, decode.d8.loss_dice: 1.3925, loss: 41.0702\n",
      "2024-02-14 13:36:47,593 - mmseg - INFO - Iter [110/80000]\tlr: 1.042e-07, eta: 1 day, 23:22:56, time: 2.132, data_time: 0.015, memory: 23505, decode.loss_cls: 1.3797, decode.loss_mask: 0.5828, decode.loss_dice: 1.2300, decode.d0.loss_cls: 4.2250, decode.d0.loss_mask: 0.8445, decode.d0.loss_dice: 1.7872, decode.d1.loss_cls: 2.2897, decode.d1.loss_mask: 0.7071, decode.d1.loss_dice: 1.3795, decode.d2.loss_cls: 1.6676, decode.d2.loss_mask: 0.6291, decode.d2.loss_dice: 1.2901, decode.d3.loss_cls: 1.4126, decode.d3.loss_mask: 0.6153, decode.d3.loss_dice: 1.2692, decode.d4.loss_cls: 1.4039, decode.d4.loss_mask: 0.5948, decode.d4.loss_dice: 1.2600, decode.d5.loss_cls: 1.4663, decode.d5.loss_mask: 0.5783, decode.d5.loss_dice: 1.2605, decode.d6.loss_cls: 1.3626, decode.d6.loss_mask: 0.5716, decode.d6.loss_dice: 1.2458, decode.d7.loss_cls: 1.3790, decode.d7.loss_mask: 0.5840, decode.d7.loss_dice: 1.2171, decode.d8.loss_cls: 1.3603, decode.d8.loss_mask: 0.5928, decode.d8.loss_dice: 1.2292, loss: 37.4159\n",
      "2024-02-14 13:37:08,870 - mmseg - INFO - Iter [120/80000]\tlr: 1.137e-07, eta: 1 day, 23:21:45, time: 2.128, data_time: 0.016, memory: 23505, decode.loss_cls: 1.3098, decode.loss_mask: 0.5127, decode.loss_dice: 1.0897, decode.d0.loss_cls: 4.1850, decode.d0.loss_mask: 0.7257, decode.d0.loss_dice: 1.5415, decode.d1.loss_cls: 1.9945, decode.d1.loss_mask: 0.5881, decode.d1.loss_dice: 1.1500, decode.d2.loss_cls: 1.5014, decode.d2.loss_mask: 0.5226, decode.d2.loss_dice: 1.1014, decode.d3.loss_cls: 1.3257, decode.d3.loss_mask: 0.5072, decode.d3.loss_dice: 1.1102, decode.d4.loss_cls: 1.3123, decode.d4.loss_mask: 0.4964, decode.d4.loss_dice: 1.1068, decode.d5.loss_cls: 1.3640, decode.d5.loss_mask: 0.4872, decode.d5.loss_dice: 1.0998, decode.d6.loss_cls: 1.2705, decode.d6.loss_mask: 0.4981, decode.d6.loss_dice: 1.1051, decode.d7.loss_cls: 1.2979, decode.d7.loss_mask: 0.5059, decode.d7.loss_dice: 1.0883, decode.d8.loss_cls: 1.2869, decode.d8.loss_mask: 0.4967, decode.d8.loss_dice: 1.0940, loss: 33.6749\n",
      "2024-02-14 13:37:30,146 - mmseg - INFO - Iter [130/80000]\tlr: 1.233e-07, eta: 1 day, 23:20:42, time: 2.128, data_time: 0.015, memory: 23505, decode.loss_cls: 1.2660, decode.loss_mask: 0.4932, decode.loss_dice: 0.9913, decode.d0.loss_cls: 4.2226, decode.d0.loss_mask: 0.7470, decode.d0.loss_dice: 1.4318, decode.d1.loss_cls: 1.8214, decode.d1.loss_mask: 0.6232, decode.d1.loss_dice: 1.0827, decode.d2.loss_cls: 1.3960, decode.d2.loss_mask: 0.5524, decode.d2.loss_dice: 1.0168, decode.d3.loss_cls: 1.2728, decode.d3.loss_mask: 0.5114, decode.d3.loss_dice: 1.0154, decode.d4.loss_cls: 1.2796, decode.d4.loss_mask: 0.4998, decode.d4.loss_dice: 1.0194, decode.d5.loss_cls: 1.3226, decode.d5.loss_mask: 0.4848, decode.d5.loss_dice: 1.0171, decode.d6.loss_cls: 1.2112, decode.d6.loss_mask: 0.4964, decode.d6.loss_dice: 1.0037, decode.d7.loss_cls: 1.2346, decode.d7.loss_mask: 0.5062, decode.d7.loss_dice: 0.9784, decode.d8.loss_cls: 1.2386, decode.d8.loss_mask: 0.4944, decode.d8.loss_dice: 0.9938, loss: 32.2245\n",
      "2024-02-14 13:37:51,429 - mmseg - INFO - Iter [140/80000]\tlr: 1.328e-07, eta: 1 day, 23:19:48, time: 2.128, data_time: 0.016, memory: 23505, decode.loss_cls: 1.1994, decode.loss_mask: 0.4727, decode.loss_dice: 0.9608, decode.d0.loss_cls: 4.1838, decode.d0.loss_mask: 0.6332, decode.d0.loss_dice: 1.3588, decode.d1.loss_cls: 1.6026, decode.d1.loss_mask: 0.5619, decode.d1.loss_dice: 1.0353, decode.d2.loss_cls: 1.2971, decode.d2.loss_mask: 0.4742, decode.d2.loss_dice: 1.0131, decode.d3.loss_cls: 1.2370, decode.d3.loss_mask: 0.4617, decode.d3.loss_dice: 1.0039, decode.d4.loss_cls: 1.2335, decode.d4.loss_mask: 0.4590, decode.d4.loss_dice: 0.9999, decode.d5.loss_cls: 1.2499, decode.d5.loss_mask: 0.4482, decode.d5.loss_dice: 0.9995, decode.d6.loss_cls: 1.1687, decode.d6.loss_mask: 0.4465, decode.d6.loss_dice: 0.9925, decode.d7.loss_cls: 1.1752, decode.d7.loss_mask: 0.4531, decode.d7.loss_dice: 0.9753, decode.d8.loss_cls: 1.1707, decode.d8.loss_mask: 0.4569, decode.d8.loss_dice: 0.9794, loss: 30.7038\n",
      "2024-02-14 13:38:12,714 - mmseg - INFO - Iter [150/80000]\tlr: 1.424e-07, eta: 1 day, 23:19:00, time: 2.129, data_time: 0.016, memory: 23505, decode.loss_cls: 1.1567, decode.loss_mask: 0.4773, decode.loss_dice: 0.9177, decode.d0.loss_cls: 4.1758, decode.d0.loss_mask: 0.6508, decode.d0.loss_dice: 1.3002, decode.d1.loss_cls: 1.5199, decode.d1.loss_mask: 0.5538, decode.d1.loss_dice: 0.9949, decode.d2.loss_cls: 1.2531, decode.d2.loss_mask: 0.4751, decode.d2.loss_dice: 0.9413, decode.d3.loss_cls: 1.2058, decode.d3.loss_mask: 0.4642, decode.d3.loss_dice: 0.9459, decode.d4.loss_cls: 1.1888, decode.d4.loss_mask: 0.4598, decode.d4.loss_dice: 0.9329, decode.d5.loss_cls: 1.1839, decode.d5.loss_mask: 0.4612, decode.d5.loss_dice: 0.9458, decode.d6.loss_cls: 1.0982, decode.d6.loss_mask: 0.4668, decode.d6.loss_dice: 0.9271, decode.d7.loss_cls: 1.1167, decode.d7.loss_mask: 0.4835, decode.d7.loss_dice: 0.9192, decode.d8.loss_cls: 1.1130, decode.d8.loss_mask: 0.4715, decode.d8.loss_dice: 0.9363, loss: 29.7377\n",
      "2024-02-14 13:38:33,989 - mmseg - INFO - Iter [160/80000]\tlr: 1.519e-07, eta: 1 day, 23:18:09, time: 2.127, data_time: 0.015, memory: 23505, decode.loss_cls: 1.1359, decode.loss_mask: 0.5352, decode.loss_dice: 0.9382, decode.d0.loss_cls: 4.1602, decode.d0.loss_mask: 0.7338, decode.d0.loss_dice: 1.3784, decode.d1.loss_cls: 1.4642, decode.d1.loss_mask: 0.6430, decode.d1.loss_dice: 1.0311, decode.d2.loss_cls: 1.2521, decode.d2.loss_mask: 0.5526, decode.d2.loss_dice: 0.9897, decode.d3.loss_cls: 1.1806, decode.d3.loss_mask: 0.5350, decode.d3.loss_dice: 0.9875, decode.d4.loss_cls: 1.1819, decode.d4.loss_mask: 0.5272, decode.d4.loss_dice: 0.9798, decode.d5.loss_cls: 1.1837, decode.d5.loss_mask: 0.5252, decode.d5.loss_dice: 0.9890, decode.d6.loss_cls: 1.1130, decode.d6.loss_mask: 0.5218, decode.d6.loss_dice: 0.9659, decode.d7.loss_cls: 1.1271, decode.d7.loss_mask: 0.5387, decode.d7.loss_dice: 0.9577, decode.d8.loss_cls: 1.1203, decode.d8.loss_mask: 0.5299, decode.d8.loss_dice: 0.9690, loss: 30.7476\n",
      "2024-02-14 13:38:55,292 - mmseg - INFO - Iter [170/80000]\tlr: 1.614e-07, eta: 1 day, 23:17:36, time: 2.130, data_time: 0.015, memory: 23505, decode.loss_cls: 1.0561, decode.loss_mask: 0.4607, decode.loss_dice: 0.8931, decode.d0.loss_cls: 4.1860, decode.d0.loss_mask: 0.5988, decode.d0.loss_dice: 1.2495, decode.d1.loss_cls: 1.3873, decode.d1.loss_mask: 0.5229, decode.d1.loss_dice: 0.9339, decode.d2.loss_cls: 1.2000, decode.d2.loss_mask: 0.4576, decode.d2.loss_dice: 0.9044, decode.d3.loss_cls: 1.1301, decode.d3.loss_mask: 0.4519, decode.d3.loss_dice: 0.8969, decode.d4.loss_cls: 1.1213, decode.d4.loss_mask: 0.4441, decode.d4.loss_dice: 0.8962, decode.d5.loss_cls: 1.1184, decode.d5.loss_mask: 0.4454, decode.d5.loss_dice: 0.9108, decode.d6.loss_cls: 1.0525, decode.d6.loss_mask: 0.4471, decode.d6.loss_dice: 0.8950, decode.d7.loss_cls: 1.0528, decode.d7.loss_mask: 0.4572, decode.d7.loss_dice: 0.8916, decode.d8.loss_cls: 1.0215, decode.d8.loss_mask: 0.4512, decode.d8.loss_dice: 0.8961, loss: 28.4304\n",
      "2024-02-14 13:39:16,562 - mmseg - INFO - Iter [180/80000]\tlr: 1.710e-07, eta: 1 day, 23:16:49, time: 2.127, data_time: 0.016, memory: 23505, decode.loss_cls: 1.0133, decode.loss_mask: 0.4734, decode.loss_dice: 0.8558, decode.d0.loss_cls: 4.1682, decode.d0.loss_mask: 0.5980, decode.d0.loss_dice: 1.2184, decode.d1.loss_cls: 1.3619, decode.d1.loss_mask: 0.5256, decode.d1.loss_dice: 0.9170, decode.d2.loss_cls: 1.1577, decode.d2.loss_mask: 0.4714, decode.d2.loss_dice: 0.8825, decode.d3.loss_cls: 1.0788, decode.d3.loss_mask: 0.4560, decode.d3.loss_dice: 0.8816, decode.d4.loss_cls: 1.0916, decode.d4.loss_mask: 0.4554, decode.d4.loss_dice: 0.8717, decode.d5.loss_cls: 1.0758, decode.d5.loss_mask: 0.4555, decode.d5.loss_dice: 0.8836, decode.d6.loss_cls: 0.9966, decode.d6.loss_mask: 0.4540, decode.d6.loss_dice: 0.8733, decode.d7.loss_cls: 1.0030, decode.d7.loss_mask: 0.4726, decode.d7.loss_dice: 0.8594, decode.d8.loss_cls: 0.9952, decode.d8.loss_mask: 0.4669, decode.d8.loss_dice: 0.8529, loss: 27.8670\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-14 13:39:37,845 - mmseg - INFO - Iter [190/80000]\tlr: 1.805e-07, eta: 1 day, 23:16:11, time: 2.128, data_time: 0.016, memory: 23505, decode.loss_cls: 0.9786, decode.loss_mask: 0.5045, decode.loss_dice: 0.8602, decode.d0.loss_cls: 4.1750, decode.d0.loss_mask: 0.6060, decode.d0.loss_dice: 1.1905, decode.d1.loss_cls: 1.3190, decode.d1.loss_mask: 0.5848, decode.d1.loss_dice: 0.8968, decode.d2.loss_cls: 1.1458, decode.d2.loss_mask: 0.4907, decode.d2.loss_dice: 0.8740, decode.d3.loss_cls: 1.0635, decode.d3.loss_mask: 0.4826, decode.d3.loss_dice: 0.8862, decode.d4.loss_cls: 1.0539, decode.d4.loss_mask: 0.4913, decode.d4.loss_dice: 0.8842, decode.d5.loss_cls: 1.0430, decode.d5.loss_mask: 0.4860, decode.d5.loss_dice: 0.8783, decode.d6.loss_cls: 0.9652, decode.d6.loss_mask: 0.4868, decode.d6.loss_dice: 0.8707, decode.d7.loss_cls: 0.9704, decode.d7.loss_mask: 0.4917, decode.d7.loss_dice: 0.8656, decode.d8.loss_cls: 0.9549, decode.d8.loss_mask: 0.4996, decode.d8.loss_dice: 0.8705, loss: 27.8703\n",
      "2024-02-14 13:39:59,133 - mmseg - INFO - Iter [200/80000]\tlr: 1.900e-07, eta: 1 day, 23:15:35, time: 2.129, data_time: 0.016, memory: 23505, decode.loss_cls: 0.8397, decode.loss_mask: 0.3972, decode.loss_dice: 0.7576, decode.d0.loss_cls: 4.1421, decode.d0.loss_mask: 0.5110, decode.d0.loss_dice: 1.0688, decode.d1.loss_cls: 1.2021, decode.d1.loss_mask: 0.4584, decode.d1.loss_dice: 0.8002, decode.d2.loss_cls: 1.0526, decode.d2.loss_mask: 0.4005, decode.d2.loss_dice: 0.7770, decode.d3.loss_cls: 0.9704, decode.d3.loss_mask: 0.3955, decode.d3.loss_dice: 0.7823, decode.d4.loss_cls: 0.9324, decode.d4.loss_mask: 0.3938, decode.d4.loss_dice: 0.7762, decode.d5.loss_cls: 0.9116, decode.d5.loss_mask: 0.3857, decode.d5.loss_dice: 0.7872, decode.d6.loss_cls: 0.8489, decode.d6.loss_mask: 0.3922, decode.d6.loss_dice: 0.7674, decode.d7.loss_cls: 0.8236, decode.d7.loss_mask: 0.3971, decode.d7.loss_dice: 0.7689, decode.d8.loss_cls: 0.8182, decode.d8.loss_mask: 0.3995, decode.d8.loss_dice: 0.7669, loss: 24.7250\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 40/40, 3.1 task/s, elapsed: 13s, ETA:     0s\n",
      "\n",
      "2024-02-14 13:40:12,121 - mmseg - INFO - per class results:\n",
      "2024-02-14 13:40:12,122 - mmseg - INFO - \n",
      "+---------------+-------+-------+\n",
      "|     Class     |  IoU  |  Acc  |\n",
      "+---------------+-------+-------+\n",
      "|       bg      | 96.12 | 97.25 |\n",
      "|    Anchovy    | 54.74 | 68.78 |\n",
      "|     Olives    |  76.9 | 89.76 |\n",
      "|     Salami    | 39.63 | 53.66 |\n",
      "|   Red_Pepper  | 73.93 | 95.71 |\n",
      "| Yellow_Pepper | 76.94 | 82.62 |\n",
      "+---------------+-------+-------+\n",
      "2024-02-14 13:40:12,122 - mmseg - INFO - Summary:\n",
      "2024-02-14 13:40:12,122 - mmseg - INFO - \n",
      "+-------+-------+------+\n",
      "|  aAcc |  mIoU | mAcc |\n",
      "+-------+-------+------+\n",
      "| 95.14 | 69.71 | 81.3 |\n",
      "+-------+-------+------+\n",
      "2024-02-14 13:40:28,172 - mmseg - INFO - Now best checkpoint is saved as best_mIoU_iter_200.pth.\n",
      "2024-02-14 13:40:28,172 - mmseg - INFO - Best mIoU is 0.6971 at 200 iter.\n",
      "2024-02-14 13:40:28,173 - mmseg - INFO - Iter(val) [10]\taAcc: 0.9514, mIoU: 0.6971, mAcc: 0.8130, IoU.bg: 0.9612, IoU.Anchovy: 0.5474, IoU.Olives: 0.7690, IoU.Salami: 0.3963, IoU.Red_Pepper: 0.7393, IoU.Yellow_Pepper: 0.7694, Acc.bg: 0.9725, Acc.Anchovy: 0.6878, Acc.Olives: 0.8976, Acc.Salami: 0.5366, Acc.Red_Pepper: 0.9571, Acc.Yellow_Pepper: 0.8262\n",
      "2024-02-14 13:40:49,564 - mmseg - INFO - Iter [210/80000]\tlr: 1.995e-07, eta: 2 days, 2:19:35, time: 5.043, data_time: 2.920, memory: 23505, decode.loss_cls: 0.7976, decode.loss_mask: 0.3664, decode.loss_dice: 0.6989, decode.d0.loss_cls: 4.1733, decode.d0.loss_mask: 0.4556, decode.d0.loss_dice: 0.9445, decode.d1.loss_cls: 1.1976, decode.d1.loss_mask: 0.4218, decode.d1.loss_dice: 0.7327, decode.d2.loss_cls: 1.0297, decode.d2.loss_mask: 0.3739, decode.d2.loss_dice: 0.7264, decode.d3.loss_cls: 0.9356, decode.d3.loss_mask: 0.3619, decode.d3.loss_dice: 0.7148, decode.d4.loss_cls: 0.8973, decode.d4.loss_mask: 0.3666, decode.d4.loss_dice: 0.7219, decode.d5.loss_cls: 0.8555, decode.d5.loss_mask: 0.3628, decode.d5.loss_dice: 0.7246, decode.d6.loss_cls: 0.7991, decode.d6.loss_mask: 0.3644, decode.d6.loss_dice: 0.7180, decode.d7.loss_cls: 0.7851, decode.d7.loss_mask: 0.3689, decode.d7.loss_dice: 0.7044, decode.d8.loss_cls: 0.7538, decode.d8.loss_mask: 0.3679, decode.d8.loss_dice: 0.7203, loss: 23.4413\n",
      "2024-02-14 13:41:10,854 - mmseg - INFO - Iter [220/80000]\tlr: 2.091e-07, eta: 2 days, 2:10:38, time: 2.129, data_time: 0.016, memory: 23505, decode.loss_cls: 0.7538, decode.loss_mask: 0.4593, decode.loss_dice: 0.7992, decode.d0.loss_cls: 4.1602, decode.d0.loss_mask: 0.5319, decode.d0.loss_dice: 1.0536, decode.d1.loss_cls: 1.1576, decode.d1.loss_mask: 0.5308, decode.d1.loss_dice: 0.8199, decode.d2.loss_cls: 1.0159, decode.d2.loss_mask: 0.4693, decode.d2.loss_dice: 0.8152, decode.d3.loss_cls: 0.8929, decode.d3.loss_mask: 0.4431, decode.d3.loss_dice: 0.8235, decode.d4.loss_cls: 0.8734, decode.d4.loss_mask: 0.4443, decode.d4.loss_dice: 0.8146, decode.d5.loss_cls: 0.8271, decode.d5.loss_mask: 0.4486, decode.d5.loss_dice: 0.8114, decode.d6.loss_cls: 0.7667, decode.d6.loss_mask: 0.4436, decode.d6.loss_dice: 0.8097, decode.d7.loss_cls: 0.7523, decode.d7.loss_mask: 0.4474, decode.d7.loss_dice: 0.8006, decode.d8.loss_cls: 0.7192, decode.d8.loss_mask: 0.4493, decode.d8.loss_dice: 0.8076, loss: 24.9421\n",
      "2024-02-14 13:41:32,162 - mmseg - INFO - Iter [230/80000]\tlr: 2.186e-07, eta: 2 days, 2:02:33, time: 2.131, data_time: 0.016, memory: 23505, decode.loss_cls: 0.6436, decode.loss_mask: 0.3700, decode.loss_dice: 0.6681, decode.d0.loss_cls: 4.1364, decode.d0.loss_mask: 0.4465, decode.d0.loss_dice: 0.8718, decode.d1.loss_cls: 1.0761, decode.d1.loss_mask: 0.4411, decode.d1.loss_dice: 0.6837, decode.d2.loss_cls: 0.9266, decode.d2.loss_mask: 0.3901, decode.d2.loss_dice: 0.6820, decode.d3.loss_cls: 0.8069, decode.d3.loss_mask: 0.3711, decode.d3.loss_dice: 0.6818, decode.d4.loss_cls: 0.7582, decode.d4.loss_mask: 0.3672, decode.d4.loss_dice: 0.6752, decode.d5.loss_cls: 0.7283, decode.d5.loss_mask: 0.3591, decode.d5.loss_dice: 0.6820, decode.d6.loss_cls: 0.6732, decode.d6.loss_mask: 0.3611, decode.d6.loss_dice: 0.6765, decode.d7.loss_cls: 0.6502, decode.d7.loss_mask: 0.3665, decode.d7.loss_dice: 0.6670, decode.d8.loss_cls: 0.6149, decode.d8.loss_mask: 0.3683, decode.d8.loss_dice: 0.6783, loss: 21.8218\n",
      "2024-02-14 13:41:55,280 - mmseg - INFO - Iter [240/80000]\tlr: 2.281e-07, eta: 2 days, 2:05:06, time: 2.311, data_time: 0.026, memory: 23505, decode.loss_cls: 0.5800, decode.loss_mask: 0.4355, decode.loss_dice: 0.7691, decode.d0.loss_cls: 4.1569, decode.d0.loss_mask: 0.5485, decode.d0.loss_dice: 0.9932, decode.d1.loss_cls: 1.0752, decode.d1.loss_mask: 0.5306, decode.d1.loss_dice: 0.7754, decode.d2.loss_cls: 0.9173, decode.d2.loss_mask: 0.4608, decode.d2.loss_dice: 0.7687, decode.d3.loss_cls: 0.7861, decode.d3.loss_mask: 0.4451, decode.d3.loss_dice: 0.7729, decode.d4.loss_cls: 0.7362, decode.d4.loss_mask: 0.4471, decode.d4.loss_dice: 0.7741, decode.d5.loss_cls: 0.7067, decode.d5.loss_mask: 0.4414, decode.d5.loss_dice: 0.7708, decode.d6.loss_cls: 0.6379, decode.d6.loss_mask: 0.4322, decode.d6.loss_dice: 0.7641, decode.d7.loss_cls: 0.5961, decode.d7.loss_mask: 0.4428, decode.d7.loss_dice: 0.7686, decode.d8.loss_cls: 0.5543, decode.d8.loss_mask: 0.4333, decode.d8.loss_dice: 0.7752, loss: 23.2965\n",
      "2024-02-14 13:42:24,679 - mmseg - INFO - Iter [250/80000]\tlr: 2.376e-07, eta: 2 days, 2:40:52, time: 2.940, data_time: 0.026, memory: 23505, decode.loss_cls: 0.5320, decode.loss_mask: 0.3709, decode.loss_dice: 0.7347, decode.d0.loss_cls: 4.1456, decode.d0.loss_mask: 0.4395, decode.d0.loss_dice: 0.9025, decode.d1.loss_cls: 1.0013, decode.d1.loss_mask: 0.4354, decode.d1.loss_dice: 0.7375, decode.d2.loss_cls: 0.8578, decode.d2.loss_mask: 0.3818, decode.d2.loss_dice: 0.7322, decode.d3.loss_cls: 0.7360, decode.d3.loss_mask: 0.3701, decode.d3.loss_dice: 0.7353, decode.d4.loss_cls: 0.6740, decode.d4.loss_mask: 0.3707, decode.d4.loss_dice: 0.7424, decode.d5.loss_cls: 0.6248, decode.d5.loss_mask: 0.3729, decode.d5.loss_dice: 0.7435, decode.d6.loss_cls: 0.5661, decode.d6.loss_mask: 0.3730, decode.d6.loss_dice: 0.7359, decode.d7.loss_cls: 0.5365, decode.d7.loss_mask: 0.3727, decode.d7.loss_dice: 0.7290, decode.d8.loss_cls: 0.5060, decode.d8.loss_mask: 0.3771, decode.d8.loss_dice: 0.7425, loss: 21.5797\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-14 13:43:21,185 - mmseg - INFO - Iter [260/80000]\tlr: 2.471e-07, eta: 2 days, 5:32:22, time: 5.650, data_time: 0.011, memory: 23505, decode.loss_cls: 0.4589, decode.loss_mask: 0.3731, decode.loss_dice: 0.7153, decode.d0.loss_cls: 4.1376, decode.d0.loss_mask: 0.4381, decode.d0.loss_dice: 0.8644, decode.d1.loss_cls: 0.9830, decode.d1.loss_mask: 0.4378, decode.d1.loss_dice: 0.7080, decode.d2.loss_cls: 0.8122, decode.d2.loss_mask: 0.3937, decode.d2.loss_dice: 0.7155, decode.d3.loss_cls: 0.6636, decode.d3.loss_mask: 0.3760, decode.d3.loss_dice: 0.7297, decode.d4.loss_cls: 0.6070, decode.d4.loss_mask: 0.3829, decode.d4.loss_dice: 0.7299, decode.d5.loss_cls: 0.5656, decode.d5.loss_mask: 0.3666, decode.d5.loss_dice: 0.7183, decode.d6.loss_cls: 0.5013, decode.d6.loss_mask: 0.3722, decode.d6.loss_dice: 0.7307, decode.d7.loss_cls: 0.4738, decode.d7.loss_mask: 0.3775, decode.d7.loss_dice: 0.7327, decode.d8.loss_cls: 0.4357, decode.d8.loss_mask: 0.3673, decode.d8.loss_dice: 0.7259, loss: 20.8940\n",
      "2024-02-14 13:43:56,874 - mmseg - INFO - Iter [270/80000]\tlr: 2.566e-07, eta: 2 days, 6:28:39, time: 3.569, data_time: 0.014, memory: 23505, decode.loss_cls: 0.4009, decode.loss_mask: 0.3178, decode.loss_dice: 0.6616, decode.d0.loss_cls: 4.1202, decode.d0.loss_mask: 0.3604, decode.d0.loss_dice: 0.8556, decode.d1.loss_cls: 0.8942, decode.d1.loss_mask: 0.3566, decode.d1.loss_dice: 0.6589, decode.d2.loss_cls: 0.7491, decode.d2.loss_mask: 0.3194, decode.d2.loss_dice: 0.6715, decode.d3.loss_cls: 0.5889, decode.d3.loss_mask: 0.3150, decode.d3.loss_dice: 0.6771, decode.d4.loss_cls: 0.5281, decode.d4.loss_mask: 0.3148, decode.d4.loss_dice: 0.6726, decode.d5.loss_cls: 0.4972, decode.d5.loss_mask: 0.3083, decode.d5.loss_dice: 0.6763, decode.d6.loss_cls: 0.4423, decode.d6.loss_mask: 0.3077, decode.d6.loss_dice: 0.6622, decode.d7.loss_cls: 0.4040, decode.d7.loss_mask: 0.3159, decode.d7.loss_dice: 0.6680, decode.d8.loss_cls: 0.3693, decode.d8.loss_mask: 0.3066, decode.d8.loss_dice: 0.6758, loss: 19.0961\n",
      "2024-02-14 13:44:18,163 - mmseg - INFO - Iter [280/80000]\tlr: 2.661e-07, eta: 2 days, 6:12:33, time: 2.129, data_time: 0.016, memory: 23505, decode.loss_cls: 0.3630, decode.loss_mask: 0.3594, decode.loss_dice: 0.7050, decode.d0.loss_cls: 4.0994, decode.d0.loss_mask: 0.4211, decode.d0.loss_dice: 0.9271, decode.d1.loss_cls: 0.8937, decode.d1.loss_mask: 0.4221, decode.d1.loss_dice: 0.7022, decode.d2.loss_cls: 0.7262, decode.d2.loss_mask: 0.3704, decode.d2.loss_dice: 0.7071, decode.d3.loss_cls: 0.5798, decode.d3.loss_mask: 0.3595, decode.d3.loss_dice: 0.7229, decode.d4.loss_cls: 0.5196, decode.d4.loss_mask: 0.3640, decode.d4.loss_dice: 0.7172, decode.d5.loss_cls: 0.4850, decode.d5.loss_mask: 0.3541, decode.d5.loss_dice: 0.7197, decode.d6.loss_cls: 0.4293, decode.d6.loss_mask: 0.3610, decode.d6.loss_dice: 0.7133, decode.d7.loss_cls: 0.4003, decode.d7.loss_mask: 0.3601, decode.d7.loss_dice: 0.7108, decode.d8.loss_cls: 0.3604, decode.d8.loss_mask: 0.3621, decode.d8.loss_dice: 0.7181, loss: 19.9338\n",
      "2024-02-14 13:44:39,451 - mmseg - INFO - Iter [290/80000]\tlr: 2.756e-07, eta: 2 days, 5:57:31, time: 2.129, data_time: 0.016, memory: 23505, decode.loss_cls: 0.3062, decode.loss_mask: 0.4025, decode.loss_dice: 0.7401, decode.d0.loss_cls: 4.1311, decode.d0.loss_mask: 0.4588, decode.d0.loss_dice: 0.8706, decode.d1.loss_cls: 0.9161, decode.d1.loss_mask: 0.4583, decode.d1.loss_dice: 0.7130, decode.d2.loss_cls: 0.6918, decode.d2.loss_mask: 0.4098, decode.d2.loss_dice: 0.7331, decode.d3.loss_cls: 0.5551, decode.d3.loss_mask: 0.3975, decode.d3.loss_dice: 0.7486, decode.d4.loss_cls: 0.4847, decode.d4.loss_mask: 0.4001, decode.d4.loss_dice: 0.7379, decode.d5.loss_cls: 0.4431, decode.d5.loss_mask: 0.3969, decode.d5.loss_dice: 0.7500, decode.d6.loss_cls: 0.3785, decode.d6.loss_mask: 0.3963, decode.d6.loss_dice: 0.7352, decode.d7.loss_cls: 0.3424, decode.d7.loss_mask: 0.4034, decode.d7.loss_dice: 0.7342, decode.d8.loss_cls: 0.3102, decode.d8.loss_mask: 0.3992, decode.d8.loss_dice: 0.7313, loss: 20.1759\n",
      "2024-02-14 13:45:00,743 - mmseg - INFO - Iter [300/80000]\tlr: 2.851e-07, eta: 2 days, 5:43:29, time: 2.129, data_time: 0.016, memory: 23505, decode.loss_cls: 0.2633, decode.loss_mask: 0.4029, decode.loss_dice: 0.7353, decode.d0.loss_cls: 4.0881, decode.d0.loss_mask: 0.4555, decode.d0.loss_dice: 0.9162, decode.d1.loss_cls: 0.8285, decode.d1.loss_mask: 0.4681, decode.d1.loss_dice: 0.7126, decode.d2.loss_cls: 0.6490, decode.d2.loss_mask: 0.4095, decode.d2.loss_dice: 0.7153, decode.d3.loss_cls: 0.4914, decode.d3.loss_mask: 0.3950, decode.d3.loss_dice: 0.7253, decode.d4.loss_cls: 0.4137, decode.d4.loss_mask: 0.3972, decode.d4.loss_dice: 0.7237, decode.d5.loss_cls: 0.3943, decode.d5.loss_mask: 0.3929, decode.d5.loss_dice: 0.7481, decode.d6.loss_cls: 0.3242, decode.d6.loss_mask: 0.3952, decode.d6.loss_dice: 0.7428, decode.d7.loss_cls: 0.2919, decode.d7.loss_mask: 0.4002, decode.d7.loss_dice: 0.7325, decode.d8.loss_cls: 0.2665, decode.d8.loss_mask: 0.3909, decode.d8.loss_dice: 0.7350, loss: 19.6050\n",
      "2024-02-14 13:45:22,025 - mmseg - INFO - Iter [310/80000]\tlr: 2.946e-07, eta: 2 days, 5:30:17, time: 2.128, data_time: 0.016, memory: 23505, decode.loss_cls: 0.1989, decode.loss_mask: 0.3952, decode.loss_dice: 0.7253, decode.d0.loss_cls: 4.1115, decode.d0.loss_mask: 0.4471, decode.d0.loss_dice: 0.8558, decode.d1.loss_cls: 0.7912, decode.d1.loss_mask: 0.4397, decode.d1.loss_dice: 0.7007, decode.d2.loss_cls: 0.5944, decode.d2.loss_mask: 0.3955, decode.d2.loss_dice: 0.7178, decode.d3.loss_cls: 0.4521, decode.d3.loss_mask: 0.3811, decode.d3.loss_dice: 0.7146, decode.d4.loss_cls: 0.3645, decode.d4.loss_mask: 0.3826, decode.d4.loss_dice: 0.7177, decode.d5.loss_cls: 0.3291, decode.d5.loss_mask: 0.3775, decode.d5.loss_dice: 0.7250, decode.d6.loss_cls: 0.2718, decode.d6.loss_mask: 0.3867, decode.d6.loss_dice: 0.7177, decode.d7.loss_cls: 0.2211, decode.d7.loss_mask: 0.3952, decode.d7.loss_dice: 0.7261, decode.d8.loss_cls: 0.1989, decode.d8.loss_mask: 0.3911, decode.d8.loss_dice: 0.7222, loss: 18.8480\n",
      "2024-02-14 13:45:43,301 - mmseg - INFO - Iter [320/80000]\tlr: 3.041e-07, eta: 2 days, 5:17:52, time: 2.128, data_time: 0.016, memory: 23505, decode.loss_cls: 0.1556, decode.loss_mask: 0.3677, decode.loss_dice: 0.6927, decode.d0.loss_cls: 4.0841, decode.d0.loss_mask: 0.4325, decode.d0.loss_dice: 0.8374, decode.d1.loss_cls: 0.7271, decode.d1.loss_mask: 0.4381, decode.d1.loss_dice: 0.6714, decode.d2.loss_cls: 0.5556, decode.d2.loss_mask: 0.3978, decode.d2.loss_dice: 0.6863, decode.d3.loss_cls: 0.4047, decode.d3.loss_mask: 0.3762, decode.d3.loss_dice: 0.6944, decode.d4.loss_cls: 0.3070, decode.d4.loss_mask: 0.3718, decode.d4.loss_dice: 0.7008, decode.d5.loss_cls: 0.2795, decode.d5.loss_mask: 0.3648, decode.d5.loss_dice: 0.7021, decode.d6.loss_cls: 0.2188, decode.d6.loss_mask: 0.3737, decode.d6.loss_dice: 0.6888, decode.d7.loss_cls: 0.1975, decode.d7.loss_mask: 0.3734, decode.d7.loss_dice: 0.6895, decode.d8.loss_cls: 0.1611, decode.d8.loss_mask: 0.3685, decode.d8.loss_dice: 0.6941, loss: 18.0133\n",
      "2024-02-14 13:46:06,682 - mmseg - INFO - Iter [330/80000]\tlr: 3.136e-07, eta: 2 days, 5:14:39, time: 2.338, data_time: 0.224, memory: 23505, decode.loss_cls: 0.1481, decode.loss_mask: 0.3533, decode.loss_dice: 0.7198, decode.d0.loss_cls: 4.0989, decode.d0.loss_mask: 0.4142, decode.d0.loss_dice: 0.8594, decode.d1.loss_cls: 0.7390, decode.d1.loss_mask: 0.4001, decode.d1.loss_dice: 0.6975, decode.d2.loss_cls: 0.5445, decode.d2.loss_mask: 0.3763, decode.d2.loss_dice: 0.7355, decode.d3.loss_cls: 0.4000, decode.d3.loss_mask: 0.3557, decode.d3.loss_dice: 0.7273, decode.d4.loss_cls: 0.3048, decode.d4.loss_mask: 0.3536, decode.d4.loss_dice: 0.7310, decode.d5.loss_cls: 0.2613, decode.d5.loss_mask: 0.3497, decode.d5.loss_dice: 0.7193, decode.d6.loss_cls: 0.2116, decode.d6.loss_mask: 0.3484, decode.d6.loss_dice: 0.7131, decode.d7.loss_cls: 0.1796, decode.d7.loss_mask: 0.3531, decode.d7.loss_dice: 0.7156, decode.d8.loss_cls: 0.1576, decode.d8.loss_mask: 0.3473, decode.d8.loss_dice: 0.7173, loss: 18.0331\n",
      "2024-02-14 13:46:27,997 - mmseg - INFO - Iter [340/80000]\tlr: 3.231e-07, eta: 2 days, 5:03:32, time: 2.132, data_time: 0.016, memory: 23505, decode.loss_cls: 0.1063, decode.loss_mask: 0.3549, decode.loss_dice: 0.6896, decode.d0.loss_cls: 4.0794, decode.d0.loss_mask: 0.4018, decode.d0.loss_dice: 0.8033, decode.d1.loss_cls: 0.6708, decode.d1.loss_mask: 0.4013, decode.d1.loss_dice: 0.6768, decode.d2.loss_cls: 0.4890, decode.d2.loss_mask: 0.3662, decode.d2.loss_dice: 0.6830, decode.d3.loss_cls: 0.3380, decode.d3.loss_mask: 0.3464, decode.d3.loss_dice: 0.6864, decode.d4.loss_cls: 0.2378, decode.d4.loss_mask: 0.3459, decode.d4.loss_dice: 0.6909, decode.d5.loss_cls: 0.1980, decode.d5.loss_mask: 0.3507, decode.d5.loss_dice: 0.6891, decode.d6.loss_cls: 0.1656, decode.d6.loss_mask: 0.3546, decode.d6.loss_dice: 0.6793, decode.d7.loss_cls: 0.1346, decode.d7.loss_mask: 0.3580, decode.d7.loss_dice: 0.6833, decode.d8.loss_cls: 0.1131, decode.d8.loss_mask: 0.3566, decode.d8.loss_dice: 0.6905, loss: 17.1413\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-14 13:46:49,271 - mmseg - INFO - Iter [350/80000]\tlr: 3.326e-07, eta: 2 days, 4:52:53, time: 2.127, data_time: 0.015, memory: 23505, decode.loss_cls: 0.1072, decode.loss_mask: 0.3341, decode.loss_dice: 0.6495, decode.d0.loss_cls: 4.0808, decode.d0.loss_mask: 0.3730, decode.d0.loss_dice: 0.7441, decode.d1.loss_cls: 0.6534, decode.d1.loss_mask: 0.3642, decode.d1.loss_dice: 0.6391, decode.d2.loss_cls: 0.4537, decode.d2.loss_mask: 0.3392, decode.d2.loss_dice: 0.6506, decode.d3.loss_cls: 0.3061, decode.d3.loss_mask: 0.3223, decode.d3.loss_dice: 0.6569, decode.d4.loss_cls: 0.2139, decode.d4.loss_mask: 0.3209, decode.d4.loss_dice: 0.6520, decode.d5.loss_cls: 0.1917, decode.d5.loss_mask: 0.3243, decode.d5.loss_dice: 0.6571, decode.d6.loss_cls: 0.1504, decode.d6.loss_mask: 0.3315, decode.d6.loss_dice: 0.6452, decode.d7.loss_cls: 0.1302, decode.d7.loss_mask: 0.3356, decode.d7.loss_dice: 0.6539, decode.d8.loss_cls: 0.1134, decode.d8.loss_mask: 0.3260, decode.d8.loss_dice: 0.6404, loss: 16.3605\n",
      "2024-02-14 13:47:10,575 - mmseg - INFO - Iter [360/80000]\tlr: 3.421e-07, eta: 2 days, 4:42:54, time: 2.130, data_time: 0.017, memory: 23505, decode.loss_cls: 0.0732, decode.loss_mask: 0.3825, decode.loss_dice: 0.6960, decode.d0.loss_cls: 4.0712, decode.d0.loss_mask: 0.4392, decode.d0.loss_dice: 0.8179, decode.d1.loss_cls: 0.6282, decode.d1.loss_mask: 0.4253, decode.d1.loss_dice: 0.6860, decode.d2.loss_cls: 0.4492, decode.d2.loss_mask: 0.4003, decode.d2.loss_dice: 0.6871, decode.d3.loss_cls: 0.2914, decode.d3.loss_mask: 0.3827, decode.d3.loss_dice: 0.6967, decode.d4.loss_cls: 0.1840, decode.d4.loss_mask: 0.3789, decode.d4.loss_dice: 0.7113, decode.d5.loss_cls: 0.1515, decode.d5.loss_mask: 0.3821, decode.d5.loss_dice: 0.6976, decode.d6.loss_cls: 0.1084, decode.d6.loss_mask: 0.3855, decode.d6.loss_dice: 0.6966, decode.d7.loss_cls: 0.0904, decode.d7.loss_mask: 0.3835, decode.d7.loss_dice: 0.6977, decode.d8.loss_cls: 0.0761, decode.d8.loss_mask: 0.3798, decode.d8.loss_dice: 0.7033, loss: 17.1537\n",
      "2024-02-14 13:47:31,875 - mmseg - INFO - Iter [370/80000]\tlr: 3.516e-07, eta: 2 days, 4:33:26, time: 2.130, data_time: 0.016, memory: 23505, decode.loss_cls: 0.0641, decode.loss_mask: 0.3478, decode.loss_dice: 0.6626, decode.d0.loss_cls: 4.0591, decode.d0.loss_mask: 0.3889, decode.d0.loss_dice: 0.7803, decode.d1.loss_cls: 0.5612, decode.d1.loss_mask: 0.3840, decode.d1.loss_dice: 0.6661, decode.d2.loss_cls: 0.4006, decode.d2.loss_mask: 0.3705, decode.d2.loss_dice: 0.6674, decode.d3.loss_cls: 0.2451, decode.d3.loss_mask: 0.3489, decode.d3.loss_dice: 0.6794, decode.d4.loss_cls: 0.1502, decode.d4.loss_mask: 0.3439, decode.d4.loss_dice: 0.6655, decode.d5.loss_cls: 0.1222, decode.d5.loss_mask: 0.3471, decode.d5.loss_dice: 0.6713, decode.d6.loss_cls: 0.0924, decode.d6.loss_mask: 0.3503, decode.d6.loss_dice: 0.6611, decode.d7.loss_cls: 0.0782, decode.d7.loss_mask: 0.3500, decode.d7.loss_dice: 0.6656, decode.d8.loss_cls: 0.0667, decode.d8.loss_mask: 0.3474, decode.d8.loss_dice: 0.6728, loss: 16.2106\n",
      "2024-02-14 13:47:53,169 - mmseg - INFO - Iter [380/80000]\tlr: 3.611e-07, eta: 2 days, 4:24:25, time: 2.129, data_time: 0.016, memory: 23505, decode.loss_cls: 0.0601, decode.loss_mask: 0.2907, decode.loss_dice: 0.6090, decode.d0.loss_cls: 4.0516, decode.d0.loss_mask: 0.3349, decode.d0.loss_dice: 0.7263, decode.d1.loss_cls: 0.5105, decode.d1.loss_mask: 0.3256, decode.d1.loss_dice: 0.6052, decode.d2.loss_cls: 0.3612, decode.d2.loss_mask: 0.3066, decode.d2.loss_dice: 0.6172, decode.d3.loss_cls: 0.2143, decode.d3.loss_mask: 0.2867, decode.d3.loss_dice: 0.6143, decode.d4.loss_cls: 0.1289, decode.d4.loss_mask: 0.2937, decode.d4.loss_dice: 0.6144, decode.d5.loss_cls: 0.1110, decode.d5.loss_mask: 0.2889, decode.d5.loss_dice: 0.6118, decode.d6.loss_cls: 0.0823, decode.d6.loss_mask: 0.2916, decode.d6.loss_dice: 0.6065, decode.d7.loss_cls: 0.0716, decode.d7.loss_mask: 0.2893, decode.d7.loss_dice: 0.6142, decode.d8.loss_cls: 0.0613, decode.d8.loss_mask: 0.2844, decode.d8.loss_dice: 0.6057, loss: 14.8696\n",
      "2024-02-14 13:48:14,488 - mmseg - INFO - Iter [390/80000]\tlr: 3.705e-07, eta: 2 days, 4:15:57, time: 2.132, data_time: 0.016, memory: 23505, decode.loss_cls: 0.0584, decode.loss_mask: 0.3492, decode.loss_dice: 0.6381, decode.d0.loss_cls: 4.0665, decode.d0.loss_mask: 0.4020, decode.d0.loss_dice: 0.7591, decode.d1.loss_cls: 0.5237, decode.d1.loss_mask: 0.3932, decode.d1.loss_dice: 0.6473, decode.d2.loss_cls: 0.3738, decode.d2.loss_mask: 0.3696, decode.d2.loss_dice: 0.6426, decode.d3.loss_cls: 0.2230, decode.d3.loss_mask: 0.3548, decode.d3.loss_dice: 0.6559, decode.d4.loss_cls: 0.1394, decode.d4.loss_mask: 0.3570, decode.d4.loss_dice: 0.6436, decode.d5.loss_cls: 0.1201, decode.d5.loss_mask: 0.3537, decode.d5.loss_dice: 0.6411, decode.d6.loss_cls: 0.0837, decode.d6.loss_mask: 0.3574, decode.d6.loss_dice: 0.6448, decode.d7.loss_cls: 0.0708, decode.d7.loss_mask: 0.3546, decode.d7.loss_dice: 0.6460, decode.d8.loss_cls: 0.0595, decode.d8.loss_mask: 0.3495, decode.d8.loss_dice: 0.6542, loss: 15.9327\n",
      "2024-02-14 13:48:35,792 - mmseg - INFO - Iter [400/80000]\tlr: 3.800e-07, eta: 2 days, 4:07:49, time: 2.130, data_time: 0.017, memory: 23505, decode.loss_cls: 0.0445, decode.loss_mask: 0.3675, decode.loss_dice: 0.6782, decode.d0.loss_cls: 4.0714, decode.d0.loss_mask: 0.4127, decode.d0.loss_dice: 0.7849, decode.d1.loss_cls: 0.5083, decode.d1.loss_mask: 0.4040, decode.d1.loss_dice: 0.6847, decode.d2.loss_cls: 0.3491, decode.d2.loss_mask: 0.3846, decode.d2.loss_dice: 0.6806, decode.d3.loss_cls: 0.2017, decode.d3.loss_mask: 0.3689, decode.d3.loss_dice: 0.6846, decode.d4.loss_cls: 0.1170, decode.d4.loss_mask: 0.3685, decode.d4.loss_dice: 0.6819, decode.d5.loss_cls: 0.0920, decode.d5.loss_mask: 0.3665, decode.d5.loss_dice: 0.6841, decode.d6.loss_cls: 0.0671, decode.d6.loss_mask: 0.3731, decode.d6.loss_dice: 0.6784, decode.d7.loss_cls: 0.0560, decode.d7.loss_mask: 0.3713, decode.d7.loss_dice: 0.6773, decode.d8.loss_cls: 0.0462, decode.d8.loss_mask: 0.3691, decode.d8.loss_dice: 0.6859, loss: 16.2598\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 40/40, 6.2 task/s, elapsed: 6s, ETA:     0s\n",
      "\n",
      "2024-02-14 13:48:42,224 - mmseg - INFO - per class results:\n",
      "2024-02-14 13:48:42,225 - mmseg - INFO - \n",
      "+---------------+-------+-------+\n",
      "|     Class     |  IoU  |  Acc  |\n",
      "+---------------+-------+-------+\n",
      "|       bg      | 96.73 | 97.63 |\n",
      "|    Anchovy    | 77.05 | 91.19 |\n",
      "|     Olives    | 86.12 |  90.3 |\n",
      "|     Salami    | 60.49 |  90.2 |\n",
      "|   Red_Pepper  | 85.53 | 92.65 |\n",
      "| Yellow_Pepper | 85.28 | 94.52 |\n",
      "+---------------+-------+-------+\n",
      "2024-02-14 13:48:42,225 - mmseg - INFO - Summary:\n",
      "2024-02-14 13:48:42,225 - mmseg - INFO - \n",
      "+-------+-------+-------+\n",
      "|  aAcc |  mIoU |  mAcc |\n",
      "+-------+-------+-------+\n",
      "| 96.78 | 81.87 | 92.75 |\n",
      "+-------+-------+-------+\n",
      "2024-02-14 13:48:42,730 - mmseg - INFO - The previous best checkpoint /workspace/ViT-Adapter/segmentation/work_dirs/pizze_training_large/best_mIoU_iter_200.pth was removed\n",
      "2024-02-14 13:48:54,947 - mmseg - INFO - Now best checkpoint is saved as best_mIoU_iter_400.pth.\n",
      "2024-02-14 13:48:54,947 - mmseg - INFO - Best mIoU is 0.8187 at 400 iter.\n",
      "2024-02-14 13:48:54,947 - mmseg - INFO - Iter(val) [10]\taAcc: 0.9678, mIoU: 0.8187, mAcc: 0.9275, IoU.bg: 0.9673, IoU.Anchovy: 0.7705, IoU.Olives: 0.8612, IoU.Salami: 0.6049, IoU.Red_Pepper: 0.8553, IoU.Yellow_Pepper: 0.8528, Acc.bg: 0.9763, Acc.Anchovy: 0.9119, Acc.Olives: 0.9030, Acc.Salami: 0.9020, Acc.Red_Pepper: 0.9265, Acc.Yellow_Pepper: 0.9452\n",
      "2024-02-14 13:49:16,220 - mmseg - INFO - Iter [410/80000]\tlr: 3.895e-07, eta: 2 days, 5:01:57, time: 4.043, data_time: 1.932, memory: 23505, decode.loss_cls: 0.0400, decode.loss_mask: 0.3650, decode.loss_dice: 0.6753, decode.d0.loss_cls: 4.0441, decode.d0.loss_mask: 0.4076, decode.d0.loss_dice: 0.7893, decode.d1.loss_cls: 0.4439, decode.d1.loss_mask: 0.4070, decode.d1.loss_dice: 0.6919, decode.d2.loss_cls: 0.2986, decode.d2.loss_mask: 0.3793, decode.d2.loss_dice: 0.6926, decode.d3.loss_cls: 0.1756, decode.d3.loss_mask: 0.3628, decode.d3.loss_dice: 0.6879, decode.d4.loss_cls: 0.1007, decode.d4.loss_mask: 0.3683, decode.d4.loss_dice: 0.6840, decode.d5.loss_cls: 0.0795, decode.d5.loss_mask: 0.3639, decode.d5.loss_dice: 0.6852, decode.d6.loss_cls: 0.0584, decode.d6.loss_mask: 0.3705, decode.d6.loss_dice: 0.6827, decode.d7.loss_cls: 0.0492, decode.d7.loss_mask: 0.3697, decode.d7.loss_dice: 0.6821, decode.d8.loss_cls: 0.0415, decode.d8.loss_mask: 0.3669, decode.d8.loss_dice: 0.6784, loss: 16.0420\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-14 13:49:40,689 - mmseg - INFO - Iter [420/80000]\tlr: 3.990e-07, eta: 2 days, 5:03:04, time: 2.447, data_time: 0.016, memory: 23505, decode.loss_cls: 0.0317, decode.loss_mask: 0.2911, decode.loss_dice: 0.6129, decode.d0.loss_cls: 4.0157, decode.d0.loss_mask: 0.3302, decode.d0.loss_dice: 0.7200, decode.d1.loss_cls: 0.3922, decode.d1.loss_mask: 0.3164, decode.d1.loss_dice: 0.6212, decode.d2.loss_cls: 0.2548, decode.d2.loss_mask: 0.3013, decode.d2.loss_dice: 0.6216, decode.d3.loss_cls: 0.1359, decode.d3.loss_mask: 0.2895, decode.d3.loss_dice: 0.6236, decode.d4.loss_cls: 0.0764, decode.d4.loss_mask: 0.2902, decode.d4.loss_dice: 0.6184, decode.d5.loss_cls: 0.0632, decode.d5.loss_mask: 0.2875, decode.d5.loss_dice: 0.6229, decode.d6.loss_cls: 0.0466, decode.d6.loss_mask: 0.2921, decode.d6.loss_dice: 0.6141, decode.d7.loss_cls: 0.0395, decode.d7.loss_mask: 0.2861, decode.d7.loss_dice: 0.6095, decode.d8.loss_cls: 0.0329, decode.d8.loss_mask: 0.2869, decode.d8.loss_dice: 0.6123, loss: 14.3369\n",
      "2024-02-14 13:50:11,070 - mmseg - INFO - Iter [430/80000]\tlr: 4.084e-07, eta: 2 days, 5:22:21, time: 3.038, data_time: 0.031, memory: 23505, decode.loss_cls: 0.0325, decode.loss_mask: 0.3534, decode.loss_dice: 0.6553, decode.d0.loss_cls: 4.0371, decode.d0.loss_mask: 0.4003, decode.d0.loss_dice: 0.7536, decode.d1.loss_cls: 0.3898, decode.d1.loss_mask: 0.3766, decode.d1.loss_dice: 0.6682, decode.d2.loss_cls: 0.2659, decode.d2.loss_mask: 0.3634, decode.d2.loss_dice: 0.6659, decode.d3.loss_cls: 0.1444, decode.d3.loss_mask: 0.3563, decode.d3.loss_dice: 0.6639, decode.d4.loss_cls: 0.0846, decode.d4.loss_mask: 0.3539, decode.d4.loss_dice: 0.6487, decode.d5.loss_cls: 0.0669, decode.d5.loss_mask: 0.3491, decode.d5.loss_dice: 0.6497, decode.d6.loss_cls: 0.0464, decode.d6.loss_mask: 0.3513, decode.d6.loss_dice: 0.6533, decode.d7.loss_cls: 0.0394, decode.d7.loss_mask: 0.3524, decode.d7.loss_dice: 0.6555, decode.d8.loss_cls: 0.0331, decode.d8.loss_mask: 0.3502, decode.d8.loss_dice: 0.6583, loss: 15.4194\n",
      "2024-02-14 13:51:13,469 - mmseg - INFO - Iter [440/80000]\tlr: 4.179e-07, eta: 2 days, 7:17:13, time: 6.240, data_time: 0.016, memory: 23505, decode.loss_cls: 0.0331, decode.loss_mask: 0.2931, decode.loss_dice: 0.6145, decode.d0.loss_cls: 3.9995, decode.d0.loss_mask: 0.3279, decode.d0.loss_dice: 0.6894, decode.d1.loss_cls: 0.3593, decode.d1.loss_mask: 0.3201, decode.d1.loss_dice: 0.6392, decode.d2.loss_cls: 0.2300, decode.d2.loss_mask: 0.3033, decode.d2.loss_dice: 0.6335, decode.d3.loss_cls: 0.1276, decode.d3.loss_mask: 0.3022, decode.d3.loss_dice: 0.6250, decode.d4.loss_cls: 0.0721, decode.d4.loss_mask: 0.2971, decode.d4.loss_dice: 0.6215, decode.d5.loss_cls: 0.0630, decode.d5.loss_mask: 0.2938, decode.d5.loss_dice: 0.6170, decode.d6.loss_cls: 0.0472, decode.d6.loss_mask: 0.2978, decode.d6.loss_dice: 0.6218, decode.d7.loss_cls: 0.0424, decode.d7.loss_mask: 0.2983, decode.d7.loss_dice: 0.6163, decode.d8.loss_cls: 0.0349, decode.d8.loss_mask: 0.2973, decode.d8.loss_dice: 0.6187, loss: 14.3370\n",
      "2024-02-14 13:51:40,998 - mmseg - INFO - Iter [450/80000]\tlr: 4.274e-07, eta: 2 days, 7:24:12, time: 2.753, data_time: 0.015, memory: 23505, decode.loss_cls: 0.0253, decode.loss_mask: 0.3395, decode.loss_dice: 0.6292, decode.d0.loss_cls: 4.0273, decode.d0.loss_mask: 0.3815, decode.d0.loss_dice: 0.7100, decode.d1.loss_cls: 0.3486, decode.d1.loss_mask: 0.3745, decode.d1.loss_dice: 0.6524, decode.d2.loss_cls: 0.2283, decode.d2.loss_mask: 0.3530, decode.d2.loss_dice: 0.6372, decode.d3.loss_cls: 0.1234, decode.d3.loss_mask: 0.3416, decode.d3.loss_dice: 0.6395, decode.d4.loss_cls: 0.0664, decode.d4.loss_mask: 0.3435, decode.d4.loss_dice: 0.6406, decode.d5.loss_cls: 0.0522, decode.d5.loss_mask: 0.3416, decode.d5.loss_dice: 0.6417, decode.d6.loss_cls: 0.0381, decode.d6.loss_mask: 0.3392, decode.d6.loss_dice: 0.6287, decode.d7.loss_cls: 0.0319, decode.d7.loss_mask: 0.3419, decode.d7.loss_dice: 0.6379, decode.d8.loss_cls: 0.0265, decode.d8.loss_mask: 0.3435, decode.d8.loss_dice: 0.6294, loss: 14.9143\n",
      "2024-02-14 13:52:02,314 - mmseg - INFO - Iter [460/80000]\tlr: 4.368e-07, eta: 2 days, 7:12:57, time: 2.132, data_time: 0.017, memory: 23505, decode.loss_cls: 0.0243, decode.loss_mask: 0.3403, decode.loss_dice: 0.6444, decode.d0.loss_cls: 4.0105, decode.d0.loss_mask: 0.3869, decode.d0.loss_dice: 0.7352, decode.d1.loss_cls: 0.3148, decode.d1.loss_mask: 0.3731, decode.d1.loss_dice: 0.6664, decode.d2.loss_cls: 0.2115, decode.d2.loss_mask: 0.3517, decode.d2.loss_dice: 0.6421, decode.d3.loss_cls: 0.1167, decode.d3.loss_mask: 0.3549, decode.d3.loss_dice: 0.6586, decode.d4.loss_cls: 0.0645, decode.d4.loss_mask: 0.3465, decode.d4.loss_dice: 0.6555, decode.d5.loss_cls: 0.0512, decode.d5.loss_mask: 0.3456, decode.d5.loss_dice: 0.6546, decode.d6.loss_cls: 0.0366, decode.d6.loss_mask: 0.3474, decode.d6.loss_dice: 0.6466, decode.d7.loss_cls: 0.0308, decode.d7.loss_mask: 0.3439, decode.d7.loss_dice: 0.6533, decode.d8.loss_cls: 0.0258, decode.d8.loss_mask: 0.3417, decode.d8.loss_dice: 0.6491, loss: 15.0244\n",
      "2024-02-14 13:52:23,629 - mmseg - INFO - Iter [470/80000]\tlr: 4.463e-07, eta: 2 days, 7:02:11, time: 2.132, data_time: 0.017, memory: 23505, decode.loss_cls: 0.0241, decode.loss_mask: 0.3802, decode.loss_dice: 0.7259, decode.d0.loss_cls: 4.0348, decode.d0.loss_mask: 0.4334, decode.d0.loss_dice: 0.8193, decode.d1.loss_cls: 0.3300, decode.d1.loss_mask: 0.4030, decode.d1.loss_dice: 0.7568, decode.d2.loss_cls: 0.2186, decode.d2.loss_mask: 0.3953, decode.d2.loss_dice: 0.7435, decode.d3.loss_cls: 0.1330, decode.d3.loss_mask: 0.3872, decode.d3.loss_dice: 0.7302, decode.d4.loss_cls: 0.0774, decode.d4.loss_mask: 0.3839, decode.d4.loss_dice: 0.7302, decode.d5.loss_cls: 0.0536, decode.d5.loss_mask: 0.3819, decode.d5.loss_dice: 0.7268, decode.d6.loss_cls: 0.0372, decode.d6.loss_mask: 0.3850, decode.d6.loss_dice: 0.7290, decode.d7.loss_cls: 0.0320, decode.d7.loss_mask: 0.3797, decode.d7.loss_dice: 0.7348, decode.d8.loss_cls: 0.0263, decode.d8.loss_mask: 0.3826, decode.d8.loss_dice: 0.7363, loss: 16.3122\n",
      "2024-02-14 13:52:44,934 - mmseg - INFO - Iter [480/80000]\tlr: 4.558e-07, eta: 2 days, 6:51:47, time: 2.130, data_time: 0.018, memory: 23505, decode.loss_cls: 0.0264, decode.loss_mask: 0.3583, decode.loss_dice: 0.6609, decode.d0.loss_cls: 4.0063, decode.d0.loss_mask: 0.3816, decode.d0.loss_dice: 0.7517, decode.d1.loss_cls: 0.2998, decode.d1.loss_mask: 0.3594, decode.d1.loss_dice: 0.6834, decode.d2.loss_cls: 0.2058, decode.d2.loss_mask: 0.3560, decode.d2.loss_dice: 0.6749, decode.d3.loss_cls: 0.1161, decode.d3.loss_mask: 0.3542, decode.d3.loss_dice: 0.6730, decode.d4.loss_cls: 0.0714, decode.d4.loss_mask: 0.3544, decode.d4.loss_dice: 0.6641, decode.d5.loss_cls: 0.0509, decode.d5.loss_mask: 0.3536, decode.d5.loss_dice: 0.6709, decode.d6.loss_cls: 0.0377, decode.d6.loss_mask: 0.3552, decode.d6.loss_dice: 0.6560, decode.d7.loss_cls: 0.0316, decode.d7.loss_mask: 0.3517, decode.d7.loss_dice: 0.6519, decode.d8.loss_cls: 0.0273, decode.d8.loss_mask: 0.3570, decode.d8.loss_dice: 0.6613, loss: 15.2030\n",
      "2024-02-14 13:53:06,257 - mmseg - INFO - Iter [490/80000]\tlr: 4.652e-07, eta: 2 days, 6:41:53, time: 2.133, data_time: 0.016, memory: 23505, decode.loss_cls: 0.0200, decode.loss_mask: 0.3176, decode.loss_dice: 0.6359, decode.d0.loss_cls: 3.9874, decode.d0.loss_mask: 0.3444, decode.d0.loss_dice: 0.7136, decode.d1.loss_cls: 0.2640, decode.d1.loss_mask: 0.3292, decode.d1.loss_dice: 0.6561, decode.d2.loss_cls: 0.1700, decode.d2.loss_mask: 0.3270, decode.d2.loss_dice: 0.6430, decode.d3.loss_cls: 0.0919, decode.d3.loss_mask: 0.3153, decode.d3.loss_dice: 0.6384, decode.d4.loss_cls: 0.0509, decode.d4.loss_mask: 0.3178, decode.d4.loss_dice: 0.6503, decode.d5.loss_cls: 0.0408, decode.d5.loss_mask: 0.3173, decode.d5.loss_dice: 0.6409, decode.d6.loss_cls: 0.0291, decode.d6.loss_mask: 0.3223, decode.d6.loss_dice: 0.6356, decode.d7.loss_cls: 0.0250, decode.d7.loss_mask: 0.3196, decode.d7.loss_dice: 0.6411, decode.d8.loss_cls: 0.0212, decode.d8.loss_mask: 0.3160, decode.d8.loss_dice: 0.6374, loss: 14.4191\n",
      "2024-02-14 13:53:27,595 - mmseg - INFO - Iter [500/80000]\tlr: 4.747e-07, eta: 2 days, 6:32:23, time: 2.134, data_time: 0.017, memory: 23505, decode.loss_cls: 0.0156, decode.loss_mask: 0.3369, decode.loss_dice: 0.6316, decode.d0.loss_cls: 3.9861, decode.d0.loss_mask: 0.3709, decode.d0.loss_dice: 0.7028, decode.d1.loss_cls: 0.2433, decode.d1.loss_mask: 0.3636, decode.d1.loss_dice: 0.6360, decode.d2.loss_cls: 0.1541, decode.d2.loss_mask: 0.3530, decode.d2.loss_dice: 0.6284, decode.d3.loss_cls: 0.0880, decode.d3.loss_mask: 0.3469, decode.d3.loss_dice: 0.6306, decode.d4.loss_cls: 0.0442, decode.d4.loss_mask: 0.3417, decode.d4.loss_dice: 0.6242, decode.d5.loss_cls: 0.0335, decode.d5.loss_mask: 0.3388, decode.d5.loss_dice: 0.6306, decode.d6.loss_cls: 0.0231, decode.d6.loss_mask: 0.3383, decode.d6.loss_dice: 0.6212, decode.d7.loss_cls: 0.0194, decode.d7.loss_mask: 0.3353, decode.d7.loss_dice: 0.6199, decode.d8.loss_cls: 0.0164, decode.d8.loss_mask: 0.3325, decode.d8.loss_dice: 0.6236, loss: 14.4305\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-14 13:53:48,926 - mmseg - INFO - Iter [510/80000]\tlr: 4.841e-07, eta: 2 days, 6:23:14, time: 2.133, data_time: 0.016, memory: 23505, decode.loss_cls: 0.0153, decode.loss_mask: 0.2843, decode.loss_dice: 0.6371, decode.d0.loss_cls: 3.9705, decode.d0.loss_mask: 0.3171, decode.d0.loss_dice: 0.7024, decode.d1.loss_cls: 0.2338, decode.d1.loss_mask: 0.3048, decode.d1.loss_dice: 0.6383, decode.d2.loss_cls: 0.1439, decode.d2.loss_mask: 0.2950, decode.d2.loss_dice: 0.6308, decode.d3.loss_cls: 0.0785, decode.d3.loss_mask: 0.2880, decode.d3.loss_dice: 0.6224, decode.d4.loss_cls: 0.0411, decode.d4.loss_mask: 0.2898, decode.d4.loss_dice: 0.6299, decode.d5.loss_cls: 0.0321, decode.d5.loss_mask: 0.2899, decode.d5.loss_dice: 0.6301, decode.d6.loss_cls: 0.0227, decode.d6.loss_mask: 0.2887, decode.d6.loss_dice: 0.6266, decode.d7.loss_cls: 0.0188, decode.d7.loss_mask: 0.2872, decode.d7.loss_dice: 0.6253, decode.d8.loss_cls: 0.0162, decode.d8.loss_mask: 0.2843, decode.d8.loss_dice: 0.6254, loss: 13.8704\n",
      "2024-02-14 13:54:10,236 - mmseg - INFO - Iter [520/80000]\tlr: 4.936e-07, eta: 2 days, 6:14:21, time: 2.131, data_time: 0.017, memory: 23505, decode.loss_cls: 0.0133, decode.loss_mask: 0.2717, decode.loss_dice: 0.5490, decode.d0.loss_cls: 3.9644, decode.d0.loss_mask: 0.2901, decode.d0.loss_dice: 0.6168, decode.d1.loss_cls: 0.2161, decode.d1.loss_mask: 0.2863, decode.d1.loss_dice: 0.5543, decode.d2.loss_cls: 0.1362, decode.d2.loss_mask: 0.2744, decode.d2.loss_dice: 0.5512, decode.d3.loss_cls: 0.0758, decode.d3.loss_mask: 0.2696, decode.d3.loss_dice: 0.5465, decode.d4.loss_cls: 0.0377, decode.d4.loss_mask: 0.2694, decode.d4.loss_dice: 0.5449, decode.d5.loss_cls: 0.0333, decode.d5.loss_mask: 0.2662, decode.d5.loss_dice: 0.5321, decode.d6.loss_cls: 0.0195, decode.d6.loss_mask: 0.2727, decode.d6.loss_dice: 0.5422, decode.d7.loss_cls: 0.0164, decode.d7.loss_mask: 0.2722, decode.d7.loss_dice: 0.5418, decode.d8.loss_cls: 0.0137, decode.d8.loss_mask: 0.2701, decode.d8.loss_dice: 0.5432, loss: 12.7909\n",
      "2024-02-14 13:54:31,528 - mmseg - INFO - Iter [530/80000]\tlr: 5.030e-07, eta: 2 days, 6:05:46, time: 2.129, data_time: 0.017, memory: 23505, decode.loss_cls: 0.0139, decode.loss_mask: 0.3232, decode.loss_dice: 0.6437, decode.d0.loss_cls: 3.9804, decode.d0.loss_mask: 0.3477, decode.d0.loss_dice: 0.7100, decode.d1.loss_cls: 0.2086, decode.d1.loss_mask: 0.3383, decode.d1.loss_dice: 0.6721, decode.d2.loss_cls: 0.1291, decode.d2.loss_mask: 0.3211, decode.d2.loss_dice: 0.6539, decode.d3.loss_cls: 0.0716, decode.d3.loss_mask: 0.3260, decode.d3.loss_dice: 0.6508, decode.d4.loss_cls: 0.0356, decode.d4.loss_mask: 0.3225, decode.d4.loss_dice: 0.6494, decode.d5.loss_cls: 0.0276, decode.d5.loss_mask: 0.3228, decode.d5.loss_dice: 0.6474, decode.d6.loss_cls: 0.0191, decode.d6.loss_mask: 0.3248, decode.d6.loss_dice: 0.6465, decode.d7.loss_cls: 0.0166, decode.d7.loss_mask: 0.3230, decode.d7.loss_dice: 0.6458, decode.d8.loss_cls: 0.0146, decode.d8.loss_mask: 0.3210, decode.d8.loss_dice: 0.6434, loss: 14.3504\n",
      "2024-02-14 13:54:52,833 - mmseg - INFO - Iter [540/80000]\tlr: 5.125e-07, eta: 2 days, 5:57:30, time: 2.130, data_time: 0.018, memory: 23505, decode.loss_cls: 0.0126, decode.loss_mask: 0.3247, decode.loss_dice: 0.6235, decode.d0.loss_cls: 3.9675, decode.d0.loss_mask: 0.3587, decode.d0.loss_dice: 0.7005, decode.d1.loss_cls: 0.2006, decode.d1.loss_mask: 0.3363, decode.d1.loss_dice: 0.6324, decode.d2.loss_cls: 0.1265, decode.d2.loss_mask: 0.3321, decode.d2.loss_dice: 0.6270, decode.d3.loss_cls: 0.0729, decode.d3.loss_mask: 0.3285, decode.d3.loss_dice: 0.6254, decode.d4.loss_cls: 0.0367, decode.d4.loss_mask: 0.3251, decode.d4.loss_dice: 0.6197, decode.d5.loss_cls: 0.0270, decode.d5.loss_mask: 0.3265, decode.d5.loss_dice: 0.6205, decode.d6.loss_cls: 0.0186, decode.d6.loss_mask: 0.3210, decode.d6.loss_dice: 0.6152, decode.d7.loss_cls: 0.0157, decode.d7.loss_mask: 0.3193, decode.d7.loss_dice: 0.6189, decode.d8.loss_cls: 0.0132, decode.d8.loss_mask: 0.3233, decode.d8.loss_dice: 0.6213, loss: 14.0912\n",
      "2024-02-14 13:55:14,126 - mmseg - INFO - Iter [550/80000]\tlr: 5.219e-07, eta: 2 days, 5:49:30, time: 2.129, data_time: 0.017, memory: 23505, decode.loss_cls: 0.0111, decode.loss_mask: 0.3263, decode.loss_dice: 0.6541, decode.d0.loss_cls: 3.9651, decode.d0.loss_mask: 0.3640, decode.d0.loss_dice: 0.7426, decode.d1.loss_cls: 0.1797, decode.d1.loss_mask: 0.3486, decode.d1.loss_dice: 0.6687, decode.d2.loss_cls: 0.1128, decode.d2.loss_mask: 0.3377, decode.d2.loss_dice: 0.6608, decode.d3.loss_cls: 0.0673, decode.d3.loss_mask: 0.3291, decode.d3.loss_dice: 0.6541, decode.d4.loss_cls: 0.0342, decode.d4.loss_mask: 0.3288, decode.d4.loss_dice: 0.6576, decode.d5.loss_cls: 0.0242, decode.d5.loss_mask: 0.3270, decode.d5.loss_dice: 0.6576, decode.d6.loss_cls: 0.0157, decode.d6.loss_mask: 0.3279, decode.d6.loss_dice: 0.6532, decode.d7.loss_cls: 0.0130, decode.d7.loss_mask: 0.3265, decode.d7.loss_dice: 0.6597, decode.d8.loss_cls: 0.0114, decode.d8.loss_mask: 0.3286, decode.d8.loss_dice: 0.6603, loss: 14.4478\n",
      "2024-02-14 13:55:35,432 - mmseg - INFO - Iter [560/80000]\tlr: 5.313e-07, eta: 2 days, 5:41:48, time: 2.131, data_time: 0.018, memory: 23505, decode.loss_cls: 0.0121, decode.loss_mask: 0.3389, decode.loss_dice: 0.6212, decode.d0.loss_cls: 3.9769, decode.d0.loss_mask: 0.3757, decode.d0.loss_dice: 0.6995, decode.d1.loss_cls: 0.1775, decode.d1.loss_mask: 0.3556, decode.d1.loss_dice: 0.6454, decode.d2.loss_cls: 0.1117, decode.d2.loss_mask: 0.3429, decode.d2.loss_dice: 0.6332, decode.d3.loss_cls: 0.0672, decode.d3.loss_mask: 0.3408, decode.d3.loss_dice: 0.6302, decode.d4.loss_cls: 0.0355, decode.d4.loss_mask: 0.3385, decode.d4.loss_dice: 0.6297, decode.d5.loss_cls: 0.0263, decode.d5.loss_mask: 0.3381, decode.d5.loss_dice: 0.6316, decode.d6.loss_cls: 0.0183, decode.d6.loss_mask: 0.3368, decode.d6.loss_dice: 0.6211, decode.d7.loss_cls: 0.0152, decode.d7.loss_mask: 0.3387, decode.d7.loss_dice: 0.6267, decode.d8.loss_cls: 0.0130, decode.d8.loss_mask: 0.3422, decode.d8.loss_dice: 0.6266, loss: 14.2674\n",
      "2024-02-14 13:55:56,717 - mmseg - INFO - Iter [570/80000]\tlr: 5.408e-07, eta: 2 days, 5:34:19, time: 2.129, data_time: 0.016, memory: 23505, decode.loss_cls: 0.0109, decode.loss_mask: 0.2813, decode.loss_dice: 0.5768, decode.d0.loss_cls: 3.9442, decode.d0.loss_mask: 0.3064, decode.d0.loss_dice: 0.6613, decode.d1.loss_cls: 0.1623, decode.d1.loss_mask: 0.2862, decode.d1.loss_dice: 0.5974, decode.d2.loss_cls: 0.1058, decode.d2.loss_mask: 0.2837, decode.d2.loss_dice: 0.5844, decode.d3.loss_cls: 0.0650, decode.d3.loss_mask: 0.2845, decode.d3.loss_dice: 0.5839, decode.d4.loss_cls: 0.0340, decode.d4.loss_mask: 0.2826, decode.d4.loss_dice: 0.5811, decode.d5.loss_cls: 0.0236, decode.d5.loss_mask: 0.2795, decode.d5.loss_dice: 0.5840, decode.d6.loss_cls: 0.0157, decode.d6.loss_mask: 0.2830, decode.d6.loss_dice: 0.5892, decode.d7.loss_cls: 0.0133, decode.d7.loss_mask: 0.2813, decode.d7.loss_dice: 0.5811, decode.d8.loss_cls: 0.0114, decode.d8.loss_mask: 0.2828, decode.d8.loss_dice: 0.5865, loss: 13.1634\n",
      "2024-02-14 13:56:18,012 - mmseg - INFO - Iter [580/80000]\tlr: 5.502e-07, eta: 2 days, 5:27:06, time: 2.129, data_time: 0.017, memory: 23505, decode.loss_cls: 0.0111, decode.loss_mask: 0.2781, decode.loss_dice: 0.5555, decode.d0.loss_cls: 3.9360, decode.d0.loss_mask: 0.3002, decode.d0.loss_dice: 0.6433, decode.d1.loss_cls: 0.1597, decode.d1.loss_mask: 0.2838, decode.d1.loss_dice: 0.5641, decode.d2.loss_cls: 0.0974, decode.d2.loss_mask: 0.2777, decode.d2.loss_dice: 0.5595, decode.d3.loss_cls: 0.0603, decode.d3.loss_mask: 0.2789, decode.d3.loss_dice: 0.5570, decode.d4.loss_cls: 0.0328, decode.d4.loss_mask: 0.2776, decode.d4.loss_dice: 0.5525, decode.d5.loss_cls: 0.0237, decode.d5.loss_mask: 0.2756, decode.d5.loss_dice: 0.5423, decode.d6.loss_cls: 0.0168, decode.d6.loss_mask: 0.2762, decode.d6.loss_dice: 0.5483, decode.d7.loss_cls: 0.0145, decode.d7.loss_mask: 0.2749, decode.d7.loss_dice: 0.5503, decode.d8.loss_cls: 0.0119, decode.d8.loss_mask: 0.2786, decode.d8.loss_dice: 0.5577, loss: 12.7963\n",
      "2024-02-14 13:56:39,314 - mmseg - INFO - Iter [590/80000]\tlr: 5.596e-07, eta: 2 days, 5:20:08, time: 2.130, data_time: 0.017, memory: 23505, decode.loss_cls: 0.0103, decode.loss_mask: 0.3521, decode.loss_dice: 0.6087, decode.d0.loss_cls: 3.9502, decode.d0.loss_mask: 0.3923, decode.d0.loss_dice: 0.6815, decode.d1.loss_cls: 0.1669, decode.d1.loss_mask: 0.3715, decode.d1.loss_dice: 0.6071, decode.d2.loss_cls: 0.1048, decode.d2.loss_mask: 0.3601, decode.d2.loss_dice: 0.6139, decode.d3.loss_cls: 0.0641, decode.d3.loss_mask: 0.3517, decode.d3.loss_dice: 0.6119, decode.d4.loss_cls: 0.0316, decode.d4.loss_mask: 0.3545, decode.d4.loss_dice: 0.6103, decode.d5.loss_cls: 0.0203, decode.d5.loss_mask: 0.3523, decode.d5.loss_dice: 0.6124, decode.d6.loss_cls: 0.0143, decode.d6.loss_mask: 0.3522, decode.d6.loss_dice: 0.6041, decode.d7.loss_cls: 0.0121, decode.d7.loss_mask: 0.3551, decode.d7.loss_dice: 0.6036, decode.d8.loss_cls: 0.0104, decode.d8.loss_mask: 0.3532, decode.d8.loss_dice: 0.6092, loss: 14.1428\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-14 13:57:00,608 - mmseg - INFO - Iter [600/80000]\tlr: 5.691e-07, eta: 2 days, 5:13:22, time: 2.129, data_time: 0.018, memory: 23505, decode.loss_cls: 0.0087, decode.loss_mask: 0.2621, decode.loss_dice: 0.5582, decode.d0.loss_cls: 3.9228, decode.d0.loss_mask: 0.3037, decode.d0.loss_dice: 0.6103, decode.d1.loss_cls: 0.1413, decode.d1.loss_mask: 0.2815, decode.d1.loss_dice: 0.5715, decode.d2.loss_cls: 0.0903, decode.d2.loss_mask: 0.2716, decode.d2.loss_dice: 0.5526, decode.d3.loss_cls: 0.0497, decode.d3.loss_mask: 0.2679, decode.d3.loss_dice: 0.5562, decode.d4.loss_cls: 0.0256, decode.d4.loss_mask: 0.2655, decode.d4.loss_dice: 0.5578, decode.d5.loss_cls: 0.0175, decode.d5.loss_mask: 0.2653, decode.d5.loss_dice: 0.5598, decode.d6.loss_cls: 0.0120, decode.d6.loss_mask: 0.2638, decode.d6.loss_dice: 0.5579, decode.d7.loss_cls: 0.0105, decode.d7.loss_mask: 0.2655, decode.d7.loss_dice: 0.5592, decode.d8.loss_cls: 0.0092, decode.d8.loss_mask: 0.2625, decode.d8.loss_dice: 0.5541, loss: 12.6345\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 40/40, 6.2 task/s, elapsed: 6s, ETA:     0s\n",
      "\n",
      "2024-02-14 13:57:07,095 - mmseg - INFO - per class results:\n",
      "2024-02-14 13:57:07,096 - mmseg - INFO - \n",
      "+---------------+-------+-------+\n",
      "|     Class     |  IoU  |  Acc  |\n",
      "+---------------+-------+-------+\n",
      "|       bg      | 97.11 | 98.13 |\n",
      "|    Anchovy    | 78.36 | 91.57 |\n",
      "|     Olives    |  87.1 | 91.72 |\n",
      "|     Salami    |  65.7 | 86.25 |\n",
      "|   Red_Pepper  | 86.12 | 93.01 |\n",
      "| Yellow_Pepper | 85.82 | 94.65 |\n",
      "+---------------+-------+-------+\n",
      "2024-02-14 13:57:07,096 - mmseg - INFO - Summary:\n",
      "2024-02-14 13:57:07,096 - mmseg - INFO - \n",
      "+-------+-------+-------+\n",
      "|  aAcc |  mIoU |  mAcc |\n",
      "+-------+-------+-------+\n",
      "| 97.16 | 83.37 | 92.55 |\n",
      "+-------+-------+-------+\n",
      "2024-02-14 13:57:07,599 - mmseg - INFO - The previous best checkpoint /workspace/ViT-Adapter/segmentation/work_dirs/pizze_training_large/best_mIoU_iter_400.pth was removed\n",
      "2024-02-14 13:57:19,615 - mmseg - INFO - Now best checkpoint is saved as best_mIoU_iter_600.pth.\n",
      "2024-02-14 13:57:19,616 - mmseg - INFO - Best mIoU is 0.8337 at 600 iter.\n",
      "2024-02-14 13:57:19,616 - mmseg - INFO - Iter(val) [10]\taAcc: 0.9716, mIoU: 0.8337, mAcc: 0.9255, IoU.bg: 0.9711, IoU.Anchovy: 0.7836, IoU.Olives: 0.8710, IoU.Salami: 0.6570, IoU.Red_Pepper: 0.8612, IoU.Yellow_Pepper: 0.8582, Acc.bg: 0.9813, Acc.Anchovy: 0.9157, Acc.Olives: 0.9172, Acc.Salami: 0.8625, Acc.Red_Pepper: 0.9301, Acc.Yellow_Pepper: 0.9465\n",
      "2024-02-14 13:57:40,890 - mmseg - INFO - Iter [610/80000]\tlr: 5.785e-07, eta: 2 days, 5:48:00, time: 4.028, data_time: 1.918, memory: 23505, decode.loss_cls: 0.0092, decode.loss_mask: 0.3176, decode.loss_dice: 0.6174, decode.d0.loss_cls: 3.9194, decode.d0.loss_mask: 0.3558, decode.d0.loss_dice: 0.7000, decode.d1.loss_cls: 0.1519, decode.d1.loss_mask: 0.3212, decode.d1.loss_dice: 0.6382, decode.d2.loss_cls: 0.0898, decode.d2.loss_mask: 0.3166, decode.d2.loss_dice: 0.6299, decode.d3.loss_cls: 0.0519, decode.d3.loss_mask: 0.3142, decode.d3.loss_dice: 0.6150, decode.d4.loss_cls: 0.0269, decode.d4.loss_mask: 0.3173, decode.d4.loss_dice: 0.6149, decode.d5.loss_cls: 0.0179, decode.d5.loss_mask: 0.3207, decode.d5.loss_dice: 0.6184, decode.d6.loss_cls: 0.0128, decode.d6.loss_mask: 0.3181, decode.d6.loss_dice: 0.6128, decode.d7.loss_cls: 0.0109, decode.d7.loss_mask: 0.3165, decode.d7.loss_dice: 0.6138, decode.d8.loss_cls: 0.0096, decode.d8.loss_mask: 0.3167, decode.d8.loss_dice: 0.6092, loss: 13.7845\n",
      "2024-02-14 13:58:02,185 - mmseg - INFO - Iter [620/80000]\tlr: 5.879e-07, eta: 2 days, 5:40:58, time: 2.129, data_time: 0.017, memory: 23505, decode.loss_cls: 0.0097, decode.loss_mask: 0.3040, decode.loss_dice: 0.6026, decode.d0.loss_cls: 3.9251, decode.d0.loss_mask: 0.3383, decode.d0.loss_dice: 0.6576, decode.d1.loss_cls: 0.1307, decode.d1.loss_mask: 0.3177, decode.d1.loss_dice: 0.6177, decode.d2.loss_cls: 0.0815, decode.d2.loss_mask: 0.3106, decode.d2.loss_dice: 0.6143, decode.d3.loss_cls: 0.0506, decode.d3.loss_mask: 0.3069, decode.d3.loss_dice: 0.6109, decode.d4.loss_cls: 0.0237, decode.d4.loss_mask: 0.3054, decode.d4.loss_dice: 0.5985, decode.d5.loss_cls: 0.0168, decode.d5.loss_mask: 0.3027, decode.d5.loss_dice: 0.5991, decode.d6.loss_cls: 0.0122, decode.d6.loss_mask: 0.3064, decode.d6.loss_dice: 0.5989, decode.d7.loss_cls: 0.0108, decode.d7.loss_mask: 0.3100, decode.d7.loss_dice: 0.6010, decode.d8.loss_cls: 0.0098, decode.d8.loss_mask: 0.3078, decode.d8.loss_dice: 0.6086, loss: 13.4899\n",
      "2024-02-14 13:58:23,479 - mmseg - INFO - Iter [630/80000]\tlr: 5.973e-07, eta: 2 days, 5:34:10, time: 2.129, data_time: 0.017, memory: 23505, decode.loss_cls: 0.0075, decode.loss_mask: 0.3339, decode.loss_dice: 0.6388, decode.d0.loss_cls: 3.9297, decode.d0.loss_mask: 0.3729, decode.d0.loss_dice: 0.6792, decode.d1.loss_cls: 0.1292, decode.d1.loss_mask: 0.3491, decode.d1.loss_dice: 0.6590, decode.d2.loss_cls: 0.0774, decode.d2.loss_mask: 0.3407, decode.d2.loss_dice: 0.6429, decode.d3.loss_cls: 0.0475, decode.d3.loss_mask: 0.3420, decode.d3.loss_dice: 0.6426, decode.d4.loss_cls: 0.0232, decode.d4.loss_mask: 0.3393, decode.d4.loss_dice: 0.6397, decode.d5.loss_cls: 0.0149, decode.d5.loss_mask: 0.3359, decode.d5.loss_dice: 0.6363, decode.d6.loss_cls: 0.0103, decode.d6.loss_mask: 0.3354, decode.d6.loss_dice: 0.6295, decode.d7.loss_cls: 0.0091, decode.d7.loss_mask: 0.3374, decode.d7.loss_dice: 0.6405, decode.d8.loss_cls: 0.0081, decode.d8.loss_mask: 0.3348, decode.d8.loss_dice: 0.6400, loss: 14.1270\n",
      "2024-02-14 13:58:44,766 - mmseg - INFO - Iter [640/80000]\tlr: 6.068e-07, eta: 2 days, 5:27:32, time: 2.129, data_time: 0.017, memory: 23505, decode.loss_cls: 0.0071, decode.loss_mask: 0.2345, decode.loss_dice: 0.5180, decode.d0.loss_cls: 3.9090, decode.d0.loss_mask: 0.2417, decode.d0.loss_dice: 0.5687, decode.d1.loss_cls: 0.1126, decode.d1.loss_mask: 0.2394, decode.d1.loss_dice: 0.5254, decode.d2.loss_cls: 0.0722, decode.d2.loss_mask: 0.2375, decode.d2.loss_dice: 0.5349, decode.d3.loss_cls: 0.0393, decode.d3.loss_mask: 0.2306, decode.d3.loss_dice: 0.5206, decode.d4.loss_cls: 0.0187, decode.d4.loss_mask: 0.2322, decode.d4.loss_dice: 0.5187, decode.d5.loss_cls: 0.0135, decode.d5.loss_mask: 0.2304, decode.d5.loss_dice: 0.5243, decode.d6.loss_cls: 0.0095, decode.d6.loss_mask: 0.2304, decode.d6.loss_dice: 0.5114, decode.d7.loss_cls: 0.0086, decode.d7.loss_mask: 0.2309, decode.d7.loss_dice: 0.5110, decode.d8.loss_cls: 0.0075, decode.d8.loss_mask: 0.2355, decode.d8.loss_dice: 0.5164, loss: 11.7907\n",
      "2024-02-14 13:59:08,163 - mmseg - INFO - Iter [650/80000]\tlr: 6.162e-07, eta: 2 days, 5:25:23, time: 2.340, data_time: 0.226, memory: 23505, decode.loss_cls: 0.0069, decode.loss_mask: 0.3122, decode.loss_dice: 0.5826, decode.d0.loss_cls: 3.9212, decode.d0.loss_mask: 0.3415, decode.d0.loss_dice: 0.6233, decode.d1.loss_cls: 0.1304, decode.d1.loss_mask: 0.3276, decode.d1.loss_dice: 0.5939, decode.d2.loss_cls: 0.0777, decode.d2.loss_mask: 0.3155, decode.d2.loss_dice: 0.5872, decode.d3.loss_cls: 0.0474, decode.d3.loss_mask: 0.3101, decode.d3.loss_dice: 0.5839, decode.d4.loss_cls: 0.0218, decode.d4.loss_mask: 0.3083, decode.d4.loss_dice: 0.5801, decode.d5.loss_cls: 0.0138, decode.d5.loss_mask: 0.3116, decode.d5.loss_dice: 0.5801, decode.d6.loss_cls: 0.0095, decode.d6.loss_mask: 0.3170, decode.d6.loss_dice: 0.5818, decode.d7.loss_cls: 0.0084, decode.d7.loss_mask: 0.3175, decode.d7.loss_dice: 0.5835, decode.d8.loss_cls: 0.0074, decode.d8.loss_mask: 0.3113, decode.d8.loss_dice: 0.5772, loss: 13.2905\n",
      "2024-02-14 13:59:29,465 - mmseg - INFO - Iter [660/80000]\tlr: 6.256e-07, eta: 2 days, 5:19:06, time: 2.130, data_time: 0.017, memory: 23505, decode.loss_cls: 0.0071, decode.loss_mask: 0.2930, decode.loss_dice: 0.5734, decode.d0.loss_cls: 3.9093, decode.d0.loss_mask: 0.3267, decode.d0.loss_dice: 0.6205, decode.d1.loss_cls: 0.1168, decode.d1.loss_mask: 0.3071, decode.d1.loss_dice: 0.5832, decode.d2.loss_cls: 0.0696, decode.d2.loss_mask: 0.2934, decode.d2.loss_dice: 0.5678, decode.d3.loss_cls: 0.0432, decode.d3.loss_mask: 0.2951, decode.d3.loss_dice: 0.5655, decode.d4.loss_cls: 0.0200, decode.d4.loss_mask: 0.2968, decode.d4.loss_dice: 0.5674, decode.d5.loss_cls: 0.0131, decode.d5.loss_mask: 0.2912, decode.d5.loss_dice: 0.5664, decode.d6.loss_cls: 0.0094, decode.d6.loss_mask: 0.2925, decode.d6.loss_dice: 0.5654, decode.d7.loss_cls: 0.0084, decode.d7.loss_mask: 0.2914, decode.d7.loss_dice: 0.5585, decode.d8.loss_cls: 0.0074, decode.d8.loss_mask: 0.2949, decode.d8.loss_dice: 0.5698, loss: 12.9244\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-14 13:59:50,801 - mmseg - INFO - Iter [670/80000]\tlr: 6.350e-07, eta: 2 days, 5:13:01, time: 2.132, data_time: 0.017, memory: 23505, decode.loss_cls: 0.0073, decode.loss_mask: 0.2849, decode.loss_dice: 0.5698, decode.d0.loss_cls: 3.9040, decode.d0.loss_mask: 0.3133, decode.d0.loss_dice: 0.6219, decode.d1.loss_cls: 0.1128, decode.d1.loss_mask: 0.2889, decode.d1.loss_dice: 0.5845, decode.d2.loss_cls: 0.0688, decode.d2.loss_mask: 0.2899, decode.d2.loss_dice: 0.5788, decode.d3.loss_cls: 0.0415, decode.d3.loss_mask: 0.2902, decode.d3.loss_dice: 0.5758, decode.d4.loss_cls: 0.0217, decode.d4.loss_mask: 0.2899, decode.d4.loss_dice: 0.5756, decode.d5.loss_cls: 0.0156, decode.d5.loss_mask: 0.2819, decode.d5.loss_dice: 0.5746, decode.d6.loss_cls: 0.0100, decode.d6.loss_mask: 0.2846, decode.d6.loss_dice: 0.5752, decode.d7.loss_cls: 0.0093, decode.d7.loss_mask: 0.2817, decode.d7.loss_dice: 0.5752, decode.d8.loss_cls: 0.0078, decode.d8.loss_mask: 0.2847, decode.d8.loss_dice: 0.5693, loss: 12.8895\n",
      "2024-02-14 14:00:12,088 - mmseg - INFO - Iter [680/80000]\tlr: 6.444e-07, eta: 2 days, 5:07:06, time: 2.131, data_time: 0.019, memory: 23505, decode.loss_cls: 0.0056, decode.loss_mask: 0.3006, decode.loss_dice: 0.5630, decode.d0.loss_cls: 3.9075, decode.d0.loss_mask: 0.3332, decode.d0.loss_dice: 0.6058, decode.d1.loss_cls: 0.1094, decode.d1.loss_mask: 0.3077, decode.d1.loss_dice: 0.5775, decode.d2.loss_cls: 0.0616, decode.d2.loss_mask: 0.3052, decode.d2.loss_dice: 0.5741, decode.d3.loss_cls: 0.0359, decode.d3.loss_mask: 0.3045, decode.d3.loss_dice: 0.5662, decode.d4.loss_cls: 0.0167, decode.d4.loss_mask: 0.3022, decode.d4.loss_dice: 0.5668, decode.d5.loss_cls: 0.0105, decode.d5.loss_mask: 0.3022, decode.d5.loss_dice: 0.5670, decode.d6.loss_cls: 0.0075, decode.d6.loss_mask: 0.3027, decode.d6.loss_dice: 0.5640, decode.d7.loss_cls: 0.0066, decode.d7.loss_mask: 0.3033, decode.d7.loss_dice: 0.5659, decode.d8.loss_cls: 0.0059, decode.d8.loss_mask: 0.3023, decode.d8.loss_dice: 0.5635, loss: 12.9448\n",
      "2024-02-14 14:00:33,408 - mmseg - INFO - Iter [690/80000]\tlr: 6.538e-07, eta: 2 days, 5:01:21, time: 2.132, data_time: 0.016, memory: 23505, decode.loss_cls: 0.0065, decode.loss_mask: 0.2530, decode.loss_dice: 0.5397, decode.d0.loss_cls: 3.8951, decode.d0.loss_mask: 0.2808, decode.d0.loss_dice: 0.5924, decode.d1.loss_cls: 0.1129, decode.d1.loss_mask: 0.2579, decode.d1.loss_dice: 0.5452, decode.d2.loss_cls: 0.0758, decode.d2.loss_mask: 0.2580, decode.d2.loss_dice: 0.5436, decode.d3.loss_cls: 0.0384, decode.d3.loss_mask: 0.2554, decode.d3.loss_dice: 0.5283, decode.d4.loss_cls: 0.0178, decode.d4.loss_mask: 0.2509, decode.d4.loss_dice: 0.5366, decode.d5.loss_cls: 0.0119, decode.d5.loss_mask: 0.2536, decode.d5.loss_dice: 0.5357, decode.d6.loss_cls: 0.0088, decode.d6.loss_mask: 0.2511, decode.d6.loss_dice: 0.5348, decode.d7.loss_cls: 0.0080, decode.d7.loss_mask: 0.2515, decode.d7.loss_dice: 0.5365, decode.d8.loss_cls: 0.0071, decode.d8.loss_mask: 0.2559, decode.d8.loss_dice: 0.5383, loss: 12.1817\n",
      "2024-02-14 14:00:54,718 - mmseg - INFO - Iter [700/80000]\tlr: 6.632e-07, eta: 2 days, 4:55:45, time: 2.131, data_time: 0.017, memory: 23505, decode.loss_cls: 0.0066, decode.loss_mask: 0.3328, decode.loss_dice: 0.6205, decode.d0.loss_cls: 3.8999, decode.d0.loss_mask: 0.3725, decode.d0.loss_dice: 0.6602, decode.d1.loss_cls: 0.0980, decode.d1.loss_mask: 0.3455, decode.d1.loss_dice: 0.6346, decode.d2.loss_cls: 0.0615, decode.d2.loss_mask: 0.3384, decode.d2.loss_dice: 0.6224, decode.d3.loss_cls: 0.0378, decode.d3.loss_mask: 0.3421, decode.d3.loss_dice: 0.6297, decode.d4.loss_cls: 0.0193, decode.d4.loss_mask: 0.3327, decode.d4.loss_dice: 0.6191, decode.d5.loss_cls: 0.0119, decode.d5.loss_mask: 0.3340, decode.d5.loss_dice: 0.6298, decode.d6.loss_cls: 0.0086, decode.d6.loss_mask: 0.3350, decode.d6.loss_dice: 0.6241, decode.d7.loss_cls: 0.0076, decode.d7.loss_mask: 0.3346, decode.d7.loss_dice: 0.6346, decode.d8.loss_cls: 0.0068, decode.d8.loss_mask: 0.3318, decode.d8.loss_dice: 0.6188, loss: 13.8511\n",
      "2024-02-14 14:01:16,034 - mmseg - INFO - Iter [710/80000]\tlr: 6.726e-07, eta: 2 days, 4:50:18, time: 2.131, data_time: 0.017, memory: 23505, decode.loss_cls: 0.0048, decode.loss_mask: 0.2958, decode.loss_dice: 0.5549, decode.d0.loss_cls: 3.8912, decode.d0.loss_mask: 0.3278, decode.d0.loss_dice: 0.5987, decode.d1.loss_cls: 0.0873, decode.d1.loss_mask: 0.3091, decode.d1.loss_dice: 0.5649, decode.d2.loss_cls: 0.0537, decode.d2.loss_mask: 0.3012, decode.d2.loss_dice: 0.5597, decode.d3.loss_cls: 0.0332, decode.d3.loss_mask: 0.2924, decode.d3.loss_dice: 0.5573, decode.d4.loss_cls: 0.0135, decode.d4.loss_mask: 0.2979, decode.d4.loss_dice: 0.5586, decode.d5.loss_cls: 0.0084, decode.d5.loss_mask: 0.2985, decode.d5.loss_dice: 0.5628, decode.d6.loss_cls: 0.0063, decode.d6.loss_mask: 0.2972, decode.d6.loss_dice: 0.5616, decode.d7.loss_cls: 0.0058, decode.d7.loss_mask: 0.2963, decode.d7.loss_dice: 0.5607, decode.d8.loss_cls: 0.0051, decode.d8.loss_mask: 0.2959, decode.d8.loss_dice: 0.5562, loss: 12.7567\n",
      "2024-02-14 14:01:37,338 - mmseg - INFO - Iter [720/80000]\tlr: 6.820e-07, eta: 2 days, 4:44:58, time: 2.130, data_time: 0.018, memory: 23505, decode.loss_cls: 0.0054, decode.loss_mask: 0.2737, decode.loss_dice: 0.5635, decode.d0.loss_cls: 3.8960, decode.d0.loss_mask: 0.2963, decode.d0.loss_dice: 0.5940, decode.d1.loss_cls: 0.1013, decode.d1.loss_mask: 0.2797, decode.d1.loss_dice: 0.5756, decode.d2.loss_cls: 0.0695, decode.d2.loss_mask: 0.2828, decode.d2.loss_dice: 0.5764, decode.d3.loss_cls: 0.0368, decode.d3.loss_mask: 0.2774, decode.d3.loss_dice: 0.5660, decode.d4.loss_cls: 0.0167, decode.d4.loss_mask: 0.2734, decode.d4.loss_dice: 0.5661, decode.d5.loss_cls: 0.0103, decode.d5.loss_mask: 0.2778, decode.d5.loss_dice: 0.5642, decode.d6.loss_cls: 0.0072, decode.d6.loss_mask: 0.2748, decode.d6.loss_dice: 0.5636, decode.d7.loss_cls: 0.0063, decode.d7.loss_mask: 0.2762, decode.d7.loss_dice: 0.5647, decode.d8.loss_cls: 0.0057, decode.d8.loss_mask: 0.2727, decode.d8.loss_dice: 0.5657, loss: 12.6401\n",
      "2024-02-14 14:01:58,658 - mmseg - INFO - Iter [730/80000]\tlr: 6.914e-07, eta: 2 days, 4:39:48, time: 2.132, data_time: 0.017, memory: 23505, decode.loss_cls: 0.0046, decode.loss_mask: 0.2927, decode.loss_dice: 0.5421, decode.d0.loss_cls: 3.8900, decode.d0.loss_mask: 0.3170, decode.d0.loss_dice: 0.5776, decode.d1.loss_cls: 0.0830, decode.d1.loss_mask: 0.3007, decode.d1.loss_dice: 0.5571, decode.d2.loss_cls: 0.0501, decode.d2.loss_mask: 0.2924, decode.d2.loss_dice: 0.5448, decode.d3.loss_cls: 0.0309, decode.d3.loss_mask: 0.2913, decode.d3.loss_dice: 0.5421, decode.d4.loss_cls: 0.0136, decode.d4.loss_mask: 0.2903, decode.d4.loss_dice: 0.5452, decode.d5.loss_cls: 0.0082, decode.d5.loss_mask: 0.2931, decode.d5.loss_dice: 0.5466, decode.d6.loss_cls: 0.0060, decode.d6.loss_mask: 0.2915, decode.d6.loss_dice: 0.5409, decode.d7.loss_cls: 0.0055, decode.d7.loss_mask: 0.2931, decode.d7.loss_dice: 0.5413, decode.d8.loss_cls: 0.0050, decode.d8.loss_mask: 0.2923, decode.d8.loss_dice: 0.5422, loss: 12.5311\n",
      "2024-02-14 14:02:19,997 - mmseg - INFO - Iter [740/80000]\tlr: 7.008e-07, eta: 2 days, 4:34:48, time: 2.134, data_time: 0.017, memory: 23505, decode.loss_cls: 0.0050, decode.loss_mask: 0.3290, decode.loss_dice: 0.6242, decode.d0.loss_cls: 3.8887, decode.d0.loss_mask: 0.3456, decode.d0.loss_dice: 0.6687, decode.d1.loss_cls: 0.0816, decode.d1.loss_mask: 0.3243, decode.d1.loss_dice: 0.6339, decode.d2.loss_cls: 0.0491, decode.d2.loss_mask: 0.3286, decode.d2.loss_dice: 0.6343, decode.d3.loss_cls: 0.0306, decode.d3.loss_mask: 0.3256, decode.d3.loss_dice: 0.6274, decode.d4.loss_cls: 0.0151, decode.d4.loss_mask: 0.3213, decode.d4.loss_dice: 0.6246, decode.d5.loss_cls: 0.0089, decode.d5.loss_mask: 0.3286, decode.d5.loss_dice: 0.6292, decode.d6.loss_cls: 0.0065, decode.d6.loss_mask: 0.3250, decode.d6.loss_dice: 0.6221, decode.d7.loss_cls: 0.0058, decode.d7.loss_mask: 0.3252, decode.d7.loss_dice: 0.6210, decode.d8.loss_cls: 0.0054, decode.d8.loss_mask: 0.3289, decode.d8.loss_dice: 0.6276, loss: 13.6916\n",
      "2024-02-14 14:02:41,322 - mmseg - INFO - Iter [750/80000]\tlr: 7.102e-07, eta: 2 days, 4:29:54, time: 2.132, data_time: 0.018, memory: 23505, decode.loss_cls: 0.0048, decode.loss_mask: 0.2579, decode.loss_dice: 0.5428, decode.d0.loss_cls: 3.8820, decode.d0.loss_mask: 0.2776, decode.d0.loss_dice: 0.5702, decode.d1.loss_cls: 0.0816, decode.d1.loss_mask: 0.2759, decode.d1.loss_dice: 0.5433, decode.d2.loss_cls: 0.0489, decode.d2.loss_mask: 0.2731, decode.d2.loss_dice: 0.5426, decode.d3.loss_cls: 0.0476, decode.d3.loss_mask: 0.2643, decode.d3.loss_dice: 0.5371, decode.d4.loss_cls: 0.0327, decode.d4.loss_mask: 0.2616, decode.d4.loss_dice: 0.5357, decode.d5.loss_cls: 0.0079, decode.d5.loss_mask: 0.2631, decode.d5.loss_dice: 0.5454, decode.d6.loss_cls: 0.0061, decode.d6.loss_mask: 0.2660, decode.d6.loss_dice: 0.5405, decode.d7.loss_cls: 0.0055, decode.d7.loss_mask: 0.2610, decode.d7.loss_dice: 0.5440, decode.d8.loss_cls: 0.0051, decode.d8.loss_mask: 0.2630, decode.d8.loss_dice: 0.5448, loss: 12.2320\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-14 14:03:02,635 - mmseg - INFO - Iter [760/80000]\tlr: 7.196e-07, eta: 2 days, 4:25:06, time: 2.131, data_time: 0.017, memory: 23505, decode.loss_cls: 0.0045, decode.loss_mask: 0.2759, decode.loss_dice: 0.5604, decode.d0.loss_cls: 3.8780, decode.d0.loss_mask: 0.2879, decode.d0.loss_dice: 0.5933, decode.d1.loss_cls: 0.0715, decode.d1.loss_mask: 0.2793, decode.d1.loss_dice: 0.5614, decode.d2.loss_cls: 0.0485, decode.d2.loss_mask: 0.2802, decode.d2.loss_dice: 0.5735, decode.d3.loss_cls: 0.0297, decode.d3.loss_mask: 0.2785, decode.d3.loss_dice: 0.5650, decode.d4.loss_cls: 0.0116, decode.d4.loss_mask: 0.2799, decode.d4.loss_dice: 0.5641, decode.d5.loss_cls: 0.0073, decode.d5.loss_mask: 0.2737, decode.d5.loss_dice: 0.5630, decode.d6.loss_cls: 0.0057, decode.d6.loss_mask: 0.2736, decode.d6.loss_dice: 0.5604, decode.d7.loss_cls: 0.0053, decode.d7.loss_mask: 0.2729, decode.d7.loss_dice: 0.5623, decode.d8.loss_cls: 0.0048, decode.d8.loss_mask: 0.2753, decode.d8.loss_dice: 0.5625, loss: 12.5101\n",
      "2024-02-14 14:03:23,953 - mmseg - INFO - Iter [770/80000]\tlr: 7.290e-07, eta: 2 days, 4:20:25, time: 2.132, data_time: 0.017, memory: 23505, decode.loss_cls: 0.0041, decode.loss_mask: 0.2626, decode.loss_dice: 0.5362, decode.d0.loss_cls: 3.8750, decode.d0.loss_mask: 0.2815, decode.d0.loss_dice: 0.5844, decode.d1.loss_cls: 0.0799, decode.d1.loss_mask: 0.2630, decode.d1.loss_dice: 0.5524, decode.d2.loss_cls: 0.0480, decode.d2.loss_mask: 0.2631, decode.d2.loss_dice: 0.5411, decode.d3.loss_cls: 0.0289, decode.d3.loss_mask: 0.2615, decode.d3.loss_dice: 0.5400, decode.d4.loss_cls: 0.0119, decode.d4.loss_mask: 0.2625, decode.d4.loss_dice: 0.5392, decode.d5.loss_cls: 0.0072, decode.d5.loss_mask: 0.2597, decode.d5.loss_dice: 0.5362, decode.d6.loss_cls: 0.0054, decode.d6.loss_mask: 0.2628, decode.d6.loss_dice: 0.5366, decode.d7.loss_cls: 0.0048, decode.d7.loss_mask: 0.2627, decode.d7.loss_dice: 0.5325, decode.d8.loss_cls: 0.0044, decode.d8.loss_mask: 0.2628, decode.d8.loss_dice: 0.5292, loss: 12.1394\n",
      "2024-02-14 14:03:45,247 - mmseg - INFO - Iter [780/80000]\tlr: 7.384e-07, eta: 2 days, 4:15:49, time: 2.129, data_time: 0.018, memory: 23505, decode.loss_cls: 0.0041, decode.loss_mask: 0.3104, decode.loss_dice: 0.5838, decode.d0.loss_cls: 3.8734, decode.d0.loss_mask: 0.3301, decode.d0.loss_dice: 0.6133, decode.d1.loss_cls: 0.0765, decode.d1.loss_mask: 0.3195, decode.d1.loss_dice: 0.5866, decode.d2.loss_cls: 0.0489, decode.d2.loss_mask: 0.3097, decode.d2.loss_dice: 0.5702, decode.d3.loss_cls: 0.0280, decode.d3.loss_mask: 0.3129, decode.d3.loss_dice: 0.5791, decode.d4.loss_cls: 0.0120, decode.d4.loss_mask: 0.3123, decode.d4.loss_dice: 0.5751, decode.d5.loss_cls: 0.0070, decode.d5.loss_mask: 0.3155, decode.d5.loss_dice: 0.5806, decode.d6.loss_cls: 0.0052, decode.d6.loss_mask: 0.3124, decode.d6.loss_dice: 0.5743, decode.d7.loss_cls: 0.0048, decode.d7.loss_mask: 0.3140, decode.d7.loss_dice: 0.5780, decode.d8.loss_cls: 0.0044, decode.d8.loss_mask: 0.3101, decode.d8.loss_dice: 0.5758, loss: 13.0277\n",
      "2024-02-14 14:04:06,545 - mmseg - INFO - Iter [790/80000]\tlr: 7.478e-07, eta: 2 days, 4:11:19, time: 2.130, data_time: 0.017, memory: 23505, decode.loss_cls: 0.0042, decode.loss_mask: 0.2789, decode.loss_dice: 0.5713, decode.d0.loss_cls: 3.8759, decode.d0.loss_mask: 0.3129, decode.d0.loss_dice: 0.6132, decode.d1.loss_cls: 0.0738, decode.d1.loss_mask: 0.2902, decode.d1.loss_dice: 0.5714, decode.d2.loss_cls: 0.0459, decode.d2.loss_mask: 0.2837, decode.d2.loss_dice: 0.5666, decode.d3.loss_cls: 0.0270, decode.d3.loss_mask: 0.2807, decode.d3.loss_dice: 0.5736, decode.d4.loss_cls: 0.0124, decode.d4.loss_mask: 0.2803, decode.d4.loss_dice: 0.5683, decode.d5.loss_cls: 0.0074, decode.d5.loss_mask: 0.2786, decode.d5.loss_dice: 0.5684, decode.d6.loss_cls: 0.0055, decode.d6.loss_mask: 0.2826, decode.d6.loss_dice: 0.5796, decode.d7.loss_cls: 0.0050, decode.d7.loss_mask: 0.2779, decode.d7.loss_dice: 0.5744, decode.d8.loss_cls: 0.0045, decode.d8.loss_mask: 0.2785, decode.d8.loss_dice: 0.5674, loss: 12.6602\n",
      "2024-02-14 14:04:27,850 - mmseg - INFO - Iter [800/80000]\tlr: 7.572e-07, eta: 2 days, 4:06:56, time: 2.130, data_time: 0.017, memory: 23505, decode.loss_cls: 0.0037, decode.loss_mask: 0.2742, decode.loss_dice: 0.5188, decode.d0.loss_cls: 3.8652, decode.d0.loss_mask: 0.2852, decode.d0.loss_dice: 0.5648, decode.d1.loss_cls: 0.0634, decode.d1.loss_mask: 0.2801, decode.d1.loss_dice: 0.5325, decode.d2.loss_cls: 0.0403, decode.d2.loss_mask: 0.2732, decode.d2.loss_dice: 0.5219, decode.d3.loss_cls: 0.0229, decode.d3.loss_mask: 0.2746, decode.d3.loss_dice: 0.5181, decode.d4.loss_cls: 0.0099, decode.d4.loss_mask: 0.2753, decode.d4.loss_dice: 0.5206, decode.d5.loss_cls: 0.0062, decode.d5.loss_mask: 0.2760, decode.d5.loss_dice: 0.5229, decode.d6.loss_cls: 0.0048, decode.d6.loss_mask: 0.2737, decode.d6.loss_dice: 0.5197, decode.d7.loss_cls: 0.0043, decode.d7.loss_mask: 0.2779, decode.d7.loss_dice: 0.5160, decode.d8.loss_cls: 0.0040, decode.d8.loss_mask: 0.2780, decode.d8.loss_dice: 0.5168, loss: 12.0449\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 40/40, 6.2 task/s, elapsed: 6s, ETA:     0s\n",
      "\n",
      "2024-02-14 14:04:34,296 - mmseg - INFO - per class results:\n",
      "2024-02-14 14:04:34,297 - mmseg - INFO - \n",
      "+---------------+-------+-------+\n",
      "|     Class     |  IoU  |  Acc  |\n",
      "+---------------+-------+-------+\n",
      "|       bg      | 97.17 | 98.15 |\n",
      "|    Anchovy    | 78.81 | 91.93 |\n",
      "|     Olives    | 86.83 | 91.84 |\n",
      "|     Salami    | 66.85 | 86.91 |\n",
      "|   Red_Pepper  | 86.46 | 93.34 |\n",
      "| Yellow_Pepper | 85.68 | 94.57 |\n",
      "+---------------+-------+-------+\n",
      "2024-02-14 14:04:34,297 - mmseg - INFO - Summary:\n",
      "2024-02-14 14:04:34,297 - mmseg - INFO - \n",
      "+-------+-------+-------+\n",
      "|  aAcc |  mIoU |  mAcc |\n",
      "+-------+-------+-------+\n",
      "| 97.22 | 83.63 | 92.79 |\n",
      "+-------+-------+-------+\n",
      "2024-02-14 14:04:34,797 - mmseg - INFO - The previous best checkpoint /workspace/ViT-Adapter/segmentation/work_dirs/pizze_training_large/best_mIoU_iter_600.pth was removed\n",
      "2024-02-14 14:04:46,938 - mmseg - INFO - Now best checkpoint is saved as best_mIoU_iter_800.pth.\n",
      "2024-02-14 14:04:46,938 - mmseg - INFO - Best mIoU is 0.8363 at 800 iter.\n",
      "2024-02-14 14:04:46,939 - mmseg - INFO - Iter(val) [10]\taAcc: 0.9722, mIoU: 0.8363, mAcc: 0.9279, IoU.bg: 0.9717, IoU.Anchovy: 0.7881, IoU.Olives: 0.8683, IoU.Salami: 0.6685, IoU.Red_Pepper: 0.8646, IoU.Yellow_Pepper: 0.8568, Acc.bg: 0.9815, Acc.Anchovy: 0.9193, Acc.Olives: 0.9184, Acc.Salami: 0.8691, Acc.Red_Pepper: 0.9334, Acc.Yellow_Pepper: 0.9457\n",
      "2024-02-14 14:05:08,237 - mmseg - INFO - Iter [810/80000]\tlr: 7.665e-07, eta: 2 days, 4:33:45, time: 4.039, data_time: 1.926, memory: 23505, decode.loss_cls: 0.0039, decode.loss_mask: 0.2994, decode.loss_dice: 0.5549, decode.d0.loss_cls: 3.8622, decode.d0.loss_mask: 0.3165, decode.d0.loss_dice: 0.5924, decode.d1.loss_cls: 0.0709, decode.d1.loss_mask: 0.3071, decode.d1.loss_dice: 0.5636, decode.d2.loss_cls: 0.0479, decode.d2.loss_mask: 0.3034, decode.d2.loss_dice: 0.5604, decode.d3.loss_cls: 0.0256, decode.d3.loss_mask: 0.3068, decode.d3.loss_dice: 0.5585, decode.d4.loss_cls: 0.0108, decode.d4.loss_mask: 0.3047, decode.d4.loss_dice: 0.5559, decode.d5.loss_cls: 0.0067, decode.d5.loss_mask: 0.2994, decode.d5.loss_dice: 0.5558, decode.d6.loss_cls: 0.0051, decode.d6.loss_mask: 0.3007, decode.d6.loss_dice: 0.5490, decode.d7.loss_cls: 0.0047, decode.d7.loss_mask: 0.3002, decode.d7.loss_dice: 0.5588, decode.d8.loss_cls: 0.0043, decode.d8.loss_mask: 0.3001, decode.d8.loss_dice: 0.5582, loss: 12.6877\n",
      "2024-02-14 14:05:29,543 - mmseg - INFO - Iter [820/80000]\tlr: 7.759e-07, eta: 2 days, 4:29:11, time: 2.131, data_time: 0.018, memory: 23505, decode.loss_cls: 0.0037, decode.loss_mask: 0.2928, decode.loss_dice: 0.5839, decode.d0.loss_cls: 3.8637, decode.d0.loss_mask: 0.3113, decode.d0.loss_dice: 0.6176, decode.d1.loss_cls: 0.0655, decode.d1.loss_mask: 0.2938, decode.d1.loss_dice: 0.5897, decode.d2.loss_cls: 0.0408, decode.d2.loss_mask: 0.2947, decode.d2.loss_dice: 0.5912, decode.d3.loss_cls: 0.0243, decode.d3.loss_mask: 0.2960, decode.d3.loss_dice: 0.5871, decode.d4.loss_cls: 0.0113, decode.d4.loss_mask: 0.2925, decode.d4.loss_dice: 0.5936, decode.d5.loss_cls: 0.0067, decode.d5.loss_mask: 0.2909, decode.d5.loss_dice: 0.5851, decode.d6.loss_cls: 0.0051, decode.d6.loss_mask: 0.2929, decode.d6.loss_dice: 0.5852, decode.d7.loss_cls: 0.0046, decode.d7.loss_mask: 0.2909, decode.d7.loss_dice: 0.5888, decode.d8.loss_cls: 0.0041, decode.d8.loss_mask: 0.2942, decode.d8.loss_dice: 0.5885, loss: 12.8908\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-14 14:05:50,843 - mmseg - INFO - Iter [830/80000]\tlr: 7.853e-07, eta: 2 days, 4:24:43, time: 2.130, data_time: 0.017, memory: 23505, decode.loss_cls: 0.0035, decode.loss_mask: 0.2933, decode.loss_dice: 0.5695, decode.d0.loss_cls: 3.8583, decode.d0.loss_mask: 0.3078, decode.d0.loss_dice: 0.6032, decode.d1.loss_cls: 0.0723, decode.d1.loss_mask: 0.2985, decode.d1.loss_dice: 0.5734, decode.d2.loss_cls: 0.0454, decode.d2.loss_mask: 0.2934, decode.d2.loss_dice: 0.5664, decode.d3.loss_cls: 0.0234, decode.d3.loss_mask: 0.2947, decode.d3.loss_dice: 0.5636, decode.d4.loss_cls: 0.0100, decode.d4.loss_mask: 0.2963, decode.d4.loss_dice: 0.5654, decode.d5.loss_cls: 0.0060, decode.d5.loss_mask: 0.2923, decode.d5.loss_dice: 0.5676, decode.d6.loss_cls: 0.0047, decode.d6.loss_mask: 0.2958, decode.d6.loss_dice: 0.5569, decode.d7.loss_cls: 0.0043, decode.d7.loss_mask: 0.2933, decode.d7.loss_dice: 0.5637, decode.d8.loss_cls: 0.0038, decode.d8.loss_mask: 0.2969, decode.d8.loss_dice: 0.5752, loss: 12.6989\n",
      "2024-02-14 14:06:12,154 - mmseg - INFO - Iter [840/80000]\tlr: 7.947e-07, eta: 2 days, 4:20:21, time: 2.131, data_time: 0.017, memory: 23505, decode.loss_cls: 0.0035, decode.loss_mask: 0.2559, decode.loss_dice: 0.5294, decode.d0.loss_cls: 3.8515, decode.d0.loss_mask: 0.2865, decode.d0.loss_dice: 0.5695, decode.d1.loss_cls: 0.0588, decode.d1.loss_mask: 0.2652, decode.d1.loss_dice: 0.5316, decode.d2.loss_cls: 0.0394, decode.d2.loss_mask: 0.2621, decode.d2.loss_dice: 0.5314, decode.d3.loss_cls: 0.0211, decode.d3.loss_mask: 0.2610, decode.d3.loss_dice: 0.5374, decode.d4.loss_cls: 0.0093, decode.d4.loss_mask: 0.2584, decode.d4.loss_dice: 0.5298, decode.d5.loss_cls: 0.0060, decode.d5.loss_mask: 0.2579, decode.d5.loss_dice: 0.5306, decode.d6.loss_cls: 0.0045, decode.d6.loss_mask: 0.2593, decode.d6.loss_dice: 0.5271, decode.d7.loss_cls: 0.0040, decode.d7.loss_mask: 0.2554, decode.d7.loss_dice: 0.5247, decode.d8.loss_cls: 0.0037, decode.d8.loss_mask: 0.2551, decode.d8.loss_dice: 0.5243, loss: 11.9545\n",
      "2024-02-14 14:06:33,457 - mmseg - INFO - Iter [850/80000]\tlr: 8.040e-07, eta: 2 days, 4:16:05, time: 2.130, data_time: 0.017, memory: 23505, decode.loss_cls: 0.0034, decode.loss_mask: 0.2949, decode.loss_dice: 0.5574, decode.d0.loss_cls: 3.8525, decode.d0.loss_mask: 0.3149, decode.d0.loss_dice: 0.5959, decode.d1.loss_cls: 0.0572, decode.d1.loss_mask: 0.2961, decode.d1.loss_dice: 0.5632, decode.d2.loss_cls: 0.0366, decode.d2.loss_mask: 0.2961, decode.d2.loss_dice: 0.5644, decode.d3.loss_cls: 0.0194, decode.d3.loss_mask: 0.2938, decode.d3.loss_dice: 0.5588, decode.d4.loss_cls: 0.0089, decode.d4.loss_mask: 0.2998, decode.d4.loss_dice: 0.5680, decode.d5.loss_cls: 0.0054, decode.d5.loss_mask: 0.2979, decode.d5.loss_dice: 0.5651, decode.d6.loss_cls: 0.0042, decode.d6.loss_mask: 0.2948, decode.d6.loss_dice: 0.5541, decode.d7.loss_cls: 0.0039, decode.d7.loss_mask: 0.2979, decode.d7.loss_dice: 0.5587, decode.d8.loss_cls: 0.0036, decode.d8.loss_mask: 0.2944, decode.d8.loss_dice: 0.5571, loss: 12.6188\n",
      "2024-02-14 14:06:54,764 - mmseg - INFO - Iter [860/80000]\tlr: 8.134e-07, eta: 2 days, 4:11:54, time: 2.131, data_time: 0.018, memory: 23505, decode.loss_cls: 0.0198, decode.loss_mask: 0.2767, decode.loss_dice: 0.5686, decode.d0.loss_cls: 3.8502, decode.d0.loss_mask: 0.2852, decode.d0.loss_dice: 0.6041, decode.d1.loss_cls: 0.0678, decode.d1.loss_mask: 0.2785, decode.d1.loss_dice: 0.5750, decode.d2.loss_cls: 0.0470, decode.d2.loss_mask: 0.2779, decode.d2.loss_dice: 0.5664, decode.d3.loss_cls: 0.0377, decode.d3.loss_mask: 0.2766, decode.d3.loss_dice: 0.5680, decode.d4.loss_cls: 0.0149, decode.d4.loss_mask: 0.2728, decode.d4.loss_dice: 0.5578, decode.d5.loss_cls: 0.0211, decode.d5.loss_mask: 0.2793, decode.d5.loss_dice: 0.5692, decode.d6.loss_cls: 0.0098, decode.d6.loss_mask: 0.2770, decode.d6.loss_dice: 0.5652, decode.d7.loss_cls: 0.0050, decode.d7.loss_mask: 0.2760, decode.d7.loss_dice: 0.5719, decode.d8.loss_cls: 0.0194, decode.d8.loss_mask: 0.2760, decode.d8.loss_dice: 0.5648, loss: 12.5795\n",
      "2024-02-14 14:07:16,191 - mmseg - INFO - Iter [870/80000]\tlr: 8.228e-07, eta: 2 days, 4:07:59, time: 2.143, data_time: 0.017, memory: 23505, decode.loss_cls: 0.0032, decode.loss_mask: 0.2884, decode.loss_dice: 0.5431, decode.d0.loss_cls: 3.8413, decode.d0.loss_mask: 0.3071, decode.d0.loss_dice: 0.5869, decode.d1.loss_cls: 0.0579, decode.d1.loss_mask: 0.2960, decode.d1.loss_dice: 0.5513, decode.d2.loss_cls: 0.0361, decode.d2.loss_mask: 0.2941, decode.d2.loss_dice: 0.5565, decode.d3.loss_cls: 0.0189, decode.d3.loss_mask: 0.2897, decode.d3.loss_dice: 0.5459, decode.d4.loss_cls: 0.0081, decode.d4.loss_mask: 0.2903, decode.d4.loss_dice: 0.5495, decode.d5.loss_cls: 0.0052, decode.d5.loss_mask: 0.2870, decode.d5.loss_dice: 0.5519, decode.d6.loss_cls: 0.0041, decode.d6.loss_mask: 0.2881, decode.d6.loss_dice: 0.5516, decode.d7.loss_cls: 0.0038, decode.d7.loss_mask: 0.2870, decode.d7.loss_dice: 0.5456, decode.d8.loss_cls: 0.0034, decode.d8.loss_mask: 0.2904, decode.d8.loss_dice: 0.5518, loss: 12.4341\n",
      "2024-02-14 14:07:37,503 - mmseg - INFO - Iter [880/80000]\tlr: 8.321e-07, eta: 2 days, 4:03:59, time: 2.131, data_time: 0.018, memory: 23505, decode.loss_cls: 0.0033, decode.loss_mask: 0.2704, decode.loss_dice: 0.5449, decode.d0.loss_cls: 3.8435, decode.d0.loss_mask: 0.2863, decode.d0.loss_dice: 0.5738, decode.d1.loss_cls: 0.0468, decode.d1.loss_mask: 0.2778, decode.d1.loss_dice: 0.5567, decode.d2.loss_cls: 0.0321, decode.d2.loss_mask: 0.2749, decode.d2.loss_dice: 0.5484, decode.d3.loss_cls: 0.0176, decode.d3.loss_mask: 0.2793, decode.d3.loss_dice: 0.5537, decode.d4.loss_cls: 0.0078, decode.d4.loss_mask: 0.2715, decode.d4.loss_dice: 0.5446, decode.d5.loss_cls: 0.0048, decode.d5.loss_mask: 0.2713, decode.d5.loss_dice: 0.5570, decode.d6.loss_cls: 0.0038, decode.d6.loss_mask: 0.2705, decode.d6.loss_dice: 0.5548, decode.d7.loss_cls: 0.0035, decode.d7.loss_mask: 0.2760, decode.d7.loss_dice: 0.5530, decode.d8.loss_cls: 0.0034, decode.d8.loss_mask: 0.2731, decode.d8.loss_dice: 0.5516, loss: 12.2565\n",
      "2024-02-14 14:07:58,823 - mmseg - INFO - Iter [890/80000]\tlr: 8.415e-07, eta: 2 days, 4:00:05, time: 2.132, data_time: 0.017, memory: 23505, decode.loss_cls: 0.0031, decode.loss_mask: 0.2890, decode.loss_dice: 0.5594, decode.d0.loss_cls: 3.8400, decode.d0.loss_mask: 0.3116, decode.d0.loss_dice: 0.6006, decode.d1.loss_cls: 0.0530, decode.d1.loss_mask: 0.2950, decode.d1.loss_dice: 0.5742, decode.d2.loss_cls: 0.0339, decode.d2.loss_mask: 0.2966, decode.d2.loss_dice: 0.5696, decode.d3.loss_cls: 0.0192, decode.d3.loss_mask: 0.2973, decode.d3.loss_dice: 0.5690, decode.d4.loss_cls: 0.0085, decode.d4.loss_mask: 0.2924, decode.d4.loss_dice: 0.5627, decode.d5.loss_cls: 0.0052, decode.d5.loss_mask: 0.2897, decode.d5.loss_dice: 0.5617, decode.d6.loss_cls: 0.0040, decode.d6.loss_mask: 0.2932, decode.d6.loss_dice: 0.5610, decode.d7.loss_cls: 0.0036, decode.d7.loss_mask: 0.2951, decode.d7.loss_dice: 0.5655, decode.d8.loss_cls: 0.0034, decode.d8.loss_mask: 0.2889, decode.d8.loss_dice: 0.5547, loss: 12.6009\n",
      "2024-02-14 14:08:20,134 - mmseg - INFO - Iter [900/80000]\tlr: 8.509e-07, eta: 2 days, 3:56:14, time: 2.131, data_time: 0.017, memory: 23505, decode.loss_cls: 0.0028, decode.loss_mask: 0.2370, decode.loss_dice: 0.4986, decode.d0.loss_cls: 3.8308, decode.d0.loss_mask: 0.2555, decode.d0.loss_dice: 0.5246, decode.d1.loss_cls: 0.0485, decode.d1.loss_mask: 0.2416, decode.d1.loss_dice: 0.4950, decode.d2.loss_cls: 0.0317, decode.d2.loss_mask: 0.2412, decode.d2.loss_dice: 0.4933, decode.d3.loss_cls: 0.0161, decode.d3.loss_mask: 0.2407, decode.d3.loss_dice: 0.4916, decode.d4.loss_cls: 0.0072, decode.d4.loss_mask: 0.2366, decode.d4.loss_dice: 0.4954, decode.d5.loss_cls: 0.0047, decode.d5.loss_mask: 0.2363, decode.d5.loss_dice: 0.4936, decode.d6.loss_cls: 0.0035, decode.d6.loss_mask: 0.2362, decode.d6.loss_dice: 0.4907, decode.d7.loss_cls: 0.0032, decode.d7.loss_mask: 0.2383, decode.d7.loss_dice: 0.4955, decode.d8.loss_cls: 0.0030, decode.d8.loss_mask: 0.2306, decode.d8.loss_dice: 0.4854, loss: 11.3092\n",
      "2024-02-14 14:08:41,441 - mmseg - INFO - Iter [910/80000]\tlr: 8.602e-07, eta: 2 days, 3:52:28, time: 2.131, data_time: 0.017, memory: 23505, decode.loss_cls: 0.0029, decode.loss_mask: 0.2841, decode.loss_dice: 0.5496, decode.d0.loss_cls: 3.8294, decode.d0.loss_mask: 0.2955, decode.d0.loss_dice: 0.5795, decode.d1.loss_cls: 0.0492, decode.d1.loss_mask: 0.2883, decode.d1.loss_dice: 0.5414, decode.d2.loss_cls: 0.0301, decode.d2.loss_mask: 0.2884, decode.d2.loss_dice: 0.5492, decode.d3.loss_cls: 0.0158, decode.d3.loss_mask: 0.2894, decode.d3.loss_dice: 0.5452, decode.d4.loss_cls: 0.0068, decode.d4.loss_mask: 0.2828, decode.d4.loss_dice: 0.5437, decode.d5.loss_cls: 0.0045, decode.d5.loss_mask: 0.2873, decode.d5.loss_dice: 0.5455, decode.d6.loss_cls: 0.0036, decode.d6.loss_mask: 0.2842, decode.d6.loss_dice: 0.5335, decode.d7.loss_cls: 0.0033, decode.d7.loss_mask: 0.2849, decode.d7.loss_dice: 0.5431, decode.d8.loss_cls: 0.0031, decode.d8.loss_mask: 0.2828, decode.d8.loss_dice: 0.5424, loss: 12.2895\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-14 14:09:02,731 - mmseg - INFO - Iter [920/80000]\tlr: 8.696e-07, eta: 2 days, 3:48:45, time: 2.129, data_time: 0.018, memory: 23505, decode.loss_cls: 0.0026, decode.loss_mask: 0.2580, decode.loss_dice: 0.5192, decode.d0.loss_cls: 3.8315, decode.d0.loss_mask: 0.2710, decode.d0.loss_dice: 0.5454, decode.d1.loss_cls: 0.0452, decode.d1.loss_mask: 0.2609, decode.d1.loss_dice: 0.5215, decode.d2.loss_cls: 0.0340, decode.d2.loss_mask: 0.2599, decode.d2.loss_dice: 0.5234, decode.d3.loss_cls: 0.0171, decode.d3.loss_mask: 0.2572, decode.d3.loss_dice: 0.5225, decode.d4.loss_cls: 0.0064, decode.d4.loss_mask: 0.2598, decode.d4.loss_dice: 0.5162, decode.d5.loss_cls: 0.0041, decode.d5.loss_mask: 0.2611, decode.d5.loss_dice: 0.5227, decode.d6.loss_cls: 0.0033, decode.d6.loss_mask: 0.2579, decode.d6.loss_dice: 0.5207, decode.d7.loss_cls: 0.0030, decode.d7.loss_mask: 0.2612, decode.d7.loss_dice: 0.5263, decode.d8.loss_cls: 0.0028, decode.d8.loss_mask: 0.2583, decode.d8.loss_dice: 0.5257, loss: 11.7986\n",
      "2024-02-14 14:09:24,020 - mmseg - INFO - Iter [930/80000]\tlr: 8.789e-07, eta: 2 days, 3:45:06, time: 2.129, data_time: 0.017, memory: 23505, decode.loss_cls: 0.0036, decode.loss_mask: 0.3037, decode.loss_dice: 0.5920, decode.d0.loss_cls: 3.8270, decode.d0.loss_mask: 0.3220, decode.d0.loss_dice: 0.6308, decode.d1.loss_cls: 0.0518, decode.d1.loss_mask: 0.3031, decode.d1.loss_dice: 0.6080, decode.d2.loss_cls: 0.0469, decode.d2.loss_mask: 0.3030, decode.d2.loss_dice: 0.5990, decode.d3.loss_cls: 0.0276, decode.d3.loss_mask: 0.3037, decode.d3.loss_dice: 0.5892, decode.d4.loss_cls: 0.0148, decode.d4.loss_mask: 0.3060, decode.d4.loss_dice: 0.5957, decode.d5.loss_cls: 0.0086, decode.d5.loss_mask: 0.3031, decode.d5.loss_dice: 0.5909, decode.d6.loss_cls: 0.0053, decode.d6.loss_mask: 0.3031, decode.d6.loss_dice: 0.5892, decode.d7.loss_cls: 0.0045, decode.d7.loss_mask: 0.3029, decode.d7.loss_dice: 0.5931, decode.d8.loss_cls: 0.0041, decode.d8.loss_mask: 0.3026, decode.d8.loss_dice: 0.5928, loss: 13.0283\n",
      "2024-02-14 14:09:45,312 - mmseg - INFO - Iter [940/80000]\tlr: 8.883e-07, eta: 2 days, 3:41:32, time: 2.129, data_time: 0.017, memory: 23505, decode.loss_cls: 0.0024, decode.loss_mask: 0.2771, decode.loss_dice: 0.5437, decode.d0.loss_cls: 3.8171, decode.d0.loss_mask: 0.2910, decode.d0.loss_dice: 0.5807, decode.d1.loss_cls: 0.0413, decode.d1.loss_mask: 0.2923, decode.d1.loss_dice: 0.5387, decode.d2.loss_cls: 0.0282, decode.d2.loss_mask: 0.2852, decode.d2.loss_dice: 0.5467, decode.d3.loss_cls: 0.0148, decode.d3.loss_mask: 0.2789, decode.d3.loss_dice: 0.5481, decode.d4.loss_cls: 0.0061, decode.d4.loss_mask: 0.2766, decode.d4.loss_dice: 0.5455, decode.d5.loss_cls: 0.0038, decode.d5.loss_mask: 0.2792, decode.d5.loss_dice: 0.5526, decode.d6.loss_cls: 0.0030, decode.d6.loss_mask: 0.2795, decode.d6.loss_dice: 0.5529, decode.d7.loss_cls: 0.0028, decode.d7.loss_mask: 0.2803, decode.d7.loss_dice: 0.5492, decode.d8.loss_cls: 0.0026, decode.d8.loss_mask: 0.2786, decode.d8.loss_dice: 0.5459, loss: 12.2448\n",
      "2024-02-14 14:10:06,602 - mmseg - INFO - Iter [950/80000]\tlr: 8.976e-07, eta: 2 days, 3:38:01, time: 2.129, data_time: 0.017, memory: 23505, decode.loss_cls: 0.0027, decode.loss_mask: 0.2910, decode.loss_dice: 0.5855, decode.d0.loss_cls: 3.8175, decode.d0.loss_mask: 0.3066, decode.d0.loss_dice: 0.5915, decode.d1.loss_cls: 0.0482, decode.d1.loss_mask: 0.3021, decode.d1.loss_dice: 0.5782, decode.d2.loss_cls: 0.0298, decode.d2.loss_mask: 0.2937, decode.d2.loss_dice: 0.5723, decode.d3.loss_cls: 0.0181, decode.d3.loss_mask: 0.2927, decode.d3.loss_dice: 0.5781, decode.d4.loss_cls: 0.0074, decode.d4.loss_mask: 0.2896, decode.d4.loss_dice: 0.5850, decode.d5.loss_cls: 0.0044, decode.d5.loss_mask: 0.2930, decode.d5.loss_dice: 0.5840, decode.d6.loss_cls: 0.0033, decode.d6.loss_mask: 0.2883, decode.d6.loss_dice: 0.5757, decode.d7.loss_cls: 0.0031, decode.d7.loss_mask: 0.2902, decode.d7.loss_dice: 0.5775, decode.d8.loss_cls: 0.0029, decode.d8.loss_mask: 0.2901, decode.d8.loss_dice: 0.5815, loss: 12.6841\n",
      "2024-02-14 14:10:27,917 - mmseg - INFO - Iter [960/80000]\tlr: 9.069e-07, eta: 2 days, 3:34:36, time: 2.131, data_time: 0.018, memory: 23505, decode.loss_cls: 0.0024, decode.loss_mask: 0.2671, decode.loss_dice: 0.5403, decode.d0.loss_cls: 3.8109, decode.d0.loss_mask: 0.2821, decode.d0.loss_dice: 0.5631, decode.d1.loss_cls: 0.0399, decode.d1.loss_mask: 0.2663, decode.d1.loss_dice: 0.5381, decode.d2.loss_cls: 0.0257, decode.d2.loss_mask: 0.2661, decode.d2.loss_dice: 0.5348, decode.d3.loss_cls: 0.0140, decode.d3.loss_mask: 0.2662, decode.d3.loss_dice: 0.5369, decode.d4.loss_cls: 0.0055, decode.d4.loss_mask: 0.2648, decode.d4.loss_dice: 0.5391, decode.d5.loss_cls: 0.0035, decode.d5.loss_mask: 0.2631, decode.d5.loss_dice: 0.5296, decode.d6.loss_cls: 0.0029, decode.d6.loss_mask: 0.2647, decode.d6.loss_dice: 0.5274, decode.d7.loss_cls: 0.0028, decode.d7.loss_mask: 0.2652, decode.d7.loss_dice: 0.5340, decode.d8.loss_cls: 0.0026, decode.d8.loss_mask: 0.2682, decode.d8.loss_dice: 0.5384, loss: 11.9660\n",
      "2024-02-14 14:10:51,329 - mmseg - INFO - Iter [970/80000]\tlr: 9.163e-07, eta: 2 days, 3:34:06, time: 2.341, data_time: 0.226, memory: 23505, decode.loss_cls: 0.0030, decode.loss_mask: 0.3180, decode.loss_dice: 0.5838, decode.d0.loss_cls: 3.8175, decode.d0.loss_mask: 0.3356, decode.d0.loss_dice: 0.6059, decode.d1.loss_cls: 0.0548, decode.d1.loss_mask: 0.3162, decode.d1.loss_dice: 0.5899, decode.d2.loss_cls: 0.0433, decode.d2.loss_mask: 0.3189, decode.d2.loss_dice: 0.5800, decode.d3.loss_cls: 0.0174, decode.d3.loss_mask: 0.3178, decode.d3.loss_dice: 0.5812, decode.d4.loss_cls: 0.0078, decode.d4.loss_mask: 0.3192, decode.d4.loss_dice: 0.5836, decode.d5.loss_cls: 0.0042, decode.d5.loss_mask: 0.3154, decode.d5.loss_dice: 0.5790, decode.d6.loss_cls: 0.0035, decode.d6.loss_mask: 0.3201, decode.d6.loss_dice: 0.5840, decode.d7.loss_cls: 0.0035, decode.d7.loss_mask: 0.3197, decode.d7.loss_dice: 0.5854, decode.d8.loss_cls: 0.0033, decode.d8.loss_mask: 0.3182, decode.d8.loss_dice: 0.5861, loss: 13.0162\n",
      "2024-02-14 14:11:12,650 - mmseg - INFO - Iter [980/80000]\tlr: 9.256e-07, eta: 2 days, 3:30:48, time: 2.133, data_time: 0.018, memory: 23505, decode.loss_cls: 0.0023, decode.loss_mask: 0.2300, decode.loss_dice: 0.4762, decode.d0.loss_cls: 3.7999, decode.d0.loss_mask: 0.2458, decode.d0.loss_dice: 0.5170, decode.d1.loss_cls: 0.0396, decode.d1.loss_mask: 0.2305, decode.d1.loss_dice: 0.4844, decode.d2.loss_cls: 0.0240, decode.d2.loss_mask: 0.2302, decode.d2.loss_dice: 0.4806, decode.d3.loss_cls: 0.0119, decode.d3.loss_mask: 0.2280, decode.d3.loss_dice: 0.4718, decode.d4.loss_cls: 0.0048, decode.d4.loss_mask: 0.2321, decode.d4.loss_dice: 0.4754, decode.d5.loss_cls: 0.0032, decode.d5.loss_mask: 0.2281, decode.d5.loss_dice: 0.4797, decode.d6.loss_cls: 0.0028, decode.d6.loss_mask: 0.2299, decode.d6.loss_dice: 0.4782, decode.d7.loss_cls: 0.0027, decode.d7.loss_mask: 0.2292, decode.d7.loss_dice: 0.4785, decode.d8.loss_cls: 0.0025, decode.d8.loss_mask: 0.2273, decode.d8.loss_dice: 0.4673, loss: 11.0141\n",
      "2024-02-14 14:11:33,949 - mmseg - INFO - Iter [990/80000]\tlr: 9.350e-07, eta: 2 days, 3:27:31, time: 2.130, data_time: 0.017, memory: 23505, decode.loss_cls: 0.0022, decode.loss_mask: 0.2707, decode.loss_dice: 0.5415, decode.d0.loss_cls: 3.7992, decode.d0.loss_mask: 0.2774, decode.d0.loss_dice: 0.5622, decode.d1.loss_cls: 0.0353, decode.d1.loss_mask: 0.2701, decode.d1.loss_dice: 0.5526, decode.d2.loss_cls: 0.0224, decode.d2.loss_mask: 0.2685, decode.d2.loss_dice: 0.5392, decode.d3.loss_cls: 0.0114, decode.d3.loss_mask: 0.2676, decode.d3.loss_dice: 0.5366, decode.d4.loss_cls: 0.0047, decode.d4.loss_mask: 0.2666, decode.d4.loss_dice: 0.5377, decode.d5.loss_cls: 0.0030, decode.d5.loss_mask: 0.2621, decode.d5.loss_dice: 0.5382, decode.d6.loss_cls: 0.0026, decode.d6.loss_mask: 0.2699, decode.d6.loss_dice: 0.5469, decode.d7.loss_cls: 0.0025, decode.d7.loss_mask: 0.2661, decode.d7.loss_dice: 0.5456, decode.d8.loss_cls: 0.0024, decode.d8.loss_mask: 0.2692, decode.d8.loss_dice: 0.5461, loss: 12.0203\n",
      "2024-02-14 14:11:55,268 - mmseg - INFO - Exp name: pizze_training_large.py\n",
      "2024-02-14 14:11:55,269 - mmseg - INFO - Iter [1000/80000]\tlr: 9.443e-07, eta: 2 days, 3:24:20, time: 2.132, data_time: 0.017, memory: 23505, decode.loss_cls: 0.0022, decode.loss_mask: 0.3084, decode.loss_dice: 0.5764, decode.d0.loss_cls: 3.7966, decode.d0.loss_mask: 0.3210, decode.d0.loss_dice: 0.6097, decode.d1.loss_cls: 0.0422, decode.d1.loss_mask: 0.3073, decode.d1.loss_dice: 0.5764, decode.d2.loss_cls: 0.0256, decode.d2.loss_mask: 0.3066, decode.d2.loss_dice: 0.5756, decode.d3.loss_cls: 0.0149, decode.d3.loss_mask: 0.3060, decode.d3.loss_dice: 0.5703, decode.d4.loss_cls: 0.0066, decode.d4.loss_mask: 0.3061, decode.d4.loss_dice: 0.5753, decode.d5.loss_cls: 0.0036, decode.d5.loss_mask: 0.3059, decode.d5.loss_dice: 0.5746, decode.d6.loss_cls: 0.0028, decode.d6.loss_mask: 0.3080, decode.d6.loss_dice: 0.5677, decode.d7.loss_cls: 0.0026, decode.d7.loss_mask: 0.3081, decode.d7.loss_dice: 0.5698, decode.d8.loss_cls: 0.0025, decode.d8.loss_mask: 0.3096, decode.d8.loss_dice: 0.5719, loss: 12.7544\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 40/40, 6.2 task/s, elapsed: 6s, ETA:     0s\n",
      "\n",
      "2024-02-14 14:12:01,708 - mmseg - INFO - per class results:\n",
      "2024-02-14 14:12:01,709 - mmseg - INFO - \n",
      "+---------------+-------+-------+\n",
      "|     Class     |  IoU  |  Acc  |\n",
      "+---------------+-------+-------+\n",
      "|       bg      |  97.3 | 98.34 |\n",
      "|    Anchovy    | 79.54 | 92.68 |\n",
      "|     Olives    | 86.79 | 90.81 |\n",
      "|     Salami    | 68.24 | 87.21 |\n",
      "|   Red_Pepper  |  87.0 | 92.89 |\n",
      "| Yellow_Pepper | 85.91 | 94.45 |\n",
      "+---------------+-------+-------+\n",
      "2024-02-14 14:12:01,709 - mmseg - INFO - Summary:\n",
      "2024-02-14 14:12:01,709 - mmseg - INFO - \n",
      "+-------+-------+-------+\n",
      "|  aAcc |  mIoU |  mAcc |\n",
      "+-------+-------+-------+\n",
      "| 97.34 | 84.13 | 92.73 |\n",
      "+-------+-------+-------+\n",
      "2024-02-14 14:12:02,213 - mmseg - INFO - The previous best checkpoint /workspace/ViT-Adapter/segmentation/work_dirs/pizze_training_large/best_mIoU_iter_800.pth was removed\n",
      "2024-02-14 14:12:14,310 - mmseg - INFO - Now best checkpoint is saved as best_mIoU_iter_1000.pth.\n",
      "2024-02-14 14:12:14,310 - mmseg - INFO - Best mIoU is 0.8413 at 1000 iter.\n",
      "2024-02-14 14:12:14,311 - mmseg - INFO - Exp name: pizze_training_large.py\n",
      "2024-02-14 14:12:14,311 - mmseg - INFO - Iter(val) [10]\taAcc: 0.9734, mIoU: 0.8413, mAcc: 0.9273, IoU.bg: 0.9730, IoU.Anchovy: 0.7954, IoU.Olives: 0.8679, IoU.Salami: 0.6824, IoU.Red_Pepper: 0.8700, IoU.Yellow_Pepper: 0.8591, Acc.bg: 0.9834, Acc.Anchovy: 0.9268, Acc.Olives: 0.9081, Acc.Salami: 0.8721, Acc.Red_Pepper: 0.9289, Acc.Yellow_Pepper: 0.9445\n",
      "2024-02-14 14:12:35,594 - mmseg - INFO - Iter [1010/80000]\tlr: 9.536e-07, eta: 2 days, 3:45:58, time: 4.033, data_time: 1.921, memory: 23505, decode.loss_cls: 0.0026, decode.loss_mask: 0.3240, decode.loss_dice: 0.5876, decode.d0.loss_cls: 3.7951, decode.d0.loss_mask: 0.3365, decode.d0.loss_dice: 0.6290, decode.d1.loss_cls: 0.0358, decode.d1.loss_mask: 0.3338, decode.d1.loss_dice: 0.5925, decode.d2.loss_cls: 0.0230, decode.d2.loss_mask: 0.3294, decode.d2.loss_dice: 0.5881, decode.d3.loss_cls: 0.0144, decode.d3.loss_mask: 0.3334, decode.d3.loss_dice: 0.5930, decode.d4.loss_cls: 0.0080, decode.d4.loss_mask: 0.3251, decode.d4.loss_dice: 0.5878, decode.d5.loss_cls: 0.0047, decode.d5.loss_mask: 0.3248, decode.d5.loss_dice: 0.5873, decode.d6.loss_cls: 0.0035, decode.d6.loss_mask: 0.3292, decode.d6.loss_dice: 0.5943, decode.d7.loss_cls: 0.0030, decode.d7.loss_mask: 0.3266, decode.d7.loss_dice: 0.5872, decode.d8.loss_cls: 0.0029, decode.d8.loss_mask: 0.3262, decode.d8.loss_dice: 0.5869, loss: 13.1155\n",
      "2024-02-14 14:12:56,880 - mmseg - INFO - Iter [1020/80000]\tlr: 9.630e-07, eta: 2 days, 3:42:36, time: 2.129, data_time: 0.017, memory: 23505, decode.loss_cls: 0.0022, decode.loss_mask: 0.2495, decode.loss_dice: 0.5177, decode.d0.loss_cls: 3.7850, decode.d0.loss_mask: 0.2658, decode.d0.loss_dice: 0.5352, decode.d1.loss_cls: 0.0391, decode.d1.loss_mask: 0.2533, decode.d1.loss_dice: 0.5230, decode.d2.loss_cls: 0.0234, decode.d2.loss_mask: 0.2544, decode.d2.loss_dice: 0.5140, decode.d3.loss_cls: 0.0110, decode.d3.loss_mask: 0.2512, decode.d3.loss_dice: 0.5117, decode.d4.loss_cls: 0.0053, decode.d4.loss_mask: 0.2488, decode.d4.loss_dice: 0.5168, decode.d5.loss_cls: 0.0032, decode.d5.loss_mask: 0.2483, decode.d5.loss_dice: 0.5172, decode.d6.loss_cls: 0.0027, decode.d6.loss_mask: 0.2489, decode.d6.loss_dice: 0.5147, decode.d7.loss_cls: 0.0026, decode.d7.loss_mask: 0.2474, decode.d7.loss_dice: 0.5183, decode.d8.loss_cls: 0.0023, decode.d8.loss_mask: 0.2489, decode.d8.loss_dice: 0.5128, loss: 11.5749\n",
      "2024-02-14 14:13:18,187 - mmseg - INFO - Iter [1030/80000]\tlr: 9.723e-07, eta: 2 days, 3:39:19, time: 2.131, data_time: 0.017, memory: 23505, decode.loss_cls: 0.0020, decode.loss_mask: 0.2393, decode.loss_dice: 0.4644, decode.d0.loss_cls: 3.7810, decode.d0.loss_mask: 0.2498, decode.d0.loss_dice: 0.4954, decode.d1.loss_cls: 0.0395, decode.d1.loss_mask: 0.2428, decode.d1.loss_dice: 0.4764, decode.d2.loss_cls: 0.0218, decode.d2.loss_mask: 0.2352, decode.d2.loss_dice: 0.4686, decode.d3.loss_cls: 0.0103, decode.d3.loss_mask: 0.2386, decode.d3.loss_dice: 0.4724, decode.d4.loss_cls: 0.0047, decode.d4.loss_mask: 0.2417, decode.d4.loss_dice: 0.4744, decode.d5.loss_cls: 0.0031, decode.d5.loss_mask: 0.2369, decode.d5.loss_dice: 0.4683, decode.d6.loss_cls: 0.0026, decode.d6.loss_mask: 0.2390, decode.d6.loss_dice: 0.4736, decode.d7.loss_cls: 0.0024, decode.d7.loss_mask: 0.2376, decode.d7.loss_dice: 0.4665, decode.d8.loss_cls: 0.0022, decode.d8.loss_mask: 0.2421, decode.d8.loss_dice: 0.4717, loss: 11.0043\n",
      "2024-02-14 14:13:39,491 - mmseg - INFO - Iter [1040/80000]\tlr: 9.816e-07, eta: 2 days, 3:36:05, time: 2.130, data_time: 0.017, memory: 23505, decode.loss_cls: 0.0020, decode.loss_mask: 0.2545, decode.loss_dice: 0.5269, decode.d0.loss_cls: 3.7780, decode.d0.loss_mask: 0.2663, decode.d0.loss_dice: 0.5349, decode.d1.loss_cls: 0.0321, decode.d1.loss_mask: 0.2585, decode.d1.loss_dice: 0.5256, decode.d2.loss_cls: 0.0252, decode.d2.loss_mask: 0.2516, decode.d2.loss_dice: 0.5203, decode.d3.loss_cls: 0.0101, decode.d3.loss_mask: 0.2568, decode.d3.loss_dice: 0.5215, decode.d4.loss_cls: 0.0043, decode.d4.loss_mask: 0.2514, decode.d4.loss_dice: 0.5173, decode.d5.loss_cls: 0.0030, decode.d5.loss_mask: 0.2536, decode.d5.loss_dice: 0.5171, decode.d6.loss_cls: 0.0024, decode.d6.loss_mask: 0.2518, decode.d6.loss_dice: 0.5171, decode.d7.loss_cls: 0.0023, decode.d7.loss_mask: 0.2528, decode.d7.loss_dice: 0.5214, decode.d8.loss_cls: 0.0021, decode.d8.loss_mask: 0.2528, decode.d8.loss_dice: 0.5187, loss: 11.6325\n",
      "2024-02-14 14:14:00,801 - mmseg - INFO - Iter [1050/80000]\tlr: 9.909e-07, eta: 2 days, 3:32:55, time: 2.131, data_time: 0.016, memory: 23505, decode.loss_cls: 0.0019, decode.loss_mask: 0.2202, decode.loss_dice: 0.4513, decode.d0.loss_cls: 3.7720, decode.d0.loss_mask: 0.2322, decode.d0.loss_dice: 0.4702, decode.d1.loss_cls: 0.0461, decode.d1.loss_mask: 0.2279, decode.d1.loss_dice: 0.4580, decode.d2.loss_cls: 0.0233, decode.d2.loss_mask: 0.2250, decode.d2.loss_dice: 0.4545, decode.d3.loss_cls: 0.0091, decode.d3.loss_mask: 0.2223, decode.d3.loss_dice: 0.4550, decode.d4.loss_cls: 0.0038, decode.d4.loss_mask: 0.2238, decode.d4.loss_dice: 0.4544, decode.d5.loss_cls: 0.0027, decode.d5.loss_mask: 0.2261, decode.d5.loss_dice: 0.4622, decode.d6.loss_cls: 0.0023, decode.d6.loss_mask: 0.2249, decode.d6.loss_dice: 0.4615, decode.d7.loss_cls: 0.0022, decode.d7.loss_mask: 0.2224, decode.d7.loss_dice: 0.4567, decode.d8.loss_cls: 0.0020, decode.d8.loss_mask: 0.2227, decode.d8.loss_dice: 0.4547, loss: 10.6911\n",
      "2024-02-14 14:14:22,107 - mmseg - INFO - Iter [1060/80000]\tlr: 1.000e-06, eta: 2 days, 3:29:47, time: 2.131, data_time: 0.017, memory: 23505, decode.loss_cls: 0.0018, decode.loss_mask: 0.2972, decode.loss_dice: 0.5229, decode.d0.loss_cls: 3.7705, decode.d0.loss_mask: 0.3084, decode.d0.loss_dice: 0.5541, decode.d1.loss_cls: 0.0377, decode.d1.loss_mask: 0.2995, decode.d1.loss_dice: 0.5392, decode.d2.loss_cls: 0.0238, decode.d2.loss_mask: 0.3007, decode.d2.loss_dice: 0.5306, decode.d3.loss_cls: 0.0105, decode.d3.loss_mask: 0.2933, decode.d3.loss_dice: 0.5245, decode.d4.loss_cls: 0.0045, decode.d4.loss_mask: 0.2991, decode.d4.loss_dice: 0.5278, decode.d5.loss_cls: 0.0028, decode.d5.loss_mask: 0.2965, decode.d5.loss_dice: 0.5269, decode.d6.loss_cls: 0.0023, decode.d6.loss_mask: 0.2975, decode.d6.loss_dice: 0.5214, decode.d7.loss_cls: 0.0022, decode.d7.loss_mask: 0.2965, decode.d7.loss_dice: 0.5274, decode.d8.loss_cls: 0.0020, decode.d8.loss_mask: 0.2965, decode.d8.loss_dice: 0.5260, loss: 12.1440\n",
      "2024-02-14 14:14:43,412 - mmseg - INFO - Iter [1070/80000]\tlr: 1.010e-06, eta: 2 days, 3:26:43, time: 2.131, data_time: 0.017, memory: 23505, decode.loss_cls: 0.0017, decode.loss_mask: 0.2599, decode.loss_dice: 0.5014, decode.d0.loss_cls: 3.7642, decode.d0.loss_mask: 0.2655, decode.d0.loss_dice: 0.5301, decode.d1.loss_cls: 0.0371, decode.d1.loss_mask: 0.2610, decode.d1.loss_dice: 0.5094, decode.d2.loss_cls: 0.0220, decode.d2.loss_mask: 0.2611, decode.d2.loss_dice: 0.5088, decode.d3.loss_cls: 0.0096, decode.d3.loss_mask: 0.2579, decode.d3.loss_dice: 0.5024, decode.d4.loss_cls: 0.0040, decode.d4.loss_mask: 0.2594, decode.d4.loss_dice: 0.5047, decode.d5.loss_cls: 0.0027, decode.d5.loss_mask: 0.2616, decode.d5.loss_dice: 0.5026, decode.d6.loss_cls: 0.0022, decode.d6.loss_mask: 0.2579, decode.d6.loss_dice: 0.4969, decode.d7.loss_cls: 0.0020, decode.d7.loss_mask: 0.2609, decode.d7.loss_dice: 0.5050, decode.d8.loss_cls: 0.0019, decode.d8.loss_mask: 0.2643, decode.d8.loss_dice: 0.5042, loss: 11.5225\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-14 14:15:04,724 - mmseg - INFO - Iter [1080/80000]\tlr: 1.019e-06, eta: 2 days, 3:23:42, time: 2.131, data_time: 0.017, memory: 23505, decode.loss_cls: 0.0017, decode.loss_mask: 0.2134, decode.loss_dice: 0.4582, decode.d0.loss_cls: 3.7583, decode.d0.loss_mask: 0.2310, decode.d0.loss_dice: 0.4890, decode.d1.loss_cls: 0.0312, decode.d1.loss_mask: 0.2206, decode.d1.loss_dice: 0.4691, decode.d2.loss_cls: 0.0222, decode.d2.loss_mask: 0.2188, decode.d2.loss_dice: 0.4622, decode.d3.loss_cls: 0.0090, decode.d3.loss_mask: 0.2159, decode.d3.loss_dice: 0.4581, decode.d4.loss_cls: 0.0035, decode.d4.loss_mask: 0.2150, decode.d4.loss_dice: 0.4576, decode.d5.loss_cls: 0.0025, decode.d5.loss_mask: 0.2151, decode.d5.loss_dice: 0.4599, decode.d6.loss_cls: 0.0021, decode.d6.loss_mask: 0.2159, decode.d6.loss_dice: 0.4580, decode.d7.loss_cls: 0.0019, decode.d7.loss_mask: 0.2138, decode.d7.loss_dice: 0.4599, decode.d8.loss_cls: 0.0018, decode.d8.loss_mask: 0.2135, decode.d8.loss_dice: 0.4559, loss: 10.6349\n",
      "2024-02-14 14:15:26,047 - mmseg - INFO - Iter [1090/80000]\tlr: 1.028e-06, eta: 2 days, 3:20:45, time: 2.132, data_time: 0.017, memory: 23505, decode.loss_cls: 0.0018, decode.loss_mask: 0.2787, decode.loss_dice: 0.5465, decode.d0.loss_cls: 3.7575, decode.d0.loss_mask: 0.3011, decode.d0.loss_dice: 0.5756, decode.d1.loss_cls: 0.0330, decode.d1.loss_mask: 0.2865, decode.d1.loss_dice: 0.5617, decode.d2.loss_cls: 0.0208, decode.d2.loss_mask: 0.2810, decode.d2.loss_dice: 0.5494, decode.d3.loss_cls: 0.0105, decode.d3.loss_mask: 0.2794, decode.d3.loss_dice: 0.5438, decode.d4.loss_cls: 0.0046, decode.d4.loss_mask: 0.2802, decode.d4.loss_dice: 0.5484, decode.d5.loss_cls: 0.0028, decode.d5.loss_mask: 0.2796, decode.d5.loss_dice: 0.5507, decode.d6.loss_cls: 0.0023, decode.d6.loss_mask: 0.2799, decode.d6.loss_dice: 0.5510, decode.d7.loss_cls: 0.0022, decode.d7.loss_mask: 0.2785, decode.d7.loss_dice: 0.5393, decode.d8.loss_cls: 0.0020, decode.d8.loss_mask: 0.2794, decode.d8.loss_dice: 0.5509, loss: 12.1793\n",
      "2024-02-14 14:15:47,361 - mmseg - INFO - Iter [1100/80000]\tlr: 1.038e-06, eta: 2 days, 3:17:51, time: 2.131, data_time: 0.017, memory: 23505, decode.loss_cls: 0.0018, decode.loss_mask: 0.2090, decode.loss_dice: 0.4515, decode.d0.loss_cls: 3.7465, decode.d0.loss_mask: 0.2180, decode.d0.loss_dice: 0.4936, decode.d1.loss_cls: 0.0325, decode.d1.loss_mask: 0.2128, decode.d1.loss_dice: 0.4663, decode.d2.loss_cls: 0.0258, decode.d2.loss_mask: 0.2116, decode.d2.loss_dice: 0.4646, decode.d3.loss_cls: 0.0099, decode.d3.loss_mask: 0.2087, decode.d3.loss_dice: 0.4530, decode.d4.loss_cls: 0.0038, decode.d4.loss_mask: 0.2112, decode.d4.loss_dice: 0.4529, decode.d5.loss_cls: 0.0027, decode.d5.loss_mask: 0.2082, decode.d5.loss_dice: 0.4518, decode.d6.loss_cls: 0.0022, decode.d6.loss_mask: 0.2090, decode.d6.loss_dice: 0.4491, decode.d7.loss_cls: 0.0021, decode.d7.loss_mask: 0.2102, decode.d7.loss_dice: 0.4522, decode.d8.loss_cls: 0.0020, decode.d8.loss_mask: 0.2074, decode.d8.loss_dice: 0.4563, loss: 10.5264\n",
      "2024-02-14 14:16:08,694 - mmseg - INFO - Iter [1110/80000]\tlr: 1.047e-06, eta: 2 days, 3:15:00, time: 2.133, data_time: 0.017, memory: 23505, decode.loss_cls: 0.0016, decode.loss_mask: 0.2476, decode.loss_dice: 0.4903, decode.d0.loss_cls: 3.7461, decode.d0.loss_mask: 0.2621, decode.d0.loss_dice: 0.5171, decode.d1.loss_cls: 0.0288, decode.d1.loss_mask: 0.2521, decode.d1.loss_dice: 0.4886, decode.d2.loss_cls: 0.0203, decode.d2.loss_mask: 0.2515, decode.d2.loss_dice: 0.4860, decode.d3.loss_cls: 0.0094, decode.d3.loss_mask: 0.2475, decode.d3.loss_dice: 0.4865, decode.d4.loss_cls: 0.0040, decode.d4.loss_mask: 0.2473, decode.d4.loss_dice: 0.4837, decode.d5.loss_cls: 0.0025, decode.d5.loss_mask: 0.2484, decode.d5.loss_dice: 0.4843, decode.d6.loss_cls: 0.0021, decode.d6.loss_mask: 0.2494, decode.d6.loss_dice: 0.4911, decode.d7.loss_cls: 0.0019, decode.d7.loss_mask: 0.2468, decode.d7.loss_dice: 0.4885, decode.d8.loss_cls: 0.0019, decode.d8.loss_mask: 0.2484, decode.d8.loss_dice: 0.4875, loss: 11.2234\n",
      "2024-02-14 14:16:29,991 - mmseg - INFO - Iter [1120/80000]\tlr: 1.056e-06, eta: 2 days, 3:12:09, time: 2.130, data_time: 0.017, memory: 23505, decode.loss_cls: 0.0015, decode.loss_mask: 0.2243, decode.loss_dice: 0.4559, decode.d0.loss_cls: 3.7399, decode.d0.loss_mask: 0.2306, decode.d0.loss_dice: 0.4707, decode.d1.loss_cls: 0.0299, decode.d1.loss_mask: 0.2268, decode.d1.loss_dice: 0.4542, decode.d2.loss_cls: 0.0181, decode.d2.loss_mask: 0.2206, decode.d2.loss_dice: 0.4505, decode.d3.loss_cls: 0.0078, decode.d3.loss_mask: 0.2206, decode.d3.loss_dice: 0.4512, decode.d4.loss_cls: 0.0034, decode.d4.loss_mask: 0.2258, decode.d4.loss_dice: 0.4606, decode.d5.loss_cls: 0.0023, decode.d5.loss_mask: 0.2226, decode.d5.loss_dice: 0.4491, decode.d6.loss_cls: 0.0019, decode.d6.loss_mask: 0.2236, decode.d6.loss_dice: 0.4499, decode.d7.loss_cls: 0.0018, decode.d7.loss_mask: 0.2234, decode.d7.loss_dice: 0.4541, decode.d8.loss_cls: 0.0017, decode.d8.loss_mask: 0.2222, decode.d8.loss_dice: 0.4520, loss: 10.5970\n",
      "2024-02-14 14:16:51,291 - mmseg - INFO - Iter [1130/80000]\tlr: 1.065e-06, eta: 2 days, 3:09:21, time: 2.130, data_time: 0.017, memory: 23505, decode.loss_cls: 0.0014, decode.loss_mask: 0.2785, decode.loss_dice: 0.5360, decode.d0.loss_cls: 3.7370, decode.d0.loss_mask: 0.2933, decode.d0.loss_dice: 0.5608, decode.d1.loss_cls: 0.0312, decode.d1.loss_mask: 0.2873, decode.d1.loss_dice: 0.5400, decode.d2.loss_cls: 0.0175, decode.d2.loss_mask: 0.2823, decode.d2.loss_dice: 0.5344, decode.d3.loss_cls: 0.0079, decode.d3.loss_mask: 0.2837, decode.d3.loss_dice: 0.5431, decode.d4.loss_cls: 0.0037, decode.d4.loss_mask: 0.2780, decode.d4.loss_dice: 0.5351, decode.d5.loss_cls: 0.0022, decode.d5.loss_mask: 0.2782, decode.d5.loss_dice: 0.5365, decode.d6.loss_cls: 0.0019, decode.d6.loss_mask: 0.2806, decode.d6.loss_dice: 0.5379, decode.d7.loss_cls: 0.0017, decode.d7.loss_mask: 0.2765, decode.d7.loss_dice: 0.5350, decode.d8.loss_cls: 0.0016, decode.d8.loss_mask: 0.2784, decode.d8.loss_dice: 0.5370, loss: 12.0187\n",
      "2024-02-14 14:17:12,594 - mmseg - INFO - Iter [1140/80000]\tlr: 1.075e-06, eta: 2 days, 3:06:37, time: 2.130, data_time: 0.017, memory: 23505, decode.loss_cls: 0.0019, decode.loss_mask: 0.2484, decode.loss_dice: 0.5158, decode.d0.loss_cls: 3.7335, decode.d0.loss_mask: 0.2581, decode.d0.loss_dice: 0.5482, decode.d1.loss_cls: 0.0443, decode.d1.loss_mask: 0.2559, decode.d1.loss_dice: 0.5110, decode.d2.loss_cls: 0.0298, decode.d2.loss_mask: 0.2479, decode.d2.loss_dice: 0.5095, decode.d3.loss_cls: 0.0078, decode.d3.loss_mask: 0.2517, decode.d3.loss_dice: 0.5179, decode.d4.loss_cls: 0.0039, decode.d4.loss_mask: 0.2506, decode.d4.loss_dice: 0.5135, decode.d5.loss_cls: 0.0027, decode.d5.loss_mask: 0.2514, decode.d5.loss_dice: 0.5159, decode.d6.loss_cls: 0.0024, decode.d6.loss_mask: 0.2522, decode.d6.loss_dice: 0.5145, decode.d7.loss_cls: 0.0023, decode.d7.loss_mask: 0.2509, decode.d7.loss_dice: 0.5166, decode.d8.loss_cls: 0.0022, decode.d8.loss_mask: 0.2495, decode.d8.loss_dice: 0.5164, loss: 11.5264\n",
      "2024-02-14 14:17:33,917 - mmseg - INFO - Iter [1150/80000]\tlr: 1.084e-06, eta: 2 days, 3:03:55, time: 2.132, data_time: 0.017, memory: 23505, decode.loss_cls: 0.0016, decode.loss_mask: 0.2719, decode.loss_dice: 0.4980, decode.d0.loss_cls: 3.7300, decode.d0.loss_mask: 0.2841, decode.d0.loss_dice: 0.5263, decode.d1.loss_cls: 0.0285, decode.d1.loss_mask: 0.2738, decode.d1.loss_dice: 0.5056, decode.d2.loss_cls: 0.0154, decode.d2.loss_mask: 0.2725, decode.d2.loss_dice: 0.4997, decode.d3.loss_cls: 0.0074, decode.d3.loss_mask: 0.2724, decode.d3.loss_dice: 0.5028, decode.d4.loss_cls: 0.0041, decode.d4.loss_mask: 0.2757, decode.d4.loss_dice: 0.5043, decode.d5.loss_cls: 0.0024, decode.d5.loss_mask: 0.2748, decode.d5.loss_dice: 0.5059, decode.d6.loss_cls: 0.0020, decode.d6.loss_mask: 0.2757, decode.d6.loss_dice: 0.5016, decode.d7.loss_cls: 0.0019, decode.d7.loss_mask: 0.2747, decode.d7.loss_dice: 0.5005, decode.d8.loss_cls: 0.0018, decode.d8.loss_mask: 0.2735, decode.d8.loss_dice: 0.5017, loss: 11.5908\n",
      "2024-02-14 14:17:55,248 - mmseg - INFO - Iter [1160/80000]\tlr: 1.093e-06, eta: 2 days, 3:01:17, time: 2.133, data_time: 0.018, memory: 23505, decode.loss_cls: 0.0013, decode.loss_mask: 0.3270, decode.loss_dice: 0.6015, decode.d0.loss_cls: 3.7286, decode.d0.loss_mask: 0.3402, decode.d0.loss_dice: 0.6220, decode.d1.loss_cls: 0.0249, decode.d1.loss_mask: 0.3273, decode.d1.loss_dice: 0.6086, decode.d2.loss_cls: 0.0138, decode.d2.loss_mask: 0.3268, decode.d2.loss_dice: 0.5960, decode.d3.loss_cls: 0.0068, decode.d3.loss_mask: 0.3218, decode.d3.loss_dice: 0.6024, decode.d4.loss_cls: 0.0042, decode.d4.loss_mask: 0.3254, decode.d4.loss_dice: 0.5942, decode.d5.loss_cls: 0.0021, decode.d5.loss_mask: 0.3256, decode.d5.loss_dice: 0.5979, decode.d6.loss_cls: 0.0018, decode.d6.loss_mask: 0.3251, decode.d6.loss_dice: 0.5923, decode.d7.loss_cls: 0.0017, decode.d7.loss_mask: 0.3258, decode.d7.loss_dice: 0.6026, decode.d8.loss_cls: 0.0015, decode.d8.loss_mask: 0.3239, decode.d8.loss_dice: 0.5948, loss: 13.0679\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-14 14:18:16,561 - mmseg - INFO - Iter [1170/80000]\tlr: 1.103e-06, eta: 2 days, 2:58:40, time: 2.131, data_time: 0.017, memory: 23505, decode.loss_cls: 0.0013, decode.loss_mask: 0.2656, decode.loss_dice: 0.5175, decode.d0.loss_cls: 3.7171, decode.d0.loss_mask: 0.2772, decode.d0.loss_dice: 0.5327, decode.d1.loss_cls: 0.0282, decode.d1.loss_mask: 0.2727, decode.d1.loss_dice: 0.5216, decode.d2.loss_cls: 0.0154, decode.d2.loss_mask: 0.2706, decode.d2.loss_dice: 0.5201, decode.d3.loss_cls: 0.0061, decode.d3.loss_mask: 0.2706, decode.d3.loss_dice: 0.5135, decode.d4.loss_cls: 0.0036, decode.d4.loss_mask: 0.2694, decode.d4.loss_dice: 0.5137, decode.d5.loss_cls: 0.0021, decode.d5.loss_mask: 0.2689, decode.d5.loss_dice: 0.5140, decode.d6.loss_cls: 0.0017, decode.d6.loss_mask: 0.2701, decode.d6.loss_dice: 0.5161, decode.d7.loss_cls: 0.0016, decode.d7.loss_mask: 0.2662, decode.d7.loss_dice: 0.5138, decode.d8.loss_cls: 0.0015, decode.d8.loss_mask: 0.2651, decode.d8.loss_dice: 0.5143, loss: 11.6522\n",
      "2024-02-14 14:18:37,868 - mmseg - INFO - Iter [1180/80000]\tlr: 1.112e-06, eta: 2 days, 2:56:05, time: 2.131, data_time: 0.017, memory: 23505, decode.loss_cls: 0.0013, decode.loss_mask: 0.2557, decode.loss_dice: 0.5133, decode.d0.loss_cls: 3.7108, decode.d0.loss_mask: 0.2629, decode.d0.loss_dice: 0.5095, decode.d1.loss_cls: 0.0243, decode.d1.loss_mask: 0.2561, decode.d1.loss_dice: 0.5097, decode.d2.loss_cls: 0.0138, decode.d2.loss_mask: 0.2580, decode.d2.loss_dice: 0.5128, decode.d3.loss_cls: 0.0065, decode.d3.loss_mask: 0.2547, decode.d3.loss_dice: 0.5135, decode.d4.loss_cls: 0.0031, decode.d4.loss_mask: 0.2535, decode.d4.loss_dice: 0.5144, decode.d5.loss_cls: 0.0020, decode.d5.loss_mask: 0.2556, decode.d5.loss_dice: 0.5100, decode.d6.loss_cls: 0.0017, decode.d6.loss_mask: 0.2566, decode.d6.loss_dice: 0.5142, decode.d7.loss_cls: 0.0016, decode.d7.loss_mask: 0.2544, decode.d7.loss_dice: 0.5139, decode.d8.loss_cls: 0.0015, decode.d8.loss_mask: 0.2522, decode.d8.loss_dice: 0.5095, loss: 11.4472\n",
      "2024-02-14 14:18:59,170 - mmseg - INFO - Iter [1190/80000]\tlr: 1.121e-06, eta: 2 days, 2:53:32, time: 2.130, data_time: 0.017, memory: 23505, decode.loss_cls: 0.0013, decode.loss_mask: 0.2534, decode.loss_dice: 0.4886, decode.d0.loss_cls: 3.7056, decode.d0.loss_mask: 0.2605, decode.d0.loss_dice: 0.5117, decode.d1.loss_cls: 0.0270, decode.d1.loss_mask: 0.2525, decode.d1.loss_dice: 0.4859, decode.d2.loss_cls: 0.0150, decode.d2.loss_mask: 0.2483, decode.d2.loss_dice: 0.4873, decode.d3.loss_cls: 0.0067, decode.d3.loss_mask: 0.2497, decode.d3.loss_dice: 0.4931, decode.d4.loss_cls: 0.0031, decode.d4.loss_mask: 0.2479, decode.d4.loss_dice: 0.4878, decode.d5.loss_cls: 0.0020, decode.d5.loss_mask: 0.2504, decode.d5.loss_dice: 0.4918, decode.d6.loss_cls: 0.0017, decode.d6.loss_mask: 0.2519, decode.d6.loss_dice: 0.4903, decode.d7.loss_cls: 0.0015, decode.d7.loss_mask: 0.2501, decode.d7.loss_dice: 0.4878, decode.d8.loss_cls: 0.0015, decode.d8.loss_mask: 0.2525, decode.d8.loss_dice: 0.4866, loss: 11.1935\n",
      "2024-02-14 14:19:20,500 - mmseg - INFO - Iter [1200/80000]\tlr: 1.130e-06, eta: 2 days, 2:51:02, time: 2.133, data_time: 0.017, memory: 23505, decode.loss_cls: 0.0015, decode.loss_mask: 0.2792, decode.loss_dice: 0.5235, decode.d0.loss_cls: 3.7058, decode.d0.loss_mask: 0.2961, decode.d0.loss_dice: 0.5406, decode.d1.loss_cls: 0.0241, decode.d1.loss_mask: 0.2883, decode.d1.loss_dice: 0.5310, decode.d2.loss_cls: 0.0128, decode.d2.loss_mask: 0.2880, decode.d2.loss_dice: 0.5280, decode.d3.loss_cls: 0.0071, decode.d3.loss_mask: 0.2837, decode.d3.loss_dice: 0.5262, decode.d4.loss_cls: 0.0038, decode.d4.loss_mask: 0.2836, decode.d4.loss_dice: 0.5252, decode.d5.loss_cls: 0.0022, decode.d5.loss_mask: 0.2807, decode.d5.loss_dice: 0.5218, decode.d6.loss_cls: 0.0019, decode.d6.loss_mask: 0.2855, decode.d6.loss_dice: 0.5272, decode.d7.loss_cls: 0.0017, decode.d7.loss_mask: 0.2860, decode.d7.loss_dice: 0.5246, decode.d8.loss_cls: 0.0017, decode.d8.loss_mask: 0.2813, decode.d8.loss_dice: 0.5200, loss: 11.8828\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 40/40, 6.2 task/s, elapsed: 6s, ETA:     0s\n",
      "\n",
      "2024-02-14 14:19:26,938 - mmseg - INFO - per class results:\n",
      "2024-02-14 14:19:26,939 - mmseg - INFO - \n",
      "+---------------+-------+-------+\n",
      "|     Class     |  IoU  |  Acc  |\n",
      "+---------------+-------+-------+\n",
      "|       bg      | 97.33 | 98.12 |\n",
      "|    Anchovy    | 79.59 | 93.77 |\n",
      "|     Olives    | 87.38 | 92.18 |\n",
      "|     Salami    | 69.82 |  85.0 |\n",
      "|   Red_Pepper  | 87.01 | 95.96 |\n",
      "| Yellow_Pepper | 85.74 | 94.89 |\n",
      "+---------------+-------+-------+\n",
      "2024-02-14 14:19:26,939 - mmseg - INFO - Summary:\n",
      "2024-02-14 14:19:26,939 - mmseg - INFO - \n",
      "+-------+-------+-------+\n",
      "|  aAcc |  mIoU |  mAcc |\n",
      "+-------+-------+-------+\n",
      "| 97.39 | 84.48 | 93.32 |\n",
      "+-------+-------+-------+\n",
      "2024-02-14 14:19:27,440 - mmseg - INFO - The previous best checkpoint /workspace/ViT-Adapter/segmentation/work_dirs/pizze_training_large/best_mIoU_iter_1000.pth was removed\n",
      "2024-02-14 14:19:40,394 - mmseg - INFO - Now best checkpoint is saved as best_mIoU_iter_1200.pth.\n",
      "2024-02-14 14:19:40,395 - mmseg - INFO - Best mIoU is 0.8448 at 1200 iter.\n",
      "2024-02-14 14:19:40,395 - mmseg - INFO - Iter(val) [10]\taAcc: 0.9739, mIoU: 0.8448, mAcc: 0.9332, IoU.bg: 0.9733, IoU.Anchovy: 0.7959, IoU.Olives: 0.8738, IoU.Salami: 0.6982, IoU.Red_Pepper: 0.8701, IoU.Yellow_Pepper: 0.8574, Acc.bg: 0.9812, Acc.Anchovy: 0.9377, Acc.Olives: 0.9218, Acc.Salami: 0.8500, Acc.Red_Pepper: 0.9596, Acc.Yellow_Pepper: 0.9489\n",
      "2024-02-14 14:20:01,694 - mmseg - INFO - Iter [1210/80000]\tlr: 1.140e-06, eta: 2 days, 3:10:09, time: 4.120, data_time: 2.007, memory: 23505, decode.loss_cls: 0.0014, decode.loss_mask: 0.2880, decode.loss_dice: 0.5284, decode.d0.loss_cls: 3.6977, decode.d0.loss_mask: 0.3010, decode.d0.loss_dice: 0.5574, decode.d1.loss_cls: 0.0243, decode.d1.loss_mask: 0.2896, decode.d1.loss_dice: 0.5333, decode.d2.loss_cls: 0.0140, decode.d2.loss_mask: 0.2959, decode.d2.loss_dice: 0.5419, decode.d3.loss_cls: 0.0069, decode.d3.loss_mask: 0.2940, decode.d3.loss_dice: 0.5336, decode.d4.loss_cls: 0.0036, decode.d4.loss_mask: 0.2904, decode.d4.loss_dice: 0.5318, decode.d5.loss_cls: 0.0021, decode.d5.loss_mask: 0.2900, decode.d5.loss_dice: 0.5337, decode.d6.loss_cls: 0.0018, decode.d6.loss_mask: 0.2880, decode.d6.loss_dice: 0.5291, decode.d7.loss_cls: 0.0017, decode.d7.loss_mask: 0.2902, decode.d7.loss_dice: 0.5325, decode.d8.loss_cls: 0.0016, decode.d8.loss_mask: 0.2924, decode.d8.loss_dice: 0.5345, loss: 12.0307\n",
      "2024-02-14 14:20:23,002 - mmseg - INFO - Iter [1220/80000]\tlr: 1.149e-06, eta: 2 days, 3:07:32, time: 2.131, data_time: 0.018, memory: 23505, decode.loss_cls: 0.0017, decode.loss_mask: 0.2625, decode.loss_dice: 0.4959, decode.d0.loss_cls: 3.6919, decode.d0.loss_mask: 0.2771, decode.d0.loss_dice: 0.5167, decode.d1.loss_cls: 0.0249, decode.d1.loss_mask: 0.2609, decode.d1.loss_dice: 0.5087, decode.d2.loss_cls: 0.0136, decode.d2.loss_mask: 0.2654, decode.d2.loss_dice: 0.5006, decode.d3.loss_cls: 0.0061, decode.d3.loss_mask: 0.2621, decode.d3.loss_dice: 0.4963, decode.d4.loss_cls: 0.0031, decode.d4.loss_mask: 0.2635, decode.d4.loss_dice: 0.5039, decode.d5.loss_cls: 0.0023, decode.d5.loss_mask: 0.2637, decode.d5.loss_dice: 0.4969, decode.d6.loss_cls: 0.0021, decode.d6.loss_mask: 0.2604, decode.d6.loss_dice: 0.4952, decode.d7.loss_cls: 0.0020, decode.d7.loss_mask: 0.2636, decode.d7.loss_dice: 0.5035, decode.d8.loss_cls: 0.0019, decode.d8.loss_mask: 0.2620, decode.d8.loss_dice: 0.4955, loss: 11.4041\n",
      "2024-02-14 14:20:44,327 - mmseg - INFO - Iter [1230/80000]\tlr: 1.158e-06, eta: 2 days, 3:04:58, time: 2.132, data_time: 0.017, memory: 23505, decode.loss_cls: 0.0013, decode.loss_mask: 0.2710, decode.loss_dice: 0.5274, decode.d0.loss_cls: 3.6859, decode.d0.loss_mask: 0.2817, decode.d0.loss_dice: 0.5555, decode.d1.loss_cls: 0.0209, decode.d1.loss_mask: 0.2725, decode.d1.loss_dice: 0.5301, decode.d2.loss_cls: 0.0121, decode.d2.loss_mask: 0.2756, decode.d2.loss_dice: 0.5368, decode.d3.loss_cls: 0.0062, decode.d3.loss_mask: 0.2741, decode.d3.loss_dice: 0.5278, decode.d4.loss_cls: 0.0031, decode.d4.loss_mask: 0.2750, decode.d4.loss_dice: 0.5286, decode.d5.loss_cls: 0.0019, decode.d5.loss_mask: 0.2722, decode.d5.loss_dice: 0.5349, decode.d6.loss_cls: 0.0016, decode.d6.loss_mask: 0.2734, decode.d6.loss_dice: 0.5350, decode.d7.loss_cls: 0.0015, decode.d7.loss_mask: 0.2737, decode.d7.loss_dice: 0.5320, decode.d8.loss_cls: 0.0015, decode.d8.loss_mask: 0.2722, decode.d8.loss_dice: 0.5351, loss: 11.8205\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-14 14:21:05,649 - mmseg - INFO - Iter [1240/80000]\tlr: 1.168e-06, eta: 2 days, 3:02:26, time: 2.132, data_time: 0.017, memory: 23505, decode.loss_cls: 0.0012, decode.loss_mask: 0.2162, decode.loss_dice: 0.4573, decode.d0.loss_cls: 3.6762, decode.d0.loss_mask: 0.2289, decode.d0.loss_dice: 0.4828, decode.d1.loss_cls: 0.0239, decode.d1.loss_mask: 0.2236, decode.d1.loss_dice: 0.4620, decode.d2.loss_cls: 0.0126, decode.d2.loss_mask: 0.2142, decode.d2.loss_dice: 0.4559, decode.d3.loss_cls: 0.0052, decode.d3.loss_mask: 0.2153, decode.d3.loss_dice: 0.4584, decode.d4.loss_cls: 0.0025, decode.d4.loss_mask: 0.2148, decode.d4.loss_dice: 0.4599, decode.d5.loss_cls: 0.0018, decode.d5.loss_mask: 0.2187, decode.d5.loss_dice: 0.4646, decode.d6.loss_cls: 0.0015, decode.d6.loss_mask: 0.2169, decode.d6.loss_dice: 0.4605, decode.d7.loss_cls: 0.0015, decode.d7.loss_mask: 0.2171, decode.d7.loss_dice: 0.4661, decode.d8.loss_cls: 0.0014, decode.d8.loss_mask: 0.2144, decode.d8.loss_dice: 0.4630, loss: 10.5383\n",
      "2024-02-14 14:21:26,961 - mmseg - INFO - Iter [1250/80000]\tlr: 1.177e-06, eta: 2 days, 2:59:56, time: 2.131, data_time: 0.017, memory: 23505, decode.loss_cls: 0.0012, decode.loss_mask: 0.2570, decode.loss_dice: 0.4971, decode.d0.loss_cls: 3.6747, decode.d0.loss_mask: 0.2658, decode.d0.loss_dice: 0.5316, decode.d1.loss_cls: 0.0249, decode.d1.loss_mask: 0.2580, decode.d1.loss_dice: 0.5007, decode.d2.loss_cls: 0.0128, decode.d2.loss_mask: 0.2525, decode.d2.loss_dice: 0.4989, decode.d3.loss_cls: 0.0061, decode.d3.loss_mask: 0.2532, decode.d3.loss_dice: 0.5038, decode.d4.loss_cls: 0.0031, decode.d4.loss_mask: 0.2518, decode.d4.loss_dice: 0.5061, decode.d5.loss_cls: 0.0019, decode.d5.loss_mask: 0.2524, decode.d5.loss_dice: 0.5019, decode.d6.loss_cls: 0.0016, decode.d6.loss_mask: 0.2504, decode.d6.loss_dice: 0.4924, decode.d7.loss_cls: 0.0015, decode.d7.loss_mask: 0.2554, decode.d7.loss_dice: 0.5025, decode.d8.loss_cls: 0.0014, decode.d8.loss_mask: 0.2554, decode.d8.loss_dice: 0.4995, loss: 11.3154\n",
      "2024-02-14 14:21:48,296 - mmseg - INFO - Iter [1260/80000]\tlr: 1.186e-06, eta: 2 days, 2:57:29, time: 2.134, data_time: 0.017, memory: 23505, decode.loss_cls: 0.0012, decode.loss_mask: 0.2608, decode.loss_dice: 0.5000, decode.d0.loss_cls: 3.6703, decode.d0.loss_mask: 0.2670, decode.d0.loss_dice: 0.5198, decode.d1.loss_cls: 0.0255, decode.d1.loss_mask: 0.2656, decode.d1.loss_dice: 0.5022, decode.d2.loss_cls: 0.0124, decode.d2.loss_mask: 0.2601, decode.d2.loss_dice: 0.5020, decode.d3.loss_cls: 0.0053, decode.d3.loss_mask: 0.2609, decode.d3.loss_dice: 0.5049, decode.d4.loss_cls: 0.0029, decode.d4.loss_mask: 0.2602, decode.d4.loss_dice: 0.5005, decode.d5.loss_cls: 0.0018, decode.d5.loss_mask: 0.2611, decode.d5.loss_dice: 0.5025, decode.d6.loss_cls: 0.0015, decode.d6.loss_mask: 0.2633, decode.d6.loss_dice: 0.5019, decode.d7.loss_cls: 0.0014, decode.d7.loss_mask: 0.2618, decode.d7.loss_dice: 0.5024, decode.d8.loss_cls: 0.0014, decode.d8.loss_mask: 0.2634, decode.d8.loss_dice: 0.5108, loss: 11.3949\n",
      "2024-02-14 14:22:09,638 - mmseg - INFO - Iter [1270/80000]\tlr: 1.195e-06, eta: 2 days, 2:55:04, time: 2.134, data_time: 0.017, memory: 23505, decode.loss_cls: 0.0011, decode.loss_mask: 0.2678, decode.loss_dice: 0.5122, decode.d0.loss_cls: 3.6644, decode.d0.loss_mask: 0.2859, decode.d0.loss_dice: 0.5360, decode.d1.loss_cls: 0.0201, decode.d1.loss_mask: 0.2736, decode.d1.loss_dice: 0.5183, decode.d2.loss_cls: 0.0112, decode.d2.loss_mask: 0.2703, decode.d2.loss_dice: 0.5099, decode.d3.loss_cls: 0.0051, decode.d3.loss_mask: 0.2668, decode.d3.loss_dice: 0.5074, decode.d4.loss_cls: 0.0028, decode.d4.loss_mask: 0.2677, decode.d4.loss_dice: 0.5140, decode.d5.loss_cls: 0.0017, decode.d5.loss_mask: 0.2668, decode.d5.loss_dice: 0.5120, decode.d6.loss_cls: 0.0015, decode.d6.loss_mask: 0.2710, decode.d6.loss_dice: 0.5195, decode.d7.loss_cls: 0.0013, decode.d7.loss_mask: 0.2676, decode.d7.loss_dice: 0.5156, decode.d8.loss_cls: 0.0013, decode.d8.loss_mask: 0.2681, decode.d8.loss_dice: 0.5151, loss: 11.5762\n",
      "2024-02-14 14:22:30,950 - mmseg - INFO - Iter [1280/80000]\tlr: 1.205e-06, eta: 2 days, 2:52:40, time: 2.131, data_time: 0.017, memory: 23505, decode.loss_cls: 0.0010, decode.loss_mask: 0.2412, decode.loss_dice: 0.4832, decode.d0.loss_cls: 3.6556, decode.d0.loss_mask: 0.2562, decode.d0.loss_dice: 0.5019, decode.d1.loss_cls: 0.0229, decode.d1.loss_mask: 0.2444, decode.d1.loss_dice: 0.4915, decode.d2.loss_cls: 0.0112, decode.d2.loss_mask: 0.2444, decode.d2.loss_dice: 0.4854, decode.d3.loss_cls: 0.0053, decode.d3.loss_mask: 0.2459, decode.d3.loss_dice: 0.4855, decode.d4.loss_cls: 0.0021, decode.d4.loss_mask: 0.2453, decode.d4.loss_dice: 0.4801, decode.d5.loss_cls: 0.0015, decode.d5.loss_mask: 0.2436, decode.d5.loss_dice: 0.4846, decode.d6.loss_cls: 0.0013, decode.d6.loss_mask: 0.2444, decode.d6.loss_dice: 0.4793, decode.d7.loss_cls: 0.0012, decode.d7.loss_mask: 0.2432, decode.d7.loss_dice: 0.4831, decode.d8.loss_cls: 0.0012, decode.d8.loss_mask: 0.2454, decode.d8.loss_dice: 0.4872, loss: 11.0192\n",
      "2024-02-14 14:22:54,352 - mmseg - INFO - Iter [1290/80000]\tlr: 1.214e-06, eta: 2 days, 2:52:25, time: 2.340, data_time: 0.224, memory: 23505, decode.loss_cls: 0.0011, decode.loss_mask: 0.2588, decode.loss_dice: 0.4990, decode.d0.loss_cls: 3.6504, decode.d0.loss_mask: 0.2672, decode.d0.loss_dice: 0.5216, decode.d1.loss_cls: 0.0245, decode.d1.loss_mask: 0.2634, decode.d1.loss_dice: 0.5042, decode.d2.loss_cls: 0.0113, decode.d2.loss_mask: 0.2623, decode.d2.loss_dice: 0.5016, decode.d3.loss_cls: 0.0057, decode.d3.loss_mask: 0.2639, decode.d3.loss_dice: 0.5053, decode.d4.loss_cls: 0.0023, decode.d4.loss_mask: 0.2583, decode.d4.loss_dice: 0.4973, decode.d5.loss_cls: 0.0016, decode.d5.loss_mask: 0.2616, decode.d5.loss_dice: 0.5039, decode.d6.loss_cls: 0.0014, decode.d6.loss_mask: 0.2575, decode.d6.loss_dice: 0.4953, decode.d7.loss_cls: 0.0013, decode.d7.loss_mask: 0.2601, decode.d7.loss_dice: 0.4978, decode.d8.loss_cls: 0.0012, decode.d8.loss_mask: 0.2612, decode.d8.loss_dice: 0.5035, loss: 11.3446\n",
      "2024-02-14 14:23:15,666 - mmseg - INFO - Iter [1300/80000]\tlr: 1.223e-06, eta: 2 days, 2:50:03, time: 2.131, data_time: 0.017, memory: 23505, decode.loss_cls: 0.0012, decode.loss_mask: 0.2382, decode.loss_dice: 0.4935, decode.d0.loss_cls: 3.6457, decode.d0.loss_mask: 0.2473, decode.d0.loss_dice: 0.5102, decode.d1.loss_cls: 0.0296, decode.d1.loss_mask: 0.2472, decode.d1.loss_dice: 0.4982, decode.d2.loss_cls: 0.0161, decode.d2.loss_mask: 0.2402, decode.d2.loss_dice: 0.4952, decode.d3.loss_cls: 0.0062, decode.d3.loss_mask: 0.2410, decode.d3.loss_dice: 0.4942, decode.d4.loss_cls: 0.0025, decode.d4.loss_mask: 0.2389, decode.d4.loss_dice: 0.4947, decode.d5.loss_cls: 0.0018, decode.d5.loss_mask: 0.2387, decode.d5.loss_dice: 0.4966, decode.d6.loss_cls: 0.0015, decode.d6.loss_mask: 0.2408, decode.d6.loss_dice: 0.4940, decode.d7.loss_cls: 0.0014, decode.d7.loss_mask: 0.2402, decode.d7.loss_dice: 0.4907, decode.d8.loss_cls: 0.0014, decode.d8.loss_mask: 0.2408, decode.d8.loss_dice: 0.4907, loss: 11.0786\n",
      "2024-02-14 14:23:36,978 - mmseg - INFO - Iter [1310/80000]\tlr: 1.232e-06, eta: 2 days, 2:47:43, time: 2.131, data_time: 0.017, memory: 23505, decode.loss_cls: 0.0010, decode.loss_mask: 0.2647, decode.loss_dice: 0.4990, decode.d0.loss_cls: 3.6401, decode.d0.loss_mask: 0.2709, decode.d0.loss_dice: 0.5154, decode.d1.loss_cls: 0.0213, decode.d1.loss_mask: 0.2660, decode.d1.loss_dice: 0.5033, decode.d2.loss_cls: 0.0110, decode.d2.loss_mask: 0.2658, decode.d2.loss_dice: 0.5047, decode.d3.loss_cls: 0.0050, decode.d3.loss_mask: 0.2679, decode.d3.loss_dice: 0.4984, decode.d4.loss_cls: 0.0025, decode.d4.loss_mask: 0.2658, decode.d4.loss_dice: 0.4988, decode.d5.loss_cls: 0.0016, decode.d5.loss_mask: 0.2649, decode.d5.loss_dice: 0.4998, decode.d6.loss_cls: 0.0013, decode.d6.loss_mask: 0.2664, decode.d6.loss_dice: 0.4974, decode.d7.loss_cls: 0.0012, decode.d7.loss_mask: 0.2650, decode.d7.loss_dice: 0.5008, decode.d8.loss_cls: 0.0012, decode.d8.loss_mask: 0.2656, decode.d8.loss_dice: 0.5013, loss: 11.3684\n",
      "2024-02-14 14:23:58,319 - mmseg - INFO - Iter [1320/80000]\tlr: 1.242e-06, eta: 2 days, 2:45:27, time: 2.134, data_time: 0.017, memory: 23505, decode.loss_cls: 0.0010, decode.loss_mask: 0.2630, decode.loss_dice: 0.5011, decode.d0.loss_cls: 3.6345, decode.d0.loss_mask: 0.2724, decode.d0.loss_dice: 0.5184, decode.d1.loss_cls: 0.0209, decode.d1.loss_mask: 0.2663, decode.d1.loss_dice: 0.5101, decode.d2.loss_cls: 0.0103, decode.d2.loss_mask: 0.2674, decode.d2.loss_dice: 0.5034, decode.d3.loss_cls: 0.0045, decode.d3.loss_mask: 0.2629, decode.d3.loss_dice: 0.4996, decode.d4.loss_cls: 0.0025, decode.d4.loss_mask: 0.2618, decode.d4.loss_dice: 0.5026, decode.d5.loss_cls: 0.0015, decode.d5.loss_mask: 0.2649, decode.d5.loss_dice: 0.5087, decode.d6.loss_cls: 0.0013, decode.d6.loss_mask: 0.2612, decode.d6.loss_dice: 0.4961, decode.d7.loss_cls: 0.0012, decode.d7.loss_mask: 0.2635, decode.d7.loss_dice: 0.5068, decode.d8.loss_cls: 0.0012, decode.d8.loss_mask: 0.2647, decode.d8.loss_dice: 0.5052, loss: 11.3791\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-14 14:24:22,900 - mmseg - INFO - Iter [1330/80000]\tlr: 1.251e-06, eta: 2 days, 2:46:24, time: 2.458, data_time: 0.017, memory: 23505, decode.loss_cls: 0.0013, decode.loss_mask: 0.2338, decode.loss_dice: 0.4588, decode.d0.loss_cls: 3.6270, decode.d0.loss_mask: 0.2423, decode.d0.loss_dice: 0.4747, decode.d1.loss_cls: 0.0216, decode.d1.loss_mask: 0.2318, decode.d1.loss_dice: 0.4622, decode.d2.loss_cls: 0.0111, decode.d2.loss_mask: 0.2301, decode.d2.loss_dice: 0.4589, decode.d3.loss_cls: 0.0047, decode.d3.loss_mask: 0.2294, decode.d3.loss_dice: 0.4537, decode.d4.loss_cls: 0.0026, decode.d4.loss_mask: 0.2281, decode.d4.loss_dice: 0.4575, decode.d5.loss_cls: 0.0019, decode.d5.loss_mask: 0.2300, decode.d5.loss_dice: 0.4556, decode.d6.loss_cls: 0.0016, decode.d6.loss_mask: 0.2321, decode.d6.loss_dice: 0.4586, decode.d7.loss_cls: 0.0016, decode.d7.loss_mask: 0.2292, decode.d7.loss_dice: 0.4539, decode.d8.loss_cls: 0.0015, decode.d8.loss_mask: 0.2291, decode.d8.loss_dice: 0.4517, loss: 10.5764\n",
      "2024-02-14 14:25:03,905 - mmseg - INFO - Iter [1340/80000]\tlr: 1.260e-06, eta: 2 days, 3:03:24, time: 4.100, data_time: 0.019, memory: 23505, decode.loss_cls: 0.0011, decode.loss_mask: 0.2344, decode.loss_dice: 0.4558, decode.d0.loss_cls: 3.6197, decode.d0.loss_mask: 0.2422, decode.d0.loss_dice: 0.4678, decode.d1.loss_cls: 0.0208, decode.d1.loss_mask: 0.2349, decode.d1.loss_dice: 0.4562, decode.d2.loss_cls: 0.0099, decode.d2.loss_mask: 0.2332, decode.d2.loss_dice: 0.4514, decode.d3.loss_cls: 0.0045, decode.d3.loss_mask: 0.2336, decode.d3.loss_dice: 0.4535, decode.d4.loss_cls: 0.0025, decode.d4.loss_mask: 0.2338, decode.d4.loss_dice: 0.4540, decode.d5.loss_cls: 0.0015, decode.d5.loss_mask: 0.2333, decode.d5.loss_dice: 0.4514, decode.d6.loss_cls: 0.0013, decode.d6.loss_mask: 0.2321, decode.d6.loss_dice: 0.4496, decode.d7.loss_cls: 0.0013, decode.d7.loss_mask: 0.2340, decode.d7.loss_dice: 0.4599, decode.d8.loss_cls: 0.0012, decode.d8.loss_mask: 0.2316, decode.d8.loss_dice: 0.4522, loss: 10.5586\n",
      "2024-02-14 14:25:59,739 - mmseg - INFO - Iter [1350/80000]\tlr: 1.269e-06, eta: 2 days, 3:34:32, time: 5.584, data_time: 0.012, memory: 23505, decode.loss_cls: 0.0010, decode.loss_mask: 0.2731, decode.loss_dice: 0.5117, decode.d0.loss_cls: 3.6154, decode.d0.loss_mask: 0.2843, decode.d0.loss_dice: 0.5303, decode.d1.loss_cls: 0.0191, decode.d1.loss_mask: 0.2771, decode.d1.loss_dice: 0.5124, decode.d2.loss_cls: 0.0089, decode.d2.loss_mask: 0.2721, decode.d2.loss_dice: 0.5142, decode.d3.loss_cls: 0.0044, decode.d3.loss_mask: 0.2744, decode.d3.loss_dice: 0.5171, decode.d4.loss_cls: 0.0024, decode.d4.loss_mask: 0.2739, decode.d4.loss_dice: 0.5155, decode.d5.loss_cls: 0.0016, decode.d5.loss_mask: 0.2735, decode.d5.loss_dice: 0.5171, decode.d6.loss_cls: 0.0013, decode.d6.loss_mask: 0.2726, decode.d6.loss_dice: 0.5216, decode.d7.loss_cls: 0.0012, decode.d7.loss_mask: 0.2720, decode.d7.loss_dice: 0.5157, decode.d8.loss_cls: 0.0012, decode.d8.loss_mask: 0.2731, decode.d8.loss_dice: 0.5190, loss: 11.5775\n",
      "2024-02-14 14:26:21,033 - mmseg - INFO - Iter [1360/80000]\tlr: 1.279e-06, eta: 2 days, 3:31:55, time: 2.129, data_time: 0.016, memory: 23505, decode.loss_cls: 0.0009, decode.loss_mask: 0.2137, decode.loss_dice: 0.4457, decode.d0.loss_cls: 3.6065, decode.d0.loss_mask: 0.2306, decode.d0.loss_dice: 0.4657, decode.d1.loss_cls: 0.0210, decode.d1.loss_mask: 0.2164, decode.d1.loss_dice: 0.4479, decode.d2.loss_cls: 0.0098, decode.d2.loss_mask: 0.2173, decode.d2.loss_dice: 0.4556, decode.d3.loss_cls: 0.0043, decode.d3.loss_mask: 0.2167, decode.d3.loss_dice: 0.4557, decode.d4.loss_cls: 0.0021, decode.d4.loss_mask: 0.2176, decode.d4.loss_dice: 0.4542, decode.d5.loss_cls: 0.0014, decode.d5.loss_mask: 0.2152, decode.d5.loss_dice: 0.4499, decode.d6.loss_cls: 0.0012, decode.d6.loss_mask: 0.2156, decode.d6.loss_dice: 0.4521, decode.d7.loss_cls: 0.0012, decode.d7.loss_mask: 0.2154, decode.d7.loss_dice: 0.4520, decode.d8.loss_cls: 0.0011, decode.d8.loss_mask: 0.2173, decode.d8.loss_dice: 0.4546, loss: 10.3586\n",
      "2024-02-14 14:26:42,359 - mmseg - INFO - Iter [1370/80000]\tlr: 1.288e-06, eta: 2 days, 3:29:21, time: 2.133, data_time: 0.016, memory: 23505, decode.loss_cls: 0.0010, decode.loss_mask: 0.2489, decode.loss_dice: 0.4622, decode.d0.loss_cls: 3.6024, decode.d0.loss_mask: 0.2566, decode.d0.loss_dice: 0.4841, decode.d1.loss_cls: 0.0194, decode.d1.loss_mask: 0.2490, decode.d1.loss_dice: 0.4714, decode.d2.loss_cls: 0.0090, decode.d2.loss_mask: 0.2438, decode.d2.loss_dice: 0.4622, decode.d3.loss_cls: 0.0051, decode.d3.loss_mask: 0.2477, decode.d3.loss_dice: 0.4674, decode.d4.loss_cls: 0.0022, decode.d4.loss_mask: 0.2503, decode.d4.loss_dice: 0.4744, decode.d5.loss_cls: 0.0014, decode.d5.loss_mask: 0.2501, decode.d5.loss_dice: 0.4744, decode.d6.loss_cls: 0.0012, decode.d6.loss_mask: 0.2496, decode.d6.loss_dice: 0.4646, decode.d7.loss_cls: 0.0012, decode.d7.loss_mask: 0.2487, decode.d7.loss_dice: 0.4651, decode.d8.loss_cls: 0.0012, decode.d8.loss_mask: 0.2481, decode.d8.loss_dice: 0.4721, loss: 10.8347\n",
      "2024-02-14 14:27:03,677 - mmseg - INFO - Iter [1380/80000]\tlr: 1.297e-06, eta: 2 days, 3:26:49, time: 2.132, data_time: 0.017, memory: 23505, decode.loss_cls: 0.0010, decode.loss_mask: 0.2662, decode.loss_dice: 0.5121, decode.d0.loss_cls: 3.5984, decode.d0.loss_mask: 0.2775, decode.d0.loss_dice: 0.5298, decode.d1.loss_cls: 0.0187, decode.d1.loss_mask: 0.2694, decode.d1.loss_dice: 0.5149, decode.d2.loss_cls: 0.0083, decode.d2.loss_mask: 0.2663, decode.d2.loss_dice: 0.5126, decode.d3.loss_cls: 0.0044, decode.d3.loss_mask: 0.2660, decode.d3.loss_dice: 0.5134, decode.d4.loss_cls: 0.0021, decode.d4.loss_mask: 0.2635, decode.d4.loss_dice: 0.5182, decode.d5.loss_cls: 0.0014, decode.d5.loss_mask: 0.2646, decode.d5.loss_dice: 0.5150, decode.d6.loss_cls: 0.0012, decode.d6.loss_mask: 0.2635, decode.d6.loss_dice: 0.5089, decode.d7.loss_cls: 0.0012, decode.d7.loss_mask: 0.2661, decode.d7.loss_dice: 0.5189, decode.d8.loss_cls: 0.0011, decode.d8.loss_mask: 0.2653, decode.d8.loss_dice: 0.5091, loss: 11.4593\n",
      "2024-02-14 14:27:24,975 - mmseg - INFO - Iter [1390/80000]\tlr: 1.306e-06, eta: 2 days, 3:24:18, time: 2.130, data_time: 0.017, memory: 23505, decode.loss_cls: 0.0010, decode.loss_mask: 0.2495, decode.loss_dice: 0.4804, decode.d0.loss_cls: 3.5915, decode.d0.loss_mask: 0.2565, decode.d0.loss_dice: 0.5064, decode.d1.loss_cls: 0.0216, decode.d1.loss_mask: 0.2489, decode.d1.loss_dice: 0.4937, decode.d2.loss_cls: 0.0094, decode.d2.loss_mask: 0.2427, decode.d2.loss_dice: 0.4840, decode.d3.loss_cls: 0.0048, decode.d3.loss_mask: 0.2454, decode.d3.loss_dice: 0.4837, decode.d4.loss_cls: 0.0024, decode.d4.loss_mask: 0.2461, decode.d4.loss_dice: 0.4873, decode.d5.loss_cls: 0.0015, decode.d5.loss_mask: 0.2462, decode.d5.loss_dice: 0.4813, decode.d6.loss_cls: 0.0012, decode.d6.loss_mask: 0.2453, decode.d6.loss_dice: 0.4820, decode.d7.loss_cls: 0.0012, decode.d7.loss_mask: 0.2461, decode.d7.loss_dice: 0.4781, decode.d8.loss_cls: 0.0012, decode.d8.loss_mask: 0.2480, decode.d8.loss_dice: 0.4855, loss: 10.9730\n",
      "2024-02-14 14:27:46,291 - mmseg - INFO - Iter [1400/80000]\tlr: 1.316e-06, eta: 2 days, 3:21:49, time: 2.132, data_time: 0.017, memory: 23505, decode.loss_cls: 0.0009, decode.loss_mask: 0.2505, decode.loss_dice: 0.4881, decode.d0.loss_cls: 3.5827, decode.d0.loss_mask: 0.2661, decode.d0.loss_dice: 0.5095, decode.d1.loss_cls: 0.0196, decode.d1.loss_mask: 0.2566, decode.d1.loss_dice: 0.4960, decode.d2.loss_cls: 0.0086, decode.d2.loss_mask: 0.2608, decode.d2.loss_dice: 0.4896, decode.d3.loss_cls: 0.0039, decode.d3.loss_mask: 0.2585, decode.d3.loss_dice: 0.4932, decode.d4.loss_cls: 0.0019, decode.d4.loss_mask: 0.2581, decode.d4.loss_dice: 0.4908, decode.d5.loss_cls: 0.0013, decode.d5.loss_mask: 0.2534, decode.d5.loss_dice: 0.4882, decode.d6.loss_cls: 0.0011, decode.d6.loss_mask: 0.2554, decode.d6.loss_dice: 0.4927, decode.d7.loss_cls: 0.0011, decode.d7.loss_mask: 0.2563, decode.d7.loss_dice: 0.4944, decode.d8.loss_cls: 0.0011, decode.d8.loss_mask: 0.2561, decode.d8.loss_dice: 0.4905, loss: 11.1272\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 40/40, 6.2 task/s, elapsed: 6s, ETA:     0s\n",
      "\n",
      "2024-02-14 14:27:52,735 - mmseg - INFO - per class results:\n",
      "2024-02-14 14:27:52,736 - mmseg - INFO - \n",
      "+---------------+-------+-------+\n",
      "|     Class     |  IoU  |  Acc  |\n",
      "+---------------+-------+-------+\n",
      "|       bg      | 97.42 | 98.54 |\n",
      "|    Anchovy    | 80.16 | 92.53 |\n",
      "|     Olives    | 87.11 | 90.87 |\n",
      "|     Salami    | 69.48 | 84.78 |\n",
      "|   Red_Pepper  | 87.67 | 93.47 |\n",
      "| Yellow_Pepper |  86.0 | 93.67 |\n",
      "+---------------+-------+-------+\n",
      "2024-02-14 14:27:52,736 - mmseg - INFO - Summary:\n",
      "2024-02-14 14:27:52,736 - mmseg - INFO - \n",
      "+-------+-------+-------+\n",
      "|  aAcc |  mIoU |  mAcc |\n",
      "+-------+-------+-------+\n",
      "| 97.47 | 84.64 | 92.31 |\n",
      "+-------+-------+-------+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-14 14:27:53,237 - mmseg - INFO - The previous best checkpoint /workspace/ViT-Adapter/segmentation/work_dirs/pizze_training_large/best_mIoU_iter_1200.pth was removed\n",
      "2024-02-14 14:28:06,680 - mmseg - INFO - Now best checkpoint is saved as best_mIoU_iter_1400.pth.\n",
      "2024-02-14 14:28:06,681 - mmseg - INFO - Best mIoU is 0.8464 at 1400 iter.\n",
      "2024-02-14 14:28:06,681 - mmseg - INFO - Iter(val) [10]\taAcc: 0.9747, mIoU: 0.8464, mAcc: 0.9231, IoU.bg: 0.9742, IoU.Anchovy: 0.8016, IoU.Olives: 0.8711, IoU.Salami: 0.6948, IoU.Red_Pepper: 0.8767, IoU.Yellow_Pepper: 0.8600, Acc.bg: 0.9854, Acc.Anchovy: 0.9253, Acc.Olives: 0.9087, Acc.Salami: 0.8478, Acc.Red_Pepper: 0.9347, Acc.Yellow_Pepper: 0.9367\n",
      "2024-02-14 14:28:27,967 - mmseg - INFO - Iter [1410/80000]\tlr: 1.325e-06, eta: 2 days, 3:38:17, time: 4.168, data_time: 2.056, memory: 23505, decode.loss_cls: 0.0009, decode.loss_mask: 0.2473, decode.loss_dice: 0.5040, decode.d0.loss_cls: 3.5777, decode.d0.loss_mask: 0.2588, decode.d0.loss_dice: 0.5119, decode.d1.loss_cls: 0.0175, decode.d1.loss_mask: 0.2518, decode.d1.loss_dice: 0.4984, decode.d2.loss_cls: 0.0079, decode.d2.loss_mask: 0.2508, decode.d2.loss_dice: 0.5053, decode.d3.loss_cls: 0.0038, decode.d3.loss_mask: 0.2496, decode.d3.loss_dice: 0.5038, decode.d4.loss_cls: 0.0019, decode.d4.loss_mask: 0.2499, decode.d4.loss_dice: 0.5052, decode.d5.loss_cls: 0.0013, decode.d5.loss_mask: 0.2496, decode.d5.loss_dice: 0.5072, decode.d6.loss_cls: 0.0011, decode.d6.loss_mask: 0.2520, decode.d6.loss_dice: 0.5075, decode.d7.loss_cls: 0.0011, decode.d7.loss_mask: 0.2503, decode.d7.loss_dice: 0.5108, decode.d8.loss_cls: 0.0011, decode.d8.loss_mask: 0.2472, decode.d8.loss_dice: 0.4990, loss: 11.1746\n",
      "2024-02-14 14:28:49,244 - mmseg - INFO - Iter [1420/80000]\tlr: 1.334e-06, eta: 2 days, 3:35:42, time: 2.128, data_time: 0.017, memory: 23505, decode.loss_cls: 0.0010, decode.loss_mask: 0.2760, decode.loss_dice: 0.5158, decode.d0.loss_cls: 3.5709, decode.d0.loss_mask: 0.2838, decode.d0.loss_dice: 0.5324, decode.d1.loss_cls: 0.0178, decode.d1.loss_mask: 0.2736, decode.d1.loss_dice: 0.5173, decode.d2.loss_cls: 0.0082, decode.d2.loss_mask: 0.2718, decode.d2.loss_dice: 0.5121, decode.d3.loss_cls: 0.0043, decode.d3.loss_mask: 0.2723, decode.d3.loss_dice: 0.5215, decode.d4.loss_cls: 0.0020, decode.d4.loss_mask: 0.2729, decode.d4.loss_dice: 0.5141, decode.d5.loss_cls: 0.0013, decode.d5.loss_mask: 0.2729, decode.d5.loss_dice: 0.5161, decode.d6.loss_cls: 0.0012, decode.d6.loss_mask: 0.2740, decode.d6.loss_dice: 0.5126, decode.d7.loss_cls: 0.0011, decode.d7.loss_mask: 0.2746, decode.d7.loss_dice: 0.5054, decode.d8.loss_cls: 0.0011, decode.d8.loss_mask: 0.2730, decode.d8.loss_dice: 0.5135, loss: 11.5146\n",
      "2024-02-14 14:29:10,551 - mmseg - INFO - Iter [1430/80000]\tlr: 1.343e-06, eta: 2 days, 3:33:10, time: 2.131, data_time: 0.017, memory: 23505, decode.loss_cls: 0.0009, decode.loss_mask: 0.2675, decode.loss_dice: 0.5250, decode.d0.loss_cls: 3.5650, decode.d0.loss_mask: 0.2759, decode.d0.loss_dice: 0.5291, decode.d1.loss_cls: 0.0163, decode.d1.loss_mask: 0.2704, decode.d1.loss_dice: 0.5307, decode.d2.loss_cls: 0.0073, decode.d2.loss_mask: 0.2681, decode.d2.loss_dice: 0.5237, decode.d3.loss_cls: 0.0039, decode.d3.loss_mask: 0.2701, decode.d3.loss_dice: 0.5259, decode.d4.loss_cls: 0.0020, decode.d4.loss_mask: 0.2681, decode.d4.loss_dice: 0.5207, decode.d5.loss_cls: 0.0013, decode.d5.loss_mask: 0.2671, decode.d5.loss_dice: 0.5216, decode.d6.loss_cls: 0.0011, decode.d6.loss_mask: 0.2663, decode.d6.loss_dice: 0.5261, decode.d7.loss_cls: 0.0011, decode.d7.loss_mask: 0.2645, decode.d7.loss_dice: 0.5216, decode.d8.loss_cls: 0.0011, decode.d8.loss_mask: 0.2676, decode.d8.loss_dice: 0.5247, loss: 11.5344\n",
      "2024-02-14 14:29:31,857 - mmseg - INFO - Iter [1440/80000]\tlr: 1.353e-06, eta: 2 days, 3:30:40, time: 2.131, data_time: 0.017, memory: 23505, decode.loss_cls: 0.0010, decode.loss_mask: 0.2885, decode.loss_dice: 0.5094, decode.d0.loss_cls: 3.5571, decode.d0.loss_mask: 0.2880, decode.d0.loss_dice: 0.5327, decode.d1.loss_cls: 0.0181, decode.d1.loss_mask: 0.2847, decode.d1.loss_dice: 0.5155, decode.d2.loss_cls: 0.0078, decode.d2.loss_mask: 0.2867, decode.d2.loss_dice: 0.5182, decode.d3.loss_cls: 0.0042, decode.d3.loss_mask: 0.2855, decode.d3.loss_dice: 0.5059, decode.d4.loss_cls: 0.0022, decode.d4.loss_mask: 0.2840, decode.d4.loss_dice: 0.5061, decode.d5.loss_cls: 0.0014, decode.d5.loss_mask: 0.2896, decode.d5.loss_dice: 0.5088, decode.d6.loss_cls: 0.0012, decode.d6.loss_mask: 0.2891, decode.d6.loss_dice: 0.5039, decode.d7.loss_cls: 0.0012, decode.d7.loss_mask: 0.2886, decode.d7.loss_dice: 0.5087, decode.d8.loss_cls: 0.0012, decode.d8.loss_mask: 0.2817, decode.d8.loss_dice: 0.5034, loss: 11.5742\n",
      "2024-02-14 14:29:53,171 - mmseg - INFO - Iter [1450/80000]\tlr: 1.362e-06, eta: 2 days, 3:28:13, time: 2.131, data_time: 0.016, memory: 23505, decode.loss_cls: 0.0010, decode.loss_mask: 0.2642, decode.loss_dice: 0.5471, decode.d0.loss_cls: 3.5490, decode.d0.loss_mask: 0.2756, decode.d0.loss_dice: 0.5540, decode.d1.loss_cls: 0.0197, decode.d1.loss_mask: 0.2681, decode.d1.loss_dice: 0.5443, decode.d2.loss_cls: 0.0090, decode.d2.loss_mask: 0.2641, decode.d2.loss_dice: 0.5461, decode.d3.loss_cls: 0.0041, decode.d3.loss_mask: 0.2643, decode.d3.loss_dice: 0.5435, decode.d4.loss_cls: 0.0020, decode.d4.loss_mask: 0.2665, decode.d4.loss_dice: 0.5528, decode.d5.loss_cls: 0.0014, decode.d5.loss_mask: 0.2646, decode.d5.loss_dice: 0.5468, decode.d6.loss_cls: 0.0012, decode.d6.loss_mask: 0.2637, decode.d6.loss_dice: 0.5455, decode.d7.loss_cls: 0.0012, decode.d7.loss_mask: 0.2645, decode.d7.loss_dice: 0.5487, decode.d8.loss_cls: 0.0011, decode.d8.loss_mask: 0.2623, decode.d8.loss_dice: 0.5430, loss: 11.7194\n",
      "2024-02-14 14:30:14,486 - mmseg - INFO - Iter [1460/80000]\tlr: 1.371e-06, eta: 2 days, 3:25:47, time: 2.131, data_time: 0.017, memory: 23505, decode.loss_cls: 0.0010, decode.loss_mask: 0.2252, decode.loss_dice: 0.4625, decode.d0.loss_cls: 3.5399, decode.d0.loss_mask: 0.2325, decode.d0.loss_dice: 0.4723, decode.d1.loss_cls: 0.0300, decode.d1.loss_mask: 0.2290, decode.d1.loss_dice: 0.4619, decode.d2.loss_cls: 0.0110, decode.d2.loss_mask: 0.2255, decode.d2.loss_dice: 0.4631, decode.d3.loss_cls: 0.0042, decode.d3.loss_mask: 0.2249, decode.d3.loss_dice: 0.4572, decode.d4.loss_cls: 0.0021, decode.d4.loss_mask: 0.2225, decode.d4.loss_dice: 0.4563, decode.d5.loss_cls: 0.0018, decode.d5.loss_mask: 0.2229, decode.d5.loss_dice: 0.4578, decode.d6.loss_cls: 0.0015, decode.d6.loss_mask: 0.2214, decode.d6.loss_dice: 0.4590, decode.d7.loss_cls: 0.0013, decode.d7.loss_mask: 0.2225, decode.d7.loss_dice: 0.4618, decode.d8.loss_cls: 0.0012, decode.d8.loss_mask: 0.2245, decode.d8.loss_dice: 0.4559, loss: 10.4526\n",
      "2024-02-14 14:30:35,811 - mmseg - INFO - Iter [1470/80000]\tlr: 1.380e-06, eta: 2 days, 3:23:23, time: 2.132, data_time: 0.016, memory: 23505, decode.loss_cls: 0.0010, decode.loss_mask: 0.2393, decode.loss_dice: 0.4878, decode.d0.loss_cls: 3.5343, decode.d0.loss_mask: 0.2525, decode.d0.loss_dice: 0.4950, decode.d1.loss_cls: 0.0168, decode.d1.loss_mask: 0.2461, decode.d1.loss_dice: 0.4878, decode.d2.loss_cls: 0.0068, decode.d2.loss_mask: 0.2431, decode.d2.loss_dice: 0.4910, decode.d3.loss_cls: 0.0037, decode.d3.loss_mask: 0.2445, decode.d3.loss_dice: 0.4932, decode.d4.loss_cls: 0.0017, decode.d4.loss_mask: 0.2402, decode.d4.loss_dice: 0.4899, decode.d5.loss_cls: 0.0013, decode.d5.loss_mask: 0.2420, decode.d5.loss_dice: 0.4933, decode.d6.loss_cls: 0.0012, decode.d6.loss_mask: 0.2379, decode.d6.loss_dice: 0.4819, decode.d7.loss_cls: 0.0011, decode.d7.loss_mask: 0.2415, decode.d7.loss_dice: 0.4913, decode.d8.loss_cls: 0.0011, decode.d8.loss_mask: 0.2391, decode.d8.loss_dice: 0.4873, loss: 10.8936\n",
      "2024-02-14 14:30:57,124 - mmseg - INFO - Iter [1480/80000]\tlr: 1.390e-06, eta: 2 days, 3:21:00, time: 2.131, data_time: 0.017, memory: 23505, decode.loss_cls: 0.0009, decode.loss_mask: 0.2165, decode.loss_dice: 0.4395, decode.d0.loss_cls: 3.5250, decode.d0.loss_mask: 0.2230, decode.d0.loss_dice: 0.4562, decode.d1.loss_cls: 0.0173, decode.d1.loss_mask: 0.2123, decode.d1.loss_dice: 0.4347, decode.d2.loss_cls: 0.0071, decode.d2.loss_mask: 0.2145, decode.d2.loss_dice: 0.4475, decode.d3.loss_cls: 0.0034, decode.d3.loss_mask: 0.2127, decode.d3.loss_dice: 0.4331, decode.d4.loss_cls: 0.0016, decode.d4.loss_mask: 0.2155, decode.d4.loss_dice: 0.4335, decode.d5.loss_cls: 0.0013, decode.d5.loss_mask: 0.2217, decode.d5.loss_dice: 0.4409, decode.d6.loss_cls: 0.0012, decode.d6.loss_mask: 0.2176, decode.d6.loss_dice: 0.4361, decode.d7.loss_cls: 0.0011, decode.d7.loss_mask: 0.2163, decode.d7.loss_dice: 0.4309, decode.d8.loss_cls: 0.0011, decode.d8.loss_mask: 0.2161, decode.d8.loss_dice: 0.4311, loss: 10.1099\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-14 14:31:18,442 - mmseg - INFO - Iter [1490/80000]\tlr: 1.399e-06, eta: 2 days, 3:18:40, time: 2.132, data_time: 0.017, memory: 23505, decode.loss_cls: 0.0009, decode.loss_mask: 0.2530, decode.loss_dice: 0.4828, decode.d0.loss_cls: 3.5225, decode.d0.loss_mask: 0.2624, decode.d0.loss_dice: 0.4948, decode.d1.loss_cls: 0.0157, decode.d1.loss_mask: 0.2538, decode.d1.loss_dice: 0.4883, decode.d2.loss_cls: 0.0064, decode.d2.loss_mask: 0.2546, decode.d2.loss_dice: 0.4915, decode.d3.loss_cls: 0.0038, decode.d3.loss_mask: 0.2533, decode.d3.loss_dice: 0.4891, decode.d4.loss_cls: 0.0018, decode.d4.loss_mask: 0.2555, decode.d4.loss_dice: 0.4937, decode.d5.loss_cls: 0.0013, decode.d5.loss_mask: 0.2529, decode.d5.loss_dice: 0.4891, decode.d6.loss_cls: 0.0012, decode.d6.loss_mask: 0.2550, decode.d6.loss_dice: 0.4849, decode.d7.loss_cls: 0.0012, decode.d7.loss_mask: 0.2568, decode.d7.loss_dice: 0.4896, decode.d8.loss_cls: 0.0011, decode.d8.loss_mask: 0.2548, decode.d8.loss_dice: 0.4853, loss: 10.9972\n",
      "2024-02-14 14:31:39,767 - mmseg - INFO - Iter [1500/80000]\tlr: 1.408e-06, eta: 2 days, 3:16:21, time: 2.132, data_time: 0.017, memory: 23505, decode.loss_cls: 0.0008, decode.loss_mask: 0.2195, decode.loss_dice: 0.4554, decode.d0.loss_cls: 3.5119, decode.d0.loss_mask: 0.2256, decode.d0.loss_dice: 0.4739, decode.d1.loss_cls: 0.0183, decode.d1.loss_mask: 0.2188, decode.d1.loss_dice: 0.4615, decode.d2.loss_cls: 0.0064, decode.d2.loss_mask: 0.2210, decode.d2.loss_dice: 0.4559, decode.d3.loss_cls: 0.0031, decode.d3.loss_mask: 0.2194, decode.d3.loss_dice: 0.4602, decode.d4.loss_cls: 0.0016, decode.d4.loss_mask: 0.2204, decode.d4.loss_dice: 0.4608, decode.d5.loss_cls: 0.0012, decode.d5.loss_mask: 0.2200, decode.d5.loss_dice: 0.4630, decode.d6.loss_cls: 0.0010, decode.d6.loss_mask: 0.2209, decode.d6.loss_dice: 0.4664, decode.d7.loss_cls: 0.0010, decode.d7.loss_mask: 0.2232, decode.d7.loss_dice: 0.4662, decode.d8.loss_cls: 0.0010, decode.d8.loss_mask: 0.2198, decode.d8.loss_dice: 0.4575, loss: 10.3758\n",
      "2024-02-14 14:32:01,079 - mmseg - INFO - Iter [1510/80000]\tlr: 1.409e-06, eta: 2 days, 3:14:03, time: 2.131, data_time: 0.017, memory: 23505, decode.loss_cls: 0.0009, decode.loss_mask: 0.2438, decode.loss_dice: 0.4520, decode.d0.loss_cls: 3.5066, decode.d0.loss_mask: 0.2437, decode.d0.loss_dice: 0.4651, decode.d1.loss_cls: 0.0194, decode.d1.loss_mask: 0.2456, decode.d1.loss_dice: 0.4597, decode.d2.loss_cls: 0.0070, decode.d2.loss_mask: 0.2418, decode.d2.loss_dice: 0.4520, decode.d3.loss_cls: 0.0035, decode.d3.loss_mask: 0.2437, decode.d3.loss_dice: 0.4509, decode.d4.loss_cls: 0.0018, decode.d4.loss_mask: 0.2436, decode.d4.loss_dice: 0.4543, decode.d5.loss_cls: 0.0013, decode.d5.loss_mask: 0.2421, decode.d5.loss_dice: 0.4501, decode.d6.loss_cls: 0.0011, decode.d6.loss_mask: 0.2423, decode.d6.loss_dice: 0.4532, decode.d7.loss_cls: 0.0011, decode.d7.loss_mask: 0.2390, decode.d7.loss_dice: 0.4546, decode.d8.loss_cls: 0.0010, decode.d8.loss_mask: 0.2424, decode.d8.loss_dice: 0.4506, loss: 10.5143\n",
      "2024-02-14 14:32:22,374 - mmseg - INFO - Iter [1520/80000]\tlr: 1.409e-06, eta: 2 days, 3:11:46, time: 2.130, data_time: 0.017, memory: 23505, decode.loss_cls: 0.0009, decode.loss_mask: 0.2357, decode.loss_dice: 0.4562, decode.d0.loss_cls: 3.4998, decode.d0.loss_mask: 0.2411, decode.d0.loss_dice: 0.4668, decode.d1.loss_cls: 0.0157, decode.d1.loss_mask: 0.2404, decode.d1.loss_dice: 0.4537, decode.d2.loss_cls: 0.0061, decode.d2.loss_mask: 0.2359, decode.d2.loss_dice: 0.4495, decode.d3.loss_cls: 0.0031, decode.d3.loss_mask: 0.2360, decode.d3.loss_dice: 0.4565, decode.d4.loss_cls: 0.0019, decode.d4.loss_mask: 0.2369, decode.d4.loss_dice: 0.4559, decode.d5.loss_cls: 0.0013, decode.d5.loss_mask: 0.2374, decode.d5.loss_dice: 0.4595, decode.d6.loss_cls: 0.0011, decode.d6.loss_mask: 0.2323, decode.d6.loss_dice: 0.4504, decode.d7.loss_cls: 0.0010, decode.d7.loss_mask: 0.2343, decode.d7.loss_dice: 0.4580, decode.d8.loss_cls: 0.0010, decode.d8.loss_mask: 0.2376, decode.d8.loss_dice: 0.4562, loss: 10.4621\n",
      "2024-02-14 14:32:43,676 - mmseg - INFO - Iter [1530/80000]\tlr: 1.408e-06, eta: 2 days, 3:09:30, time: 2.130, data_time: 0.016, memory: 23505, decode.loss_cls: 0.0008, decode.loss_mask: 0.2477, decode.loss_dice: 0.4849, decode.d0.loss_cls: 3.4943, decode.d0.loss_mask: 0.2557, decode.d0.loss_dice: 0.4995, decode.d1.loss_cls: 0.0181, decode.d1.loss_mask: 0.2518, decode.d1.loss_dice: 0.4875, decode.d2.loss_cls: 0.0067, decode.d2.loss_mask: 0.2447, decode.d2.loss_dice: 0.4807, decode.d3.loss_cls: 0.0033, decode.d3.loss_mask: 0.2463, decode.d3.loss_dice: 0.4870, decode.d4.loss_cls: 0.0020, decode.d4.loss_mask: 0.2462, decode.d4.loss_dice: 0.4825, decode.d5.loss_cls: 0.0013, decode.d5.loss_mask: 0.2471, decode.d5.loss_dice: 0.4842, decode.d6.loss_cls: 0.0010, decode.d6.loss_mask: 0.2505, decode.d6.loss_dice: 0.4854, decode.d7.loss_cls: 0.0010, decode.d7.loss_mask: 0.2492, decode.d7.loss_dice: 0.4813, decode.d8.loss_cls: 0.0010, decode.d8.loss_mask: 0.2460, decode.d8.loss_dice: 0.4822, loss: 10.8697\n",
      "2024-02-14 14:33:04,959 - mmseg - INFO - Iter [1540/80000]\tlr: 1.408e-06, eta: 2 days, 3:07:15, time: 2.128, data_time: 0.016, memory: 23505, decode.loss_cls: 0.0008, decode.loss_mask: 0.2062, decode.loss_dice: 0.4312, decode.d0.loss_cls: 3.4828, decode.d0.loss_mask: 0.2067, decode.d0.loss_dice: 0.4451, decode.d1.loss_cls: 0.0161, decode.d1.loss_mask: 0.2082, decode.d1.loss_dice: 0.4327, decode.d2.loss_cls: 0.0057, decode.d2.loss_mask: 0.2076, decode.d2.loss_dice: 0.4365, decode.d3.loss_cls: 0.0029, decode.d3.loss_mask: 0.2061, decode.d3.loss_dice: 0.4274, decode.d4.loss_cls: 0.0014, decode.d4.loss_mask: 0.2057, decode.d4.loss_dice: 0.4309, decode.d5.loss_cls: 0.0011, decode.d5.loss_mask: 0.2040, decode.d5.loss_dice: 0.4284, decode.d6.loss_cls: 0.0009, decode.d6.loss_mask: 0.2057, decode.d6.loss_dice: 0.4334, decode.d7.loss_cls: 0.0009, decode.d7.loss_mask: 0.2069, decode.d7.loss_dice: 0.4327, decode.d8.loss_cls: 0.0009, decode.d8.loss_mask: 0.2087, decode.d8.loss_dice: 0.4337, loss: 9.9112\n",
      "2024-02-14 14:33:26,251 - mmseg - INFO - Iter [1550/80000]\tlr: 1.408e-06, eta: 2 days, 3:05:02, time: 2.129, data_time: 0.016, memory: 23505, decode.loss_cls: 0.0009, decode.loss_mask: 0.2563, decode.loss_dice: 0.4761, decode.d0.loss_cls: 3.4771, decode.d0.loss_mask: 0.2677, decode.d0.loss_dice: 0.4979, decode.d1.loss_cls: 0.0202, decode.d1.loss_mask: 0.2592, decode.d1.loss_dice: 0.4832, decode.d2.loss_cls: 0.0075, decode.d2.loss_mask: 0.2588, decode.d2.loss_dice: 0.4810, decode.d3.loss_cls: 0.0038, decode.d3.loss_mask: 0.2580, decode.d3.loss_dice: 0.4773, decode.d4.loss_cls: 0.0017, decode.d4.loss_mask: 0.2557, decode.d4.loss_dice: 0.4805, decode.d5.loss_cls: 0.0012, decode.d5.loss_mask: 0.2570, decode.d5.loss_dice: 0.4773, decode.d6.loss_cls: 0.0011, decode.d6.loss_mask: 0.2549, decode.d6.loss_dice: 0.4752, decode.d7.loss_cls: 0.0010, decode.d7.loss_mask: 0.2543, decode.d7.loss_dice: 0.4757, decode.d8.loss_cls: 0.0010, decode.d8.loss_mask: 0.2540, decode.d8.loss_dice: 0.4777, loss: 10.8931\n",
      "2024-02-14 14:33:47,541 - mmseg - INFO - Iter [1560/80000]\tlr: 1.408e-06, eta: 2 days, 3:02:51, time: 2.129, data_time: 0.016, memory: 23505, decode.loss_cls: 0.0007, decode.loss_mask: 0.2583, decode.loss_dice: 0.4806, decode.d0.loss_cls: 3.4702, decode.d0.loss_mask: 0.2672, decode.d0.loss_dice: 0.4860, decode.d1.loss_cls: 0.0174, decode.d1.loss_mask: 0.2574, decode.d1.loss_dice: 0.4813, decode.d2.loss_cls: 0.0058, decode.d2.loss_mask: 0.2566, decode.d2.loss_dice: 0.4778, decode.d3.loss_cls: 0.0029, decode.d3.loss_mask: 0.2561, decode.d3.loss_dice: 0.4811, decode.d4.loss_cls: 0.0014, decode.d4.loss_mask: 0.2598, decode.d4.loss_dice: 0.4779, decode.d5.loss_cls: 0.0010, decode.d5.loss_mask: 0.2584, decode.d5.loss_dice: 0.4850, decode.d6.loss_cls: 0.0009, decode.d6.loss_mask: 0.2590, decode.d6.loss_dice: 0.4766, decode.d7.loss_cls: 0.0008, decode.d7.loss_mask: 0.2586, decode.d7.loss_dice: 0.4807, decode.d8.loss_cls: 0.0008, decode.d8.loss_mask: 0.2579, decode.d8.loss_dice: 0.4808, loss: 10.8991\n",
      "2024-02-14 14:34:08,887 - mmseg - INFO - Iter [1570/80000]\tlr: 1.408e-06, eta: 2 days, 3:00:43, time: 2.135, data_time: 0.017, memory: 23505, decode.loss_cls: 0.0008, decode.loss_mask: 0.2729, decode.loss_dice: 0.5158, decode.d0.loss_cls: 3.4687, decode.d0.loss_mask: 0.2857, decode.d0.loss_dice: 0.5296, decode.d1.loss_cls: 0.0133, decode.d1.loss_mask: 0.2761, decode.d1.loss_dice: 0.5170, decode.d2.loss_cls: 0.0054, decode.d2.loss_mask: 0.2762, decode.d2.loss_dice: 0.5163, decode.d3.loss_cls: 0.0032, decode.d3.loss_mask: 0.2737, decode.d3.loss_dice: 0.5193, decode.d4.loss_cls: 0.0018, decode.d4.loss_mask: 0.2727, decode.d4.loss_dice: 0.5124, decode.d5.loss_cls: 0.0011, decode.d5.loss_mask: 0.2781, decode.d5.loss_dice: 0.5190, decode.d6.loss_cls: 0.0010, decode.d6.loss_mask: 0.2747, decode.d6.loss_dice: 0.5095, decode.d7.loss_cls: 0.0009, decode.d7.loss_mask: 0.2718, decode.d7.loss_dice: 0.5159, decode.d8.loss_cls: 0.0009, decode.d8.loss_mask: 0.2731, decode.d8.loss_dice: 0.5086, loss: 11.4155\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-14 14:34:30,245 - mmseg - INFO - Iter [1580/80000]\tlr: 1.407e-06, eta: 2 days, 2:58:38, time: 2.136, data_time: 0.016, memory: 23505, decode.loss_cls: 0.0016, decode.loss_mask: 0.2312, decode.loss_dice: 0.4411, decode.d0.loss_cls: 3.4531, decode.d0.loss_mask: 0.2269, decode.d0.loss_dice: 0.4567, decode.d1.loss_cls: 0.0183, decode.d1.loss_mask: 0.2239, decode.d1.loss_dice: 0.4440, decode.d2.loss_cls: 0.0060, decode.d2.loss_mask: 0.2233, decode.d2.loss_dice: 0.4426, decode.d3.loss_cls: 0.0031, decode.d3.loss_mask: 0.2255, decode.d3.loss_dice: 0.4421, decode.d4.loss_cls: 0.0022, decode.d4.loss_mask: 0.2278, decode.d4.loss_dice: 0.4417, decode.d5.loss_cls: 0.0019, decode.d5.loss_mask: 0.2257, decode.d5.loss_dice: 0.4346, decode.d6.loss_cls: 0.0017, decode.d6.loss_mask: 0.2302, decode.d6.loss_dice: 0.4455, decode.d7.loss_cls: 0.0017, decode.d7.loss_mask: 0.2314, decode.d7.loss_dice: 0.4432, decode.d8.loss_cls: 0.0017, decode.d8.loss_mask: 0.2283, decode.d8.loss_dice: 0.4430, loss: 10.2000\n",
      "2024-02-14 14:34:51,564 - mmseg - INFO - Iter [1590/80000]\tlr: 1.407e-06, eta: 2 days, 2:56:31, time: 2.132, data_time: 0.017, memory: 23505, decode.loss_cls: 0.0007, decode.loss_mask: 0.2230, decode.loss_dice: 0.4620, decode.d0.loss_cls: 3.4476, decode.d0.loss_mask: 0.2314, decode.d0.loss_dice: 0.4754, decode.d1.loss_cls: 0.0173, decode.d1.loss_mask: 0.2284, decode.d1.loss_dice: 0.4608, decode.d2.loss_cls: 0.0054, decode.d2.loss_mask: 0.2264, decode.d2.loss_dice: 0.4589, decode.d3.loss_cls: 0.0026, decode.d3.loss_mask: 0.2256, decode.d3.loss_dice: 0.4602, decode.d4.loss_cls: 0.0015, decode.d4.loss_mask: 0.2257, decode.d4.loss_dice: 0.4614, decode.d5.loss_cls: 0.0010, decode.d5.loss_mask: 0.2249, decode.d5.loss_dice: 0.4611, decode.d6.loss_cls: 0.0009, decode.d6.loss_mask: 0.2280, decode.d6.loss_dice: 0.4620, decode.d7.loss_cls: 0.0008, decode.d7.loss_mask: 0.2256, decode.d7.loss_dice: 0.4641, decode.d8.loss_cls: 0.0008, decode.d8.loss_mask: 0.2252, decode.d8.loss_dice: 0.4637, loss: 10.3726\n",
      "2024-02-14 14:35:12,864 - mmseg - INFO - Iter [1600/80000]\tlr: 1.407e-06, eta: 2 days, 2:54:26, time: 2.130, data_time: 0.017, memory: 23505, decode.loss_cls: 0.0007, decode.loss_mask: 0.2398, decode.loss_dice: 0.4454, decode.d0.loss_cls: 3.4414, decode.d0.loss_mask: 0.2493, decode.d0.loss_dice: 0.4618, decode.d1.loss_cls: 0.0241, decode.d1.loss_mask: 0.2444, decode.d1.loss_dice: 0.4411, decode.d2.loss_cls: 0.0075, decode.d2.loss_mask: 0.2443, decode.d2.loss_dice: 0.4483, decode.d3.loss_cls: 0.0034, decode.d3.loss_mask: 0.2405, decode.d3.loss_dice: 0.4421, decode.d4.loss_cls: 0.0015, decode.d4.loss_mask: 0.2395, decode.d4.loss_dice: 0.4410, decode.d5.loss_cls: 0.0010, decode.d5.loss_mask: 0.2389, decode.d5.loss_dice: 0.4429, decode.d6.loss_cls: 0.0009, decode.d6.loss_mask: 0.2388, decode.d6.loss_dice: 0.4453, decode.d7.loss_cls: 0.0009, decode.d7.loss_mask: 0.2376, decode.d7.loss_dice: 0.4410, decode.d8.loss_cls: 0.0009, decode.d8.loss_mask: 0.2413, decode.d8.loss_dice: 0.4450, loss: 10.3507\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 40/40, 6.2 task/s, elapsed: 6s, ETA:     0s\n",
      "\n",
      "2024-02-14 14:35:19,302 - mmseg - INFO - per class results:\n",
      "2024-02-14 14:35:19,302 - mmseg - INFO - \n",
      "+---------------+-------+-------+\n",
      "|     Class     |  IoU  |  Acc  |\n",
      "+---------------+-------+-------+\n",
      "|       bg      | 97.42 | 98.36 |\n",
      "|    Anchovy    | 79.67 | 93.84 |\n",
      "|     Olives    | 86.98 | 91.07 |\n",
      "|     Salami    | 70.36 | 87.49 |\n",
      "|   Red_Pepper  | 87.79 | 93.96 |\n",
      "| Yellow_Pepper | 85.98 | 94.72 |\n",
      "+---------------+-------+-------+\n",
      "2024-02-14 14:35:19,302 - mmseg - INFO - Summary:\n",
      "2024-02-14 14:35:19,303 - mmseg - INFO - \n",
      "+-------+------+-------+\n",
      "|  aAcc | mIoU |  mAcc |\n",
      "+-------+------+-------+\n",
      "| 97.47 | 84.7 | 93.24 |\n",
      "+-------+------+-------+\n",
      "2024-02-14 14:35:19,807 - mmseg - INFO - The previous best checkpoint /workspace/ViT-Adapter/segmentation/work_dirs/pizze_training_large/best_mIoU_iter_1400.pth was removed\n",
      "2024-02-14 14:35:32,965 - mmseg - INFO - Now best checkpoint is saved as best_mIoU_iter_1600.pth.\n",
      "2024-02-14 14:35:32,966 - mmseg - INFO - Best mIoU is 0.8470 at 1600 iter.\n",
      "2024-02-14 14:35:32,966 - mmseg - INFO - Iter(val) [10]\taAcc: 0.9747, mIoU: 0.8470, mAcc: 0.9324, IoU.bg: 0.9742, IoU.Anchovy: 0.7967, IoU.Olives: 0.8698, IoU.Salami: 0.7036, IoU.Red_Pepper: 0.8779, IoU.Yellow_Pepper: 0.8598, Acc.bg: 0.9836, Acc.Anchovy: 0.9384, Acc.Olives: 0.9107, Acc.Salami: 0.8749, Acc.Red_Pepper: 0.9396, Acc.Yellow_Pepper: 0.9472\n",
      "2024-02-14 14:35:56,304 - mmseg - INFO - Iter [1610/80000]\tlr: 1.407e-06, eta: 2 days, 3:10:19, time: 4.344, data_time: 2.233, memory: 23505, decode.loss_cls: 0.0008, decode.loss_mask: 0.2503, decode.loss_dice: 0.4964, decode.d0.loss_cls: 3.4344, decode.d0.loss_mask: 0.2592, decode.d0.loss_dice: 0.5176, decode.d1.loss_cls: 0.0167, decode.d1.loss_mask: 0.2508, decode.d1.loss_dice: 0.4993, decode.d2.loss_cls: 0.0057, decode.d2.loss_mask: 0.2478, decode.d2.loss_dice: 0.5001, decode.d3.loss_cls: 0.0030, decode.d3.loss_mask: 0.2465, decode.d3.loss_dice: 0.4921, decode.d4.loss_cls: 0.0015, decode.d4.loss_mask: 0.2499, decode.d4.loss_dice: 0.4957, decode.d5.loss_cls: 0.0011, decode.d5.loss_mask: 0.2509, decode.d5.loss_dice: 0.4939, decode.d6.loss_cls: 0.0009, decode.d6.loss_mask: 0.2501, decode.d6.loss_dice: 0.5011, decode.d7.loss_cls: 0.0009, decode.d7.loss_mask: 0.2518, decode.d7.loss_dice: 0.4984, decode.d8.loss_cls: 0.0009, decode.d8.loss_mask: 0.2514, decode.d8.loss_dice: 0.5010, loss: 10.9702\n",
      "2024-02-14 14:36:17,586 - mmseg - INFO - Iter [1620/80000]\tlr: 1.407e-06, eta: 2 days, 3:08:08, time: 2.128, data_time: 0.017, memory: 23505, decode.loss_cls: 0.0007, decode.loss_mask: 0.2097, decode.loss_dice: 0.4190, decode.d0.loss_cls: 3.4256, decode.d0.loss_mask: 0.2117, decode.d0.loss_dice: 0.4317, decode.d1.loss_cls: 0.0158, decode.d1.loss_mask: 0.2093, decode.d1.loss_dice: 0.4196, decode.d2.loss_cls: 0.0050, decode.d2.loss_mask: 0.2094, decode.d2.loss_dice: 0.4219, decode.d3.loss_cls: 0.0026, decode.d3.loss_mask: 0.2109, decode.d3.loss_dice: 0.4216, decode.d4.loss_cls: 0.0013, decode.d4.loss_mask: 0.2098, decode.d4.loss_dice: 0.4219, decode.d5.loss_cls: 0.0009, decode.d5.loss_mask: 0.2126, decode.d5.loss_dice: 0.4158, decode.d6.loss_cls: 0.0008, decode.d6.loss_mask: 0.2118, decode.d6.loss_dice: 0.4205, decode.d7.loss_cls: 0.0008, decode.d7.loss_mask: 0.2106, decode.d7.loss_dice: 0.4240, decode.d8.loss_cls: 0.0008, decode.d8.loss_mask: 0.2104, decode.d8.loss_dice: 0.4214, loss: 9.7784\n",
      "2024-02-14 14:36:38,865 - mmseg - INFO - Iter [1630/80000]\tlr: 1.407e-06, eta: 2 days, 3:05:59, time: 2.128, data_time: 0.016, memory: 23505, decode.loss_cls: 0.0007, decode.loss_mask: 0.2282, decode.loss_dice: 0.4625, decode.d0.loss_cls: 3.4192, decode.d0.loss_mask: 0.2359, decode.d0.loss_dice: 0.4704, decode.d1.loss_cls: 0.0141, decode.d1.loss_mask: 0.2296, decode.d1.loss_dice: 0.4627, decode.d2.loss_cls: 0.0047, decode.d2.loss_mask: 0.2281, decode.d2.loss_dice: 0.4553, decode.d3.loss_cls: 0.0029, decode.d3.loss_mask: 0.2285, decode.d3.loss_dice: 0.4589, decode.d4.loss_cls: 0.0013, decode.d4.loss_mask: 0.2245, decode.d4.loss_dice: 0.4587, decode.d5.loss_cls: 0.0009, decode.d5.loss_mask: 0.2293, decode.d5.loss_dice: 0.4645, decode.d6.loss_cls: 0.0008, decode.d6.loss_mask: 0.2278, decode.d6.loss_dice: 0.4612, decode.d7.loss_cls: 0.0008, decode.d7.loss_mask: 0.2293, decode.d7.loss_dice: 0.4675, decode.d8.loss_cls: 0.0008, decode.d8.loss_mask: 0.2278, decode.d8.loss_dice: 0.4588, loss: 10.3559\n",
      "2024-02-14 14:37:00,145 - mmseg - INFO - Iter [1640/80000]\tlr: 1.406e-06, eta: 2 days, 3:03:51, time: 2.128, data_time: 0.017, memory: 23505, decode.loss_cls: 0.0009, decode.loss_mask: 0.2449, decode.loss_dice: 0.4647, decode.d0.loss_cls: 3.4132, decode.d0.loss_mask: 0.2594, decode.d0.loss_dice: 0.4828, decode.d1.loss_cls: 0.0147, decode.d1.loss_mask: 0.2482, decode.d1.loss_dice: 0.4681, decode.d2.loss_cls: 0.0053, decode.d2.loss_mask: 0.2454, decode.d2.loss_dice: 0.4625, decode.d3.loss_cls: 0.0035, decode.d3.loss_mask: 0.2470, decode.d3.loss_dice: 0.4644, decode.d4.loss_cls: 0.0017, decode.d4.loss_mask: 0.2437, decode.d4.loss_dice: 0.4683, decode.d5.loss_cls: 0.0012, decode.d5.loss_mask: 0.2458, decode.d5.loss_dice: 0.4671, decode.d6.loss_cls: 0.0010, decode.d6.loss_mask: 0.2445, decode.d6.loss_dice: 0.4634, decode.d7.loss_cls: 0.0010, decode.d7.loss_mask: 0.2426, decode.d7.loss_dice: 0.4639, decode.d8.loss_cls: 0.0010, decode.d8.loss_mask: 0.2452, decode.d8.loss_dice: 0.4662, loss: 10.5815\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-14 14:37:21,448 - mmseg - INFO - Iter [1650/80000]\tlr: 1.406e-06, eta: 2 days, 3:01:44, time: 2.130, data_time: 0.016, memory: 23505, decode.loss_cls: 0.0007, decode.loss_mask: 0.2321, decode.loss_dice: 0.4341, decode.d0.loss_cls: 3.4037, decode.d0.loss_mask: 0.2370, decode.d0.loss_dice: 0.4549, decode.d1.loss_cls: 0.0153, decode.d1.loss_mask: 0.2342, decode.d1.loss_dice: 0.4366, decode.d2.loss_cls: 0.0047, decode.d2.loss_mask: 0.2337, decode.d2.loss_dice: 0.4369, decode.d3.loss_cls: 0.0030, decode.d3.loss_mask: 0.2326, decode.d3.loss_dice: 0.4344, decode.d4.loss_cls: 0.0013, decode.d4.loss_mask: 0.2319, decode.d4.loss_dice: 0.4406, decode.d5.loss_cls: 0.0010, decode.d5.loss_mask: 0.2343, decode.d5.loss_dice: 0.4381, decode.d6.loss_cls: 0.0009, decode.d6.loss_mask: 0.2324, decode.d6.loss_dice: 0.4376, decode.d7.loss_cls: 0.0009, decode.d7.loss_mask: 0.2323, decode.d7.loss_dice: 0.4436, decode.d8.loss_cls: 0.0009, decode.d8.loss_mask: 0.2351, decode.d8.loss_dice: 0.4406, loss: 10.1654\n",
      "2024-02-14 14:37:42,725 - mmseg - INFO - Iter [1660/80000]\tlr: 1.406e-06, eta: 2 days, 2:59:39, time: 2.128, data_time: 0.017, memory: 23505, decode.loss_cls: 0.0007, decode.loss_mask: 0.2668, decode.loss_dice: 0.4895, decode.d0.loss_cls: 3.3973, decode.d0.loss_mask: 0.2684, decode.d0.loss_dice: 0.5011, decode.d1.loss_cls: 0.0132, decode.d1.loss_mask: 0.2650, decode.d1.loss_dice: 0.4946, decode.d2.loss_cls: 0.0046, decode.d2.loss_mask: 0.2648, decode.d2.loss_dice: 0.4875, decode.d3.loss_cls: 0.0028, decode.d3.loss_mask: 0.2656, decode.d3.loss_dice: 0.4876, decode.d4.loss_cls: 0.0013, decode.d4.loss_mask: 0.2658, decode.d4.loss_dice: 0.4821, decode.d5.loss_cls: 0.0010, decode.d5.loss_mask: 0.2659, decode.d5.loss_dice: 0.4874, decode.d6.loss_cls: 0.0009, decode.d6.loss_mask: 0.2657, decode.d6.loss_dice: 0.4887, decode.d7.loss_cls: 0.0008, decode.d7.loss_mask: 0.2651, decode.d7.loss_dice: 0.4880, decode.d8.loss_cls: 0.0008, decode.d8.loss_mask: 0.2678, decode.d8.loss_dice: 0.4913, loss: 10.9825\n",
      "2024-02-14 14:38:04,032 - mmseg - INFO - Iter [1670/80000]\tlr: 1.406e-06, eta: 2 days, 2:57:36, time: 2.131, data_time: 0.016, memory: 23505, decode.loss_cls: 0.0007, decode.loss_mask: 0.2701, decode.loss_dice: 0.5119, decode.d0.loss_cls: 3.3917, decode.d0.loss_mask: 0.2825, decode.d0.loss_dice: 0.5317, decode.d1.loss_cls: 0.0130, decode.d1.loss_mask: 0.2727, decode.d1.loss_dice: 0.5213, decode.d2.loss_cls: 0.0044, decode.d2.loss_mask: 0.2750, decode.d2.loss_dice: 0.5234, decode.d3.loss_cls: 0.0031, decode.d3.loss_mask: 0.2720, decode.d3.loss_dice: 0.5120, decode.d4.loss_cls: 0.0015, decode.d4.loss_mask: 0.2721, decode.d4.loss_dice: 0.5093, decode.d5.loss_cls: 0.0010, decode.d5.loss_mask: 0.2733, decode.d5.loss_dice: 0.5146, decode.d6.loss_cls: 0.0009, decode.d6.loss_mask: 0.2675, decode.d6.loss_dice: 0.5088, decode.d7.loss_cls: 0.0008, decode.d7.loss_mask: 0.2693, decode.d7.loss_dice: 0.5112, decode.d8.loss_cls: 0.0008, decode.d8.loss_mask: 0.2699, decode.d8.loss_dice: 0.5103, loss: 11.2971\n",
      "2024-02-14 14:38:25,328 - mmseg - INFO - Iter [1680/80000]\tlr: 1.406e-06, eta: 2 days, 2:55:33, time: 2.130, data_time: 0.016, memory: 23505, decode.loss_cls: 0.0007, decode.loss_mask: 0.2534, decode.loss_dice: 0.4827, decode.d0.loss_cls: 3.3824, decode.d0.loss_mask: 0.2615, decode.d0.loss_dice: 0.5002, decode.d1.loss_cls: 0.0126, decode.d1.loss_mask: 0.2562, decode.d1.loss_dice: 0.4857, decode.d2.loss_cls: 0.0044, decode.d2.loss_mask: 0.2529, decode.d2.loss_dice: 0.4927, decode.d3.loss_cls: 0.0024, decode.d3.loss_mask: 0.2515, decode.d3.loss_dice: 0.4830, decode.d4.loss_cls: 0.0012, decode.d4.loss_mask: 0.2540, decode.d4.loss_dice: 0.4815, decode.d5.loss_cls: 0.0009, decode.d5.loss_mask: 0.2506, decode.d5.loss_dice: 0.4811, decode.d6.loss_cls: 0.0008, decode.d6.loss_mask: 0.2492, decode.d6.loss_dice: 0.4842, decode.d7.loss_cls: 0.0008, decode.d7.loss_mask: 0.2527, decode.d7.loss_dice: 0.4865, decode.d8.loss_cls: 0.0008, decode.d8.loss_mask: 0.2517, decode.d8.loss_dice: 0.4865, loss: 10.8047\n",
      "2024-02-14 14:38:46,630 - mmseg - INFO - Iter [1690/80000]\tlr: 1.405e-06, eta: 2 days, 2:53:32, time: 2.130, data_time: 0.016, memory: 23505, decode.loss_cls: 0.0007, decode.loss_mask: 0.2418, decode.loss_dice: 0.4646, decode.d0.loss_cls: 3.3737, decode.d0.loss_mask: 0.2523, decode.d0.loss_dice: 0.4932, decode.d1.loss_cls: 0.0143, decode.d1.loss_mask: 0.2436, decode.d1.loss_dice: 0.4692, decode.d2.loss_cls: 0.0044, decode.d2.loss_mask: 0.2434, decode.d2.loss_dice: 0.4715, decode.d3.loss_cls: 0.0026, decode.d3.loss_mask: 0.2415, decode.d3.loss_dice: 0.4701, decode.d4.loss_cls: 0.0013, decode.d4.loss_mask: 0.2425, decode.d4.loss_dice: 0.4688, decode.d5.loss_cls: 0.0009, decode.d5.loss_mask: 0.2434, decode.d5.loss_dice: 0.4654, decode.d6.loss_cls: 0.0008, decode.d6.loss_mask: 0.2420, decode.d6.loss_dice: 0.4709, decode.d7.loss_cls: 0.0008, decode.d7.loss_mask: 0.2418, decode.d7.loss_dice: 0.4701, decode.d8.loss_cls: 0.0008, decode.d8.loss_mask: 0.2432, decode.d8.loss_dice: 0.4686, loss: 10.5480\n",
      "2024-02-14 14:39:07,922 - mmseg - INFO - Iter [1700/80000]\tlr: 1.405e-06, eta: 2 days, 2:51:32, time: 2.129, data_time: 0.016, memory: 23505, decode.loss_cls: 0.0006, decode.loss_mask: 0.2284, decode.loss_dice: 0.4491, decode.d0.loss_cls: 3.3668, decode.d0.loss_mask: 0.2312, decode.d0.loss_dice: 0.4612, decode.d1.loss_cls: 0.0147, decode.d1.loss_mask: 0.2299, decode.d1.loss_dice: 0.4427, decode.d2.loss_cls: 0.0044, decode.d2.loss_mask: 0.2294, decode.d2.loss_dice: 0.4513, decode.d3.loss_cls: 0.0022, decode.d3.loss_mask: 0.2302, decode.d3.loss_dice: 0.4480, decode.d4.loss_cls: 0.0013, decode.d4.loss_mask: 0.2305, decode.d4.loss_dice: 0.4489, decode.d5.loss_cls: 0.0009, decode.d5.loss_mask: 0.2292, decode.d5.loss_dice: 0.4525, decode.d6.loss_cls: 0.0008, decode.d6.loss_mask: 0.2281, decode.d6.loss_dice: 0.4445, decode.d7.loss_cls: 0.0007, decode.d7.loss_mask: 0.2303, decode.d7.loss_dice: 0.4459, decode.d8.loss_cls: 0.0007, decode.d8.loss_mask: 0.2314, decode.d8.loss_dice: 0.4534, loss: 10.1895\n",
      "2024-02-14 14:39:29,216 - mmseg - INFO - Iter [1710/80000]\tlr: 1.405e-06, eta: 2 days, 2:49:33, time: 2.129, data_time: 0.015, memory: 23505, decode.loss_cls: 0.0006, decode.loss_mask: 0.2214, decode.loss_dice: 0.4314, decode.d0.loss_cls: 3.3564, decode.d0.loss_mask: 0.2239, decode.d0.loss_dice: 0.4460, decode.d1.loss_cls: 0.0271, decode.d1.loss_mask: 0.2226, decode.d1.loss_dice: 0.4350, decode.d2.loss_cls: 0.0082, decode.d2.loss_mask: 0.2195, decode.d2.loss_dice: 0.4307, decode.d3.loss_cls: 0.0025, decode.d3.loss_mask: 0.2230, decode.d3.loss_dice: 0.4354, decode.d4.loss_cls: 0.0013, decode.d4.loss_mask: 0.2224, decode.d4.loss_dice: 0.4402, decode.d5.loss_cls: 0.0009, decode.d5.loss_mask: 0.2208, decode.d5.loss_dice: 0.4330, decode.d6.loss_cls: 0.0008, decode.d6.loss_mask: 0.2190, decode.d6.loss_dice: 0.4339, decode.d7.loss_cls: 0.0007, decode.d7.loss_mask: 0.2224, decode.d7.loss_dice: 0.4376, decode.d8.loss_cls: 0.0007, decode.d8.loss_mask: 0.2207, decode.d8.loss_dice: 0.4310, loss: 9.9690\n",
      "2024-02-14 14:39:50,497 - mmseg - INFO - Iter [1720/80000]\tlr: 1.405e-06, eta: 2 days, 2:47:34, time: 2.128, data_time: 0.016, memory: 23505, decode.loss_cls: 0.0007, decode.loss_mask: 0.2033, decode.loss_dice: 0.4570, decode.d0.loss_cls: 3.3485, decode.d0.loss_mask: 0.2080, decode.d0.loss_dice: 0.4694, decode.d1.loss_cls: 0.0146, decode.d1.loss_mask: 0.2039, decode.d1.loss_dice: 0.4608, decode.d2.loss_cls: 0.0044, decode.d2.loss_mask: 0.2054, decode.d2.loss_dice: 0.4588, decode.d3.loss_cls: 0.0021, decode.d3.loss_mask: 0.2057, decode.d3.loss_dice: 0.4563, decode.d4.loss_cls: 0.0012, decode.d4.loss_mask: 0.2051, decode.d4.loss_dice: 0.4529, decode.d5.loss_cls: 0.0009, decode.d5.loss_mask: 0.2030, decode.d5.loss_dice: 0.4546, decode.d6.loss_cls: 0.0009, decode.d6.loss_mask: 0.2038, decode.d6.loss_dice: 0.4546, decode.d7.loss_cls: 0.0008, decode.d7.loss_mask: 0.2032, decode.d7.loss_dice: 0.4539, decode.d8.loss_cls: 0.0008, decode.d8.loss_mask: 0.2057, decode.d8.loss_dice: 0.4604, loss: 10.0008\n",
      "2024-02-14 14:40:11,793 - mmseg - INFO - Iter [1730/80000]\tlr: 1.405e-06, eta: 2 days, 2:45:37, time: 2.129, data_time: 0.016, memory: 23505, decode.loss_cls: 0.0006, decode.loss_mask: 0.2268, decode.loss_dice: 0.4098, decode.d0.loss_cls: 3.3424, decode.d0.loss_mask: 0.2344, decode.d0.loss_dice: 0.4363, decode.d1.loss_cls: 0.0151, decode.d1.loss_mask: 0.2237, decode.d1.loss_dice: 0.4172, decode.d2.loss_cls: 0.0042, decode.d2.loss_mask: 0.2273, decode.d2.loss_dice: 0.4140, decode.d3.loss_cls: 0.0020, decode.d3.loss_mask: 0.2279, decode.d3.loss_dice: 0.4110, decode.d4.loss_cls: 0.0011, decode.d4.loss_mask: 0.2291, decode.d4.loss_dice: 0.4073, decode.d5.loss_cls: 0.0008, decode.d5.loss_mask: 0.2285, decode.d5.loss_dice: 0.4106, decode.d6.loss_cls: 0.0007, decode.d6.loss_mask: 0.2309, decode.d6.loss_dice: 0.4148, decode.d7.loss_cls: 0.0007, decode.d7.loss_mask: 0.2276, decode.d7.loss_dice: 0.4160, decode.d8.loss_cls: 0.0007, decode.d8.loss_mask: 0.2273, decode.d8.loss_dice: 0.4120, loss: 9.8012\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-14 14:40:33,083 - mmseg - INFO - Iter [1740/80000]\tlr: 1.405e-06, eta: 2 days, 2:43:42, time: 2.129, data_time: 0.016, memory: 23505, decode.loss_cls: 0.0006, decode.loss_mask: 0.2211, decode.loss_dice: 0.4311, decode.d0.loss_cls: 3.3355, decode.d0.loss_mask: 0.2312, decode.d0.loss_dice: 0.4481, decode.d1.loss_cls: 0.0133, decode.d1.loss_mask: 0.2244, decode.d1.loss_dice: 0.4338, decode.d2.loss_cls: 0.0038, decode.d2.loss_mask: 0.2224, decode.d2.loss_dice: 0.4310, decode.d3.loss_cls: 0.0020, decode.d3.loss_mask: 0.2227, decode.d3.loss_dice: 0.4281, decode.d4.loss_cls: 0.0011, decode.d4.loss_mask: 0.2225, decode.d4.loss_dice: 0.4302, decode.d5.loss_cls: 0.0008, decode.d5.loss_mask: 0.2223, decode.d5.loss_dice: 0.4309, decode.d6.loss_cls: 0.0007, decode.d6.loss_mask: 0.2224, decode.d6.loss_dice: 0.4314, decode.d7.loss_cls: 0.0007, decode.d7.loss_mask: 0.2212, decode.d7.loss_dice: 0.4349, decode.d8.loss_cls: 0.0007, decode.d8.loss_mask: 0.2217, decode.d8.loss_dice: 0.4305, loss: 9.9211\n",
      "2024-02-14 14:40:54,381 - mmseg - INFO - Iter [1750/80000]\tlr: 1.404e-06, eta: 2 days, 2:41:47, time: 2.130, data_time: 0.017, memory: 23505, decode.loss_cls: 0.0006, decode.loss_mask: 0.2532, decode.loss_dice: 0.4752, decode.d0.loss_cls: 3.3292, decode.d0.loss_mask: 0.2583, decode.d0.loss_dice: 0.4938, decode.d1.loss_cls: 0.0117, decode.d1.loss_mask: 0.2547, decode.d1.loss_dice: 0.4732, decode.d2.loss_cls: 0.0035, decode.d2.loss_mask: 0.2554, decode.d2.loss_dice: 0.4755, decode.d3.loss_cls: 0.0022, decode.d3.loss_mask: 0.2541, decode.d3.loss_dice: 0.4791, decode.d4.loss_cls: 0.0011, decode.d4.loss_mask: 0.2499, decode.d4.loss_dice: 0.4761, decode.d5.loss_cls: 0.0008, decode.d5.loss_mask: 0.2542, decode.d5.loss_dice: 0.4780, decode.d6.loss_cls: 0.0007, decode.d6.loss_mask: 0.2525, decode.d6.loss_dice: 0.4719, decode.d7.loss_cls: 0.0007, decode.d7.loss_mask: 0.2541, decode.d7.loss_dice: 0.4790, decode.d8.loss_cls: 0.0007, decode.d8.loss_mask: 0.2527, decode.d8.loss_dice: 0.4746, loss: 10.6668\n",
      "2024-02-14 14:41:15,682 - mmseg - INFO - Iter [1760/80000]\tlr: 1.404e-06, eta: 2 days, 2:39:54, time: 2.130, data_time: 0.016, memory: 23505, decode.loss_cls: 0.0005, decode.loss_mask: 0.2203, decode.loss_dice: 0.4418, decode.d0.loss_cls: 3.3181, decode.d0.loss_mask: 0.2240, decode.d0.loss_dice: 0.4495, decode.d1.loss_cls: 0.0141, decode.d1.loss_mask: 0.2224, decode.d1.loss_dice: 0.4442, decode.d2.loss_cls: 0.0038, decode.d2.loss_mask: 0.2216, decode.d2.loss_dice: 0.4443, decode.d3.loss_cls: 0.0019, decode.d3.loss_mask: 0.2200, decode.d3.loss_dice: 0.4470, decode.d4.loss_cls: 0.0010, decode.d4.loss_mask: 0.2200, decode.d4.loss_dice: 0.4454, decode.d5.loss_cls: 0.0008, decode.d5.loss_mask: 0.2171, decode.d5.loss_dice: 0.4442, decode.d6.loss_cls: 0.0007, decode.d6.loss_mask: 0.2196, decode.d6.loss_dice: 0.4432, decode.d7.loss_cls: 0.0007, decode.d7.loss_mask: 0.2189, decode.d7.loss_dice: 0.4409, decode.d8.loss_cls: 0.0007, decode.d8.loss_mask: 0.2199, decode.d8.loss_dice: 0.4434, loss: 9.9899\n",
      "2024-02-14 14:41:36,983 - mmseg - INFO - Iter [1770/80000]\tlr: 1.404e-06, eta: 2 days, 2:38:02, time: 2.130, data_time: 0.017, memory: 23505, decode.loss_cls: 0.0006, decode.loss_mask: 0.2302, decode.loss_dice: 0.4485, decode.d0.loss_cls: 3.3126, decode.d0.loss_mask: 0.2328, decode.d0.loss_dice: 0.4535, decode.d1.loss_cls: 0.0129, decode.d1.loss_mask: 0.2263, decode.d1.loss_dice: 0.4390, decode.d2.loss_cls: 0.0036, decode.d2.loss_mask: 0.2314, decode.d2.loss_dice: 0.4462, decode.d3.loss_cls: 0.0023, decode.d3.loss_mask: 0.2298, decode.d3.loss_dice: 0.4432, decode.d4.loss_cls: 0.0011, decode.d4.loss_mask: 0.2279, decode.d4.loss_dice: 0.4434, decode.d5.loss_cls: 0.0009, decode.d5.loss_mask: 0.2287, decode.d5.loss_dice: 0.4425, decode.d6.loss_cls: 0.0008, decode.d6.loss_mask: 0.2288, decode.d6.loss_dice: 0.4429, decode.d7.loss_cls: 0.0007, decode.d7.loss_mask: 0.2319, decode.d7.loss_dice: 0.4429, decode.d8.loss_cls: 0.0007, decode.d8.loss_mask: 0.2277, decode.d8.loss_dice: 0.4413, loss: 10.0751\n",
      "2024-02-14 14:41:58,251 - mmseg - INFO - Iter [1780/80000]\tlr: 1.404e-06, eta: 2 days, 2:36:09, time: 2.127, data_time: 0.016, memory: 23505, decode.loss_cls: 0.0006, decode.loss_mask: 0.2103, decode.loss_dice: 0.4400, decode.d0.loss_cls: 3.3025, decode.d0.loss_mask: 0.2187, decode.d0.loss_dice: 0.4571, decode.d1.loss_cls: 0.0162, decode.d1.loss_mask: 0.2101, decode.d1.loss_dice: 0.4345, decode.d2.loss_cls: 0.0038, decode.d2.loss_mask: 0.2111, decode.d2.loss_dice: 0.4410, decode.d3.loss_cls: 0.0019, decode.d3.loss_mask: 0.2093, decode.d3.loss_dice: 0.4389, decode.d4.loss_cls: 0.0010, decode.d4.loss_mask: 0.2090, decode.d4.loss_dice: 0.4439, decode.d5.loss_cls: 0.0008, decode.d5.loss_mask: 0.2087, decode.d5.loss_dice: 0.4376, decode.d6.loss_cls: 0.0007, decode.d6.loss_mask: 0.2096, decode.d6.loss_dice: 0.4379, decode.d7.loss_cls: 0.0007, decode.d7.loss_mask: 0.2093, decode.d7.loss_dice: 0.4428, decode.d8.loss_cls: 0.0007, decode.d8.loss_mask: 0.2112, decode.d8.loss_dice: 0.4430, loss: 9.8528\n",
      "2024-02-14 14:42:19,544 - mmseg - INFO - Iter [1790/80000]\tlr: 1.404e-06, eta: 2 days, 2:34:19, time: 2.129, data_time: 0.016, memory: 23505, decode.loss_cls: 0.0006, decode.loss_mask: 0.2140, decode.loss_dice: 0.4241, decode.d0.loss_cls: 3.2955, decode.d0.loss_mask: 0.2234, decode.d0.loss_dice: 0.4401, decode.d1.loss_cls: 0.0133, decode.d1.loss_mask: 0.2131, decode.d1.loss_dice: 0.4237, decode.d2.loss_cls: 0.0080, decode.d2.loss_mask: 0.2165, decode.d2.loss_dice: 0.4253, decode.d3.loss_cls: 0.0028, decode.d3.loss_mask: 0.2134, decode.d3.loss_dice: 0.4234, decode.d4.loss_cls: 0.0010, decode.d4.loss_mask: 0.2124, decode.d4.loss_dice: 0.4223, decode.d5.loss_cls: 0.0008, decode.d5.loss_mask: 0.2149, decode.d5.loss_dice: 0.4255, decode.d6.loss_cls: 0.0007, decode.d6.loss_mask: 0.2145, decode.d6.loss_dice: 0.4265, decode.d7.loss_cls: 0.0007, decode.d7.loss_mask: 0.2148, decode.d7.loss_dice: 0.4289, decode.d8.loss_cls: 0.0007, decode.d8.loss_mask: 0.2119, decode.d8.loss_dice: 0.4262, loss: 9.7391\n",
      "2024-02-14 14:42:40,838 - mmseg - INFO - Iter [1800/80000]\tlr: 1.404e-06, eta: 2 days, 2:32:29, time: 2.129, data_time: 0.017, memory: 23505, decode.loss_cls: 0.0008, decode.loss_mask: 0.2478, decode.loss_dice: 0.4818, decode.d0.loss_cls: 3.2958, decode.d0.loss_mask: 0.2631, decode.d0.loss_dice: 0.4880, decode.d1.loss_cls: 0.0128, decode.d1.loss_mask: 0.2563, decode.d1.loss_dice: 0.4835, decode.d2.loss_cls: 0.0036, decode.d2.loss_mask: 0.2520, decode.d2.loss_dice: 0.4776, decode.d3.loss_cls: 0.0023, decode.d3.loss_mask: 0.2504, decode.d3.loss_dice: 0.4821, decode.d4.loss_cls: 0.0014, decode.d4.loss_mask: 0.2461, decode.d4.loss_dice: 0.4799, decode.d5.loss_cls: 0.0010, decode.d5.loss_mask: 0.2515, decode.d5.loss_dice: 0.4901, decode.d6.loss_cls: 0.0011, decode.d6.loss_mask: 0.2503, decode.d6.loss_dice: 0.4849, decode.d7.loss_cls: 0.0010, decode.d7.loss_mask: 0.2485, decode.d7.loss_dice: 0.4839, decode.d8.loss_cls: 0.0009, decode.d8.loss_mask: 0.2490, decode.d8.loss_dice: 0.4843, loss: 10.6716\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 40/40, 6.2 task/s, elapsed: 6s, ETA:     0s\n",
      "\n",
      "2024-02-14 14:42:47,283 - mmseg - INFO - per class results:\n",
      "2024-02-14 14:42:47,284 - mmseg - INFO - \n",
      "+---------------+-------+-------+\n",
      "|     Class     |  IoU  |  Acc  |\n",
      "+---------------+-------+-------+\n",
      "|       bg      | 97.52 | 98.52 |\n",
      "|    Anchovy    | 80.97 | 92.69 |\n",
      "|     Olives    | 87.17 |  90.8 |\n",
      "|     Salami    | 71.03 | 84.82 |\n",
      "|   Red_Pepper  | 88.02 | 94.69 |\n",
      "| Yellow_Pepper | 86.63 | 94.66 |\n",
      "+---------------+-------+-------+\n",
      "2024-02-14 14:42:47,284 - mmseg - INFO - Summary:\n",
      "2024-02-14 14:42:47,284 - mmseg - INFO - \n",
      "+-------+-------+------+\n",
      "|  aAcc |  mIoU | mAcc |\n",
      "+-------+-------+------+\n",
      "| 97.58 | 85.23 | 92.7 |\n",
      "+-------+-------+------+\n",
      "2024-02-14 14:42:47,788 - mmseg - INFO - The previous best checkpoint /workspace/ViT-Adapter/segmentation/work_dirs/pizze_training_large/best_mIoU_iter_1600.pth was removed\n",
      "2024-02-14 14:43:00,029 - mmseg - INFO - Now best checkpoint is saved as best_mIoU_iter_1800.pth.\n",
      "2024-02-14 14:43:00,029 - mmseg - INFO - Best mIoU is 0.8523 at 1800 iter.\n",
      "2024-02-14 14:43:00,030 - mmseg - INFO - Iter(val) [10]\taAcc: 0.9758, mIoU: 0.8523, mAcc: 0.9270, IoU.bg: 0.9752, IoU.Anchovy: 0.8097, IoU.Olives: 0.8717, IoU.Salami: 0.7103, IoU.Red_Pepper: 0.8802, IoU.Yellow_Pepper: 0.8663, Acc.bg: 0.9852, Acc.Anchovy: 0.9269, Acc.Olives: 0.9080, Acc.Salami: 0.8482, Acc.Red_Pepper: 0.9469, Acc.Yellow_Pepper: 0.9466\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-14 14:43:21,307 - mmseg - INFO - Iter [1810/80000]\tlr: 1.403e-06, eta: 2 days, 2:44:29, time: 4.047, data_time: 1.936, memory: 23505, decode.loss_cls: 0.0005, decode.loss_mask: 0.2217, decode.loss_dice: 0.4265, decode.d0.loss_cls: 3.2834, decode.d0.loss_mask: 0.2257, decode.d0.loss_dice: 0.4457, decode.d1.loss_cls: 0.0161, decode.d1.loss_mask: 0.2178, decode.d1.loss_dice: 0.4327, decode.d2.loss_cls: 0.0041, decode.d2.loss_mask: 0.2196, decode.d2.loss_dice: 0.4321, decode.d3.loss_cls: 0.0022, decode.d3.loss_mask: 0.2187, decode.d3.loss_dice: 0.4264, decode.d4.loss_cls: 0.0012, decode.d4.loss_mask: 0.2176, decode.d4.loss_dice: 0.4277, decode.d5.loss_cls: 0.0008, decode.d5.loss_mask: 0.2193, decode.d5.loss_dice: 0.4283, decode.d6.loss_cls: 0.0007, decode.d6.loss_mask: 0.2151, decode.d6.loss_dice: 0.4258, decode.d7.loss_cls: 0.0007, decode.d7.loss_mask: 0.2188, decode.d7.loss_dice: 0.4266, decode.d8.loss_cls: 0.0007, decode.d8.loss_mask: 0.2195, decode.d8.loss_dice: 0.4254, loss: 9.8010\n",
      "2024-02-14 14:43:42,590 - mmseg - INFO - Iter [1820/80000]\tlr: 1.403e-06, eta: 2 days, 2:42:36, time: 2.128, data_time: 0.017, memory: 23505, decode.loss_cls: 0.0005, decode.loss_mask: 0.2633, decode.loss_dice: 0.4873, decode.d0.loss_cls: 3.2790, decode.d0.loss_mask: 0.2680, decode.d0.loss_dice: 0.5034, decode.d1.loss_cls: 0.0109, decode.d1.loss_mask: 0.2629, decode.d1.loss_dice: 0.4918, decode.d2.loss_cls: 0.0033, decode.d2.loss_mask: 0.2615, decode.d2.loss_dice: 0.4828, decode.d3.loss_cls: 0.0020, decode.d3.loss_mask: 0.2640, decode.d3.loss_dice: 0.4835, decode.d4.loss_cls: 0.0012, decode.d4.loss_mask: 0.2627, decode.d4.loss_dice: 0.4883, decode.d5.loss_cls: 0.0008, decode.d5.loss_mask: 0.2613, decode.d5.loss_dice: 0.4838, decode.d6.loss_cls: 0.0007, decode.d6.loss_mask: 0.2621, decode.d6.loss_dice: 0.4798, decode.d7.loss_cls: 0.0006, decode.d7.loss_mask: 0.2628, decode.d7.loss_dice: 0.4815, decode.d8.loss_cls: 0.0006, decode.d8.loss_mask: 0.2610, decode.d8.loss_dice: 0.4793, loss: 10.7905\n",
      "2024-02-14 14:44:03,862 - mmseg - INFO - Iter [1830/80000]\tlr: 1.403e-06, eta: 2 days, 2:40:44, time: 2.127, data_time: 0.016, memory: 23505, decode.loss_cls: 0.0005, decode.loss_mask: 0.2367, decode.loss_dice: 0.4618, decode.d0.loss_cls: 3.2689, decode.d0.loss_mask: 0.2433, decode.d0.loss_dice: 0.4751, decode.d1.loss_cls: 0.0113, decode.d1.loss_mask: 0.2437, decode.d1.loss_dice: 0.4635, decode.d2.loss_cls: 0.0032, decode.d2.loss_mask: 0.2388, decode.d2.loss_dice: 0.4570, decode.d3.loss_cls: 0.0019, decode.d3.loss_mask: 0.2382, decode.d3.loss_dice: 0.4644, decode.d4.loss_cls: 0.0011, decode.d4.loss_mask: 0.2373, decode.d4.loss_dice: 0.4561, decode.d5.loss_cls: 0.0008, decode.d5.loss_mask: 0.2367, decode.d5.loss_dice: 0.4568, decode.d6.loss_cls: 0.0007, decode.d6.loss_mask: 0.2367, decode.d6.loss_dice: 0.4573, decode.d7.loss_cls: 0.0006, decode.d7.loss_mask: 0.2363, decode.d7.loss_dice: 0.4596, decode.d8.loss_cls: 0.0006, decode.d8.loss_mask: 0.2366, decode.d8.loss_dice: 0.4595, loss: 10.2850\n",
      "2024-02-14 14:44:25,147 - mmseg - INFO - Iter [1840/80000]\tlr: 1.403e-06, eta: 2 days, 2:38:54, time: 2.129, data_time: 0.017, memory: 23505, decode.loss_cls: 0.0005, decode.loss_mask: 0.2543, decode.loss_dice: 0.4663, decode.d0.loss_cls: 3.2625, decode.d0.loss_mask: 0.2634, decode.d0.loss_dice: 0.4890, decode.d1.loss_cls: 0.0103, decode.d1.loss_mask: 0.2569, decode.d1.loss_dice: 0.4681, decode.d2.loss_cls: 0.0031, decode.d2.loss_mask: 0.2549, decode.d2.loss_dice: 0.4694, decode.d3.loss_cls: 0.0019, decode.d3.loss_mask: 0.2577, decode.d3.loss_dice: 0.4696, decode.d4.loss_cls: 0.0011, decode.d4.loss_mask: 0.2559, decode.d4.loss_dice: 0.4646, decode.d5.loss_cls: 0.0008, decode.d5.loss_mask: 0.2551, decode.d5.loss_dice: 0.4680, decode.d6.loss_cls: 0.0007, decode.d6.loss_mask: 0.2544, decode.d6.loss_dice: 0.4652, decode.d7.loss_cls: 0.0006, decode.d7.loss_mask: 0.2595, decode.d7.loss_dice: 0.4726, decode.d8.loss_cls: 0.0006, decode.d8.loss_mask: 0.2562, decode.d8.loss_dice: 0.4677, loss: 10.5511\n",
      "2024-02-14 14:44:46,429 - mmseg - INFO - Iter [1850/80000]\tlr: 1.403e-06, eta: 2 days, 2:37:04, time: 2.128, data_time: 0.016, memory: 23505, decode.loss_cls: 0.0005, decode.loss_mask: 0.2023, decode.loss_dice: 0.4183, decode.d0.loss_cls: 3.2501, decode.d0.loss_mask: 0.2098, decode.d0.loss_dice: 0.4361, decode.d1.loss_cls: 0.0120, decode.d1.loss_mask: 0.1998, decode.d1.loss_dice: 0.4211, decode.d2.loss_cls: 0.0034, decode.d2.loss_mask: 0.2014, decode.d2.loss_dice: 0.4205, decode.d3.loss_cls: 0.0019, decode.d3.loss_mask: 0.2019, decode.d3.loss_dice: 0.4203, decode.d4.loss_cls: 0.0010, decode.d4.loss_mask: 0.2018, decode.d4.loss_dice: 0.4196, decode.d5.loss_cls: 0.0007, decode.d5.loss_mask: 0.2027, decode.d5.loss_dice: 0.4196, decode.d6.loss_cls: 0.0007, decode.d6.loss_mask: 0.2034, decode.d6.loss_dice: 0.4231, decode.d7.loss_cls: 0.0006, decode.d7.loss_mask: 0.2029, decode.d7.loss_dice: 0.4203, decode.d8.loss_cls: 0.0006, decode.d8.loss_mask: 0.2021, decode.d8.loss_dice: 0.4198, loss: 9.5185\n",
      "2024-02-14 14:45:07,706 - mmseg - INFO - Iter [1860/80000]\tlr: 1.402e-06, eta: 2 days, 2:35:15, time: 2.128, data_time: 0.017, memory: 23505, decode.loss_cls: 0.0005, decode.loss_mask: 0.2700, decode.loss_dice: 0.5019, decode.d0.loss_cls: 3.2465, decode.d0.loss_mask: 0.2790, decode.d0.loss_dice: 0.5223, decode.d1.loss_cls: 0.0098, decode.d1.loss_mask: 0.2738, decode.d1.loss_dice: 0.5087, decode.d2.loss_cls: 0.0031, decode.d2.loss_mask: 0.2737, decode.d2.loss_dice: 0.5083, decode.d3.loss_cls: 0.0021, decode.d3.loss_mask: 0.2732, decode.d3.loss_dice: 0.5061, decode.d4.loss_cls: 0.0010, decode.d4.loss_mask: 0.2700, decode.d4.loss_dice: 0.5049, decode.d5.loss_cls: 0.0007, decode.d5.loss_mask: 0.2727, decode.d5.loss_dice: 0.5076, decode.d6.loss_cls: 0.0007, decode.d6.loss_mask: 0.2691, decode.d6.loss_dice: 0.5017, decode.d7.loss_cls: 0.0006, decode.d7.loss_mask: 0.2716, decode.d7.loss_dice: 0.5062, decode.d8.loss_cls: 0.0006, decode.d8.loss_mask: 0.2715, decode.d8.loss_dice: 0.5014, loss: 11.0594\n",
      "2024-02-14 14:45:29,000 - mmseg - INFO - Iter [1870/80000]\tlr: 1.402e-06, eta: 2 days, 2:33:27, time: 2.129, data_time: 0.016, memory: 23505, decode.loss_cls: 0.0005, decode.loss_mask: 0.1971, decode.loss_dice: 0.4047, decode.d0.loss_cls: 3.2327, decode.d0.loss_mask: 0.2068, decode.d0.loss_dice: 0.4160, decode.d1.loss_cls: 0.0129, decode.d1.loss_mask: 0.2025, decode.d1.loss_dice: 0.4051, decode.d2.loss_cls: 0.0031, decode.d2.loss_mask: 0.2014, decode.d2.loss_dice: 0.4090, decode.d3.loss_cls: 0.0016, decode.d3.loss_mask: 0.2015, decode.d3.loss_dice: 0.4066, decode.d4.loss_cls: 0.0009, decode.d4.loss_mask: 0.1999, decode.d4.loss_dice: 0.4011, decode.d5.loss_cls: 0.0007, decode.d5.loss_mask: 0.2027, decode.d5.loss_dice: 0.4074, decode.d6.loss_cls: 0.0006, decode.d6.loss_mask: 0.2013, decode.d6.loss_dice: 0.4031, decode.d7.loss_cls: 0.0006, decode.d7.loss_mask: 0.2002, decode.d7.loss_dice: 0.4042, decode.d8.loss_cls: 0.0006, decode.d8.loss_mask: 0.1972, decode.d8.loss_dice: 0.3995, loss: 9.3215\n",
      "2024-02-14 14:45:51,954 - mmseg - INFO - Iter [1880/80000]\tlr: 1.402e-06, eta: 2 days, 2:32:43, time: 2.279, data_time: 0.016, memory: 23505, decode.loss_cls: 0.0005, decode.loss_mask: 0.2260, decode.loss_dice: 0.4370, decode.d0.loss_cls: 3.2270, decode.d0.loss_mask: 0.2400, decode.d0.loss_dice: 0.4616, decode.d1.loss_cls: 0.0112, decode.d1.loss_mask: 0.2259, decode.d1.loss_dice: 0.4420, decode.d2.loss_cls: 0.0030, decode.d2.loss_mask: 0.2266, decode.d2.loss_dice: 0.4347, decode.d3.loss_cls: 0.0017, decode.d3.loss_mask: 0.2258, decode.d3.loss_dice: 0.4375, decode.d4.loss_cls: 0.0010, decode.d4.loss_mask: 0.2240, decode.d4.loss_dice: 0.4338, decode.d5.loss_cls: 0.0007, decode.d5.loss_mask: 0.2280, decode.d5.loss_dice: 0.4417, decode.d6.loss_cls: 0.0006, decode.d6.loss_mask: 0.2272, decode.d6.loss_dice: 0.4391, decode.d7.loss_cls: 0.0006, decode.d7.loss_mask: 0.2268, decode.d7.loss_dice: 0.4348, decode.d8.loss_cls: 0.0006, decode.d8.loss_mask: 0.2294, decode.d8.loss_dice: 0.4399, loss: 9.9286\n",
      "2024-02-14 14:46:21,915 - mmseg - INFO - Iter [1890/80000]\tlr: 1.402e-06, eta: 2 days, 2:37:02, time: 3.012, data_time: 0.045, memory: 23505, decode.loss_cls: 0.0005, decode.loss_mask: 0.2737, decode.loss_dice: 0.5068, decode.d0.loss_cls: 3.2230, decode.d0.loss_mask: 0.2793, decode.d0.loss_dice: 0.5153, decode.d1.loss_cls: 0.0083, decode.d1.loss_mask: 0.2737, decode.d1.loss_dice: 0.5060, decode.d2.loss_cls: 0.0027, decode.d2.loss_mask: 0.2753, decode.d2.loss_dice: 0.5052, decode.d3.loss_cls: 0.0016, decode.d3.loss_mask: 0.2766, decode.d3.loss_dice: 0.5005, decode.d4.loss_cls: 0.0010, decode.d4.loss_mask: 0.2729, decode.d4.loss_dice: 0.5012, decode.d5.loss_cls: 0.0007, decode.d5.loss_mask: 0.2717, decode.d5.loss_dice: 0.5043, decode.d6.loss_cls: 0.0006, decode.d6.loss_mask: 0.2699, decode.d6.loss_dice: 0.5088, decode.d7.loss_cls: 0.0006, decode.d7.loss_mask: 0.2722, decode.d7.loss_dice: 0.5068, decode.d8.loss_cls: 0.0006, decode.d8.loss_mask: 0.2736, decode.d8.loss_dice: 0.5112, loss: 11.0443\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-14 14:47:17,972 - mmseg - INFO - Iter [1900/80000]\tlr: 1.402e-06, eta: 2 days, 2:59:04, time: 5.605, data_time: 0.011, memory: 23505, decode.loss_cls: 0.0005, decode.loss_mask: 0.2578, decode.loss_dice: 0.4925, decode.d0.loss_cls: 3.2141, decode.d0.loss_mask: 0.2636, decode.d0.loss_dice: 0.5149, decode.d1.loss_cls: 0.0134, decode.d1.loss_mask: 0.2580, decode.d1.loss_dice: 0.4930, decode.d2.loss_cls: 0.0031, decode.d2.loss_mask: 0.2558, decode.d2.loss_dice: 0.4889, decode.d3.loss_cls: 0.0017, decode.d3.loss_mask: 0.2528, decode.d3.loss_dice: 0.4884, decode.d4.loss_cls: 0.0010, decode.d4.loss_mask: 0.2565, decode.d4.loss_dice: 0.4957, decode.d5.loss_cls: 0.0007, decode.d5.loss_mask: 0.2576, decode.d5.loss_dice: 0.4934, decode.d6.loss_cls: 0.0006, decode.d6.loss_mask: 0.2535, decode.d6.loss_dice: 0.4905, decode.d7.loss_cls: 0.0006, decode.d7.loss_mask: 0.2537, decode.d7.loss_dice: 0.4889, decode.d8.loss_cls: 0.0006, decode.d8.loss_mask: 0.2591, decode.d8.loss_dice: 0.4896, loss: 10.7403\n",
      "2024-02-14 14:47:53,641 - mmseg - INFO - Iter [1910/80000]\tlr: 1.402e-06, eta: 2 days, 3:06:58, time: 3.567, data_time: 0.015, memory: 23505, decode.loss_cls: 0.0005, decode.loss_mask: 0.2360, decode.loss_dice: 0.4481, decode.d0.loss_cls: 3.2062, decode.d0.loss_mask: 0.2423, decode.d0.loss_dice: 0.4615, decode.d1.loss_cls: 0.0141, decode.d1.loss_mask: 0.2329, decode.d1.loss_dice: 0.4473, decode.d2.loss_cls: 0.0031, decode.d2.loss_mask: 0.2315, decode.d2.loss_dice: 0.4448, decode.d3.loss_cls: 0.0017, decode.d3.loss_mask: 0.2324, decode.d3.loss_dice: 0.4420, decode.d4.loss_cls: 0.0011, decode.d4.loss_mask: 0.2367, decode.d4.loss_dice: 0.4562, decode.d5.loss_cls: 0.0007, decode.d5.loss_mask: 0.2339, decode.d5.loss_dice: 0.4435, decode.d6.loss_cls: 0.0006, decode.d6.loss_mask: 0.2339, decode.d6.loss_dice: 0.4455, decode.d7.loss_cls: 0.0006, decode.d7.loss_mask: 0.2315, decode.d7.loss_dice: 0.4438, decode.d8.loss_cls: 0.0006, decode.d8.loss_mask: 0.2326, decode.d8.loss_dice: 0.4424, loss: 10.0480\n",
      "2024-02-14 14:48:14,986 - mmseg - INFO - Iter [1920/80000]\tlr: 1.401e-06, eta: 2 days, 3:05:04, time: 2.135, data_time: 0.019, memory: 23505, decode.loss_cls: 0.0005, decode.loss_mask: 0.2162, decode.loss_dice: 0.4275, decode.d0.loss_cls: 3.1952, decode.d0.loss_mask: 0.2205, decode.d0.loss_dice: 0.4397, decode.d1.loss_cls: 0.0179, decode.d1.loss_mask: 0.2192, decode.d1.loss_dice: 0.4290, decode.d2.loss_cls: 0.0036, decode.d2.loss_mask: 0.2150, decode.d2.loss_dice: 0.4230, decode.d3.loss_cls: 0.0016, decode.d3.loss_mask: 0.2144, decode.d3.loss_dice: 0.4225, decode.d4.loss_cls: 0.0010, decode.d4.loss_mask: 0.2141, decode.d4.loss_dice: 0.4187, decode.d5.loss_cls: 0.0007, decode.d5.loss_mask: 0.2159, decode.d5.loss_dice: 0.4261, decode.d6.loss_cls: 0.0006, decode.d6.loss_mask: 0.2152, decode.d6.loss_dice: 0.4233, decode.d7.loss_cls: 0.0006, decode.d7.loss_mask: 0.2170, decode.d7.loss_dice: 0.4273, decode.d8.loss_cls: 0.0006, decode.d8.loss_mask: 0.2152, decode.d8.loss_dice: 0.4286, loss: 9.6507\n",
      "2024-02-14 14:48:38,376 - mmseg - INFO - Iter [1930/80000]\tlr: 1.401e-06, eta: 2 days, 3:04:34, time: 2.339, data_time: 0.224, memory: 23505, decode.loss_cls: 0.0005, decode.loss_mask: 0.1977, decode.loss_dice: 0.4057, decode.d0.loss_cls: 3.1882, decode.d0.loss_mask: 0.1997, decode.d0.loss_dice: 0.4265, decode.d1.loss_cls: 0.0154, decode.d1.loss_mask: 0.1981, decode.d1.loss_dice: 0.4099, decode.d2.loss_cls: 0.0037, decode.d2.loss_mask: 0.2009, decode.d2.loss_dice: 0.4138, decode.d3.loss_cls: 0.0017, decode.d3.loss_mask: 0.1965, decode.d3.loss_dice: 0.4002, decode.d4.loss_cls: 0.0008, decode.d4.loss_mask: 0.2002, decode.d4.loss_dice: 0.4104, decode.d5.loss_cls: 0.0007, decode.d5.loss_mask: 0.1953, decode.d5.loss_dice: 0.4005, decode.d6.loss_cls: 0.0006, decode.d6.loss_mask: 0.1992, decode.d6.loss_dice: 0.4012, decode.d7.loss_cls: 0.0005, decode.d7.loss_mask: 0.1990, decode.d7.loss_dice: 0.4067, decode.d8.loss_cls: 0.0006, decode.d8.loss_mask: 0.1993, decode.d8.loss_dice: 0.4096, loss: 9.2829\n",
      "2024-02-14 14:48:59,695 - mmseg - INFO - Iter [1940/80000]\tlr: 1.401e-06, eta: 2 days, 3:02:41, time: 2.132, data_time: 0.018, memory: 23505, decode.loss_cls: 0.0005, decode.loss_mask: 0.2547, decode.loss_dice: 0.4694, decode.d0.loss_cls: 3.1858, decode.d0.loss_mask: 0.2588, decode.d0.loss_dice: 0.4776, decode.d1.loss_cls: 0.0114, decode.d1.loss_mask: 0.2687, decode.d1.loss_dice: 0.4676, decode.d2.loss_cls: 0.0029, decode.d2.loss_mask: 0.2538, decode.d2.loss_dice: 0.4667, decode.d3.loss_cls: 0.0017, decode.d3.loss_mask: 0.2551, decode.d3.loss_dice: 0.4658, decode.d4.loss_cls: 0.0012, decode.d4.loss_mask: 0.2571, decode.d4.loss_dice: 0.4741, decode.d5.loss_cls: 0.0008, decode.d5.loss_mask: 0.2544, decode.d5.loss_dice: 0.4664, decode.d6.loss_cls: 0.0007, decode.d6.loss_mask: 0.2542, decode.d6.loss_dice: 0.4661, decode.d7.loss_cls: 0.0006, decode.d7.loss_mask: 0.2575, decode.d7.loss_dice: 0.4675, decode.d8.loss_cls: 0.0006, decode.d8.loss_mask: 0.2536, decode.d8.loss_dice: 0.4658, loss: 10.4611\n",
      "2024-02-14 14:49:21,023 - mmseg - INFO - Iter [1950/80000]\tlr: 1.401e-06, eta: 2 days, 3:00:49, time: 2.133, data_time: 0.016, memory: 23505, decode.loss_cls: 0.0006, decode.loss_mask: 0.2319, decode.loss_dice: 0.4439, decode.d0.loss_cls: 3.1732, decode.d0.loss_mask: 0.2367, decode.d0.loss_dice: 0.4648, decode.d1.loss_cls: 0.0146, decode.d1.loss_mask: 0.2333, decode.d1.loss_dice: 0.4531, decode.d2.loss_cls: 0.0036, decode.d2.loss_mask: 0.2289, decode.d2.loss_dice: 0.4423, decode.d3.loss_cls: 0.0021, decode.d3.loss_mask: 0.2312, decode.d3.loss_dice: 0.4476, decode.d4.loss_cls: 0.0016, decode.d4.loss_mask: 0.2299, decode.d4.loss_dice: 0.4439, decode.d5.loss_cls: 0.0013, decode.d5.loss_mask: 0.2323, decode.d5.loss_dice: 0.4468, decode.d6.loss_cls: 0.0010, decode.d6.loss_mask: 0.2314, decode.d6.loss_dice: 0.4434, decode.d7.loss_cls: 0.0008, decode.d7.loss_mask: 0.2316, decode.d7.loss_dice: 0.4478, decode.d8.loss_cls: 0.0007, decode.d8.loss_mask: 0.2317, decode.d8.loss_dice: 0.4511, loss: 10.0030\n",
      "2024-02-14 14:49:42,355 - mmseg - INFO - Iter [1960/80000]\tlr: 1.401e-06, eta: 2 days, 2:58:57, time: 2.133, data_time: 0.017, memory: 23505, decode.loss_cls: 0.0005, decode.loss_mask: 0.2228, decode.loss_dice: 0.4415, decode.d0.loss_cls: 3.1661, decode.d0.loss_mask: 0.2275, decode.d0.loss_dice: 0.4565, decode.d1.loss_cls: 0.0153, decode.d1.loss_mask: 0.2262, decode.d1.loss_dice: 0.4466, decode.d2.loss_cls: 0.0034, decode.d2.loss_mask: 0.2243, decode.d2.loss_dice: 0.4408, decode.d3.loss_cls: 0.0017, decode.d3.loss_mask: 0.2225, decode.d3.loss_dice: 0.4436, decode.d4.loss_cls: 0.0011, decode.d4.loss_mask: 0.2208, decode.d4.loss_dice: 0.4353, decode.d5.loss_cls: 0.0008, decode.d5.loss_mask: 0.2239, decode.d5.loss_dice: 0.4386, decode.d6.loss_cls: 0.0007, decode.d6.loss_mask: 0.2211, decode.d6.loss_dice: 0.4369, decode.d7.loss_cls: 0.0006, decode.d7.loss_mask: 0.2241, decode.d7.loss_dice: 0.4456, decode.d8.loss_cls: 0.0006, decode.d8.loss_mask: 0.2207, decode.d8.loss_dice: 0.4361, loss: 9.8464\n",
      "2024-02-14 14:50:03,656 - mmseg - INFO - Iter [1970/80000]\tlr: 1.400e-06, eta: 2 days, 2:57:06, time: 2.130, data_time: 0.017, memory: 23505, decode.loss_cls: 0.0005, decode.loss_mask: 0.2137, decode.loss_dice: 0.4007, decode.d0.loss_cls: 3.1575, decode.d0.loss_mask: 0.2233, decode.d0.loss_dice: 0.4197, decode.d1.loss_cls: 0.0137, decode.d1.loss_mask: 0.2121, decode.d1.loss_dice: 0.4036, decode.d2.loss_cls: 0.0031, decode.d2.loss_mask: 0.2130, decode.d2.loss_dice: 0.4036, decode.d3.loss_cls: 0.0017, decode.d3.loss_mask: 0.2124, decode.d3.loss_dice: 0.4060, decode.d4.loss_cls: 0.0010, decode.d4.loss_mask: 0.2132, decode.d4.loss_dice: 0.4051, decode.d5.loss_cls: 0.0007, decode.d5.loss_mask: 0.2125, decode.d5.loss_dice: 0.4046, decode.d6.loss_cls: 0.0006, decode.d6.loss_mask: 0.2106, decode.d6.loss_dice: 0.4023, decode.d7.loss_cls: 0.0006, decode.d7.loss_mask: 0.2112, decode.d7.loss_dice: 0.4029, decode.d8.loss_cls: 0.0006, decode.d8.loss_mask: 0.2140, decode.d8.loss_dice: 0.4006, loss: 9.3652\n",
      "2024-02-14 14:50:24,949 - mmseg - INFO - Iter [1980/80000]\tlr: 1.400e-06, eta: 2 days, 2:55:15, time: 2.129, data_time: 0.017, memory: 23505, decode.loss_cls: 0.0005, decode.loss_mask: 0.2609, decode.loss_dice: 0.4644, decode.d0.loss_cls: 3.1539, decode.d0.loss_mask: 0.2641, decode.d0.loss_dice: 0.4759, decode.d1.loss_cls: 0.0130, decode.d1.loss_mask: 0.2610, decode.d1.loss_dice: 0.4656, decode.d2.loss_cls: 0.0033, decode.d2.loss_mask: 0.2660, decode.d2.loss_dice: 0.4675, decode.d3.loss_cls: 0.0019, decode.d3.loss_mask: 0.2630, decode.d3.loss_dice: 0.4590, decode.d4.loss_cls: 0.0010, decode.d4.loss_mask: 0.2622, decode.d4.loss_dice: 0.4600, decode.d5.loss_cls: 0.0008, decode.d5.loss_mask: 0.2625, decode.d5.loss_dice: 0.4579, decode.d6.loss_cls: 0.0007, decode.d6.loss_mask: 0.2614, decode.d6.loss_dice: 0.4604, decode.d7.loss_cls: 0.0006, decode.d7.loss_mask: 0.2644, decode.d7.loss_dice: 0.4705, decode.d8.loss_cls: 0.0006, decode.d8.loss_mask: 0.2615, decode.d8.loss_dice: 0.4579, loss: 10.4425\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-14 14:50:46,248 - mmseg - INFO - Iter [1990/80000]\tlr: 1.400e-06, eta: 2 days, 2:53:26, time: 2.130, data_time: 0.016, memory: 23505, decode.loss_cls: 0.0005, decode.loss_mask: 0.2208, decode.loss_dice: 0.4471, decode.d0.loss_cls: 3.1440, decode.d0.loss_mask: 0.2247, decode.d0.loss_dice: 0.4578, decode.d1.loss_cls: 0.0123, decode.d1.loss_mask: 0.2209, decode.d1.loss_dice: 0.4376, decode.d2.loss_cls: 0.0029, decode.d2.loss_mask: 0.2160, decode.d2.loss_dice: 0.4403, decode.d3.loss_cls: 0.0019, decode.d3.loss_mask: 0.2191, decode.d3.loss_dice: 0.4430, decode.d4.loss_cls: 0.0010, decode.d4.loss_mask: 0.2199, decode.d4.loss_dice: 0.4525, decode.d5.loss_cls: 0.0007, decode.d5.loss_mask: 0.2180, decode.d5.loss_dice: 0.4433, decode.d6.loss_cls: 0.0006, decode.d6.loss_mask: 0.2190, decode.d6.loss_dice: 0.4428, decode.d7.loss_cls: 0.0006, decode.d7.loss_mask: 0.2203, decode.d7.loss_dice: 0.4413, decode.d8.loss_cls: 0.0006, decode.d8.loss_mask: 0.2209, decode.d8.loss_dice: 0.4463, loss: 9.8166\n",
      "2024-02-14 14:51:07,569 - mmseg - INFO - Exp name: pizze_training_large.py\n",
      "2024-02-14 14:51:07,570 - mmseg - INFO - Iter [2000/80000]\tlr: 1.400e-06, eta: 2 days, 2:51:38, time: 2.132, data_time: 0.017, memory: 23505, decode.loss_cls: 0.0005, decode.loss_mask: 0.2113, decode.loss_dice: 0.4133, decode.d0.loss_cls: 3.1354, decode.d0.loss_mask: 0.2116, decode.d0.loss_dice: 0.4206, decode.d1.loss_cls: 0.0129, decode.d1.loss_mask: 0.2127, decode.d1.loss_dice: 0.4193, decode.d2.loss_cls: 0.0029, decode.d2.loss_mask: 0.2108, decode.d2.loss_dice: 0.4137, decode.d3.loss_cls: 0.0016, decode.d3.loss_mask: 0.2086, decode.d3.loss_dice: 0.4122, decode.d4.loss_cls: 0.0010, decode.d4.loss_mask: 0.2078, decode.d4.loss_dice: 0.4163, decode.d5.loss_cls: 0.0008, decode.d5.loss_mask: 0.2108, decode.d5.loss_dice: 0.4179, decode.d6.loss_cls: 0.0007, decode.d6.loss_mask: 0.2093, decode.d6.loss_dice: 0.4113, decode.d7.loss_cls: 0.0006, decode.d7.loss_mask: 0.2105, decode.d7.loss_dice: 0.4169, decode.d8.loss_cls: 0.0006, decode.d8.loss_mask: 0.2096, decode.d8.loss_dice: 0.4145, loss: 9.4161\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 40/40, 6.2 task/s, elapsed: 6s, ETA:     0s\n",
      "\n",
      "2024-02-14 14:51:14,019 - mmseg - INFO - per class results:\n",
      "2024-02-14 14:51:14,020 - mmseg - INFO - \n",
      "+---------------+-------+-------+\n",
      "|     Class     |  IoU  |  Acc  |\n",
      "+---------------+-------+-------+\n",
      "|       bg      |  97.5 | 98.37 |\n",
      "|    Anchovy    | 79.06 | 94.88 |\n",
      "|     Olives    | 87.02 | 90.69 |\n",
      "|     Salami    | 70.72 | 87.46 |\n",
      "|   Red_Pepper  | 88.71 | 94.61 |\n",
      "| Yellow_Pepper | 86.24 | 95.22 |\n",
      "+---------------+-------+-------+\n",
      "2024-02-14 14:51:14,020 - mmseg - INFO - Summary:\n",
      "2024-02-14 14:51:14,020 - mmseg - INFO - \n",
      "+-------+-------+-------+\n",
      "|  aAcc |  mIoU |  mAcc |\n",
      "+-------+-------+-------+\n",
      "| 97.55 | 84.88 | 93.54 |\n",
      "+-------+-------+-------+\n",
      "2024-02-14 14:51:14,020 - mmseg - INFO - Exp name: pizze_training_large.py\n",
      "2024-02-14 14:51:14,021 - mmseg - INFO - Iter(val) [10]\taAcc: 0.9755, mIoU: 0.8488, mAcc: 0.9354, IoU.bg: 0.9750, IoU.Anchovy: 0.7906, IoU.Olives: 0.8702, IoU.Salami: 0.7072, IoU.Red_Pepper: 0.8871, IoU.Yellow_Pepper: 0.8624, Acc.bg: 0.9837, Acc.Anchovy: 0.9488, Acc.Olives: 0.9069, Acc.Salami: 0.8746, Acc.Red_Pepper: 0.9461, Acc.Yellow_Pepper: 0.9522\n",
      "2024-02-14 14:51:35,335 - mmseg - INFO - Iter [2010/80000]\tlr: 1.400e-06, eta: 2 days, 2:54:01, time: 2.777, data_time: 0.662, memory: 23505, decode.loss_cls: 0.0005, decode.loss_mask: 0.2175, decode.loss_dice: 0.4093, decode.d0.loss_cls: 3.1296, decode.d0.loss_mask: 0.2282, decode.d0.loss_dice: 0.4226, decode.d1.loss_cls: 0.0112, decode.d1.loss_mask: 0.2180, decode.d1.loss_dice: 0.4160, decode.d2.loss_cls: 0.0026, decode.d2.loss_mask: 0.2172, decode.d2.loss_dice: 0.4077, decode.d3.loss_cls: 0.0017, decode.d3.loss_mask: 0.2176, decode.d3.loss_dice: 0.4061, decode.d4.loss_cls: 0.0010, decode.d4.loss_mask: 0.2176, decode.d4.loss_dice: 0.4037, decode.d5.loss_cls: 0.0007, decode.d5.loss_mask: 0.2189, decode.d5.loss_dice: 0.4092, decode.d6.loss_cls: 0.0006, decode.d6.loss_mask: 0.2186, decode.d6.loss_dice: 0.4057, decode.d7.loss_cls: 0.0005, decode.d7.loss_mask: 0.2195, decode.d7.loss_dice: 0.4100, decode.d8.loss_cls: 0.0006, decode.d8.loss_mask: 0.2188, decode.d8.loss_dice: 0.4121, loss: 9.4431\n",
      "2024-02-14 14:51:56,641 - mmseg - INFO - Iter [2020/80000]\tlr: 1.400e-06, eta: 2 days, 2:52:13, time: 2.131, data_time: 0.017, memory: 23505, decode.loss_cls: 0.0005, decode.loss_mask: 0.2508, decode.loss_dice: 0.4704, decode.d0.loss_cls: 3.1229, decode.d0.loss_mask: 0.2540, decode.d0.loss_dice: 0.4729, decode.d1.loss_cls: 0.0110, decode.d1.loss_mask: 0.2504, decode.d1.loss_dice: 0.4634, decode.d2.loss_cls: 0.0028, decode.d2.loss_mask: 0.2486, decode.d2.loss_dice: 0.4616, decode.d3.loss_cls: 0.0017, decode.d3.loss_mask: 0.2482, decode.d3.loss_dice: 0.4622, decode.d4.loss_cls: 0.0010, decode.d4.loss_mask: 0.2493, decode.d4.loss_dice: 0.4640, decode.d5.loss_cls: 0.0007, decode.d5.loss_mask: 0.2518, decode.d5.loss_dice: 0.4697, decode.d6.loss_cls: 0.0006, decode.d6.loss_mask: 0.2496, decode.d6.loss_dice: 0.4613, decode.d7.loss_cls: 0.0006, decode.d7.loss_mask: 0.2478, decode.d7.loss_dice: 0.4646, decode.d8.loss_cls: 0.0006, decode.d8.loss_mask: 0.2495, decode.d8.loss_dice: 0.4619, loss: 10.2946\n",
      "2024-02-14 14:52:17,970 - mmseg - INFO - Iter [2030/80000]\tlr: 1.399e-06, eta: 2 days, 2:50:27, time: 2.133, data_time: 0.017, memory: 23505, decode.loss_cls: 0.0004, decode.loss_mask: 0.2353, decode.loss_dice: 0.4481, decode.d0.loss_cls: 3.1160, decode.d0.loss_mask: 0.2439, decode.d0.loss_dice: 0.4622, decode.d1.loss_cls: 0.0093, decode.d1.loss_mask: 0.2383, decode.d1.loss_dice: 0.4537, decode.d2.loss_cls: 0.0025, decode.d2.loss_mask: 0.2369, decode.d2.loss_dice: 0.4500, decode.d3.loss_cls: 0.0017, decode.d3.loss_mask: 0.2362, decode.d3.loss_dice: 0.4485, decode.d4.loss_cls: 0.0010, decode.d4.loss_mask: 0.2363, decode.d4.loss_dice: 0.4502, decode.d5.loss_cls: 0.0006, decode.d5.loss_mask: 0.2341, decode.d5.loss_dice: 0.4520, decode.d6.loss_cls: 0.0006, decode.d6.loss_mask: 0.2366, decode.d6.loss_dice: 0.4552, decode.d7.loss_cls: 0.0005, decode.d7.loss_mask: 0.2378, decode.d7.loss_dice: 0.4539, decode.d8.loss_cls: 0.0005, decode.d8.loss_mask: 0.2378, decode.d8.loss_dice: 0.4524, loss: 10.0326\n",
      "2024-02-14 14:52:39,302 - mmseg - INFO - Iter [2040/80000]\tlr: 1.399e-06, eta: 2 days, 2:48:41, time: 2.133, data_time: 0.018, memory: 23505, decode.loss_cls: 0.0005, decode.loss_mask: 0.2342, decode.loss_dice: 0.4359, decode.d0.loss_cls: 3.1037, decode.d0.loss_mask: 0.2358, decode.d0.loss_dice: 0.4487, decode.d1.loss_cls: 0.0128, decode.d1.loss_mask: 0.2374, decode.d1.loss_dice: 0.4363, decode.d2.loss_cls: 0.0031, decode.d2.loss_mask: 0.2328, decode.d2.loss_dice: 0.4301, decode.d3.loss_cls: 0.0019, decode.d3.loss_mask: 0.2366, decode.d3.loss_dice: 0.4374, decode.d4.loss_cls: 0.0010, decode.d4.loss_mask: 0.2363, decode.d4.loss_dice: 0.4378, decode.d5.loss_cls: 0.0008, decode.d5.loss_mask: 0.2319, decode.d5.loss_dice: 0.4343, decode.d6.loss_cls: 0.0007, decode.d6.loss_mask: 0.2325, decode.d6.loss_dice: 0.4333, decode.d7.loss_cls: 0.0006, decode.d7.loss_mask: 0.2340, decode.d7.loss_dice: 0.4347, decode.d8.loss_cls: 0.0006, decode.d8.loss_mask: 0.2357, decode.d8.loss_dice: 0.4346, loss: 9.8358\n",
      "2024-02-14 14:53:00,628 - mmseg - INFO - Iter [2050/80000]\tlr: 1.399e-06, eta: 2 days, 2:46:57, time: 2.133, data_time: 0.017, memory: 23505, decode.loss_cls: 0.0004, decode.loss_mask: 0.1977, decode.loss_dice: 0.4107, decode.d0.loss_cls: 3.0945, decode.d0.loss_mask: 0.2003, decode.d0.loss_dice: 0.4183, decode.d1.loss_cls: 0.0128, decode.d1.loss_mask: 0.1986, decode.d1.loss_dice: 0.4150, decode.d2.loss_cls: 0.0028, decode.d2.loss_mask: 0.1957, decode.d2.loss_dice: 0.4125, decode.d3.loss_cls: 0.0016, decode.d3.loss_mask: 0.1952, decode.d3.loss_dice: 0.4091, decode.d4.loss_cls: 0.0007, decode.d4.loss_mask: 0.1960, decode.d4.loss_dice: 0.4121, decode.d5.loss_cls: 0.0006, decode.d5.loss_mask: 0.1963, decode.d5.loss_dice: 0.4095, decode.d6.loss_cls: 0.0005, decode.d6.loss_mask: 0.1977, decode.d6.loss_dice: 0.4132, decode.d7.loss_cls: 0.0005, decode.d7.loss_mask: 0.1975, decode.d7.loss_dice: 0.4080, decode.d8.loss_cls: 0.0005, decode.d8.loss_mask: 0.1973, decode.d8.loss_dice: 0.4162, loss: 9.2118\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-14 14:53:21,946 - mmseg - INFO - Iter [2060/80000]\tlr: 1.399e-06, eta: 2 days, 2:45:12, time: 2.132, data_time: 0.017, memory: 23505, decode.loss_cls: 0.0005, decode.loss_mask: 0.2165, decode.loss_dice: 0.4405, decode.d0.loss_cls: 3.0887, decode.d0.loss_mask: 0.2183, decode.d0.loss_dice: 0.4613, decode.d1.loss_cls: 0.0121, decode.d1.loss_mask: 0.2178, decode.d1.loss_dice: 0.4361, decode.d2.loss_cls: 0.0026, decode.d2.loss_mask: 0.2199, decode.d2.loss_dice: 0.4444, decode.d3.loss_cls: 0.0017, decode.d3.loss_mask: 0.2165, decode.d3.loss_dice: 0.4411, decode.d4.loss_cls: 0.0008, decode.d4.loss_mask: 0.2193, decode.d4.loss_dice: 0.4448, decode.d5.loss_cls: 0.0007, decode.d5.loss_mask: 0.2176, decode.d5.loss_dice: 0.4438, decode.d6.loss_cls: 0.0006, decode.d6.loss_mask: 0.2146, decode.d6.loss_dice: 0.4362, decode.d7.loss_cls: 0.0005, decode.d7.loss_mask: 0.2161, decode.d7.loss_dice: 0.4374, decode.d8.loss_cls: 0.0005, decode.d8.loss_mask: 0.2178, decode.d8.loss_dice: 0.4444, loss: 9.7131\n",
      "2024-02-14 14:53:43,262 - mmseg - INFO - Iter [2070/80000]\tlr: 1.399e-06, eta: 2 days, 2:43:29, time: 2.132, data_time: 0.017, memory: 23505, decode.loss_cls: 0.0005, decode.loss_mask: 0.2057, decode.loss_dice: 0.4072, decode.d0.loss_cls: 3.0770, decode.d0.loss_mask: 0.2060, decode.d0.loss_dice: 0.4221, decode.d1.loss_cls: 0.0134, decode.d1.loss_mask: 0.2058, decode.d1.loss_dice: 0.4160, decode.d2.loss_cls: 0.0026, decode.d2.loss_mask: 0.2047, decode.d2.loss_dice: 0.4131, decode.d3.loss_cls: 0.0015, decode.d3.loss_mask: 0.2086, decode.d3.loss_dice: 0.4087, decode.d4.loss_cls: 0.0007, decode.d4.loss_mask: 0.2071, decode.d4.loss_dice: 0.4088, decode.d5.loss_cls: 0.0006, decode.d5.loss_mask: 0.2094, decode.d5.loss_dice: 0.4091, decode.d6.loss_cls: 0.0006, decode.d6.loss_mask: 0.2043, decode.d6.loss_dice: 0.4085, decode.d7.loss_cls: 0.0005, decode.d7.loss_mask: 0.2064, decode.d7.loss_dice: 0.4039, decode.d8.loss_cls: 0.0006, decode.d8.loss_mask: 0.2053, decode.d8.loss_dice: 0.4088, loss: 9.2675\n",
      "2024-02-14 14:54:04,570 - mmseg - INFO - Iter [2080/80000]\tlr: 1.398e-06, eta: 2 days, 2:41:46, time: 2.131, data_time: 0.017, memory: 23505, decode.loss_cls: 0.0004, decode.loss_mask: 0.2151, decode.loss_dice: 0.4540, decode.d0.loss_cls: 3.0708, decode.d0.loss_mask: 0.2209, decode.d0.loss_dice: 0.4672, decode.d1.loss_cls: 0.0128, decode.d1.loss_mask: 0.2215, decode.d1.loss_dice: 0.4531, decode.d2.loss_cls: 0.0024, decode.d2.loss_mask: 0.2168, decode.d2.loss_dice: 0.4490, decode.d3.loss_cls: 0.0015, decode.d3.loss_mask: 0.2154, decode.d3.loss_dice: 0.4615, decode.d4.loss_cls: 0.0008, decode.d4.loss_mask: 0.2169, decode.d4.loss_dice: 0.4558, decode.d5.loss_cls: 0.0006, decode.d5.loss_mask: 0.2198, decode.d5.loss_dice: 0.4605, decode.d6.loss_cls: 0.0005, decode.d6.loss_mask: 0.2138, decode.d6.loss_dice: 0.4506, decode.d7.loss_cls: 0.0005, decode.d7.loss_mask: 0.2164, decode.d7.loss_dice: 0.4588, decode.d8.loss_cls: 0.0005, decode.d8.loss_mask: 0.2166, decode.d8.loss_dice: 0.4552, loss: 9.8299\n",
      "2024-02-14 14:54:25,873 - mmseg - INFO - Iter [2090/80000]\tlr: 1.398e-06, eta: 2 days, 2:40:03, time: 2.130, data_time: 0.017, memory: 23505, decode.loss_cls: 0.0005, decode.loss_mask: 0.1999, decode.loss_dice: 0.3878, decode.d0.loss_cls: 3.0629, decode.d0.loss_mask: 0.1999, decode.d0.loss_dice: 0.4071, decode.d1.loss_cls: 0.0134, decode.d1.loss_mask: 0.1940, decode.d1.loss_dice: 0.3881, decode.d2.loss_cls: 0.0026, decode.d2.loss_mask: 0.2000, decode.d2.loss_dice: 0.3901, decode.d3.loss_cls: 0.0015, decode.d3.loss_mask: 0.1984, decode.d3.loss_dice: 0.3865, decode.d4.loss_cls: 0.0008, decode.d4.loss_mask: 0.2010, decode.d4.loss_dice: 0.3903, decode.d5.loss_cls: 0.0006, decode.d5.loss_mask: 0.1986, decode.d5.loss_dice: 0.3920, decode.d6.loss_cls: 0.0006, decode.d6.loss_mask: 0.2010, decode.d6.loss_dice: 0.3849, decode.d7.loss_cls: 0.0005, decode.d7.loss_mask: 0.2001, decode.d7.loss_dice: 0.3877, decode.d8.loss_cls: 0.0006, decode.d8.loss_mask: 0.2001, decode.d8.loss_dice: 0.3832, loss: 8.9747\n",
      "2024-02-14 14:54:47,182 - mmseg - INFO - Iter [2100/80000]\tlr: 1.398e-06, eta: 2 days, 2:38:22, time: 2.131, data_time: 0.017, memory: 23505, decode.loss_cls: 0.0004, decode.loss_mask: 0.2095, decode.loss_dice: 0.4079, decode.d0.loss_cls: 3.0546, decode.d0.loss_mask: 0.2130, decode.d0.loss_dice: 0.4237, decode.d1.loss_cls: 0.0126, decode.d1.loss_mask: 0.2096, decode.d1.loss_dice: 0.4033, decode.d2.loss_cls: 0.0027, decode.d2.loss_mask: 0.2054, decode.d2.loss_dice: 0.4044, decode.d3.loss_cls: 0.0014, decode.d3.loss_mask: 0.2069, decode.d3.loss_dice: 0.4014, decode.d4.loss_cls: 0.0008, decode.d4.loss_mask: 0.2070, decode.d4.loss_dice: 0.4026, decode.d5.loss_cls: 0.0007, decode.d5.loss_mask: 0.2064, decode.d5.loss_dice: 0.4063, decode.d6.loss_cls: 0.0006, decode.d6.loss_mask: 0.2053, decode.d6.loss_dice: 0.4035, decode.d7.loss_cls: 0.0005, decode.d7.loss_mask: 0.2084, decode.d7.loss_dice: 0.4008, decode.d8.loss_cls: 0.0006, decode.d8.loss_mask: 0.2058, decode.d8.loss_dice: 0.4051, loss: 9.2110\n",
      "2024-02-14 14:55:08,506 - mmseg - INFO - Iter [2110/80000]\tlr: 1.398e-06, eta: 2 days, 2:36:42, time: 2.132, data_time: 0.017, memory: 23505, decode.loss_cls: 0.0005, decode.loss_mask: 0.1746, decode.loss_dice: 0.3752, decode.d0.loss_cls: 3.0445, decode.d0.loss_mask: 0.1782, decode.d0.loss_dice: 0.3836, decode.d1.loss_cls: 0.0152, decode.d1.loss_mask: 0.1788, decode.d1.loss_dice: 0.3719, decode.d2.loss_cls: 0.0029, decode.d2.loss_mask: 0.1767, decode.d2.loss_dice: 0.3786, decode.d3.loss_cls: 0.0015, decode.d3.loss_mask: 0.1754, decode.d3.loss_dice: 0.3721, decode.d4.loss_cls: 0.0007, decode.d4.loss_mask: 0.1755, decode.d4.loss_dice: 0.3765, decode.d5.loss_cls: 0.0006, decode.d5.loss_mask: 0.1738, decode.d5.loss_dice: 0.3771, decode.d6.loss_cls: 0.0005, decode.d6.loss_mask: 0.1752, decode.d6.loss_dice: 0.3779, decode.d7.loss_cls: 0.0005, decode.d7.loss_mask: 0.1741, decode.d7.loss_dice: 0.3743, decode.d8.loss_cls: 0.0005, decode.d8.loss_mask: 0.1738, decode.d8.loss_dice: 0.3748, loss: 8.5856\n",
      "2024-02-14 14:55:29,808 - mmseg - INFO - Iter [2120/80000]\tlr: 1.398e-06, eta: 2 days, 2:35:02, time: 2.130, data_time: 0.016, memory: 23505, decode.loss_cls: 0.0004, decode.loss_mask: 0.2096, decode.loss_dice: 0.4249, decode.d0.loss_cls: 3.0425, decode.d0.loss_mask: 0.2165, decode.d0.loss_dice: 0.4360, decode.d1.loss_cls: 0.0122, decode.d1.loss_mask: 0.2128, decode.d1.loss_dice: 0.4177, decode.d2.loss_cls: 0.0026, decode.d2.loss_mask: 0.2105, decode.d2.loss_dice: 0.4213, decode.d3.loss_cls: 0.0016, decode.d3.loss_mask: 0.2110, decode.d3.loss_dice: 0.4218, decode.d4.loss_cls: 0.0008, decode.d4.loss_mask: 0.2091, decode.d4.loss_dice: 0.4203, decode.d5.loss_cls: 0.0007, decode.d5.loss_mask: 0.2083, decode.d5.loss_dice: 0.4211, decode.d6.loss_cls: 0.0006, decode.d6.loss_mask: 0.2091, decode.d6.loss_dice: 0.4185, decode.d7.loss_cls: 0.0005, decode.d7.loss_mask: 0.2111, decode.d7.loss_dice: 0.4267, decode.d8.loss_cls: 0.0005, decode.d8.loss_mask: 0.2085, decode.d8.loss_dice: 0.4255, loss: 9.4029\n",
      "2024-02-14 14:55:51,127 - mmseg - INFO - Iter [2130/80000]\tlr: 1.398e-06, eta: 2 days, 2:33:23, time: 2.132, data_time: 0.017, memory: 23505, decode.loss_cls: 0.0004, decode.loss_mask: 0.2126, decode.loss_dice: 0.3989, decode.d0.loss_cls: 3.0330, decode.d0.loss_mask: 0.2177, decode.d0.loss_dice: 0.4234, decode.d1.loss_cls: 0.0126, decode.d1.loss_mask: 0.2138, decode.d1.loss_dice: 0.4078, decode.d2.loss_cls: 0.0025, decode.d2.loss_mask: 0.2154, decode.d2.loss_dice: 0.4038, decode.d3.loss_cls: 0.0014, decode.d3.loss_mask: 0.2145, decode.d3.loss_dice: 0.4052, decode.d4.loss_cls: 0.0008, decode.d4.loss_mask: 0.2148, decode.d4.loss_dice: 0.4051, decode.d5.loss_cls: 0.0006, decode.d5.loss_mask: 0.2142, decode.d5.loss_dice: 0.4044, decode.d6.loss_cls: 0.0005, decode.d6.loss_mask: 0.2125, decode.d6.loss_dice: 0.4010, decode.d7.loss_cls: 0.0005, decode.d7.loss_mask: 0.2147, decode.d7.loss_dice: 0.4095, decode.d8.loss_cls: 0.0005, decode.d8.loss_mask: 0.2111, decode.d8.loss_dice: 0.3971, loss: 9.2503\n",
      "2024-02-14 14:56:12,420 - mmseg - INFO - Iter [2140/80000]\tlr: 1.397e-06, eta: 2 days, 2:31:44, time: 2.129, data_time: 0.017, memory: 23505, decode.loss_cls: 0.0004, decode.loss_mask: 0.2376, decode.loss_dice: 0.4567, decode.d0.loss_cls: 3.0288, decode.d0.loss_mask: 0.2473, decode.d0.loss_dice: 0.4655, decode.d1.loss_cls: 0.0110, decode.d1.loss_mask: 0.2399, decode.d1.loss_dice: 0.4686, decode.d2.loss_cls: 0.0024, decode.d2.loss_mask: 0.2391, decode.d2.loss_dice: 0.4604, decode.d3.loss_cls: 0.0016, decode.d3.loss_mask: 0.2351, decode.d3.loss_dice: 0.4510, decode.d4.loss_cls: 0.0009, decode.d4.loss_mask: 0.2388, decode.d4.loss_dice: 0.4566, decode.d5.loss_cls: 0.0006, decode.d5.loss_mask: 0.2377, decode.d5.loss_dice: 0.4579, decode.d6.loss_cls: 0.0006, decode.d6.loss_mask: 0.2398, decode.d6.loss_dice: 0.4569, decode.d7.loss_cls: 0.0005, decode.d7.loss_mask: 0.2378, decode.d7.loss_dice: 0.4599, decode.d8.loss_cls: 0.0005, decode.d8.loss_mask: 0.2386, decode.d8.loss_dice: 0.4578, loss: 10.0302\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-14 14:56:33,710 - mmseg - INFO - Iter [2150/80000]\tlr: 1.397e-06, eta: 2 days, 2:30:05, time: 2.129, data_time: 0.016, memory: 23505, decode.loss_cls: 0.0004, decode.loss_mask: 0.2307, decode.loss_dice: 0.4265, decode.d0.loss_cls: 3.0193, decode.d0.loss_mask: 0.2417, decode.d0.loss_dice: 0.4419, decode.d1.loss_cls: 0.0120, decode.d1.loss_mask: 0.2292, decode.d1.loss_dice: 0.4262, decode.d2.loss_cls: 0.0023, decode.d2.loss_mask: 0.2320, decode.d2.loss_dice: 0.4284, decode.d3.loss_cls: 0.0013, decode.d3.loss_mask: 0.2308, decode.d3.loss_dice: 0.4286, decode.d4.loss_cls: 0.0008, decode.d4.loss_mask: 0.2298, decode.d4.loss_dice: 0.4264, decode.d5.loss_cls: 0.0006, decode.d5.loss_mask: 0.2284, decode.d5.loss_dice: 0.4268, decode.d6.loss_cls: 0.0005, decode.d6.loss_mask: 0.2314, decode.d6.loss_dice: 0.4277, decode.d7.loss_cls: 0.0005, decode.d7.loss_mask: 0.2309, decode.d7.loss_dice: 0.4341, decode.d8.loss_cls: 0.0005, decode.d8.loss_mask: 0.2316, decode.d8.loss_dice: 0.4292, loss: 9.6504\n",
      "2024-02-14 14:56:55,016 - mmseg - INFO - Iter [2160/80000]\tlr: 1.397e-06, eta: 2 days, 2:28:28, time: 2.131, data_time: 0.016, memory: 23505, decode.loss_cls: 0.0004, decode.loss_mask: 0.2401, decode.loss_dice: 0.4642, decode.d0.loss_cls: 3.0085, decode.d0.loss_mask: 0.2500, decode.d0.loss_dice: 0.4775, decode.d1.loss_cls: 0.0109, decode.d1.loss_mask: 0.2407, decode.d1.loss_dice: 0.4645, decode.d2.loss_cls: 0.0024, decode.d2.loss_mask: 0.2404, decode.d2.loss_dice: 0.4633, decode.d3.loss_cls: 0.0014, decode.d3.loss_mask: 0.2445, decode.d3.loss_dice: 0.4627, decode.d4.loss_cls: 0.0009, decode.d4.loss_mask: 0.2432, decode.d4.loss_dice: 0.4635, decode.d5.loss_cls: 0.0007, decode.d5.loss_mask: 0.2396, decode.d5.loss_dice: 0.4646, decode.d6.loss_cls: 0.0005, decode.d6.loss_mask: 0.2406, decode.d6.loss_dice: 0.4648, decode.d7.loss_cls: 0.0005, decode.d7.loss_mask: 0.2420, decode.d7.loss_dice: 0.4715, decode.d8.loss_cls: 0.0005, decode.d8.loss_mask: 0.2431, decode.d8.loss_dice: 0.4645, loss: 10.1120\n",
      "2024-02-14 14:57:16,325 - mmseg - INFO - Iter [2170/80000]\tlr: 1.397e-06, eta: 2 days, 2:26:52, time: 2.130, data_time: 0.017, memory: 23505, decode.loss_cls: 0.0004, decode.loss_mask: 0.2059, decode.loss_dice: 0.4008, decode.d0.loss_cls: 3.0014, decode.d0.loss_mask: 0.2108, decode.d0.loss_dice: 0.4237, decode.d1.loss_cls: 0.0114, decode.d1.loss_mask: 0.2078, decode.d1.loss_dice: 0.4101, decode.d2.loss_cls: 0.0021, decode.d2.loss_mask: 0.2034, decode.d2.loss_dice: 0.4013, decode.d3.loss_cls: 0.0014, decode.d3.loss_mask: 0.2058, decode.d3.loss_dice: 0.4019, decode.d4.loss_cls: 0.0007, decode.d4.loss_mask: 0.2052, decode.d4.loss_dice: 0.4032, decode.d5.loss_cls: 0.0006, decode.d5.loss_mask: 0.2060, decode.d5.loss_dice: 0.4064, decode.d6.loss_cls: 0.0005, decode.d6.loss_mask: 0.2070, decode.d6.loss_dice: 0.4048, decode.d7.loss_cls: 0.0005, decode.d7.loss_mask: 0.2058, decode.d7.loss_dice: 0.4090, decode.d8.loss_cls: 0.0005, decode.d8.loss_mask: 0.2031, decode.d8.loss_dice: 0.4004, loss: 9.1419\n",
      "2024-02-14 14:57:37,634 - mmseg - INFO - Iter [2180/80000]\tlr: 1.397e-06, eta: 2 days, 2:25:16, time: 2.132, data_time: 0.018, memory: 23505, decode.loss_cls: 0.0004, decode.loss_mask: 0.2116, decode.loss_dice: 0.4026, decode.d0.loss_cls: 2.9927, decode.d0.loss_mask: 0.2142, decode.d0.loss_dice: 0.4143, decode.d1.loss_cls: 0.0111, decode.d1.loss_mask: 0.2123, decode.d1.loss_dice: 0.4019, decode.d2.loss_cls: 0.0023, decode.d2.loss_mask: 0.2082, decode.d2.loss_dice: 0.4044, decode.d3.loss_cls: 0.0014, decode.d3.loss_mask: 0.2076, decode.d3.loss_dice: 0.4044, decode.d4.loss_cls: 0.0009, decode.d4.loss_mask: 0.2067, decode.d4.loss_dice: 0.3976, decode.d5.loss_cls: 0.0007, decode.d5.loss_mask: 0.2089, decode.d5.loss_dice: 0.4098, decode.d6.loss_cls: 0.0006, decode.d6.loss_mask: 0.2112, decode.d6.loss_dice: 0.4079, decode.d7.loss_cls: 0.0005, decode.d7.loss_mask: 0.2119, decode.d7.loss_dice: 0.4056, decode.d8.loss_cls: 0.0005, decode.d8.loss_mask: 0.2107, decode.d8.loss_dice: 0.4025, loss: 9.1655\n",
      "2024-02-14 14:57:58,942 - mmseg - INFO - Iter [2190/80000]\tlr: 1.397e-06, eta: 2 days, 2:23:41, time: 2.131, data_time: 0.017, memory: 23505, decode.loss_cls: 0.0004, decode.loss_mask: 0.2211, decode.loss_dice: 0.4470, decode.d0.loss_cls: 2.9839, decode.d0.loss_mask: 0.2351, decode.d0.loss_dice: 0.4580, decode.d1.loss_cls: 0.0118, decode.d1.loss_mask: 0.2228, decode.d1.loss_dice: 0.4488, decode.d2.loss_cls: 0.0024, decode.d2.loss_mask: 0.2238, decode.d2.loss_dice: 0.4551, decode.d3.loss_cls: 0.0013, decode.d3.loss_mask: 0.2251, decode.d3.loss_dice: 0.4494, decode.d4.loss_cls: 0.0007, decode.d4.loss_mask: 0.2220, decode.d4.loss_dice: 0.4494, decode.d5.loss_cls: 0.0006, decode.d5.loss_mask: 0.2229, decode.d5.loss_dice: 0.4494, decode.d6.loss_cls: 0.0005, decode.d6.loss_mask: 0.2210, decode.d6.loss_dice: 0.4499, decode.d7.loss_cls: 0.0005, decode.d7.loss_mask: 0.2211, decode.d7.loss_dice: 0.4490, decode.d8.loss_cls: 0.0005, decode.d8.loss_mask: 0.2201, decode.d8.loss_dice: 0.4431, loss: 9.7367\n",
      "2024-02-14 14:58:20,262 - mmseg - INFO - Iter [2200/80000]\tlr: 1.396e-06, eta: 2 days, 2:22:07, time: 2.132, data_time: 0.017, memory: 23505, decode.loss_cls: 0.0004, decode.loss_mask: 0.2312, decode.loss_dice: 0.4265, decode.d0.loss_cls: 2.9783, decode.d0.loss_mask: 0.2329, decode.d0.loss_dice: 0.4398, decode.d1.loss_cls: 0.0097, decode.d1.loss_mask: 0.2335, decode.d1.loss_dice: 0.4354, decode.d2.loss_cls: 0.0021, decode.d2.loss_mask: 0.2308, decode.d2.loss_dice: 0.4338, decode.d3.loss_cls: 0.0016, decode.d3.loss_mask: 0.2350, decode.d3.loss_dice: 0.4304, decode.d4.loss_cls: 0.0007, decode.d4.loss_mask: 0.2338, decode.d4.loss_dice: 0.4304, decode.d5.loss_cls: 0.0006, decode.d5.loss_mask: 0.2363, decode.d5.loss_dice: 0.4331, decode.d6.loss_cls: 0.0006, decode.d6.loss_mask: 0.2336, decode.d6.loss_dice: 0.4254, decode.d7.loss_cls: 0.0005, decode.d7.loss_mask: 0.2338, decode.d7.loss_dice: 0.4275, decode.d8.loss_cls: 0.0005, decode.d8.loss_mask: 0.2342, decode.d8.loss_dice: 0.4252, loss: 9.6375\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 40/40, 6.2 task/s, elapsed: 6s, ETA:     0s\n",
      "\n",
      "2024-02-14 14:58:26,703 - mmseg - INFO - per class results:\n",
      "2024-02-14 14:58:26,704 - mmseg - INFO - \n",
      "+---------------+-------+-------+\n",
      "|     Class     |  IoU  |  Acc  |\n",
      "+---------------+-------+-------+\n",
      "|       bg      | 97.61 | 98.81 |\n",
      "|    Anchovy    | 81.86 | 93.36 |\n",
      "|     Olives    | 87.68 | 91.55 |\n",
      "|     Salami    | 71.54 | 84.41 |\n",
      "|   Red_Pepper  | 88.79 | 92.57 |\n",
      "| Yellow_Pepper | 86.81 | 94.74 |\n",
      "+---------------+-------+-------+\n",
      "2024-02-14 14:58:26,704 - mmseg - INFO - Summary:\n",
      "2024-02-14 14:58:26,704 - mmseg - INFO - \n",
      "+-------+-------+-------+\n",
      "|  aAcc |  mIoU |  mAcc |\n",
      "+-------+-------+-------+\n",
      "| 97.69 | 85.72 | 92.57 |\n",
      "+-------+-------+-------+\n",
      "2024-02-14 14:58:27,207 - mmseg - INFO - The previous best checkpoint /workspace/ViT-Adapter/segmentation/work_dirs/pizze_training_large/best_mIoU_iter_1800.pth was removed\n",
      "2024-02-14 14:58:39,287 - mmseg - INFO - Now best checkpoint is saved as best_mIoU_iter_2200.pth.\n",
      "2024-02-14 14:58:39,287 - mmseg - INFO - Best mIoU is 0.8572 at 2200 iter.\n",
      "2024-02-14 14:58:39,288 - mmseg - INFO - Iter(val) [10]\taAcc: 0.9769, mIoU: 0.8572, mAcc: 0.9257, IoU.bg: 0.9761, IoU.Anchovy: 0.8186, IoU.Olives: 0.8768, IoU.Salami: 0.7154, IoU.Red_Pepper: 0.8879, IoU.Yellow_Pepper: 0.8681, Acc.bg: 0.9881, Acc.Anchovy: 0.9336, Acc.Olives: 0.9155, Acc.Salami: 0.8441, Acc.Red_Pepper: 0.9257, Acc.Yellow_Pepper: 0.9474\n",
      "2024-02-14 14:59:00,557 - mmseg - INFO - Iter [2210/80000]\tlr: 1.396e-06, eta: 2 days, 2:31:42, time: 4.030, data_time: 1.920, memory: 23505, decode.loss_cls: 0.0004, decode.loss_mask: 0.2506, decode.loss_dice: 0.4472, decode.d0.loss_cls: 2.9711, decode.d0.loss_mask: 0.2575, decode.d0.loss_dice: 0.4688, decode.d1.loss_cls: 0.0120, decode.d1.loss_mask: 0.2491, decode.d1.loss_dice: 0.4617, decode.d2.loss_cls: 0.0024, decode.d2.loss_mask: 0.2496, decode.d2.loss_dice: 0.4546, decode.d3.loss_cls: 0.0015, decode.d3.loss_mask: 0.2511, decode.d3.loss_dice: 0.4516, decode.d4.loss_cls: 0.0008, decode.d4.loss_mask: 0.2506, decode.d4.loss_dice: 0.4529, decode.d5.loss_cls: 0.0006, decode.d5.loss_mask: 0.2516, decode.d5.loss_dice: 0.4479, decode.d6.loss_cls: 0.0006, decode.d6.loss_mask: 0.2501, decode.d6.loss_dice: 0.4472, decode.d7.loss_cls: 0.0005, decode.d7.loss_mask: 0.2509, decode.d7.loss_dice: 0.4510, decode.d8.loss_cls: 0.0005, decode.d8.loss_mask: 0.2515, decode.d8.loss_dice: 0.4564, loss: 10.0424\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-14 14:59:21,850 - mmseg - INFO - Iter [2220/80000]\tlr: 1.396e-06, eta: 2 days, 2:30:05, time: 2.129, data_time: 0.017, memory: 23505, decode.loss_cls: 0.0005, decode.loss_mask: 0.2295, decode.loss_dice: 0.4469, decode.d0.loss_cls: 2.9624, decode.d0.loss_mask: 0.2303, decode.d0.loss_dice: 0.4468, decode.d1.loss_cls: 0.0103, decode.d1.loss_mask: 0.2317, decode.d1.loss_dice: 0.4440, decode.d2.loss_cls: 0.0022, decode.d2.loss_mask: 0.2306, decode.d2.loss_dice: 0.4420, decode.d3.loss_cls: 0.0014, decode.d3.loss_mask: 0.2310, decode.d3.loss_dice: 0.4463, decode.d4.loss_cls: 0.0008, decode.d4.loss_mask: 0.2308, decode.d4.loss_dice: 0.4445, decode.d5.loss_cls: 0.0006, decode.d5.loss_mask: 0.2286, decode.d5.loss_dice: 0.4410, decode.d6.loss_cls: 0.0006, decode.d6.loss_mask: 0.2332, decode.d6.loss_dice: 0.4495, decode.d7.loss_cls: 0.0005, decode.d7.loss_mask: 0.2338, decode.d7.loss_dice: 0.4502, decode.d8.loss_cls: 0.0005, decode.d8.loss_mask: 0.2309, decode.d8.loss_dice: 0.4426, loss: 9.7441\n",
      "2024-02-14 14:59:43,207 - mmseg - INFO - Iter [2230/80000]\tlr: 1.396e-06, eta: 2 days, 2:28:32, time: 2.136, data_time: 0.017, memory: 23505, decode.loss_cls: 0.0004, decode.loss_mask: 0.2428, decode.loss_dice: 0.4427, decode.d0.loss_cls: 2.9552, decode.d0.loss_mask: 0.2507, decode.d0.loss_dice: 0.4655, decode.d1.loss_cls: 0.0103, decode.d1.loss_mask: 0.2478, decode.d1.loss_dice: 0.4482, decode.d2.loss_cls: 0.0022, decode.d2.loss_mask: 0.2430, decode.d2.loss_dice: 0.4450, decode.d3.loss_cls: 0.0014, decode.d3.loss_mask: 0.2438, decode.d3.loss_dice: 0.4510, decode.d4.loss_cls: 0.0007, decode.d4.loss_mask: 0.2433, decode.d4.loss_dice: 0.4470, decode.d5.loss_cls: 0.0006, decode.d5.loss_mask: 0.2437, decode.d5.loss_dice: 0.4527, decode.d6.loss_cls: 0.0006, decode.d6.loss_mask: 0.2452, decode.d6.loss_dice: 0.4508, decode.d7.loss_cls: 0.0005, decode.d7.loss_mask: 0.2469, decode.d7.loss_dice: 0.4493, decode.d8.loss_cls: 0.0005, decode.d8.loss_mask: 0.2465, decode.d8.loss_dice: 0.4493, loss: 9.9277\n",
      "2024-02-14 15:00:04,499 - mmseg - INFO - Iter [2240/80000]\tlr: 1.396e-06, eta: 2 days, 2:26:56, time: 2.129, data_time: 0.017, memory: 23505, decode.loss_cls: 0.0004, decode.loss_mask: 0.2399, decode.loss_dice: 0.4841, decode.d0.loss_cls: 2.9473, decode.d0.loss_mask: 0.2462, decode.d0.loss_dice: 0.4882, decode.d1.loss_cls: 0.0099, decode.d1.loss_mask: 0.2388, decode.d1.loss_dice: 0.4817, decode.d2.loss_cls: 0.0022, decode.d2.loss_mask: 0.2407, decode.d2.loss_dice: 0.4808, decode.d3.loss_cls: 0.0013, decode.d3.loss_mask: 0.2362, decode.d3.loss_dice: 0.4772, decode.d4.loss_cls: 0.0007, decode.d4.loss_mask: 0.2381, decode.d4.loss_dice: 0.4787, decode.d5.loss_cls: 0.0006, decode.d5.loss_mask: 0.2366, decode.d5.loss_dice: 0.4776, decode.d6.loss_cls: 0.0005, decode.d6.loss_mask: 0.2380, decode.d6.loss_dice: 0.4848, decode.d7.loss_cls: 0.0005, decode.d7.loss_mask: 0.2378, decode.d7.loss_dice: 0.4861, decode.d8.loss_cls: 0.0005, decode.d8.loss_mask: 0.2366, decode.d8.loss_dice: 0.4777, loss: 10.1699\n",
      "2024-02-14 15:00:27,860 - mmseg - INFO - Iter [2250/80000]\tlr: 1.395e-06, eta: 2 days, 2:26:33, time: 2.336, data_time: 0.225, memory: 23505, decode.loss_cls: 0.0004, decode.loss_mask: 0.2380, decode.loss_dice: 0.4333, decode.d0.loss_cls: 2.9393, decode.d0.loss_mask: 0.2425, decode.d0.loss_dice: 0.4502, decode.d1.loss_cls: 0.0095, decode.d1.loss_mask: 0.2408, decode.d1.loss_dice: 0.4369, decode.d2.loss_cls: 0.0022, decode.d2.loss_mask: 0.2376, decode.d2.loss_dice: 0.4328, decode.d3.loss_cls: 0.0014, decode.d3.loss_mask: 0.2434, decode.d3.loss_dice: 0.4359, decode.d4.loss_cls: 0.0008, decode.d4.loss_mask: 0.2425, decode.d4.loss_dice: 0.4340, decode.d5.loss_cls: 0.0006, decode.d5.loss_mask: 0.2412, decode.d5.loss_dice: 0.4332, decode.d6.loss_cls: 0.0006, decode.d6.loss_mask: 0.2425, decode.d6.loss_dice: 0.4361, decode.d7.loss_cls: 0.0005, decode.d7.loss_mask: 0.2383, decode.d7.loss_dice: 0.4271, decode.d8.loss_cls: 0.0005, decode.d8.loss_mask: 0.2422, decode.d8.loss_dice: 0.4344, loss: 9.7187\n",
      "2024-02-14 15:00:49,168 - mmseg - INFO - Iter [2260/80000]\tlr: 1.395e-06, eta: 2 days, 2:24:59, time: 2.131, data_time: 0.017, memory: 23505, decode.loss_cls: 0.0004, decode.loss_mask: 0.2220, decode.loss_dice: 0.4189, decode.d0.loss_cls: 2.9290, decode.d0.loss_mask: 0.2257, decode.d0.loss_dice: 0.4354, decode.d1.loss_cls: 0.0118, decode.d1.loss_mask: 0.2243, decode.d1.loss_dice: 0.4146, decode.d2.loss_cls: 0.0023, decode.d2.loss_mask: 0.2221, decode.d2.loss_dice: 0.4174, decode.d3.loss_cls: 0.0012, decode.d3.loss_mask: 0.2216, decode.d3.loss_dice: 0.4177, decode.d4.loss_cls: 0.0007, decode.d4.loss_mask: 0.2201, decode.d4.loss_dice: 0.4240, decode.d5.loss_cls: 0.0006, decode.d5.loss_mask: 0.2208, decode.d5.loss_dice: 0.4207, decode.d6.loss_cls: 0.0005, decode.d6.loss_mask: 0.2229, decode.d6.loss_dice: 0.4234, decode.d7.loss_cls: 0.0005, decode.d7.loss_mask: 0.2210, decode.d7.loss_dice: 0.4169, decode.d8.loss_cls: 0.0005, decode.d8.loss_mask: 0.2221, decode.d8.loss_dice: 0.4206, loss: 9.3798\n",
      "2024-02-14 15:01:10,467 - mmseg - INFO - Iter [2270/80000]\tlr: 1.395e-06, eta: 2 days, 2:23:26, time: 2.130, data_time: 0.017, memory: 23505, decode.loss_cls: 0.0004, decode.loss_mask: 0.2419, decode.loss_dice: 0.4466, decode.d0.loss_cls: 2.9257, decode.d0.loss_mask: 0.2477, decode.d0.loss_dice: 0.4713, decode.d1.loss_cls: 0.0171, decode.d1.loss_mask: 0.2466, decode.d1.loss_dice: 0.4459, decode.d2.loss_cls: 0.0035, decode.d2.loss_mask: 0.2425, decode.d2.loss_dice: 0.4486, decode.d3.loss_cls: 0.0015, decode.d3.loss_mask: 0.2399, decode.d3.loss_dice: 0.4433, decode.d4.loss_cls: 0.0008, decode.d4.loss_mask: 0.2360, decode.d4.loss_dice: 0.4452, decode.d5.loss_cls: 0.0006, decode.d5.loss_mask: 0.2395, decode.d5.loss_dice: 0.4419, decode.d6.loss_cls: 0.0005, decode.d6.loss_mask: 0.2400, decode.d6.loss_dice: 0.4465, decode.d7.loss_cls: 0.0005, decode.d7.loss_mask: 0.2420, decode.d7.loss_dice: 0.4447, decode.d8.loss_cls: 0.0005, decode.d8.loss_mask: 0.2425, decode.d8.loss_dice: 0.4422, loss: 9.8461\n",
      "2024-02-14 15:01:31,755 - mmseg - INFO - Iter [2280/80000]\tlr: 1.395e-06, eta: 2 days, 2:21:53, time: 2.129, data_time: 0.017, memory: 23505, decode.loss_cls: 0.0004, decode.loss_mask: 0.2068, decode.loss_dice: 0.4006, decode.d0.loss_cls: 2.9146, decode.d0.loss_mask: 0.2107, decode.d0.loss_dice: 0.4134, decode.d1.loss_cls: 0.0106, decode.d1.loss_mask: 0.2076, decode.d1.loss_dice: 0.4052, decode.d2.loss_cls: 0.0022, decode.d2.loss_mask: 0.2055, decode.d2.loss_dice: 0.4020, decode.d3.loss_cls: 0.0012, decode.d3.loss_mask: 0.2085, decode.d3.loss_dice: 0.4000, decode.d4.loss_cls: 0.0007, decode.d4.loss_mask: 0.2082, decode.d4.loss_dice: 0.4002, decode.d5.loss_cls: 0.0006, decode.d5.loss_mask: 0.2074, decode.d5.loss_dice: 0.4045, decode.d6.loss_cls: 0.0005, decode.d6.loss_mask: 0.2051, decode.d6.loss_dice: 0.4017, decode.d7.loss_cls: 0.0005, decode.d7.loss_mask: 0.2074, decode.d7.loss_dice: 0.4042, decode.d8.loss_cls: 0.0005, decode.d8.loss_mask: 0.2057, decode.d8.loss_dice: 0.4062, loss: 9.0427\n",
      "2024-02-14 15:01:53,045 - mmseg - INFO - Iter [2290/80000]\tlr: 1.395e-06, eta: 2 days, 2:20:20, time: 2.129, data_time: 0.017, memory: 23505, decode.loss_cls: 0.0004, decode.loss_mask: 0.2023, decode.loss_dice: 0.4044, decode.d0.loss_cls: 2.9044, decode.d0.loss_mask: 0.2017, decode.d0.loss_dice: 0.4149, decode.d1.loss_cls: 0.0118, decode.d1.loss_mask: 0.1971, decode.d1.loss_dice: 0.3993, decode.d2.loss_cls: 0.0019, decode.d2.loss_mask: 0.1972, decode.d2.loss_dice: 0.4053, decode.d3.loss_cls: 0.0012, decode.d3.loss_mask: 0.2004, decode.d3.loss_dice: 0.4047, decode.d4.loss_cls: 0.0007, decode.d4.loss_mask: 0.2009, decode.d4.loss_dice: 0.4029, decode.d5.loss_cls: 0.0006, decode.d5.loss_mask: 0.2013, decode.d5.loss_dice: 0.4021, decode.d6.loss_cls: 0.0005, decode.d6.loss_mask: 0.2005, decode.d6.loss_dice: 0.4055, decode.d7.loss_cls: 0.0005, decode.d7.loss_mask: 0.1992, decode.d7.loss_dice: 0.4024, decode.d8.loss_cls: 0.0005, decode.d8.loss_mask: 0.1969, decode.d8.loss_dice: 0.3997, loss: 8.9613\n",
      "2024-02-14 15:02:14,329 - mmseg - INFO - Iter [2300/80000]\tlr: 1.395e-06, eta: 2 days, 2:18:48, time: 2.128, data_time: 0.017, memory: 23505, decode.loss_cls: 0.0004, decode.loss_mask: 0.2370, decode.loss_dice: 0.4348, decode.d0.loss_cls: 2.8987, decode.d0.loss_mask: 0.2377, decode.d0.loss_dice: 0.4601, decode.d1.loss_cls: 0.0105, decode.d1.loss_mask: 0.2400, decode.d1.loss_dice: 0.4430, decode.d2.loss_cls: 0.0020, decode.d2.loss_mask: 0.2396, decode.d2.loss_dice: 0.4441, decode.d3.loss_cls: 0.0011, decode.d3.loss_mask: 0.2396, decode.d3.loss_dice: 0.4420, decode.d4.loss_cls: 0.0008, decode.d4.loss_mask: 0.2371, decode.d4.loss_dice: 0.4397, decode.d5.loss_cls: 0.0006, decode.d5.loss_mask: 0.2398, decode.d5.loss_dice: 0.4403, decode.d6.loss_cls: 0.0005, decode.d6.loss_mask: 0.2367, decode.d6.loss_dice: 0.4403, decode.d7.loss_cls: 0.0005, decode.d7.loss_mask: 0.2386, decode.d7.loss_dice: 0.4372, decode.d8.loss_cls: 0.0005, decode.d8.loss_mask: 0.2382, decode.d8.loss_dice: 0.4355, loss: 9.7167\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-14 15:02:35,610 - mmseg - INFO - Iter [2310/80000]\tlr: 1.394e-06, eta: 2 days, 2:17:16, time: 2.128, data_time: 0.017, memory: 23505, decode.loss_cls: 0.0004, decode.loss_mask: 0.2201, decode.loss_dice: 0.4150, decode.d0.loss_cls: 2.8914, decode.d0.loss_mask: 0.2265, decode.d0.loss_dice: 0.4347, decode.d1.loss_cls: 0.0101, decode.d1.loss_mask: 0.2184, decode.d1.loss_dice: 0.4081, decode.d2.loss_cls: 0.0019, decode.d2.loss_mask: 0.2220, decode.d2.loss_dice: 0.4147, decode.d3.loss_cls: 0.0012, decode.d3.loss_mask: 0.2228, decode.d3.loss_dice: 0.4194, decode.d4.loss_cls: 0.0008, decode.d4.loss_mask: 0.2223, decode.d4.loss_dice: 0.4205, decode.d5.loss_cls: 0.0006, decode.d5.loss_mask: 0.2210, decode.d5.loss_dice: 0.4143, decode.d6.loss_cls: 0.0005, decode.d6.loss_mask: 0.2214, decode.d6.loss_dice: 0.4161, decode.d7.loss_cls: 0.0005, decode.d7.loss_mask: 0.2210, decode.d7.loss_dice: 0.4155, decode.d8.loss_cls: 0.0005, decode.d8.loss_mask: 0.2214, decode.d8.loss_dice: 0.4127, loss: 9.2958\n",
      "2024-02-14 15:02:56,935 - mmseg - INFO - Iter [2320/80000]\tlr: 1.394e-06, eta: 2 days, 2:15:47, time: 2.133, data_time: 0.017, memory: 23505, decode.loss_cls: 0.0004, decode.loss_mask: 0.2317, decode.loss_dice: 0.4049, decode.d0.loss_cls: 2.8849, decode.d0.loss_mask: 0.2334, decode.d0.loss_dice: 0.4276, decode.d1.loss_cls: 0.0092, decode.d1.loss_mask: 0.2334, decode.d1.loss_dice: 0.4075, decode.d2.loss_cls: 0.0018, decode.d2.loss_mask: 0.2296, decode.d2.loss_dice: 0.4043, decode.d3.loss_cls: 0.0014, decode.d3.loss_mask: 0.2295, decode.d3.loss_dice: 0.4095, decode.d4.loss_cls: 0.0009, decode.d4.loss_mask: 0.2336, decode.d4.loss_dice: 0.4080, decode.d5.loss_cls: 0.0006, decode.d5.loss_mask: 0.2298, decode.d5.loss_dice: 0.4059, decode.d6.loss_cls: 0.0006, decode.d6.loss_mask: 0.2283, decode.d6.loss_dice: 0.4031, decode.d7.loss_cls: 0.0005, decode.d7.loss_mask: 0.2316, decode.d7.loss_dice: 0.4075, decode.d8.loss_cls: 0.0005, decode.d8.loss_mask: 0.2264, decode.d8.loss_dice: 0.3978, loss: 9.2843\n",
      "2024-02-14 15:03:18,214 - mmseg - INFO - Iter [2330/80000]\tlr: 1.394e-06, eta: 2 days, 2:14:16, time: 2.128, data_time: 0.017, memory: 23505, decode.loss_cls: 0.0004, decode.loss_mask: 0.2196, decode.loss_dice: 0.4313, decode.d0.loss_cls: 2.8732, decode.d0.loss_mask: 0.2253, decode.d0.loss_dice: 0.4464, decode.d1.loss_cls: 0.0105, decode.d1.loss_mask: 0.2206, decode.d1.loss_dice: 0.4318, decode.d2.loss_cls: 0.0018, decode.d2.loss_mask: 0.2187, decode.d2.loss_dice: 0.4291, decode.d3.loss_cls: 0.0011, decode.d3.loss_mask: 0.2178, decode.d3.loss_dice: 0.4332, decode.d4.loss_cls: 0.0006, decode.d4.loss_mask: 0.2192, decode.d4.loss_dice: 0.4335, decode.d5.loss_cls: 0.0005, decode.d5.loss_mask: 0.2192, decode.d5.loss_dice: 0.4346, decode.d6.loss_cls: 0.0005, decode.d6.loss_mask: 0.2158, decode.d6.loss_dice: 0.4277, decode.d7.loss_cls: 0.0004, decode.d7.loss_mask: 0.2175, decode.d7.loss_dice: 0.4289, decode.d8.loss_cls: 0.0004, decode.d8.loss_mask: 0.2164, decode.d8.loss_dice: 0.4248, loss: 9.4009\n",
      "2024-02-14 15:03:39,494 - mmseg - INFO - Iter [2340/80000]\tlr: 1.394e-06, eta: 2 days, 2:12:47, time: 2.128, data_time: 0.017, memory: 23505, decode.loss_cls: 0.0004, decode.loss_mask: 0.2632, decode.loss_dice: 0.4768, decode.d0.loss_cls: 2.8696, decode.d0.loss_mask: 0.2752, decode.d0.loss_dice: 0.4987, decode.d1.loss_cls: 0.0086, decode.d1.loss_mask: 0.2666, decode.d1.loss_dice: 0.4761, decode.d2.loss_cls: 0.0018, decode.d2.loss_mask: 0.2638, decode.d2.loss_dice: 0.4727, decode.d3.loss_cls: 0.0013, decode.d3.loss_mask: 0.2638, decode.d3.loss_dice: 0.4708, decode.d4.loss_cls: 0.0006, decode.d4.loss_mask: 0.2602, decode.d4.loss_dice: 0.4660, decode.d5.loss_cls: 0.0005, decode.d5.loss_mask: 0.2608, decode.d5.loss_dice: 0.4713, decode.d6.loss_cls: 0.0005, decode.d6.loss_mask: 0.2629, decode.d6.loss_dice: 0.4721, decode.d7.loss_cls: 0.0004, decode.d7.loss_mask: 0.2616, decode.d7.loss_dice: 0.4655, decode.d8.loss_cls: 0.0005, decode.d8.loss_mask: 0.2644, decode.d8.loss_dice: 0.4729, loss: 10.2694\n",
      "2024-02-14 15:04:00,789 - mmseg - INFO - Iter [2350/80000]\tlr: 1.394e-06, eta: 2 days, 2:11:18, time: 2.129, data_time: 0.017, memory: 23505, decode.loss_cls: 0.0004, decode.loss_mask: 0.2321, decode.loss_dice: 0.4315, decode.d0.loss_cls: 2.8609, decode.d0.loss_mask: 0.2354, decode.d0.loss_dice: 0.4552, decode.d1.loss_cls: 0.0091, decode.d1.loss_mask: 0.2314, decode.d1.loss_dice: 0.4388, decode.d2.loss_cls: 0.0019, decode.d2.loss_mask: 0.2309, decode.d2.loss_dice: 0.4326, decode.d3.loss_cls: 0.0013, decode.d3.loss_mask: 0.2295, decode.d3.loss_dice: 0.4355, decode.d4.loss_cls: 0.0007, decode.d4.loss_mask: 0.2322, decode.d4.loss_dice: 0.4369, decode.d5.loss_cls: 0.0005, decode.d5.loss_mask: 0.2303, decode.d5.loss_dice: 0.4352, decode.d6.loss_cls: 0.0005, decode.d6.loss_mask: 0.2329, decode.d6.loss_dice: 0.4382, decode.d7.loss_cls: 0.0004, decode.d7.loss_mask: 0.2343, decode.d7.loss_dice: 0.4398, decode.d8.loss_cls: 0.0005, decode.d8.loss_mask: 0.2318, decode.d8.loss_dice: 0.4374, loss: 9.5777\n",
      "2024-02-14 15:04:22,077 - mmseg - INFO - Iter [2360/80000]\tlr: 1.393e-06, eta: 2 days, 2:09:49, time: 2.129, data_time: 0.017, memory: 23505, decode.loss_cls: 0.0004, decode.loss_mask: 0.1938, decode.loss_dice: 0.4043, decode.d0.loss_cls: 2.8461, decode.d0.loss_mask: 0.1955, decode.d0.loss_dice: 0.4207, decode.d1.loss_cls: 0.0137, decode.d1.loss_mask: 0.1959, decode.d1.loss_dice: 0.4040, decode.d2.loss_cls: 0.0022, decode.d2.loss_mask: 0.1962, decode.d2.loss_dice: 0.4140, decode.d3.loss_cls: 0.0012, decode.d3.loss_mask: 0.1940, decode.d3.loss_dice: 0.4054, decode.d4.loss_cls: 0.0006, decode.d4.loss_mask: 0.1948, decode.d4.loss_dice: 0.4133, decode.d5.loss_cls: 0.0006, decode.d5.loss_mask: 0.1960, decode.d5.loss_dice: 0.4073, decode.d6.loss_cls: 0.0005, decode.d6.loss_mask: 0.1941, decode.d6.loss_dice: 0.4053, decode.d7.loss_cls: 0.0005, decode.d7.loss_mask: 0.1951, decode.d7.loss_dice: 0.4076, decode.d8.loss_cls: 0.0005, decode.d8.loss_mask: 0.1949, decode.d8.loss_dice: 0.4085, loss: 8.9071\n",
      "2024-02-14 15:04:43,406 - mmseg - INFO - Iter [2370/80000]\tlr: 1.393e-06, eta: 2 days, 2:08:23, time: 2.133, data_time: 0.015, memory: 23505, decode.loss_cls: 0.0004, decode.loss_mask: 0.2178, decode.loss_dice: 0.4267, decode.d0.loss_cls: 2.8428, decode.d0.loss_mask: 0.2242, decode.d0.loss_dice: 0.4486, decode.d1.loss_cls: 0.0315, decode.d1.loss_mask: 0.2204, decode.d1.loss_dice: 0.4285, decode.d2.loss_cls: 0.0199, decode.d2.loss_mask: 0.2181, decode.d2.loss_dice: 0.4230, decode.d3.loss_cls: 0.0011, decode.d3.loss_mask: 0.2213, decode.d3.loss_dice: 0.4272, decode.d4.loss_cls: 0.0007, decode.d4.loss_mask: 0.2203, decode.d4.loss_dice: 0.4194, decode.d5.loss_cls: 0.0005, decode.d5.loss_mask: 0.2209, decode.d5.loss_dice: 0.4301, decode.d6.loss_cls: 0.0005, decode.d6.loss_mask: 0.2204, decode.d6.loss_dice: 0.4239, decode.d7.loss_cls: 0.0004, decode.d7.loss_mask: 0.2194, decode.d7.loss_dice: 0.4287, decode.d8.loss_cls: 0.0005, decode.d8.loss_mask: 0.2196, decode.d8.loss_dice: 0.4297, loss: 9.3865\n",
      "2024-02-14 15:05:04,705 - mmseg - INFO - Iter [2380/80000]\tlr: 1.393e-06, eta: 2 days, 2:06:56, time: 2.130, data_time: 0.016, memory: 23505, decode.loss_cls: 0.0004, decode.loss_mask: 0.1915, decode.loss_dice: 0.3994, decode.d0.loss_cls: 2.8325, decode.d0.loss_mask: 0.1964, decode.d0.loss_dice: 0.4232, decode.d1.loss_cls: 0.0126, decode.d1.loss_mask: 0.1916, decode.d1.loss_dice: 0.4042, decode.d2.loss_cls: 0.0021, decode.d2.loss_mask: 0.1893, decode.d2.loss_dice: 0.4073, decode.d3.loss_cls: 0.0012, decode.d3.loss_mask: 0.1924, decode.d3.loss_dice: 0.4084, decode.d4.loss_cls: 0.0007, decode.d4.loss_mask: 0.1913, decode.d4.loss_dice: 0.4083, decode.d5.loss_cls: 0.0006, decode.d5.loss_mask: 0.1918, decode.d5.loss_dice: 0.4056, decode.d6.loss_cls: 0.0005, decode.d6.loss_mask: 0.1921, decode.d6.loss_dice: 0.4049, decode.d7.loss_cls: 0.0004, decode.d7.loss_mask: 0.1908, decode.d7.loss_dice: 0.4043, decode.d8.loss_cls: 0.0005, decode.d8.loss_mask: 0.1907, decode.d8.loss_dice: 0.4038, loss: 8.8389\n",
      "2024-02-14 15:05:26,013 - mmseg - INFO - Iter [2390/80000]\tlr: 1.393e-06, eta: 2 days, 2:05:30, time: 2.131, data_time: 0.016, memory: 23505, decode.loss_cls: 0.0004, decode.loss_mask: 0.2098, decode.loss_dice: 0.4148, decode.d0.loss_cls: 2.8237, decode.d0.loss_mask: 0.2174, decode.d0.loss_dice: 0.4340, decode.d1.loss_cls: 0.0125, decode.d1.loss_mask: 0.2159, decode.d1.loss_dice: 0.4190, decode.d2.loss_cls: 0.0021, decode.d2.loss_mask: 0.2107, decode.d2.loss_dice: 0.4195, decode.d3.loss_cls: 0.0014, decode.d3.loss_mask: 0.2118, decode.d3.loss_dice: 0.4178, decode.d4.loss_cls: 0.0006, decode.d4.loss_mask: 0.2100, decode.d4.loss_dice: 0.4185, decode.d5.loss_cls: 0.0005, decode.d5.loss_mask: 0.2120, decode.d5.loss_dice: 0.4216, decode.d6.loss_cls: 0.0005, decode.d6.loss_mask: 0.2090, decode.d6.loss_dice: 0.4247, decode.d7.loss_cls: 0.0004, decode.d7.loss_mask: 0.2096, decode.d7.loss_dice: 0.4213, decode.d8.loss_cls: 0.0005, decode.d8.loss_mask: 0.2100, decode.d8.loss_dice: 0.4181, loss: 9.1681\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-14 15:05:47,342 - mmseg - INFO - Iter [2400/80000]\tlr: 1.393e-06, eta: 2 days, 2:04:05, time: 2.133, data_time: 0.017, memory: 23505, decode.loss_cls: 0.0004, decode.loss_mask: 0.1958, decode.loss_dice: 0.3957, decode.d0.loss_cls: 2.8187, decode.d0.loss_mask: 0.1988, decode.d0.loss_dice: 0.4175, decode.d1.loss_cls: 0.0092, decode.d1.loss_mask: 0.1963, decode.d1.loss_dice: 0.3963, decode.d2.loss_cls: 0.0017, decode.d2.loss_mask: 0.1957, decode.d2.loss_dice: 0.3961, decode.d3.loss_cls: 0.0013, decode.d3.loss_mask: 0.1952, decode.d3.loss_dice: 0.3925, decode.d4.loss_cls: 0.0006, decode.d4.loss_mask: 0.1941, decode.d4.loss_dice: 0.3959, decode.d5.loss_cls: 0.0005, decode.d5.loss_mask: 0.1949, decode.d5.loss_dice: 0.3941, decode.d6.loss_cls: 0.0005, decode.d6.loss_mask: 0.1951, decode.d6.loss_dice: 0.3912, decode.d7.loss_cls: 0.0004, decode.d7.loss_mask: 0.1936, decode.d7.loss_dice: 0.3900, decode.d8.loss_cls: 0.0004, decode.d8.loss_mask: 0.1961, decode.d8.loss_dice: 0.3927, loss: 8.7514\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 40/40, 6.2 task/s, elapsed: 6s, ETA:     0s\n",
      "\n",
      "2024-02-14 15:05:53,771 - mmseg - INFO - per class results:\n",
      "2024-02-14 15:05:53,772 - mmseg - INFO - \n",
      "+---------------+-------+-------+\n",
      "|     Class     |  IoU  |  Acc  |\n",
      "+---------------+-------+-------+\n",
      "|       bg      | 97.48 | 98.47 |\n",
      "|    Anchovy    | 80.79 | 93.87 |\n",
      "|     Olives    | 86.31 | 89.43 |\n",
      "|     Salami    |  71.0 | 83.03 |\n",
      "|   Red_Pepper  | 88.38 | 95.72 |\n",
      "| Yellow_Pepper | 86.08 | 94.79 |\n",
      "+---------------+-------+-------+\n",
      "2024-02-14 15:05:53,772 - mmseg - INFO - Summary:\n",
      "2024-02-14 15:05:53,772 - mmseg - INFO - \n",
      "+-------+-------+-------+\n",
      "|  aAcc |  mIoU |  mAcc |\n",
      "+-------+-------+-------+\n",
      "| 97.56 | 85.01 | 92.55 |\n",
      "+-------+-------+-------+\n",
      "2024-02-14 15:05:53,772 - mmseg - INFO - Iter(val) [10]\taAcc: 0.9756, mIoU: 0.8501, mAcc: 0.9255, IoU.bg: 0.9748, IoU.Anchovy: 0.8079, IoU.Olives: 0.8631, IoU.Salami: 0.7100, IoU.Red_Pepper: 0.8838, IoU.Yellow_Pepper: 0.8608, Acc.bg: 0.9847, Acc.Anchovy: 0.9387, Acc.Olives: 0.8943, Acc.Salami: 0.8303, Acc.Red_Pepper: 0.9572, Acc.Yellow_Pepper: 0.9479\n",
      "2024-02-14 15:06:15,085 - mmseg - INFO - Iter [2410/80000]\tlr: 1.393e-06, eta: 2 days, 2:06:07, time: 2.774, data_time: 0.660, memory: 23505, decode.loss_cls: 0.0004, decode.loss_mask: 0.2188, decode.loss_dice: 0.4031, decode.d0.loss_cls: 2.8088, decode.d0.loss_mask: 0.2187, decode.d0.loss_dice: 0.4266, decode.d1.loss_cls: 0.0105, decode.d1.loss_mask: 0.2151, decode.d1.loss_dice: 0.4113, decode.d2.loss_cls: 0.0018, decode.d2.loss_mask: 0.2151, decode.d2.loss_dice: 0.4032, decode.d3.loss_cls: 0.0012, decode.d3.loss_mask: 0.2193, decode.d3.loss_dice: 0.4044, decode.d4.loss_cls: 0.0006, decode.d4.loss_mask: 0.2166, decode.d4.loss_dice: 0.4036, decode.d5.loss_cls: 0.0005, decode.d5.loss_mask: 0.2180, decode.d5.loss_dice: 0.3973, decode.d6.loss_cls: 0.0005, decode.d6.loss_mask: 0.2210, decode.d6.loss_dice: 0.4035, decode.d7.loss_cls: 0.0004, decode.d7.loss_mask: 0.2233, decode.d7.loss_dice: 0.4068, decode.d8.loss_cls: 0.0005, decode.d8.loss_mask: 0.2205, decode.d8.loss_dice: 0.4022, loss: 9.0735\n",
      "2024-02-14 15:06:36,369 - mmseg - INFO - Iter [2420/80000]\tlr: 1.392e-06, eta: 2 days, 2:04:41, time: 2.128, data_time: 0.017, memory: 23505, decode.loss_cls: 0.0004, decode.loss_mask: 0.1983, decode.loss_dice: 0.3777, decode.d0.loss_cls: 2.8019, decode.d0.loss_mask: 0.2051, decode.d0.loss_dice: 0.3992, decode.d1.loss_cls: 0.0110, decode.d1.loss_mask: 0.2027, decode.d1.loss_dice: 0.3828, decode.d2.loss_cls: 0.0018, decode.d2.loss_mask: 0.1989, decode.d2.loss_dice: 0.3763, decode.d3.loss_cls: 0.0013, decode.d3.loss_mask: 0.2002, decode.d3.loss_dice: 0.3780, decode.d4.loss_cls: 0.0007, decode.d4.loss_mask: 0.1993, decode.d4.loss_dice: 0.3803, decode.d5.loss_cls: 0.0005, decode.d5.loss_mask: 0.1984, decode.d5.loss_dice: 0.3736, decode.d6.loss_cls: 0.0005, decode.d6.loss_mask: 0.1970, decode.d6.loss_dice: 0.3752, decode.d7.loss_cls: 0.0005, decode.d7.loss_mask: 0.1973, decode.d7.loss_dice: 0.3745, decode.d8.loss_cls: 0.0005, decode.d8.loss_mask: 0.2000, decode.d8.loss_dice: 0.3797, loss: 8.6134\n",
      "2024-02-14 15:06:57,673 - mmseg - INFO - Iter [2430/80000]\tlr: 1.392e-06, eta: 2 days, 2:03:16, time: 2.130, data_time: 0.017, memory: 23505, decode.loss_cls: 0.0003, decode.loss_mask: 0.2175, decode.loss_dice: 0.4087, decode.d0.loss_cls: 2.7931, decode.d0.loss_mask: 0.2204, decode.d0.loss_dice: 0.4287, decode.d1.loss_cls: 0.0108, decode.d1.loss_mask: 0.2163, decode.d1.loss_dice: 0.4182, decode.d2.loss_cls: 0.0017, decode.d2.loss_mask: 0.2192, decode.d2.loss_dice: 0.4133, decode.d3.loss_cls: 0.0010, decode.d3.loss_mask: 0.2192, decode.d3.loss_dice: 0.4173, decode.d4.loss_cls: 0.0006, decode.d4.loss_mask: 0.2186, decode.d4.loss_dice: 0.4122, decode.d5.loss_cls: 0.0005, decode.d5.loss_mask: 0.2199, decode.d5.loss_dice: 0.4134, decode.d6.loss_cls: 0.0004, decode.d6.loss_mask: 0.2215, decode.d6.loss_dice: 0.4126, decode.d7.loss_cls: 0.0004, decode.d7.loss_mask: 0.2171, decode.d7.loss_dice: 0.4107, decode.d8.loss_cls: 0.0004, decode.d8.loss_mask: 0.2202, decode.d8.loss_dice: 0.4126, loss: 9.1467\n",
      "2024-02-14 15:07:18,966 - mmseg - INFO - Iter [2440/80000]\tlr: 1.392e-06, eta: 2 days, 2:01:51, time: 2.129, data_time: 0.017, memory: 23505, decode.loss_cls: 0.0003, decode.loss_mask: 0.1889, decode.loss_dice: 0.3768, decode.d0.loss_cls: 2.7826, decode.d0.loss_mask: 0.1873, decode.d0.loss_dice: 0.3872, decode.d1.loss_cls: 0.0113, decode.d1.loss_mask: 0.1845, decode.d1.loss_dice: 0.3729, decode.d2.loss_cls: 0.0016, decode.d2.loss_mask: 0.1856, decode.d2.loss_dice: 0.3720, decode.d3.loss_cls: 0.0009, decode.d3.loss_mask: 0.1865, decode.d3.loss_dice: 0.3731, decode.d4.loss_cls: 0.0006, decode.d4.loss_mask: 0.1878, decode.d4.loss_dice: 0.3737, decode.d5.loss_cls: 0.0005, decode.d5.loss_mask: 0.1879, decode.d5.loss_dice: 0.3748, decode.d6.loss_cls: 0.0004, decode.d6.loss_mask: 0.1890, decode.d6.loss_dice: 0.3763, decode.d7.loss_cls: 0.0004, decode.d7.loss_mask: 0.1859, decode.d7.loss_dice: 0.3742, decode.d8.loss_cls: 0.0004, decode.d8.loss_mask: 0.1869, decode.d8.loss_dice: 0.3765, loss: 8.4267\n",
      "2024-02-14 15:07:40,265 - mmseg - INFO - Iter [2450/80000]\tlr: 1.392e-06, eta: 2 days, 2:00:27, time: 2.130, data_time: 0.017, memory: 23505, decode.loss_cls: 0.0004, decode.loss_mask: 0.2049, decode.loss_dice: 0.4059, decode.d0.loss_cls: 2.7764, decode.d0.loss_mask: 0.2131, decode.d0.loss_dice: 0.4212, decode.d1.loss_cls: 0.0139, decode.d1.loss_mask: 0.2074, decode.d1.loss_dice: 0.4040, decode.d2.loss_cls: 0.0019, decode.d2.loss_mask: 0.2083, decode.d2.loss_dice: 0.4097, decode.d3.loss_cls: 0.0012, decode.d3.loss_mask: 0.2082, decode.d3.loss_dice: 0.4089, decode.d4.loss_cls: 0.0007, decode.d4.loss_mask: 0.2064, decode.d4.loss_dice: 0.4078, decode.d5.loss_cls: 0.0005, decode.d5.loss_mask: 0.2055, decode.d5.loss_dice: 0.4020, decode.d6.loss_cls: 0.0005, decode.d6.loss_mask: 0.2039, decode.d6.loss_dice: 0.4050, decode.d7.loss_cls: 0.0004, decode.d7.loss_mask: 0.2038, decode.d7.loss_dice: 0.4041, decode.d8.loss_cls: 0.0004, decode.d8.loss_mask: 0.2050, decode.d8.loss_dice: 0.4057, loss: 8.9371\n",
      "2024-02-14 15:08:01,562 - mmseg - INFO - Iter [2460/80000]\tlr: 1.392e-06, eta: 2 days, 1:59:03, time: 2.130, data_time: 0.017, memory: 23505, decode.loss_cls: 0.0003, decode.loss_mask: 0.2186, decode.loss_dice: 0.3990, decode.d0.loss_cls: 2.7715, decode.d0.loss_mask: 0.2256, decode.d0.loss_dice: 0.4123, decode.d1.loss_cls: 0.0092, decode.d1.loss_mask: 0.2189, decode.d1.loss_dice: 0.3962, decode.d2.loss_cls: 0.0016, decode.d2.loss_mask: 0.2185, decode.d2.loss_dice: 0.3982, decode.d3.loss_cls: 0.0010, decode.d3.loss_mask: 0.2202, decode.d3.loss_dice: 0.4038, decode.d4.loss_cls: 0.0006, decode.d4.loss_mask: 0.2170, decode.d4.loss_dice: 0.3979, decode.d5.loss_cls: 0.0005, decode.d5.loss_mask: 0.2171, decode.d5.loss_dice: 0.4019, decode.d6.loss_cls: 0.0004, decode.d6.loss_mask: 0.2173, decode.d6.loss_dice: 0.4037, decode.d7.loss_cls: 0.0004, decode.d7.loss_mask: 0.2199, decode.d7.loss_dice: 0.4059, decode.d8.loss_cls: 0.0004, decode.d8.loss_mask: 0.2170, decode.d8.loss_dice: 0.4008, loss: 8.9957\n",
      "2024-02-14 15:08:22,917 - mmseg - INFO - Iter [2470/80000]\tlr: 1.391e-06, eta: 2 days, 1:57:42, time: 2.135, data_time: 0.016, memory: 23505, decode.loss_cls: 0.0003, decode.loss_mask: 0.1840, decode.loss_dice: 0.3680, decode.d0.loss_cls: 2.7588, decode.d0.loss_mask: 0.1903, decode.d0.loss_dice: 0.3933, decode.d1.loss_cls: 0.0118, decode.d1.loss_mask: 0.1857, decode.d1.loss_dice: 0.3746, decode.d2.loss_cls: 0.0017, decode.d2.loss_mask: 0.1864, decode.d2.loss_dice: 0.3690, decode.d3.loss_cls: 0.0009, decode.d3.loss_mask: 0.1851, decode.d3.loss_dice: 0.3773, decode.d4.loss_cls: 0.0006, decode.d4.loss_mask: 0.1858, decode.d4.loss_dice: 0.3744, decode.d5.loss_cls: 0.0004, decode.d5.loss_mask: 0.1861, decode.d5.loss_dice: 0.3747, decode.d6.loss_cls: 0.0004, decode.d6.loss_mask: 0.1844, decode.d6.loss_dice: 0.3718, decode.d7.loss_cls: 0.0004, decode.d7.loss_mask: 0.1862, decode.d7.loss_dice: 0.3762, decode.d8.loss_cls: 0.0004, decode.d8.loss_mask: 0.1872, decode.d8.loss_dice: 0.3740, loss: 8.3899\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-14 15:08:44,225 - mmseg - INFO - Iter [2480/80000]\tlr: 1.391e-06, eta: 2 days, 1:56:20, time: 2.131, data_time: 0.017, memory: 23505, decode.loss_cls: 0.0004, decode.loss_mask: 0.2128, decode.loss_dice: 0.3990, decode.d0.loss_cls: 2.7531, decode.d0.loss_mask: 0.2179, decode.d0.loss_dice: 0.4174, decode.d1.loss_cls: 0.0153, decode.d1.loss_mask: 0.2164, decode.d1.loss_dice: 0.3998, decode.d2.loss_cls: 0.0021, decode.d2.loss_mask: 0.2157, decode.d2.loss_dice: 0.4014, decode.d3.loss_cls: 0.0010, decode.d3.loss_mask: 0.2131, decode.d3.loss_dice: 0.3978, decode.d4.loss_cls: 0.0006, decode.d4.loss_mask: 0.2149, decode.d4.loss_dice: 0.4044, decode.d5.loss_cls: 0.0005, decode.d5.loss_mask: 0.2135, decode.d5.loss_dice: 0.4012, decode.d6.loss_cls: 0.0004, decode.d6.loss_mask: 0.2164, decode.d6.loss_dice: 0.4000, decode.d7.loss_cls: 0.0004, decode.d7.loss_mask: 0.2135, decode.d7.loss_dice: 0.4017, decode.d8.loss_cls: 0.0004, decode.d8.loss_mask: 0.2117, decode.d8.loss_dice: 0.4013, loss: 8.9440\n",
      "2024-02-14 15:09:05,523 - mmseg - INFO - Iter [2490/80000]\tlr: 1.391e-06, eta: 2 days, 1:54:58, time: 2.130, data_time: 0.017, memory: 23505, decode.loss_cls: 0.0003, decode.loss_mask: 0.2186, decode.loss_dice: 0.4205, decode.d0.loss_cls: 2.7468, decode.d0.loss_mask: 0.2235, decode.d0.loss_dice: 0.4356, decode.d1.loss_cls: 0.0106, decode.d1.loss_mask: 0.2169, decode.d1.loss_dice: 0.4231, decode.d2.loss_cls: 0.0069, decode.d2.loss_mask: 0.2174, decode.d2.loss_dice: 0.4239, decode.d3.loss_cls: 0.0021, decode.d3.loss_mask: 0.2171, decode.d3.loss_dice: 0.4256, decode.d4.loss_cls: 0.0007, decode.d4.loss_mask: 0.2185, decode.d4.loss_dice: 0.4255, decode.d5.loss_cls: 0.0005, decode.d5.loss_mask: 0.2192, decode.d5.loss_dice: 0.4205, decode.d6.loss_cls: 0.0004, decode.d6.loss_mask: 0.2182, decode.d6.loss_dice: 0.4204, decode.d7.loss_cls: 0.0004, decode.d7.loss_mask: 0.2165, decode.d7.loss_dice: 0.4258, decode.d8.loss_cls: 0.0004, decode.d8.loss_mask: 0.2171, decode.d8.loss_dice: 0.4203, loss: 9.1934\n",
      "2024-02-14 15:09:26,926 - mmseg - INFO - Iter [2500/80000]\tlr: 1.391e-06, eta: 2 days, 1:53:39, time: 2.140, data_time: 0.017, memory: 23505, decode.loss_cls: 0.0003, decode.loss_mask: 0.1962, decode.loss_dice: 0.3754, decode.d0.loss_cls: 2.7380, decode.d0.loss_mask: 0.1995, decode.d0.loss_dice: 0.3952, decode.d1.loss_cls: 0.0099, decode.d1.loss_mask: 0.1985, decode.d1.loss_dice: 0.3773, decode.d2.loss_cls: 0.0016, decode.d2.loss_mask: 0.1968, decode.d2.loss_dice: 0.3807, decode.d3.loss_cls: 0.0009, decode.d3.loss_mask: 0.1975, decode.d3.loss_dice: 0.3790, decode.d4.loss_cls: 0.0006, decode.d4.loss_mask: 0.1974, decode.d4.loss_dice: 0.3755, decode.d5.loss_cls: 0.0004, decode.d5.loss_mask: 0.1940, decode.d5.loss_dice: 0.3727, decode.d6.loss_cls: 0.0004, decode.d6.loss_mask: 0.1953, decode.d6.loss_dice: 0.3757, decode.d7.loss_cls: 0.0004, decode.d7.loss_mask: 0.1962, decode.d7.loss_dice: 0.3771, decode.d8.loss_cls: 0.0004, decode.d8.loss_mask: 0.1975, decode.d8.loss_dice: 0.3766, loss: 8.5068\n",
      "2024-02-14 15:09:48,228 - mmseg - INFO - Iter [2510/80000]\tlr: 1.391e-06, eta: 2 days, 1:52:18, time: 2.130, data_time: 0.017, memory: 23505, decode.loss_cls: 0.0003, decode.loss_mask: 0.2307, decode.loss_dice: 0.4333, decode.d0.loss_cls: 2.7334, decode.d0.loss_mask: 0.2364, decode.d0.loss_dice: 0.4668, decode.d1.loss_cls: 0.0088, decode.d1.loss_mask: 0.2329, decode.d1.loss_dice: 0.4355, decode.d2.loss_cls: 0.0016, decode.d2.loss_mask: 0.2337, decode.d2.loss_dice: 0.4383, decode.d3.loss_cls: 0.0011, decode.d3.loss_mask: 0.2314, decode.d3.loss_dice: 0.4320, decode.d4.loss_cls: 0.0006, decode.d4.loss_mask: 0.2314, decode.d4.loss_dice: 0.4377, decode.d5.loss_cls: 0.0005, decode.d5.loss_mask: 0.2334, decode.d5.loss_dice: 0.4404, decode.d6.loss_cls: 0.0004, decode.d6.loss_mask: 0.2319, decode.d6.loss_dice: 0.4380, decode.d7.loss_cls: 0.0004, decode.d7.loss_mask: 0.2299, decode.d7.loss_dice: 0.4329, decode.d8.loss_cls: 0.0004, decode.d8.loss_mask: 0.2326, decode.d8.loss_dice: 0.4418, loss: 9.4683\n",
      "2024-02-14 15:10:09,512 - mmseg - INFO - Iter [2520/80000]\tlr: 1.391e-06, eta: 2 days, 1:50:57, time: 2.128, data_time: 0.017, memory: 23505, decode.loss_cls: 0.0003, decode.loss_mask: 0.1918, decode.loss_dice: 0.3824, decode.d0.loss_cls: 2.7196, decode.d0.loss_mask: 0.1969, decode.d0.loss_dice: 0.4077, decode.d1.loss_cls: 0.0102, decode.d1.loss_mask: 0.1916, decode.d1.loss_dice: 0.3849, decode.d2.loss_cls: 0.0018, decode.d2.loss_mask: 0.1939, decode.d2.loss_dice: 0.3887, decode.d3.loss_cls: 0.0011, decode.d3.loss_mask: 0.1923, decode.d3.loss_dice: 0.3807, decode.d4.loss_cls: 0.0005, decode.d4.loss_mask: 0.1948, decode.d4.loss_dice: 0.3859, decode.d5.loss_cls: 0.0005, decode.d5.loss_mask: 0.1931, decode.d5.loss_dice: 0.3871, decode.d6.loss_cls: 0.0004, decode.d6.loss_mask: 0.1910, decode.d6.loss_dice: 0.3785, decode.d7.loss_cls: 0.0004, decode.d7.loss_mask: 0.1925, decode.d7.loss_dice: 0.3847, decode.d8.loss_cls: 0.0004, decode.d8.loss_mask: 0.1917, decode.d8.loss_dice: 0.3837, loss: 8.5288\n",
      "2024-02-14 15:10:30,814 - mmseg - INFO - Iter [2530/80000]\tlr: 1.390e-06, eta: 2 days, 1:49:37, time: 2.130, data_time: 0.017, memory: 23505, decode.loss_cls: 0.0003, decode.loss_mask: 0.1979, decode.loss_dice: 0.4059, decode.d0.loss_cls: 2.7123, decode.d0.loss_mask: 0.1973, decode.d0.loss_dice: 0.4240, decode.d1.loss_cls: 0.0101, decode.d1.loss_mask: 0.1966, decode.d1.loss_dice: 0.4054, decode.d2.loss_cls: 0.0015, decode.d2.loss_mask: 0.1953, decode.d2.loss_dice: 0.4057, decode.d3.loss_cls: 0.0010, decode.d3.loss_mask: 0.1978, decode.d3.loss_dice: 0.4075, decode.d4.loss_cls: 0.0005, decode.d4.loss_mask: 0.1962, decode.d4.loss_dice: 0.4045, decode.d5.loss_cls: 0.0004, decode.d5.loss_mask: 0.1994, decode.d5.loss_dice: 0.4106, decode.d6.loss_cls: 0.0004, decode.d6.loss_mask: 0.1989, decode.d6.loss_dice: 0.4057, decode.d7.loss_cls: 0.0004, decode.d7.loss_mask: 0.1999, decode.d7.loss_dice: 0.4112, decode.d8.loss_cls: 0.0004, decode.d8.loss_mask: 0.1967, decode.d8.loss_dice: 0.4057, loss: 8.7895\n",
      "2024-02-14 15:10:52,087 - mmseg - INFO - Iter [2540/80000]\tlr: 1.390e-06, eta: 2 days, 1:48:16, time: 2.127, data_time: 0.017, memory: 23505, decode.loss_cls: 0.0003, decode.loss_mask: 0.2090, decode.loss_dice: 0.4086, decode.d0.loss_cls: 2.7035, decode.d0.loss_mask: 0.2166, decode.d0.loss_dice: 0.4262, decode.d1.loss_cls: 0.0113, decode.d1.loss_mask: 0.2131, decode.d1.loss_dice: 0.4064, decode.d2.loss_cls: 0.0016, decode.d2.loss_mask: 0.2104, decode.d2.loss_dice: 0.4057, decode.d3.loss_cls: 0.0010, decode.d3.loss_mask: 0.2096, decode.d3.loss_dice: 0.4059, decode.d4.loss_cls: 0.0005, decode.d4.loss_mask: 0.2086, decode.d4.loss_dice: 0.4057, decode.d5.loss_cls: 0.0004, decode.d5.loss_mask: 0.2086, decode.d5.loss_dice: 0.4074, decode.d6.loss_cls: 0.0004, decode.d6.loss_mask: 0.2078, decode.d6.loss_dice: 0.4027, decode.d7.loss_cls: 0.0004, decode.d7.loss_mask: 0.2095, decode.d7.loss_dice: 0.4055, decode.d8.loss_cls: 0.0004, decode.d8.loss_mask: 0.2107, decode.d8.loss_dice: 0.4051, loss: 8.9025\n",
      "2024-02-14 15:11:13,399 - mmseg - INFO - Iter [2550/80000]\tlr: 1.390e-06, eta: 2 days, 1:46:57, time: 2.131, data_time: 0.017, memory: 23505, decode.loss_cls: 0.0003, decode.loss_mask: 0.2289, decode.loss_dice: 0.4141, decode.d0.loss_cls: 2.7003, decode.d0.loss_mask: 0.2329, decode.d0.loss_dice: 0.4307, decode.d1.loss_cls: 0.0087, decode.d1.loss_mask: 0.2343, decode.d1.loss_dice: 0.4174, decode.d2.loss_cls: 0.0014, decode.d2.loss_mask: 0.2284, decode.d2.loss_dice: 0.4153, decode.d3.loss_cls: 0.0009, decode.d3.loss_mask: 0.2274, decode.d3.loss_dice: 0.4173, decode.d4.loss_cls: 0.0005, decode.d4.loss_mask: 0.2302, decode.d4.loss_dice: 0.4167, decode.d5.loss_cls: 0.0004, decode.d5.loss_mask: 0.2288, decode.d5.loss_dice: 0.4161, decode.d6.loss_cls: 0.0004, decode.d6.loss_mask: 0.2310, decode.d6.loss_dice: 0.4175, decode.d7.loss_cls: 0.0003, decode.d7.loss_mask: 0.2317, decode.d7.loss_dice: 0.4197, decode.d8.loss_cls: 0.0004, decode.d8.loss_mask: 0.2296, decode.d8.loss_dice: 0.4203, loss: 9.2020\n",
      "2024-02-14 15:11:34,683 - mmseg - INFO - Iter [2560/80000]\tlr: 1.390e-06, eta: 2 days, 1:45:38, time: 2.128, data_time: 0.017, memory: 23505, decode.loss_cls: 0.0003, decode.loss_mask: 0.2283, decode.loss_dice: 0.4332, decode.d0.loss_cls: 2.6900, decode.d0.loss_mask: 0.2370, decode.d0.loss_dice: 0.4485, decode.d1.loss_cls: 0.0096, decode.d1.loss_mask: 0.2288, decode.d1.loss_dice: 0.4319, decode.d2.loss_cls: 0.0015, decode.d2.loss_mask: 0.2272, decode.d2.loss_dice: 0.4349, decode.d3.loss_cls: 0.0011, decode.d3.loss_mask: 0.2244, decode.d3.loss_dice: 0.4305, decode.d4.loss_cls: 0.0005, decode.d4.loss_mask: 0.2268, decode.d4.loss_dice: 0.4272, decode.d5.loss_cls: 0.0004, decode.d5.loss_mask: 0.2249, decode.d5.loss_dice: 0.4249, decode.d6.loss_cls: 0.0004, decode.d6.loss_mask: 0.2265, decode.d6.loss_dice: 0.4292, decode.d7.loss_cls: 0.0004, decode.d7.loss_mask: 0.2249, decode.d7.loss_dice: 0.4305, decode.d8.loss_cls: 0.0004, decode.d8.loss_mask: 0.2253, decode.d8.loss_dice: 0.4332, loss: 9.3030\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-14 15:11:58,069 - mmseg - INFO - Iter [2570/80000]\tlr: 1.390e-06, eta: 2 days, 1:45:23, time: 2.338, data_time: 0.223, memory: 23505, decode.loss_cls: 0.0003, decode.loss_mask: 0.2469, decode.loss_dice: 0.4486, decode.d0.loss_cls: 2.6864, decode.d0.loss_mask: 0.2553, decode.d0.loss_dice: 0.4557, decode.d1.loss_cls: 0.0080, decode.d1.loss_mask: 0.2452, decode.d1.loss_dice: 0.4534, decode.d2.loss_cls: 0.0013, decode.d2.loss_mask: 0.2466, decode.d2.loss_dice: 0.4521, decode.d3.loss_cls: 0.0010, decode.d3.loss_mask: 0.2452, decode.d3.loss_dice: 0.4474, decode.d4.loss_cls: 0.0006, decode.d4.loss_mask: 0.2476, decode.d4.loss_dice: 0.4446, decode.d5.loss_cls: 0.0004, decode.d5.loss_mask: 0.2456, decode.d5.loss_dice: 0.4427, decode.d6.loss_cls: 0.0004, decode.d6.loss_mask: 0.2467, decode.d6.loss_dice: 0.4444, decode.d7.loss_cls: 0.0003, decode.d7.loss_mask: 0.2455, decode.d7.loss_dice: 0.4456, decode.d8.loss_cls: 0.0004, decode.d8.loss_mask: 0.2469, decode.d8.loss_dice: 0.4471, loss: 9.6524\n",
      "2024-02-14 15:12:19,364 - mmseg - INFO - Iter [2580/80000]\tlr: 1.390e-06, eta: 2 days, 1:44:04, time: 2.130, data_time: 0.018, memory: 23505, decode.loss_cls: 0.0003, decode.loss_mask: 0.2446, decode.loss_dice: 0.4346, decode.d0.loss_cls: 2.6785, decode.d0.loss_mask: 0.2442, decode.d0.loss_dice: 0.4531, decode.d1.loss_cls: 0.0089, decode.d1.loss_mask: 0.2398, decode.d1.loss_dice: 0.4361, decode.d2.loss_cls: 0.0016, decode.d2.loss_mask: 0.2440, decode.d2.loss_dice: 0.4329, decode.d3.loss_cls: 0.0011, decode.d3.loss_mask: 0.2421, decode.d3.loss_dice: 0.4332, decode.d4.loss_cls: 0.0006, decode.d4.loss_mask: 0.2454, decode.d4.loss_dice: 0.4358, decode.d5.loss_cls: 0.0004, decode.d5.loss_mask: 0.2390, decode.d5.loss_dice: 0.4292, decode.d6.loss_cls: 0.0004, decode.d6.loss_mask: 0.2436, decode.d6.loss_dice: 0.4334, decode.d7.loss_cls: 0.0004, decode.d7.loss_mask: 0.2455, decode.d7.loss_dice: 0.4322, decode.d8.loss_cls: 0.0004, decode.d8.loss_mask: 0.2419, decode.d8.loss_dice: 0.4301, loss: 9.4731\n",
      "2024-02-14 15:12:40,660 - mmseg - INFO - Iter [2590/80000]\tlr: 1.389e-06, eta: 2 days, 1:42:47, time: 2.130, data_time: 0.016, memory: 23505, decode.loss_cls: 0.0003, decode.loss_mask: 0.1900, decode.loss_dice: 0.4051, decode.d0.loss_cls: 2.6652, decode.d0.loss_mask: 0.1963, decode.d0.loss_dice: 0.4206, decode.d1.loss_cls: 0.0109, decode.d1.loss_mask: 0.1933, decode.d1.loss_dice: 0.4068, decode.d2.loss_cls: 0.0014, decode.d2.loss_mask: 0.1917, decode.d2.loss_dice: 0.4084, decode.d3.loss_cls: 0.0009, decode.d3.loss_mask: 0.1927, decode.d3.loss_dice: 0.4072, decode.d4.loss_cls: 0.0005, decode.d4.loss_mask: 0.1902, decode.d4.loss_dice: 0.4058, decode.d5.loss_cls: 0.0004, decode.d5.loss_mask: 0.1915, decode.d5.loss_dice: 0.4042, decode.d6.loss_cls: 0.0004, decode.d6.loss_mask: 0.1902, decode.d6.loss_dice: 0.3989, decode.d7.loss_cls: 0.0003, decode.d7.loss_mask: 0.1901, decode.d7.loss_dice: 0.4054, decode.d8.loss_cls: 0.0003, decode.d8.loss_mask: 0.1905, decode.d8.loss_dice: 0.4018, loss: 8.6615\n",
      "2024-02-14 15:13:01,968 - mmseg - INFO - Iter [2600/80000]\tlr: 1.389e-06, eta: 2 days, 1:41:29, time: 2.131, data_time: 0.017, memory: 23505, decode.loss_cls: 0.0003, decode.loss_mask: 0.2173, decode.loss_dice: 0.3930, decode.d0.loss_cls: 2.6614, decode.d0.loss_mask: 0.2161, decode.d0.loss_dice: 0.4091, decode.d1.loss_cls: 0.0091, decode.d1.loss_mask: 0.2174, decode.d1.loss_dice: 0.3958, decode.d2.loss_cls: 0.0014, decode.d2.loss_mask: 0.2130, decode.d2.loss_dice: 0.3912, decode.d3.loss_cls: 0.0010, decode.d3.loss_mask: 0.2113, decode.d3.loss_dice: 0.3855, decode.d4.loss_cls: 0.0005, decode.d4.loss_mask: 0.2145, decode.d4.loss_dice: 0.3935, decode.d5.loss_cls: 0.0004, decode.d5.loss_mask: 0.2157, decode.d5.loss_dice: 0.3907, decode.d6.loss_cls: 0.0004, decode.d6.loss_mask: 0.2147, decode.d6.loss_dice: 0.3916, decode.d7.loss_cls: 0.0003, decode.d7.loss_mask: 0.2138, decode.d7.loss_dice: 0.3917, decode.d8.loss_cls: 0.0004, decode.d8.loss_mask: 0.2119, decode.d8.loss_dice: 0.3870, loss: 8.7502\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 40/40, 6.2 task/s, elapsed: 6s, ETA:     0s\n",
      "\n",
      "2024-02-14 15:13:08,412 - mmseg - INFO - per class results:\n",
      "2024-02-14 15:13:08,413 - mmseg - INFO - \n",
      "+---------------+-------+-------+\n",
      "|     Class     |  IoU  |  Acc  |\n",
      "+---------------+-------+-------+\n",
      "|       bg      | 97.54 | 98.47 |\n",
      "|    Anchovy    | 81.38 | 92.69 |\n",
      "|     Olives    | 86.85 | 90.84 |\n",
      "|     Salami    |  70.3 | 87.93 |\n",
      "|   Red_Pepper  | 89.21 | 94.84 |\n",
      "| Yellow_Pepper | 86.03 | 93.77 |\n",
      "+---------------+-------+-------+\n",
      "2024-02-14 15:13:08,413 - mmseg - INFO - Summary:\n",
      "2024-02-14 15:13:08,414 - mmseg - INFO - \n",
      "+------+-------+-------+\n",
      "| aAcc |  mIoU |  mAcc |\n",
      "+------+-------+-------+\n",
      "| 97.6 | 85.22 | 93.09 |\n",
      "+------+-------+-------+\n",
      "2024-02-14 15:13:08,414 - mmseg - INFO - Iter(val) [10]\taAcc: 0.9760, mIoU: 0.8522, mAcc: 0.9309, IoU.bg: 0.9754, IoU.Anchovy: 0.8138, IoU.Olives: 0.8685, IoU.Salami: 0.7030, IoU.Red_Pepper: 0.8921, IoU.Yellow_Pepper: 0.8603, Acc.bg: 0.9847, Acc.Anchovy: 0.9269, Acc.Olives: 0.9084, Acc.Salami: 0.8793, Acc.Red_Pepper: 0.9484, Acc.Yellow_Pepper: 0.9377\n",
      "2024-02-14 15:13:29,714 - mmseg - INFO - Iter [2610/80000]\tlr: 1.389e-06, eta: 2 days, 1:43:24, time: 2.775, data_time: 0.661, memory: 23505, decode.loss_cls: 0.0003, decode.loss_mask: 0.1762, decode.loss_dice: 0.3665, decode.d0.loss_cls: 2.6450, decode.d0.loss_mask: 0.1838, decode.d0.loss_dice: 0.3851, decode.d1.loss_cls: 0.0124, decode.d1.loss_mask: 0.1814, decode.d1.loss_dice: 0.3688, decode.d2.loss_cls: 0.0014, decode.d2.loss_mask: 0.1815, decode.d2.loss_dice: 0.3682, decode.d3.loss_cls: 0.0009, decode.d3.loss_mask: 0.1778, decode.d3.loss_dice: 0.3635, decode.d4.loss_cls: 0.0004, decode.d4.loss_mask: 0.1801, decode.d4.loss_dice: 0.3682, decode.d5.loss_cls: 0.0004, decode.d5.loss_mask: 0.1788, decode.d5.loss_dice: 0.3632, decode.d6.loss_cls: 0.0004, decode.d6.loss_mask: 0.1778, decode.d6.loss_dice: 0.3697, decode.d7.loss_cls: 0.0003, decode.d7.loss_mask: 0.1777, decode.d7.loss_dice: 0.3706, decode.d8.loss_cls: 0.0004, decode.d8.loss_mask: 0.1776, decode.d8.loss_dice: 0.3743, loss: 8.1526\n",
      "2024-02-14 15:13:50,998 - mmseg - INFO - Iter [2620/80000]\tlr: 1.389e-06, eta: 2 days, 1:42:06, time: 2.128, data_time: 0.017, memory: 23505, decode.loss_cls: 0.0003, decode.loss_mask: 0.2206, decode.loss_dice: 0.4000, decode.d0.loss_cls: 2.6443, decode.d0.loss_mask: 0.2206, decode.d0.loss_dice: 0.4151, decode.d1.loss_cls: 0.0078, decode.d1.loss_mask: 0.2159, decode.d1.loss_dice: 0.4013, decode.d2.loss_cls: 0.0013, decode.d2.loss_mask: 0.2156, decode.d2.loss_dice: 0.3993, decode.d3.loss_cls: 0.0010, decode.d3.loss_mask: 0.2193, decode.d3.loss_dice: 0.3980, decode.d4.loss_cls: 0.0005, decode.d4.loss_mask: 0.2172, decode.d4.loss_dice: 0.4021, decode.d5.loss_cls: 0.0004, decode.d5.loss_mask: 0.2193, decode.d5.loss_dice: 0.4042, decode.d6.loss_cls: 0.0004, decode.d6.loss_mask: 0.2186, decode.d6.loss_dice: 0.3987, decode.d7.loss_cls: 0.0004, decode.d7.loss_mask: 0.2166, decode.d7.loss_dice: 0.3969, decode.d8.loss_cls: 0.0004, decode.d8.loss_mask: 0.2189, decode.d8.loss_dice: 0.4019, loss: 8.8568\n",
      "2024-02-14 15:14:12,292 - mmseg - INFO - Iter [2630/80000]\tlr: 1.389e-06, eta: 2 days, 1:40:49, time: 2.129, data_time: 0.016, memory: 23505, decode.loss_cls: 0.0003, decode.loss_mask: 0.1707, decode.loss_dice: 0.3510, decode.d0.loss_cls: 2.6291, decode.d0.loss_mask: 0.1739, decode.d0.loss_dice: 0.3731, decode.d1.loss_cls: 0.0128, decode.d1.loss_mask: 0.1688, decode.d1.loss_dice: 0.3482, decode.d2.loss_cls: 0.0014, decode.d2.loss_mask: 0.1706, decode.d2.loss_dice: 0.3538, decode.d3.loss_cls: 0.0009, decode.d3.loss_mask: 0.1706, decode.d3.loss_dice: 0.3429, decode.d4.loss_cls: 0.0005, decode.d4.loss_mask: 0.1702, decode.d4.loss_dice: 0.3471, decode.d5.loss_cls: 0.0004, decode.d5.loss_mask: 0.1669, decode.d5.loss_dice: 0.3431, decode.d6.loss_cls: 0.0004, decode.d6.loss_mask: 0.1678, decode.d6.loss_dice: 0.3484, decode.d7.loss_cls: 0.0003, decode.d7.loss_mask: 0.1679, decode.d7.loss_dice: 0.3456, decode.d8.loss_cls: 0.0003, decode.d8.loss_mask: 0.1689, decode.d8.loss_dice: 0.3481, loss: 7.8441\n",
      "2024-02-14 15:14:33,591 - mmseg - INFO - Iter [2640/80000]\tlr: 1.388e-06, eta: 2 days, 1:39:33, time: 2.130, data_time: 0.017, memory: 23505, decode.loss_cls: 0.0003, decode.loss_mask: 0.2110, decode.loss_dice: 0.4118, decode.d0.loss_cls: 2.6245, decode.d0.loss_mask: 0.2206, decode.d0.loss_dice: 0.4342, decode.d1.loss_cls: 0.0099, decode.d1.loss_mask: 0.2165, decode.d1.loss_dice: 0.4135, decode.d2.loss_cls: 0.0013, decode.d2.loss_mask: 0.2129, decode.d2.loss_dice: 0.4085, decode.d3.loss_cls: 0.0010, decode.d3.loss_mask: 0.2126, decode.d3.loss_dice: 0.4098, decode.d4.loss_cls: 0.0005, decode.d4.loss_mask: 0.2155, decode.d4.loss_dice: 0.4134, decode.d5.loss_cls: 0.0004, decode.d5.loss_mask: 0.2126, decode.d5.loss_dice: 0.4093, decode.d6.loss_cls: 0.0004, decode.d6.loss_mask: 0.2111, decode.d6.loss_dice: 0.4080, decode.d7.loss_cls: 0.0004, decode.d7.loss_mask: 0.2124, decode.d7.loss_dice: 0.4140, decode.d8.loss_cls: 0.0004, decode.d8.loss_mask: 0.2131, decode.d8.loss_dice: 0.4104, loss: 8.9103\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-14 15:14:54,874 - mmseg - INFO - Iter [2650/80000]\tlr: 1.388e-06, eta: 2 days, 1:38:16, time: 2.128, data_time: 0.016, memory: 23505, decode.loss_cls: 0.0003, decode.loss_mask: 0.1693, decode.loss_dice: 0.3504, decode.d0.loss_cls: 2.6116, decode.d0.loss_mask: 0.1735, decode.d0.loss_dice: 0.3750, decode.d1.loss_cls: 0.0146, decode.d1.loss_mask: 0.1745, decode.d1.loss_dice: 0.3552, decode.d2.loss_cls: 0.0016, decode.d2.loss_mask: 0.1723, decode.d2.loss_dice: 0.3521, decode.d3.loss_cls: 0.0008, decode.d3.loss_mask: 0.1726, decode.d3.loss_dice: 0.3546, decode.d4.loss_cls: 0.0005, decode.d4.loss_mask: 0.1715, decode.d4.loss_dice: 0.3517, decode.d5.loss_cls: 0.0004, decode.d5.loss_mask: 0.1698, decode.d5.loss_dice: 0.3508, decode.d6.loss_cls: 0.0004, decode.d6.loss_mask: 0.1705, decode.d6.loss_dice: 0.3523, decode.d7.loss_cls: 0.0004, decode.d7.loss_mask: 0.1687, decode.d7.loss_dice: 0.3484, decode.d8.loss_cls: 0.0004, decode.d8.loss_mask: 0.1701, decode.d8.loss_dice: 0.3531, loss: 7.8872\n",
      "2024-02-14 15:15:16,180 - mmseg - INFO - Iter [2660/80000]\tlr: 1.388e-06, eta: 2 days, 1:37:01, time: 2.131, data_time: 0.017, memory: 23505, decode.loss_cls: 0.0003, decode.loss_mask: 0.2260, decode.loss_dice: 0.4152, decode.d0.loss_cls: 2.6117, decode.d0.loss_mask: 0.2352, decode.d0.loss_dice: 0.4331, decode.d1.loss_cls: 0.0079, decode.d1.loss_mask: 0.2296, decode.d1.loss_dice: 0.4224, decode.d2.loss_cls: 0.0013, decode.d2.loss_mask: 0.2292, decode.d2.loss_dice: 0.4208, decode.d3.loss_cls: 0.0009, decode.d3.loss_mask: 0.2304, decode.d3.loss_dice: 0.4237, decode.d4.loss_cls: 0.0006, decode.d4.loss_mask: 0.2297, decode.d4.loss_dice: 0.4222, decode.d5.loss_cls: 0.0004, decode.d5.loss_mask: 0.2292, decode.d5.loss_dice: 0.4196, decode.d6.loss_cls: 0.0004, decode.d6.loss_mask: 0.2289, decode.d6.loss_dice: 0.4196, decode.d7.loss_cls: 0.0004, decode.d7.loss_mask: 0.2274, decode.d7.loss_dice: 0.4169, decode.d8.loss_cls: 0.0004, decode.d8.loss_mask: 0.2290, decode.d8.loss_dice: 0.4199, loss: 9.1323\n",
      "2024-02-14 15:15:37,490 - mmseg - INFO - Iter [2670/80000]\tlr: 1.388e-06, eta: 2 days, 1:35:46, time: 2.131, data_time: 0.017, memory: 23505, decode.loss_cls: 0.0003, decode.loss_mask: 0.2018, decode.loss_dice: 0.3852, decode.d0.loss_cls: 2.6023, decode.d0.loss_mask: 0.2028, decode.d0.loss_dice: 0.4075, decode.d1.loss_cls: 0.0090, decode.d1.loss_mask: 0.2018, decode.d1.loss_dice: 0.3849, decode.d2.loss_cls: 0.0013, decode.d2.loss_mask: 0.2009, decode.d2.loss_dice: 0.3841, decode.d3.loss_cls: 0.0008, decode.d3.loss_mask: 0.2020, decode.d3.loss_dice: 0.3850, decode.d4.loss_cls: 0.0005, decode.d4.loss_mask: 0.2006, decode.d4.loss_dice: 0.3867, decode.d5.loss_cls: 0.0004, decode.d5.loss_mask: 0.2018, decode.d5.loss_dice: 0.3862, decode.d6.loss_cls: 0.0004, decode.d6.loss_mask: 0.1998, decode.d6.loss_dice: 0.3851, decode.d7.loss_cls: 0.0003, decode.d7.loss_mask: 0.2036, decode.d7.loss_dice: 0.3831, decode.d8.loss_cls: 0.0004, decode.d8.loss_mask: 0.2026, decode.d8.loss_dice: 0.3862, loss: 8.5076\n",
      "2024-02-14 15:15:58,793 - mmseg - INFO - Iter [2680/80000]\tlr: 1.388e-06, eta: 2 days, 1:34:32, time: 2.130, data_time: 0.016, memory: 23505, decode.loss_cls: 0.0003, decode.loss_mask: 0.1994, decode.loss_dice: 0.4002, decode.d0.loss_cls: 2.5927, decode.d0.loss_mask: 0.2035, decode.d0.loss_dice: 0.4096, decode.d1.loss_cls: 0.0091, decode.d1.loss_mask: 0.2004, decode.d1.loss_dice: 0.3877, decode.d2.loss_cls: 0.0014, decode.d2.loss_mask: 0.1989, decode.d2.loss_dice: 0.3898, decode.d3.loss_cls: 0.0011, decode.d3.loss_mask: 0.1969, decode.d3.loss_dice: 0.3935, decode.d4.loss_cls: 0.0006, decode.d4.loss_mask: 0.1977, decode.d4.loss_dice: 0.3930, decode.d5.loss_cls: 0.0005, decode.d5.loss_mask: 0.1966, decode.d5.loss_dice: 0.3951, decode.d6.loss_cls: 0.0005, decode.d6.loss_mask: 0.1979, decode.d6.loss_dice: 0.4013, decode.d7.loss_cls: 0.0004, decode.d7.loss_mask: 0.1988, decode.d7.loss_dice: 0.3999, decode.d8.loss_cls: 0.0004, decode.d8.loss_mask: 0.1959, decode.d8.loss_dice: 0.3888, loss: 8.5518\n",
      "2024-02-14 15:16:20,103 - mmseg - INFO - Iter [2690/80000]\tlr: 1.388e-06, eta: 2 days, 1:33:18, time: 2.131, data_time: 0.016, memory: 23505, decode.loss_cls: 0.0003, decode.loss_mask: 0.1875, decode.loss_dice: 0.3724, decode.d0.loss_cls: 2.5852, decode.d0.loss_mask: 0.1895, decode.d0.loss_dice: 0.3890, decode.d1.loss_cls: 0.0097, decode.d1.loss_mask: 0.1896, decode.d1.loss_dice: 0.3748, decode.d2.loss_cls: 0.0014, decode.d2.loss_mask: 0.1873, decode.d2.loss_dice: 0.3711, decode.d3.loss_cls: 0.0011, decode.d3.loss_mask: 0.1887, decode.d3.loss_dice: 0.3750, decode.d4.loss_cls: 0.0005, decode.d4.loss_mask: 0.1887, decode.d4.loss_dice: 0.3738, decode.d5.loss_cls: 0.0005, decode.d5.loss_mask: 0.1882, decode.d5.loss_dice: 0.3747, decode.d6.loss_cls: 0.0004, decode.d6.loss_mask: 0.1862, decode.d6.loss_dice: 0.3662, decode.d7.loss_cls: 0.0004, decode.d7.loss_mask: 0.1877, decode.d7.loss_dice: 0.3649, decode.d8.loss_cls: 0.0004, decode.d8.loss_mask: 0.1874, decode.d8.loss_dice: 0.3717, loss: 8.2145\n",
      "2024-02-14 15:16:41,395 - mmseg - INFO - Iter [2700/80000]\tlr: 1.387e-06, eta: 2 days, 1:32:03, time: 2.129, data_time: 0.016, memory: 23505, decode.loss_cls: 0.0003, decode.loss_mask: 0.1941, decode.loss_dice: 0.3933, decode.d0.loss_cls: 2.5752, decode.d0.loss_mask: 0.2039, decode.d0.loss_dice: 0.4107, decode.d1.loss_cls: 0.0089, decode.d1.loss_mask: 0.1923, decode.d1.loss_dice: 0.3872, decode.d2.loss_cls: 0.0013, decode.d2.loss_mask: 0.1919, decode.d2.loss_dice: 0.3920, decode.d3.loss_cls: 0.0010, decode.d3.loss_mask: 0.1928, decode.d3.loss_dice: 0.3883, decode.d4.loss_cls: 0.0005, decode.d4.loss_mask: 0.1944, decode.d4.loss_dice: 0.3931, decode.d5.loss_cls: 0.0005, decode.d5.loss_mask: 0.1934, decode.d5.loss_dice: 0.3888, decode.d6.loss_cls: 0.0004, decode.d6.loss_mask: 0.1923, decode.d6.loss_dice: 0.3886, decode.d7.loss_cls: 0.0004, decode.d7.loss_mask: 0.1925, decode.d7.loss_dice: 0.3876, decode.d8.loss_cls: 0.0004, decode.d8.loss_mask: 0.1931, decode.d8.loss_dice: 0.3911, loss: 8.4504\n",
      "2024-02-14 15:17:02,684 - mmseg - INFO - Iter [2710/80000]\tlr: 1.387e-06, eta: 2 days, 1:30:50, time: 2.129, data_time: 0.016, memory: 23505, decode.loss_cls: 0.0003, decode.loss_mask: 0.1786, decode.loss_dice: 0.3531, decode.d0.loss_cls: 2.5670, decode.d0.loss_mask: 0.1832, decode.d0.loss_dice: 0.3848, decode.d1.loss_cls: 0.0089, decode.d1.loss_mask: 0.1792, decode.d1.loss_dice: 0.3603, decode.d2.loss_cls: 0.0014, decode.d2.loss_mask: 0.1818, decode.d2.loss_dice: 0.3586, decode.d3.loss_cls: 0.0009, decode.d3.loss_mask: 0.1816, decode.d3.loss_dice: 0.3497, decode.d4.loss_cls: 0.0005, decode.d4.loss_mask: 0.1826, decode.d4.loss_dice: 0.3560, decode.d5.loss_cls: 0.0005, decode.d5.loss_mask: 0.1819, decode.d5.loss_dice: 0.3598, decode.d6.loss_cls: 0.0004, decode.d6.loss_mask: 0.1822, decode.d6.loss_dice: 0.3602, decode.d7.loss_cls: 0.0004, decode.d7.loss_mask: 0.1820, decode.d7.loss_dice: 0.3556, decode.d8.loss_cls: 0.0004, decode.d8.loss_mask: 0.1835, decode.d8.loss_dice: 0.3602, loss: 7.9956\n",
      "2024-02-14 15:17:23,999 - mmseg - INFO - Iter [2720/80000]\tlr: 1.387e-06, eta: 2 days, 1:29:37, time: 2.132, data_time: 0.016, memory: 23505, decode.loss_cls: 0.0003, decode.loss_mask: 0.1991, decode.loss_dice: 0.3954, decode.d0.loss_cls: 2.5597, decode.d0.loss_mask: 0.2035, decode.d0.loss_dice: 0.4079, decode.d1.loss_cls: 0.0116, decode.d1.loss_mask: 0.2003, decode.d1.loss_dice: 0.3968, decode.d2.loss_cls: 0.0015, decode.d2.loss_mask: 0.1995, decode.d2.loss_dice: 0.3968, decode.d3.loss_cls: 0.0008, decode.d3.loss_mask: 0.2012, decode.d3.loss_dice: 0.3971, decode.d4.loss_cls: 0.0005, decode.d4.loss_mask: 0.2004, decode.d4.loss_dice: 0.3998, decode.d5.loss_cls: 0.0004, decode.d5.loss_mask: 0.2012, decode.d5.loss_dice: 0.4004, decode.d6.loss_cls: 0.0004, decode.d6.loss_mask: 0.2018, decode.d6.loss_dice: 0.4016, decode.d7.loss_cls: 0.0004, decode.d7.loss_mask: 0.2012, decode.d7.loss_dice: 0.4002, decode.d8.loss_cls: 0.0004, decode.d8.loss_mask: 0.2021, decode.d8.loss_dice: 0.3988, loss: 8.5814\n",
      "2024-02-14 15:17:45,313 - mmseg - INFO - Iter [2730/80000]\tlr: 1.387e-06, eta: 2 days, 1:28:25, time: 2.131, data_time: 0.017, memory: 23505, decode.loss_cls: 0.0003, decode.loss_mask: 0.2137, decode.loss_dice: 0.4127, decode.d0.loss_cls: 2.5554, decode.d0.loss_mask: 0.2182, decode.d0.loss_dice: 0.4399, decode.d1.loss_cls: 0.0096, decode.d1.loss_mask: 0.2158, decode.d1.loss_dice: 0.4193, decode.d2.loss_cls: 0.0014, decode.d2.loss_mask: 0.2169, decode.d2.loss_dice: 0.4161, decode.d3.loss_cls: 0.0009, decode.d3.loss_mask: 0.2161, decode.d3.loss_dice: 0.4113, decode.d4.loss_cls: 0.0006, decode.d4.loss_mask: 0.2132, decode.d4.loss_dice: 0.4116, decode.d5.loss_cls: 0.0005, decode.d5.loss_mask: 0.2158, decode.d5.loss_dice: 0.4180, decode.d6.loss_cls: 0.0004, decode.d6.loss_mask: 0.2157, decode.d6.loss_dice: 0.4160, decode.d7.loss_cls: 0.0004, decode.d7.loss_mask: 0.2165, decode.d7.loss_dice: 0.4163, decode.d8.loss_cls: 0.0004, decode.d8.loss_mask: 0.2148, decode.d8.loss_dice: 0.4155, loss: 8.9032\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-14 15:18:06,630 - mmseg - INFO - Iter [2740/80000]\tlr: 1.387e-06, eta: 2 days, 1:27:13, time: 2.132, data_time: 0.017, memory: 23505, decode.loss_cls: 0.0003, decode.loss_mask: 0.1916, decode.loss_dice: 0.3702, decode.d0.loss_cls: 2.5449, decode.d0.loss_mask: 0.1942, decode.d0.loss_dice: 0.3778, decode.d1.loss_cls: 0.0080, decode.d1.loss_mask: 0.1933, decode.d1.loss_dice: 0.3705, decode.d2.loss_cls: 0.0013, decode.d2.loss_mask: 0.1911, decode.d2.loss_dice: 0.3624, decode.d3.loss_cls: 0.0008, decode.d3.loss_mask: 0.1929, decode.d3.loss_dice: 0.3689, decode.d4.loss_cls: 0.0005, decode.d4.loss_mask: 0.1918, decode.d4.loss_dice: 0.3707, decode.d5.loss_cls: 0.0004, decode.d5.loss_mask: 0.1934, decode.d5.loss_dice: 0.3716, decode.d6.loss_cls: 0.0004, decode.d6.loss_mask: 0.1936, decode.d6.loss_dice: 0.3703, decode.d7.loss_cls: 0.0003, decode.d7.loss_mask: 0.1920, decode.d7.loss_dice: 0.3679, decode.d8.loss_cls: 0.0003, decode.d8.loss_mask: 0.1909, decode.d8.loss_dice: 0.3673, loss: 8.1795\n",
      "2024-02-14 15:18:27,939 - mmseg - INFO - Iter [2750/80000]\tlr: 1.386e-06, eta: 2 days, 1:26:01, time: 2.130, data_time: 0.016, memory: 23505, decode.loss_cls: 0.0003, decode.loss_mask: 0.2182, decode.loss_dice: 0.4069, decode.d0.loss_cls: 2.5399, decode.d0.loss_mask: 0.2199, decode.d0.loss_dice: 0.4186, decode.d1.loss_cls: 0.0083, decode.d1.loss_mask: 0.2172, decode.d1.loss_dice: 0.4142, decode.d2.loss_cls: 0.0013, decode.d2.loss_mask: 0.2163, decode.d2.loss_dice: 0.4067, decode.d3.loss_cls: 0.0008, decode.d3.loss_mask: 0.2163, decode.d3.loss_dice: 0.4092, decode.d4.loss_cls: 0.0006, decode.d4.loss_mask: 0.2161, decode.d4.loss_dice: 0.4047, decode.d5.loss_cls: 0.0004, decode.d5.loss_mask: 0.2169, decode.d5.loss_dice: 0.4046, decode.d6.loss_cls: 0.0004, decode.d6.loss_mask: 0.2174, decode.d6.loss_dice: 0.4077, decode.d7.loss_cls: 0.0004, decode.d7.loss_mask: 0.2181, decode.d7.loss_dice: 0.4100, decode.d8.loss_cls: 0.0004, decode.d8.loss_mask: 0.2187, decode.d8.loss_dice: 0.4103, loss: 8.8209\n",
      "2024-02-14 15:18:49,232 - mmseg - INFO - Iter [2760/80000]\tlr: 1.386e-06, eta: 2 days, 1:24:49, time: 2.130, data_time: 0.017, memory: 23505, decode.loss_cls: 0.0003, decode.loss_mask: 0.2088, decode.loss_dice: 0.3885, decode.d0.loss_cls: 2.5298, decode.d0.loss_mask: 0.2110, decode.d0.loss_dice: 0.4173, decode.d1.loss_cls: 0.0093, decode.d1.loss_mask: 0.2135, decode.d1.loss_dice: 0.4023, decode.d2.loss_cls: 0.0014, decode.d2.loss_mask: 0.2104, decode.d2.loss_dice: 0.3992, decode.d3.loss_cls: 0.0008, decode.d3.loss_mask: 0.2090, decode.d3.loss_dice: 0.3960, decode.d4.loss_cls: 0.0006, decode.d4.loss_mask: 0.2130, decode.d4.loss_dice: 0.4001, decode.d5.loss_cls: 0.0004, decode.d5.loss_mask: 0.2087, decode.d5.loss_dice: 0.3966, decode.d6.loss_cls: 0.0004, decode.d6.loss_mask: 0.2075, decode.d6.loss_dice: 0.3889, decode.d7.loss_cls: 0.0004, decode.d7.loss_mask: 0.2079, decode.d7.loss_dice: 0.3966, decode.d8.loss_cls: 0.0004, decode.d8.loss_mask: 0.2077, decode.d8.loss_dice: 0.4011, loss: 8.6278\n",
      "2024-02-14 15:19:10,533 - mmseg - INFO - Iter [2770/80000]\tlr: 1.386e-06, eta: 2 days, 1:23:38, time: 2.130, data_time: 0.017, memory: 23505, decode.loss_cls: 0.0003, decode.loss_mask: 0.2024, decode.loss_dice: 0.3991, decode.d0.loss_cls: 2.5248, decode.d0.loss_mask: 0.2120, decode.d0.loss_dice: 0.4148, decode.d1.loss_cls: 0.0093, decode.d1.loss_mask: 0.2050, decode.d1.loss_dice: 0.3950, decode.d2.loss_cls: 0.0013, decode.d2.loss_mask: 0.2035, decode.d2.loss_dice: 0.3969, decode.d3.loss_cls: 0.0009, decode.d3.loss_mask: 0.2036, decode.d3.loss_dice: 0.3969, decode.d4.loss_cls: 0.0005, decode.d4.loss_mask: 0.2040, decode.d4.loss_dice: 0.4008, decode.d5.loss_cls: 0.0004, decode.d5.loss_mask: 0.2031, decode.d5.loss_dice: 0.3967, decode.d6.loss_cls: 0.0004, decode.d6.loss_mask: 0.2047, decode.d6.loss_dice: 0.4012, decode.d7.loss_cls: 0.0003, decode.d7.loss_mask: 0.2037, decode.d7.loss_dice: 0.4014, decode.d8.loss_cls: 0.0003, decode.d8.loss_mask: 0.2014, decode.d8.loss_dice: 0.3986, loss: 8.5835\n",
      "2024-02-14 15:19:31,835 - mmseg - INFO - Iter [2780/80000]\tlr: 1.386e-06, eta: 2 days, 1:22:27, time: 2.130, data_time: 0.016, memory: 23505, decode.loss_cls: 0.0003, decode.loss_mask: 0.1934, decode.loss_dice: 0.3842, decode.d0.loss_cls: 2.5132, decode.d0.loss_mask: 0.1957, decode.d0.loss_dice: 0.3960, decode.d1.loss_cls: 0.0101, decode.d1.loss_mask: 0.1939, decode.d1.loss_dice: 0.3867, decode.d2.loss_cls: 0.0012, decode.d2.loss_mask: 0.1935, decode.d2.loss_dice: 0.3814, decode.d3.loss_cls: 0.0008, decode.d3.loss_mask: 0.1946, decode.d3.loss_dice: 0.3805, decode.d4.loss_cls: 0.0005, decode.d4.loss_mask: 0.1953, decode.d4.loss_dice: 0.3844, decode.d5.loss_cls: 0.0004, decode.d5.loss_mask: 0.1946, decode.d5.loss_dice: 0.3857, decode.d6.loss_cls: 0.0003, decode.d6.loss_mask: 0.1948, decode.d6.loss_dice: 0.3888, decode.d7.loss_cls: 0.0003, decode.d7.loss_mask: 0.1938, decode.d7.loss_dice: 0.3866, decode.d8.loss_cls: 0.0003, decode.d8.loss_mask: 0.1913, decode.d8.loss_dice: 0.3796, loss: 8.3224\n",
      "2024-02-14 15:19:53,154 - mmseg - INFO - Iter [2790/80000]\tlr: 1.386e-06, eta: 2 days, 1:21:17, time: 2.132, data_time: 0.017, memory: 23505, decode.loss_cls: 0.0003, decode.loss_mask: 0.2135, decode.loss_dice: 0.4044, decode.d0.loss_cls: 2.5088, decode.d0.loss_mask: 0.2165, decode.d0.loss_dice: 0.4166, decode.d1.loss_cls: 0.0084, decode.d1.loss_mask: 0.2149, decode.d1.loss_dice: 0.4061, decode.d2.loss_cls: 0.0012, decode.d2.loss_mask: 0.2122, decode.d2.loss_dice: 0.4033, decode.d3.loss_cls: 0.0009, decode.d3.loss_mask: 0.2134, decode.d3.loss_dice: 0.4049, decode.d4.loss_cls: 0.0005, decode.d4.loss_mask: 0.2126, decode.d4.loss_dice: 0.4022, decode.d5.loss_cls: 0.0004, decode.d5.loss_mask: 0.2124, decode.d5.loss_dice: 0.4056, decode.d6.loss_cls: 0.0004, decode.d6.loss_mask: 0.2135, decode.d6.loss_dice: 0.4072, decode.d7.loss_cls: 0.0003, decode.d7.loss_mask: 0.2112, decode.d7.loss_dice: 0.4022, decode.d8.loss_cls: 0.0003, decode.d8.loss_mask: 0.2117, decode.d8.loss_dice: 0.3992, loss: 8.7051\n",
      "2024-02-14 15:20:14,444 - mmseg - INFO - Iter [2800/80000]\tlr: 1.386e-06, eta: 2 days, 1:20:06, time: 2.129, data_time: 0.017, memory: 23505, decode.loss_cls: 0.0003, decode.loss_mask: 0.2025, decode.loss_dice: 0.3965, decode.d0.loss_cls: 2.5010, decode.d0.loss_mask: 0.2094, decode.d0.loss_dice: 0.4213, decode.d1.loss_cls: 0.0078, decode.d1.loss_mask: 0.2025, decode.d1.loss_dice: 0.3951, decode.d2.loss_cls: 0.0014, decode.d2.loss_mask: 0.2045, decode.d2.loss_dice: 0.3967, decode.d3.loss_cls: 0.0009, decode.d3.loss_mask: 0.2024, decode.d3.loss_dice: 0.3965, decode.d4.loss_cls: 0.0005, decode.d4.loss_mask: 0.2022, decode.d4.loss_dice: 0.3970, decode.d5.loss_cls: 0.0004, decode.d5.loss_mask: 0.2044, decode.d5.loss_dice: 0.4022, decode.d6.loss_cls: 0.0004, decode.d6.loss_mask: 0.2027, decode.d6.loss_dice: 0.3943, decode.d7.loss_cls: 0.0004, decode.d7.loss_mask: 0.2051, decode.d7.loss_dice: 0.3996, decode.d8.loss_cls: 0.0004, decode.d8.loss_mask: 0.2037, decode.d8.loss_dice: 0.3996, loss: 8.5515\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 40/40, 6.2 task/s, elapsed: 6s, ETA:     0s\n",
      "\n",
      "2024-02-14 15:20:20,889 - mmseg - INFO - per class results:\n",
      "2024-02-14 15:20:20,890 - mmseg - INFO - \n",
      "+---------------+-------+-------+\n",
      "|     Class     |  IoU  |  Acc  |\n",
      "+---------------+-------+-------+\n",
      "|       bg      | 97.53 | 98.53 |\n",
      "|    Anchovy    |  81.5 | 93.09 |\n",
      "|     Olives    | 86.35 | 89.45 |\n",
      "|     Salami    | 71.39 | 85.83 |\n",
      "|   Red_Pepper  | 88.64 | 95.17 |\n",
      "| Yellow_Pepper | 86.33 | 93.79 |\n",
      "+---------------+-------+-------+\n",
      "2024-02-14 15:20:20,890 - mmseg - INFO - Summary:\n",
      "2024-02-14 15:20:20,890 - mmseg - INFO - \n",
      "+------+-------+-------+\n",
      "| aAcc |  mIoU |  mAcc |\n",
      "+------+-------+-------+\n",
      "| 97.6 | 85.29 | 92.64 |\n",
      "+------+-------+-------+\n",
      "2024-02-14 15:20:20,890 - mmseg - INFO - Iter(val) [10]\taAcc: 0.9760, mIoU: 0.8529, mAcc: 0.9264, IoU.bg: 0.9753, IoU.Anchovy: 0.8150, IoU.Olives: 0.8635, IoU.Salami: 0.7139, IoU.Red_Pepper: 0.8864, IoU.Yellow_Pepper: 0.8633, Acc.bg: 0.9853, Acc.Anchovy: 0.9309, Acc.Olives: 0.8945, Acc.Salami: 0.8583, Acc.Red_Pepper: 0.9517, Acc.Yellow_Pepper: 0.9379\n",
      "2024-02-14 15:20:42,221 - mmseg - INFO - Iter [2810/80000]\tlr: 1.385e-06, eta: 2 days, 1:21:54, time: 2.778, data_time: 0.661, memory: 23505, decode.loss_cls: 0.0003, decode.loss_mask: 0.2324, decode.loss_dice: 0.4213, decode.d0.loss_cls: 2.4967, decode.d0.loss_mask: 0.2380, decode.d0.loss_dice: 0.4299, decode.d1.loss_cls: 0.0068, decode.d1.loss_mask: 0.2343, decode.d1.loss_dice: 0.4188, decode.d2.loss_cls: 0.0011, decode.d2.loss_mask: 0.2331, decode.d2.loss_dice: 0.4200, decode.d3.loss_cls: 0.0009, decode.d3.loss_mask: 0.2351, decode.d3.loss_dice: 0.4204, decode.d4.loss_cls: 0.0005, decode.d4.loss_mask: 0.2334, decode.d4.loss_dice: 0.4203, decode.d5.loss_cls: 0.0004, decode.d5.loss_mask: 0.2348, decode.d5.loss_dice: 0.4221, decode.d6.loss_cls: 0.0004, decode.d6.loss_mask: 0.2345, decode.d6.loss_dice: 0.4215, decode.d7.loss_cls: 0.0003, decode.d7.loss_mask: 0.2364, decode.d7.loss_dice: 0.4223, decode.d8.loss_cls: 0.0003, decode.d8.loss_mask: 0.2355, decode.d8.loss_dice: 0.4212, loss: 9.0730\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-14 15:21:03,533 - mmseg - INFO - Iter [2820/80000]\tlr: 1.385e-06, eta: 2 days, 1:20:45, time: 2.131, data_time: 0.016, memory: 23505, decode.loss_cls: 0.0003, decode.loss_mask: 0.1874, decode.loss_dice: 0.3828, decode.d0.loss_cls: 2.4811, decode.d0.loss_mask: 0.1901, decode.d0.loss_dice: 0.3993, decode.d1.loss_cls: 0.0102, decode.d1.loss_mask: 0.1860, decode.d1.loss_dice: 0.3803, decode.d2.loss_cls: 0.0012, decode.d2.loss_mask: 0.1885, decode.d2.loss_dice: 0.3838, decode.d3.loss_cls: 0.0008, decode.d3.loss_mask: 0.1859, decode.d3.loss_dice: 0.3865, decode.d4.loss_cls: 0.0004, decode.d4.loss_mask: 0.1842, decode.d4.loss_dice: 0.3787, decode.d5.loss_cls: 0.0004, decode.d5.loss_mask: 0.1852, decode.d5.loss_dice: 0.3820, decode.d6.loss_cls: 0.0003, decode.d6.loss_mask: 0.1861, decode.d6.loss_dice: 0.3816, decode.d7.loss_cls: 0.0003, decode.d7.loss_mask: 0.1859, decode.d7.loss_dice: 0.3861, decode.d8.loss_cls: 0.0003, decode.d8.loss_mask: 0.1873, decode.d8.loss_dice: 0.3805, loss: 8.2036\n",
      "2024-02-14 15:21:24,851 - mmseg - INFO - Iter [2830/80000]\tlr: 1.385e-06, eta: 2 days, 1:19:35, time: 2.132, data_time: 0.017, memory: 23505, decode.loss_cls: 0.0003, decode.loss_mask: 0.2451, decode.loss_dice: 0.4382, decode.d0.loss_cls: 2.4831, decode.d0.loss_mask: 0.2505, decode.d0.loss_dice: 0.4540, decode.d1.loss_cls: 0.0064, decode.d1.loss_mask: 0.2468, decode.d1.loss_dice: 0.4347, decode.d2.loss_cls: 0.0011, decode.d2.loss_mask: 0.2475, decode.d2.loss_dice: 0.4434, decode.d3.loss_cls: 0.0010, decode.d3.loss_mask: 0.2430, decode.d3.loss_dice: 0.4346, decode.d4.loss_cls: 0.0005, decode.d4.loss_mask: 0.2482, decode.d4.loss_dice: 0.4373, decode.d5.loss_cls: 0.0004, decode.d5.loss_mask: 0.2465, decode.d5.loss_dice: 0.4391, decode.d6.loss_cls: 0.0004, decode.d6.loss_mask: 0.2448, decode.d6.loss_dice: 0.4387, decode.d7.loss_cls: 0.0003, decode.d7.loss_mask: 0.2448, decode.d7.loss_dice: 0.4356, decode.d8.loss_cls: 0.0003, decode.d8.loss_mask: 0.2464, decode.d8.loss_dice: 0.4392, loss: 9.3522\n",
      "2024-02-14 15:21:46,142 - mmseg - INFO - Iter [2840/80000]\tlr: 1.385e-06, eta: 2 days, 1:18:25, time: 2.129, data_time: 0.016, memory: 23505, decode.loss_cls: 0.0002, decode.loss_mask: 0.1951, decode.loss_dice: 0.3802, decode.d0.loss_cls: 2.4660, decode.d0.loss_mask: 0.1969, decode.d0.loss_dice: 0.3984, decode.d1.loss_cls: 0.0113, decode.d1.loss_mask: 0.1918, decode.d1.loss_dice: 0.3856, decode.d2.loss_cls: 0.0012, decode.d2.loss_mask: 0.1939, decode.d2.loss_dice: 0.3880, decode.d3.loss_cls: 0.0009, decode.d3.loss_mask: 0.1893, decode.d3.loss_dice: 0.3832, decode.d4.loss_cls: 0.0004, decode.d4.loss_mask: 0.1925, decode.d4.loss_dice: 0.3854, decode.d5.loss_cls: 0.0004, decode.d5.loss_mask: 0.1928, decode.d5.loss_dice: 0.3842, decode.d6.loss_cls: 0.0003, decode.d6.loss_mask: 0.1918, decode.d6.loss_dice: 0.3842, decode.d7.loss_cls: 0.0003, decode.d7.loss_mask: 0.1918, decode.d7.loss_dice: 0.3799, decode.d8.loss_cls: 0.0003, decode.d8.loss_mask: 0.1911, decode.d8.loss_dice: 0.3832, loss: 8.2608\n",
      "2024-02-14 15:22:07,445 - mmseg - INFO - Iter [2850/80000]\tlr: 1.385e-06, eta: 2 days, 1:17:16, time: 2.130, data_time: 0.016, memory: 23505, decode.loss_cls: 0.0003, decode.loss_mask: 0.2136, decode.loss_dice: 0.4038, decode.d0.loss_cls: 2.4615, decode.d0.loss_mask: 0.2170, decode.d0.loss_dice: 0.4132, decode.d1.loss_cls: 0.0082, decode.d1.loss_mask: 0.2151, decode.d1.loss_dice: 0.3995, decode.d2.loss_cls: 0.0011, decode.d2.loss_mask: 0.2131, decode.d2.loss_dice: 0.3997, decode.d3.loss_cls: 0.0008, decode.d3.loss_mask: 0.2139, decode.d3.loss_dice: 0.3959, decode.d4.loss_cls: 0.0004, decode.d4.loss_mask: 0.2116, decode.d4.loss_dice: 0.3960, decode.d5.loss_cls: 0.0004, decode.d5.loss_mask: 0.2120, decode.d5.loss_dice: 0.3979, decode.d6.loss_cls: 0.0003, decode.d6.loss_mask: 0.2129, decode.d6.loss_dice: 0.3967, decode.d7.loss_cls: 0.0003, decode.d7.loss_mask: 0.2119, decode.d7.loss_dice: 0.3970, decode.d8.loss_cls: 0.0003, decode.d8.loss_mask: 0.2114, decode.d8.loss_dice: 0.3965, loss: 8.6023\n",
      "2024-02-14 15:22:28,764 - mmseg - INFO - Iter [2860/80000]\tlr: 1.384e-06, eta: 2 days, 1:16:08, time: 2.132, data_time: 0.017, memory: 23505, decode.loss_cls: 0.0003, decode.loss_mask: 0.2300, decode.loss_dice: 0.4282, decode.d0.loss_cls: 2.4547, decode.d0.loss_mask: 0.2355, decode.d0.loss_dice: 0.4411, decode.d1.loss_cls: 0.0082, decode.d1.loss_mask: 0.2310, decode.d1.loss_dice: 0.4311, decode.d2.loss_cls: 0.0012, decode.d2.loss_mask: 0.2328, decode.d2.loss_dice: 0.4308, decode.d3.loss_cls: 0.0008, decode.d3.loss_mask: 0.2327, decode.d3.loss_dice: 0.4297, decode.d4.loss_cls: 0.0005, decode.d4.loss_mask: 0.2311, decode.d4.loss_dice: 0.4293, decode.d5.loss_cls: 0.0004, decode.d5.loss_mask: 0.2317, decode.d5.loss_dice: 0.4340, decode.d6.loss_cls: 0.0003, decode.d6.loss_mask: 0.2327, decode.d6.loss_dice: 0.4317, decode.d7.loss_cls: 0.0003, decode.d7.loss_mask: 0.2334, decode.d7.loss_dice: 0.4301, decode.d8.loss_cls: 0.0003, decode.d8.loss_mask: 0.2318, decode.d8.loss_dice: 0.4316, loss: 9.1072\n",
      "2024-02-14 15:22:50,067 - mmseg - INFO - Iter [2870/80000]\tlr: 1.384e-06, eta: 2 days, 1:15:00, time: 2.130, data_time: 0.016, memory: 23505, decode.loss_cls: 0.0003, decode.loss_mask: 0.2095, decode.loss_dice: 0.3964, decode.d0.loss_cls: 2.4451, decode.d0.loss_mask: 0.2168, decode.d0.loss_dice: 0.4086, decode.d1.loss_cls: 0.0080, decode.d1.loss_mask: 0.2107, decode.d1.loss_dice: 0.3901, decode.d2.loss_cls: 0.0012, decode.d2.loss_mask: 0.2113, decode.d2.loss_dice: 0.3963, decode.d3.loss_cls: 0.0008, decode.d3.loss_mask: 0.2086, decode.d3.loss_dice: 0.3911, decode.d4.loss_cls: 0.0004, decode.d4.loss_mask: 0.2098, decode.d4.loss_dice: 0.3937, decode.d5.loss_cls: 0.0004, decode.d5.loss_mask: 0.2105, decode.d5.loss_dice: 0.3954, decode.d6.loss_cls: 0.0003, decode.d6.loss_mask: 0.2113, decode.d6.loss_dice: 0.3916, decode.d7.loss_cls: 0.0003, decode.d7.loss_mask: 0.2092, decode.d7.loss_dice: 0.3925, decode.d8.loss_cls: 0.0003, decode.d8.loss_mask: 0.2091, decode.d8.loss_dice: 0.3927, loss: 8.5125\n",
      "2024-02-14 15:23:11,358 - mmseg - INFO - Iter [2880/80000]\tlr: 1.384e-06, eta: 2 days, 1:13:51, time: 2.129, data_time: 0.017, memory: 23505, decode.loss_cls: 0.0003, decode.loss_mask: 0.1989, decode.loss_dice: 0.3979, decode.d0.loss_cls: 2.4381, decode.d0.loss_mask: 0.2045, decode.d0.loss_dice: 0.4118, decode.d1.loss_cls: 0.0070, decode.d1.loss_mask: 0.1993, decode.d1.loss_dice: 0.3989, decode.d2.loss_cls: 0.0012, decode.d2.loss_mask: 0.2004, decode.d2.loss_dice: 0.3993, decode.d3.loss_cls: 0.0008, decode.d3.loss_mask: 0.1980, decode.d3.loss_dice: 0.3985, decode.d4.loss_cls: 0.0005, decode.d4.loss_mask: 0.1992, decode.d4.loss_dice: 0.4041, decode.d5.loss_cls: 0.0004, decode.d5.loss_mask: 0.2016, decode.d5.loss_dice: 0.4054, decode.d6.loss_cls: 0.0003, decode.d6.loss_mask: 0.1992, decode.d6.loss_dice: 0.4016, decode.d7.loss_cls: 0.0003, decode.d7.loss_mask: 0.1992, decode.d7.loss_dice: 0.4028, decode.d8.loss_cls: 0.0003, decode.d8.loss_mask: 0.2005, decode.d8.loss_dice: 0.4045, loss: 8.4747\n",
      "2024-02-14 15:23:34,708 - mmseg - INFO - Iter [2890/80000]\tlr: 1.384e-06, eta: 2 days, 1:13:38, time: 2.335, data_time: 0.222, memory: 23505, decode.loss_cls: 0.0002, decode.loss_mask: 0.2007, decode.loss_dice: 0.3896, decode.d0.loss_cls: 2.4275, decode.d0.loss_mask: 0.2077, decode.d0.loss_dice: 0.4064, decode.d1.loss_cls: 0.0116, decode.d1.loss_mask: 0.2016, decode.d1.loss_dice: 0.3903, decode.d2.loss_cls: 0.0013, decode.d2.loss_mask: 0.2022, decode.d2.loss_dice: 0.3865, decode.d3.loss_cls: 0.0008, decode.d3.loss_mask: 0.2004, decode.d3.loss_dice: 0.3863, decode.d4.loss_cls: 0.0005, decode.d4.loss_mask: 0.2039, decode.d4.loss_dice: 0.3920, decode.d5.loss_cls: 0.0004, decode.d5.loss_mask: 0.2029, decode.d5.loss_dice: 0.3918, decode.d6.loss_cls: 0.0003, decode.d6.loss_mask: 0.1998, decode.d6.loss_dice: 0.3873, decode.d7.loss_cls: 0.0003, decode.d7.loss_mask: 0.2014, decode.d7.loss_dice: 0.3904, decode.d8.loss_cls: 0.0003, decode.d8.loss_mask: 0.2032, decode.d8.loss_dice: 0.3881, loss: 8.3756\n",
      "2024-02-14 15:23:55,974 - mmseg - INFO - Iter [2900/80000]\tlr: 1.384e-06, eta: 2 days, 1:12:29, time: 2.127, data_time: 0.016, memory: 23505, decode.loss_cls: 0.0002, decode.loss_mask: 0.1886, decode.loss_dice: 0.3670, decode.d0.loss_cls: 2.4179, decode.d0.loss_mask: 0.1886, decode.d0.loss_dice: 0.3920, decode.d1.loss_cls: 0.0095, decode.d1.loss_mask: 0.1876, decode.d1.loss_dice: 0.3736, decode.d2.loss_cls: 0.0012, decode.d2.loss_mask: 0.1874, decode.d2.loss_dice: 0.3670, decode.d3.loss_cls: 0.0007, decode.d3.loss_mask: 0.1865, decode.d3.loss_dice: 0.3645, decode.d4.loss_cls: 0.0004, decode.d4.loss_mask: 0.1881, decode.d4.loss_dice: 0.3709, decode.d5.loss_cls: 0.0004, decode.d5.loss_mask: 0.1907, decode.d5.loss_dice: 0.3765, decode.d6.loss_cls: 0.0003, decode.d6.loss_mask: 0.1883, decode.d6.loss_dice: 0.3643, decode.d7.loss_cls: 0.0003, decode.d7.loss_mask: 0.1893, decode.d7.loss_dice: 0.3691, decode.d8.loss_cls: 0.0003, decode.d8.loss_mask: 0.1882, decode.d8.loss_dice: 0.3705, loss: 8.0300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-14 15:24:17,284 - mmseg - INFO - Iter [2910/80000]\tlr: 1.384e-06, eta: 2 days, 1:11:22, time: 2.131, data_time: 0.015, memory: 23505, decode.loss_cls: 0.0002, decode.loss_mask: 0.1817, decode.loss_dice: 0.3651, decode.d0.loss_cls: 2.4086, decode.d0.loss_mask: 0.1840, decode.d0.loss_dice: 0.3837, decode.d1.loss_cls: 0.0115, decode.d1.loss_mask: 0.1836, decode.d1.loss_dice: 0.3712, decode.d2.loss_cls: 0.0012, decode.d2.loss_mask: 0.1816, decode.d2.loss_dice: 0.3673, decode.d3.loss_cls: 0.0007, decode.d3.loss_mask: 0.1800, decode.d3.loss_dice: 0.3604, decode.d4.loss_cls: 0.0004, decode.d4.loss_mask: 0.1816, decode.d4.loss_dice: 0.3629, decode.d5.loss_cls: 0.0004, decode.d5.loss_mask: 0.1831, decode.d5.loss_dice: 0.3693, decode.d6.loss_cls: 0.0003, decode.d6.loss_mask: 0.1787, decode.d6.loss_dice: 0.3589, decode.d7.loss_cls: 0.0003, decode.d7.loss_mask: 0.1794, decode.d7.loss_dice: 0.3653, decode.d8.loss_cls: 0.0003, decode.d8.loss_mask: 0.1783, decode.d8.loss_dice: 0.3614, loss: 7.9014\n",
      "2024-02-14 15:24:38,561 - mmseg - INFO - Iter [2920/80000]\tlr: 1.383e-06, eta: 2 days, 1:10:15, time: 2.128, data_time: 0.016, memory: 23505, decode.loss_cls: 0.0003, decode.loss_mask: 0.1764, decode.loss_dice: 0.3608, decode.d0.loss_cls: 2.3997, decode.d0.loss_mask: 0.1764, decode.d0.loss_dice: 0.3780, decode.d1.loss_cls: 0.0119, decode.d1.loss_mask: 0.1791, decode.d1.loss_dice: 0.3662, decode.d2.loss_cls: 0.0013, decode.d2.loss_mask: 0.1752, decode.d2.loss_dice: 0.3611, decode.d3.loss_cls: 0.0008, decode.d3.loss_mask: 0.1779, decode.d3.loss_dice: 0.3651, decode.d4.loss_cls: 0.0004, decode.d4.loss_mask: 0.1772, decode.d4.loss_dice: 0.3631, decode.d5.loss_cls: 0.0004, decode.d5.loss_mask: 0.1750, decode.d5.loss_dice: 0.3635, decode.d6.loss_cls: 0.0004, decode.d6.loss_mask: 0.1762, decode.d6.loss_dice: 0.3648, decode.d7.loss_cls: 0.0003, decode.d7.loss_mask: 0.1759, decode.d7.loss_dice: 0.3622, decode.d8.loss_cls: 0.0003, decode.d8.loss_mask: 0.1735, decode.d8.loss_dice: 0.3609, loss: 7.8247\n",
      "2024-02-14 15:24:59,881 - mmseg - INFO - Iter [2930/80000]\tlr: 1.383e-06, eta: 2 days, 1:09:08, time: 2.132, data_time: 0.017, memory: 23505, decode.loss_cls: 0.0003, decode.loss_mask: 0.2150, decode.loss_dice: 0.3840, decode.d0.loss_cls: 2.4016, decode.d0.loss_mask: 0.2141, decode.d0.loss_dice: 0.4004, decode.d1.loss_cls: 0.0077, decode.d1.loss_mask: 0.2181, decode.d1.loss_dice: 0.3850, decode.d2.loss_cls: 0.0011, decode.d2.loss_mask: 0.2130, decode.d2.loss_dice: 0.3776, decode.d3.loss_cls: 0.0008, decode.d3.loss_mask: 0.2142, decode.d3.loss_dice: 0.3815, decode.d4.loss_cls: 0.0005, decode.d4.loss_mask: 0.2139, decode.d4.loss_dice: 0.3815, decode.d5.loss_cls: 0.0004, decode.d5.loss_mask: 0.2147, decode.d5.loss_dice: 0.3847, decode.d6.loss_cls: 0.0003, decode.d6.loss_mask: 0.2145, decode.d6.loss_dice: 0.3781, decode.d7.loss_cls: 0.0003, decode.d7.loss_mask: 0.2152, decode.d7.loss_dice: 0.3845, decode.d8.loss_cls: 0.0003, decode.d8.loss_mask: 0.2160, decode.d8.loss_dice: 0.3838, loss: 8.4031\n",
      "2024-02-14 15:25:21,210 - mmseg - INFO - Iter [2940/80000]\tlr: 1.383e-06, eta: 2 days, 1:08:03, time: 2.133, data_time: 0.016, memory: 23505, decode.loss_cls: 0.0002, decode.loss_mask: 0.1916, decode.loss_dice: 0.3684, decode.d0.loss_cls: 2.3905, decode.d0.loss_mask: 0.1951, decode.d0.loss_dice: 0.3901, decode.d1.loss_cls: 0.0086, decode.d1.loss_mask: 0.1895, decode.d1.loss_dice: 0.3656, decode.d2.loss_cls: 0.0010, decode.d2.loss_mask: 0.1911, decode.d2.loss_dice: 0.3671, decode.d3.loss_cls: 0.0008, decode.d3.loss_mask: 0.1915, decode.d3.loss_dice: 0.3673, decode.d4.loss_cls: 0.0004, decode.d4.loss_mask: 0.1913, decode.d4.loss_dice: 0.3681, decode.d5.loss_cls: 0.0004, decode.d5.loss_mask: 0.1926, decode.d5.loss_dice: 0.3711, decode.d6.loss_cls: 0.0003, decode.d6.loss_mask: 0.1897, decode.d6.loss_dice: 0.3655, decode.d7.loss_cls: 0.0003, decode.d7.loss_mask: 0.1934, decode.d7.loss_dice: 0.3723, decode.d8.loss_cls: 0.0003, decode.d8.loss_mask: 0.1899, decode.d8.loss_dice: 0.3661, loss: 8.0200\n",
      "2024-02-14 15:25:42,505 - mmseg - INFO - Iter [2950/80000]\tlr: 1.383e-06, eta: 2 days, 1:06:56, time: 2.129, data_time: 0.017, memory: 23505, decode.loss_cls: 0.0002, decode.loss_mask: 0.1872, decode.loss_dice: 0.3614, decode.d0.loss_cls: 2.3806, decode.d0.loss_mask: 0.1906, decode.d0.loss_dice: 0.3811, decode.d1.loss_cls: 0.0097, decode.d1.loss_mask: 0.1889, decode.d1.loss_dice: 0.3633, decode.d2.loss_cls: 0.0010, decode.d2.loss_mask: 0.1887, decode.d2.loss_dice: 0.3642, decode.d3.loss_cls: 0.0008, decode.d3.loss_mask: 0.1898, decode.d3.loss_dice: 0.3632, decode.d4.loss_cls: 0.0004, decode.d4.loss_mask: 0.1873, decode.d4.loss_dice: 0.3597, decode.d5.loss_cls: 0.0004, decode.d5.loss_mask: 0.1900, decode.d5.loss_dice: 0.3655, decode.d6.loss_cls: 0.0003, decode.d6.loss_mask: 0.1902, decode.d6.loss_dice: 0.3676, decode.d7.loss_cls: 0.0003, decode.d7.loss_mask: 0.1887, decode.d7.loss_dice: 0.3648, decode.d8.loss_cls: 0.0003, decode.d8.loss_mask: 0.1888, decode.d8.loss_dice: 0.3649, loss: 7.9399\n",
      "2024-02-14 15:26:03,822 - mmseg - INFO - Iter [2960/80000]\tlr: 1.383e-06, eta: 2 days, 1:05:51, time: 2.132, data_time: 0.017, memory: 23505, decode.loss_cls: 0.0003, decode.loss_mask: 0.2197, decode.loss_dice: 0.3960, decode.d0.loss_cls: 2.3800, decode.d0.loss_mask: 0.2246, decode.d0.loss_dice: 0.4117, decode.d1.loss_cls: 0.0071, decode.d1.loss_mask: 0.2229, decode.d1.loss_dice: 0.3988, decode.d2.loss_cls: 0.0012, decode.d2.loss_mask: 0.2204, decode.d2.loss_dice: 0.3998, decode.d3.loss_cls: 0.0009, decode.d3.loss_mask: 0.2196, decode.d3.loss_dice: 0.3941, decode.d4.loss_cls: 0.0005, decode.d4.loss_mask: 0.2208, decode.d4.loss_dice: 0.3978, decode.d5.loss_cls: 0.0004, decode.d5.loss_mask: 0.2211, decode.d5.loss_dice: 0.3962, decode.d6.loss_cls: 0.0003, decode.d6.loss_mask: 0.2193, decode.d6.loss_dice: 0.3944, decode.d7.loss_cls: 0.0003, decode.d7.loss_mask: 0.2174, decode.d7.loss_dice: 0.3938, decode.d8.loss_cls: 0.0003, decode.d8.loss_mask: 0.2216, decode.d8.loss_dice: 0.3987, loss: 8.5800\n",
      "2024-02-14 15:26:25,143 - mmseg - INFO - Iter [2970/80000]\tlr: 1.383e-06, eta: 2 days, 1:04:46, time: 2.132, data_time: 0.017, memory: 23505, decode.loss_cls: 0.0002, decode.loss_mask: 0.2137, decode.loss_dice: 0.3968, decode.d0.loss_cls: 2.3690, decode.d0.loss_mask: 0.2166, decode.d0.loss_dice: 0.4168, decode.d1.loss_cls: 0.0084, decode.d1.loss_mask: 0.2142, decode.d1.loss_dice: 0.3968, decode.d2.loss_cls: 0.0010, decode.d2.loss_mask: 0.2173, decode.d2.loss_dice: 0.4017, decode.d3.loss_cls: 0.0008, decode.d3.loss_mask: 0.2136, decode.d3.loss_dice: 0.3988, decode.d4.loss_cls: 0.0005, decode.d4.loss_mask: 0.2161, decode.d4.loss_dice: 0.4043, decode.d5.loss_cls: 0.0004, decode.d5.loss_mask: 0.2159, decode.d5.loss_dice: 0.4004, decode.d6.loss_cls: 0.0003, decode.d6.loss_mask: 0.2148, decode.d6.loss_dice: 0.4039, decode.d7.loss_cls: 0.0003, decode.d7.loss_mask: 0.2139, decode.d7.loss_dice: 0.4004, decode.d8.loss_cls: 0.0003, decode.d8.loss_mask: 0.2169, decode.d8.loss_dice: 0.4040, loss: 8.5581\n",
      "2024-02-14 15:26:46,459 - mmseg - INFO - Iter [2980/80000]\tlr: 1.382e-06, eta: 2 days, 1:03:41, time: 2.132, data_time: 0.017, memory: 23505, decode.loss_cls: 0.0002, decode.loss_mask: 0.1898, decode.loss_dice: 0.3595, decode.d0.loss_cls: 2.3603, decode.d0.loss_mask: 0.1875, decode.d0.loss_dice: 0.3696, decode.d1.loss_cls: 0.0096, decode.d1.loss_mask: 0.1884, decode.d1.loss_dice: 0.3553, decode.d2.loss_cls: 0.0010, decode.d2.loss_mask: 0.1903, decode.d2.loss_dice: 0.3608, decode.d3.loss_cls: 0.0007, decode.d3.loss_mask: 0.1883, decode.d3.loss_dice: 0.3561, decode.d4.loss_cls: 0.0005, decode.d4.loss_mask: 0.1902, decode.d4.loss_dice: 0.3617, decode.d5.loss_cls: 0.0004, decode.d5.loss_mask: 0.1874, decode.d5.loss_dice: 0.3559, decode.d6.loss_cls: 0.0003, decode.d6.loss_mask: 0.1889, decode.d6.loss_dice: 0.3561, decode.d7.loss_cls: 0.0003, decode.d7.loss_mask: 0.1908, decode.d7.loss_dice: 0.3617, decode.d8.loss_cls: 0.0003, decode.d8.loss_mask: 0.1889, decode.d8.loss_dice: 0.3598, loss: 7.8608\n",
      "2024-02-14 15:27:07,768 - mmseg - INFO - Iter [2990/80000]\tlr: 1.382e-06, eta: 2 days, 1:02:36, time: 2.131, data_time: 0.016, memory: 23505, decode.loss_cls: 0.0002, decode.loss_mask: 0.2213, decode.loss_dice: 0.3927, decode.d0.loss_cls: 2.3514, decode.d0.loss_mask: 0.2234, decode.d0.loss_dice: 0.4068, decode.d1.loss_cls: 0.0086, decode.d1.loss_mask: 0.2231, decode.d1.loss_dice: 0.3947, decode.d2.loss_cls: 0.0010, decode.d2.loss_mask: 0.2222, decode.d2.loss_dice: 0.3888, decode.d3.loss_cls: 0.0007, decode.d3.loss_mask: 0.2219, decode.d3.loss_dice: 0.3926, decode.d4.loss_cls: 0.0004, decode.d4.loss_mask: 0.2215, decode.d4.loss_dice: 0.3930, decode.d5.loss_cls: 0.0004, decode.d5.loss_mask: 0.2223, decode.d5.loss_dice: 0.3940, decode.d6.loss_cls: 0.0003, decode.d6.loss_mask: 0.2208, decode.d6.loss_dice: 0.3906, decode.d7.loss_cls: 0.0003, decode.d7.loss_mask: 0.2186, decode.d7.loss_dice: 0.3894, decode.d8.loss_cls: 0.0003, decode.d8.loss_mask: 0.2227, decode.d8.loss_dice: 0.3951, loss: 8.5192\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-14 15:27:29,066 - mmseg - INFO - Exp name: pizze_training_large.py\n",
      "2024-02-14 15:27:29,066 - mmseg - INFO - Iter [3000/80000]\tlr: 1.382e-06, eta: 2 days, 1:01:32, time: 2.130, data_time: 0.017, memory: 23505, decode.loss_cls: 0.0004, decode.loss_mask: 0.1964, decode.loss_dice: 0.3846, decode.d0.loss_cls: 2.3461, decode.d0.loss_mask: 0.1988, decode.d0.loss_dice: 0.4015, decode.d1.loss_cls: 0.0080, decode.d1.loss_mask: 0.1978, decode.d1.loss_dice: 0.3859, decode.d2.loss_cls: 0.0010, decode.d2.loss_mask: 0.1957, decode.d2.loss_dice: 0.3850, decode.d3.loss_cls: 0.0009, decode.d3.loss_mask: 0.1953, decode.d3.loss_dice: 0.3836, decode.d4.loss_cls: 0.0006, decode.d4.loss_mask: 0.1964, decode.d4.loss_dice: 0.3857, decode.d5.loss_cls: 0.0005, decode.d5.loss_mask: 0.1957, decode.d5.loss_dice: 0.3839, decode.d6.loss_cls: 0.0004, decode.d6.loss_mask: 0.1963, decode.d6.loss_dice: 0.3857, decode.d7.loss_cls: 0.0004, decode.d7.loss_mask: 0.1964, decode.d7.loss_dice: 0.3841, decode.d8.loss_cls: 0.0005, decode.d8.loss_mask: 0.1966, decode.d8.loss_dice: 0.3830, loss: 8.1870\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 40/40, 6.2 task/s, elapsed: 6s, ETA:     0s\n",
      "\n",
      "2024-02-14 15:27:35,518 - mmseg - INFO - per class results:\n",
      "2024-02-14 15:27:35,519 - mmseg - INFO - \n",
      "+---------------+-------+-------+\n",
      "|     Class     |  IoU  |  Acc  |\n",
      "+---------------+-------+-------+\n",
      "|       bg      | 97.54 | 98.59 |\n",
      "|    Anchovy    |  81.1 | 94.54 |\n",
      "|     Olives    | 86.53 | 89.05 |\n",
      "|     Salami    | 71.39 | 84.98 |\n",
      "|   Red_Pepper  | 88.99 | 94.69 |\n",
      "| Yellow_Pepper | 86.25 | 94.12 |\n",
      "+---------------+-------+-------+\n",
      "2024-02-14 15:27:35,519 - mmseg - INFO - Summary:\n",
      "2024-02-14 15:27:35,519 - mmseg - INFO - \n",
      "+-------+------+-------+\n",
      "|  aAcc | mIoU |  mAcc |\n",
      "+-------+------+-------+\n",
      "| 97.62 | 85.3 | 92.66 |\n",
      "+-------+------+-------+\n",
      "2024-02-14 15:27:35,519 - mmseg - INFO - Exp name: pizze_training_large.py\n",
      "2024-02-14 15:27:35,519 - mmseg - INFO - Iter(val) [10]\taAcc: 0.9762, mIoU: 0.8530, mAcc: 0.9266, IoU.bg: 0.9754, IoU.Anchovy: 0.8110, IoU.Olives: 0.8653, IoU.Salami: 0.7139, IoU.Red_Pepper: 0.8899, IoU.Yellow_Pepper: 0.8625, Acc.bg: 0.9859, Acc.Anchovy: 0.9454, Acc.Olives: 0.8905, Acc.Salami: 0.8498, Acc.Red_Pepper: 0.9469, Acc.Yellow_Pepper: 0.9412\n",
      "2024-02-14 15:27:56,816 - mmseg - INFO - Iter [3010/80000]\tlr: 1.382e-06, eta: 2 days, 1:03:12, time: 2.775, data_time: 0.661, memory: 23505, decode.loss_cls: 0.0002, decode.loss_mask: 0.2107, decode.loss_dice: 0.3792, decode.d0.loss_cls: 2.3369, decode.d0.loss_mask: 0.2104, decode.d0.loss_dice: 0.4028, decode.d1.loss_cls: 0.0090, decode.d1.loss_mask: 0.2098, decode.d1.loss_dice: 0.3789, decode.d2.loss_cls: 0.0011, decode.d2.loss_mask: 0.2083, decode.d2.loss_dice: 0.3818, decode.d3.loss_cls: 0.0008, decode.d3.loss_mask: 0.2074, decode.d3.loss_dice: 0.3788, decode.d4.loss_cls: 0.0005, decode.d4.loss_mask: 0.2098, decode.d4.loss_dice: 0.3785, decode.d5.loss_cls: 0.0004, decode.d5.loss_mask: 0.2099, decode.d5.loss_dice: 0.3813, decode.d6.loss_cls: 0.0003, decode.d6.loss_mask: 0.2088, decode.d6.loss_dice: 0.3812, decode.d7.loss_cls: 0.0003, decode.d7.loss_mask: 0.2104, decode.d7.loss_dice: 0.3781, decode.d8.loss_cls: 0.0003, decode.d8.loss_mask: 0.2073, decode.d8.loss_dice: 0.3777, loss: 8.2609\n",
      "2024-02-14 15:28:18,141 - mmseg - INFO - Iter [3020/80000]\tlr: 1.382e-06, eta: 2 days, 1:02:08, time: 2.133, data_time: 0.017, memory: 23505, decode.loss_cls: 0.0002, decode.loss_mask: 0.2050, decode.loss_dice: 0.3920, decode.d0.loss_cls: 2.3297, decode.d0.loss_mask: 0.2098, decode.d0.loss_dice: 0.4027, decode.d1.loss_cls: 0.0070, decode.d1.loss_mask: 0.2062, decode.d1.loss_dice: 0.3846, decode.d2.loss_cls: 0.0010, decode.d2.loss_mask: 0.2058, decode.d2.loss_dice: 0.3881, decode.d3.loss_cls: 0.0008, decode.d3.loss_mask: 0.2009, decode.d3.loss_dice: 0.3874, decode.d4.loss_cls: 0.0004, decode.d4.loss_mask: 0.2041, decode.d4.loss_dice: 0.3871, decode.d5.loss_cls: 0.0004, decode.d5.loss_mask: 0.2023, decode.d5.loss_dice: 0.3893, decode.d6.loss_cls: 0.0003, decode.d6.loss_mask: 0.2040, decode.d6.loss_dice: 0.3865, decode.d7.loss_cls: 0.0003, decode.d7.loss_mask: 0.2033, decode.d7.loss_dice: 0.3836, decode.d8.loss_cls: 0.0003, decode.d8.loss_mask: 0.2024, decode.d8.loss_dice: 0.3921, loss: 8.2775\n",
      "2024-02-14 15:28:39,451 - mmseg - INFO - Iter [3030/80000]\tlr: 1.381e-06, eta: 2 days, 1:01:04, time: 2.131, data_time: 0.017, memory: 23505, decode.loss_cls: 0.0002, decode.loss_mask: 0.1880, decode.loss_dice: 0.3498, decode.d0.loss_cls: 2.3173, decode.d0.loss_mask: 0.1942, decode.d0.loss_dice: 0.3725, decode.d1.loss_cls: 0.0112, decode.d1.loss_mask: 0.1892, decode.d1.loss_dice: 0.3554, decode.d2.loss_cls: 0.0011, decode.d2.loss_mask: 0.1871, decode.d2.loss_dice: 0.3531, decode.d3.loss_cls: 0.0007, decode.d3.loss_mask: 0.1885, decode.d3.loss_dice: 0.3543, decode.d4.loss_cls: 0.0003, decode.d4.loss_mask: 0.1914, decode.d4.loss_dice: 0.3520, decode.d5.loss_cls: 0.0003, decode.d5.loss_mask: 0.1911, decode.d5.loss_dice: 0.3525, decode.d6.loss_cls: 0.0003, decode.d6.loss_mask: 0.1885, decode.d6.loss_dice: 0.3489, decode.d7.loss_cls: 0.0003, decode.d7.loss_mask: 0.1893, decode.d7.loss_dice: 0.3509, decode.d8.loss_cls: 0.0003, decode.d8.loss_mask: 0.1884, decode.d8.loss_dice: 0.3495, loss: 7.7666\n",
      "2024-02-14 15:29:00,745 - mmseg - INFO - Iter [3040/80000]\tlr: 1.381e-06, eta: 2 days, 1:00:00, time: 2.129, data_time: 0.017, memory: 23505, decode.loss_cls: 0.0003, decode.loss_mask: 0.2017, decode.loss_dice: 0.3794, decode.d0.loss_cls: 2.3146, decode.d0.loss_mask: 0.2057, decode.d0.loss_dice: 0.3959, decode.d1.loss_cls: 0.0080, decode.d1.loss_mask: 0.1987, decode.d1.loss_dice: 0.3854, decode.d2.loss_cls: 0.0011, decode.d2.loss_mask: 0.2013, decode.d2.loss_dice: 0.3806, decode.d3.loss_cls: 0.0008, decode.d3.loss_mask: 0.2008, decode.d3.loss_dice: 0.3769, decode.d4.loss_cls: 0.0005, decode.d4.loss_mask: 0.2016, decode.d4.loss_dice: 0.3793, decode.d5.loss_cls: 0.0004, decode.d5.loss_mask: 0.2029, decode.d5.loss_dice: 0.3874, decode.d6.loss_cls: 0.0004, decode.d6.loss_mask: 0.2008, decode.d6.loss_dice: 0.3801, decode.d7.loss_cls: 0.0003, decode.d7.loss_mask: 0.1990, decode.d7.loss_dice: 0.3742, decode.d8.loss_cls: 0.0004, decode.d8.loss_mask: 0.2015, decode.d8.loss_dice: 0.3782, loss: 8.1582\n",
      "2024-02-14 15:29:22,064 - mmseg - INFO - Iter [3050/80000]\tlr: 1.381e-06, eta: 2 days, 0:58:57, time: 2.132, data_time: 0.017, memory: 23505, decode.loss_cls: 0.0003, decode.loss_mask: 0.2104, decode.loss_dice: 0.3915, decode.d0.loss_cls: 2.3086, decode.d0.loss_mask: 0.2155, decode.d0.loss_dice: 0.4056, decode.d1.loss_cls: 0.0065, decode.d1.loss_mask: 0.2121, decode.d1.loss_dice: 0.3976, decode.d2.loss_cls: 0.0009, decode.d2.loss_mask: 0.2129, decode.d2.loss_dice: 0.3966, decode.d3.loss_cls: 0.0006, decode.d3.loss_mask: 0.2152, decode.d3.loss_dice: 0.3993, decode.d4.loss_cls: 0.0005, decode.d4.loss_mask: 0.2108, decode.d4.loss_dice: 0.4006, decode.d5.loss_cls: 0.0004, decode.d5.loss_mask: 0.2119, decode.d5.loss_dice: 0.3989, decode.d6.loss_cls: 0.0003, decode.d6.loss_mask: 0.2113, decode.d6.loss_dice: 0.4013, decode.d7.loss_cls: 0.0003, decode.d7.loss_mask: 0.2098, decode.d7.loss_dice: 0.3942, decode.d8.loss_cls: 0.0003, decode.d8.loss_mask: 0.2115, decode.d8.loss_dice: 0.3973, loss: 8.4230\n",
      "2024-02-14 15:29:43,375 - mmseg - INFO - Iter [3060/80000]\tlr: 1.381e-06, eta: 2 days, 0:57:53, time: 2.131, data_time: 0.017, memory: 23505, decode.loss_cls: 0.0002, decode.loss_mask: 0.1746, decode.loss_dice: 0.3459, decode.d0.loss_cls: 2.2948, decode.d0.loss_mask: 0.1795, decode.d0.loss_dice: 0.3672, decode.d1.loss_cls: 0.0094, decode.d1.loss_mask: 0.1757, decode.d1.loss_dice: 0.3536, decode.d2.loss_cls: 0.0010, decode.d2.loss_mask: 0.1760, decode.d2.loss_dice: 0.3540, decode.d3.loss_cls: 0.0006, decode.d3.loss_mask: 0.1779, decode.d3.loss_dice: 0.3574, decode.d4.loss_cls: 0.0004, decode.d4.loss_mask: 0.1765, decode.d4.loss_dice: 0.3569, decode.d5.loss_cls: 0.0003, decode.d5.loss_mask: 0.1760, decode.d5.loss_dice: 0.3562, decode.d6.loss_cls: 0.0003, decode.d6.loss_mask: 0.1734, decode.d6.loss_dice: 0.3523, decode.d7.loss_cls: 0.0003, decode.d7.loss_mask: 0.1760, decode.d7.loss_dice: 0.3553, decode.d8.loss_cls: 0.0003, decode.d8.loss_mask: 0.1772, decode.d8.loss_dice: 0.3577, loss: 7.6270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-14 15:30:04,697 - mmseg - INFO - Iter [3070/80000]\tlr: 1.381e-06, eta: 2 days, 0:56:51, time: 2.132, data_time: 0.015, memory: 23505, decode.loss_cls: 0.0002, decode.loss_mask: 0.2139, decode.loss_dice: 0.4083, decode.d0.loss_cls: 2.2889, decode.d0.loss_mask: 0.2224, decode.d0.loss_dice: 0.4333, decode.d1.loss_cls: 0.0092, decode.d1.loss_mask: 0.2141, decode.d1.loss_dice: 0.4124, decode.d2.loss_cls: 0.0009, decode.d2.loss_mask: 0.2137, decode.d2.loss_dice: 0.4067, decode.d3.loss_cls: 0.0006, decode.d3.loss_mask: 0.2159, decode.d3.loss_dice: 0.4114, decode.d4.loss_cls: 0.0004, decode.d4.loss_mask: 0.2142, decode.d4.loss_dice: 0.4142, decode.d5.loss_cls: 0.0003, decode.d5.loss_mask: 0.2136, decode.d5.loss_dice: 0.4095, decode.d6.loss_cls: 0.0003, decode.d6.loss_mask: 0.2127, decode.d6.loss_dice: 0.4097, decode.d7.loss_cls: 0.0003, decode.d7.loss_mask: 0.2123, decode.d7.loss_dice: 0.4102, decode.d8.loss_cls: 0.0003, decode.d8.loss_mask: 0.2104, decode.d8.loss_dice: 0.4062, loss: 8.5665\n",
      "2024-02-14 15:30:26,004 - mmseg - INFO - Iter [3080/80000]\tlr: 1.381e-06, eta: 2 days, 0:55:48, time: 2.131, data_time: 0.016, memory: 23505, decode.loss_cls: 0.0002, decode.loss_mask: 0.1852, decode.loss_dice: 0.3558, decode.d0.loss_cls: 2.2795, decode.d0.loss_mask: 0.1909, decode.d0.loss_dice: 0.3731, decode.d1.loss_cls: 0.0101, decode.d1.loss_mask: 0.1861, decode.d1.loss_dice: 0.3603, decode.d2.loss_cls: 0.0009, decode.d2.loss_mask: 0.1847, decode.d2.loss_dice: 0.3533, decode.d3.loss_cls: 0.0006, decode.d3.loss_mask: 0.1859, decode.d3.loss_dice: 0.3603, decode.d4.loss_cls: 0.0004, decode.d4.loss_mask: 0.1817, decode.d4.loss_dice: 0.3596, decode.d5.loss_cls: 0.0003, decode.d5.loss_mask: 0.1839, decode.d5.loss_dice: 0.3571, decode.d6.loss_cls: 0.0003, decode.d6.loss_mask: 0.1845, decode.d6.loss_dice: 0.3581, decode.d7.loss_cls: 0.0003, decode.d7.loss_mask: 0.1845, decode.d7.loss_dice: 0.3560, decode.d8.loss_cls: 0.0003, decode.d8.loss_mask: 0.1866, decode.d8.loss_dice: 0.3659, loss: 7.7463\n",
      "2024-02-14 15:30:47,312 - mmseg - INFO - Iter [3090/80000]\tlr: 1.380e-06, eta: 2 days, 0:54:45, time: 2.131, data_time: 0.017, memory: 23505, decode.loss_cls: 0.0002, decode.loss_mask: 0.2116, decode.loss_dice: 0.4104, decode.d0.loss_cls: 2.2766, decode.d0.loss_mask: 0.2165, decode.d0.loss_dice: 0.4184, decode.d1.loss_cls: 0.0078, decode.d1.loss_mask: 0.2147, decode.d1.loss_dice: 0.4159, decode.d2.loss_cls: 0.0010, decode.d2.loss_mask: 0.2142, decode.d2.loss_dice: 0.4117, decode.d3.loss_cls: 0.0006, decode.d3.loss_mask: 0.2123, decode.d3.loss_dice: 0.4107, decode.d4.loss_cls: 0.0004, decode.d4.loss_mask: 0.2115, decode.d4.loss_dice: 0.4119, decode.d5.loss_cls: 0.0003, decode.d5.loss_mask: 0.2119, decode.d5.loss_dice: 0.4110, decode.d6.loss_cls: 0.0003, decode.d6.loss_mask: 0.2158, decode.d6.loss_dice: 0.4143, decode.d7.loss_cls: 0.0003, decode.d7.loss_mask: 0.2119, decode.d7.loss_dice: 0.4101, decode.d8.loss_cls: 0.0003, decode.d8.loss_mask: 0.2126, decode.d8.loss_dice: 0.4156, loss: 8.5507\n",
      "2024-02-14 15:31:08,651 - mmseg - INFO - Iter [3100/80000]\tlr: 1.380e-06, eta: 2 days, 0:53:44, time: 2.134, data_time: 0.017, memory: 23505, decode.loss_cls: 0.0002, decode.loss_mask: 0.2275, decode.loss_dice: 0.4273, decode.d0.loss_cls: 2.2691, decode.d0.loss_mask: 0.2249, decode.d0.loss_dice: 0.4313, decode.d1.loss_cls: 0.0080, decode.d1.loss_mask: 0.2204, decode.d1.loss_dice: 0.4276, decode.d2.loss_cls: 0.0010, decode.d2.loss_mask: 0.2220, decode.d2.loss_dice: 0.4284, decode.d3.loss_cls: 0.0007, decode.d3.loss_mask: 0.2264, decode.d3.loss_dice: 0.4316, decode.d4.loss_cls: 0.0004, decode.d4.loss_mask: 0.2260, decode.d4.loss_dice: 0.4293, decode.d5.loss_cls: 0.0003, decode.d5.loss_mask: 0.2261, decode.d5.loss_dice: 0.4311, decode.d6.loss_cls: 0.0003, decode.d6.loss_mask: 0.2258, decode.d6.loss_dice: 0.4297, decode.d7.loss_cls: 0.0003, decode.d7.loss_mask: 0.2270, decode.d7.loss_dice: 0.4287, decode.d8.loss_cls: 0.0003, decode.d8.loss_mask: 0.2291, decode.d8.loss_dice: 0.4352, loss: 8.8362\n",
      "2024-02-14 15:31:29,972 - mmseg - INFO - Iter [3110/80000]\tlr: 1.380e-06, eta: 2 days, 0:52:42, time: 2.132, data_time: 0.017, memory: 23505, decode.loss_cls: 0.0002, decode.loss_mask: 0.1914, decode.loss_dice: 0.3765, decode.d0.loss_cls: 2.2575, decode.d0.loss_mask: 0.1913, decode.d0.loss_dice: 0.3949, decode.d1.loss_cls: 0.0083, decode.d1.loss_mask: 0.1925, decode.d1.loss_dice: 0.3784, decode.d2.loss_cls: 0.0010, decode.d2.loss_mask: 0.1927, decode.d2.loss_dice: 0.3834, decode.d3.loss_cls: 0.0006, decode.d3.loss_mask: 0.1905, decode.d3.loss_dice: 0.3805, decode.d4.loss_cls: 0.0004, decode.d4.loss_mask: 0.1920, decode.d4.loss_dice: 0.3828, decode.d5.loss_cls: 0.0003, decode.d5.loss_mask: 0.1912, decode.d5.loss_dice: 0.3815, decode.d6.loss_cls: 0.0003, decode.d6.loss_mask: 0.1916, decode.d6.loss_dice: 0.3780, decode.d7.loss_cls: 0.0003, decode.d7.loss_mask: 0.1894, decode.d7.loss_dice: 0.3766, decode.d8.loss_cls: 0.0003, decode.d8.loss_mask: 0.1897, decode.d8.loss_dice: 0.3754, loss: 7.9894\n",
      "2024-02-14 15:31:51,291 - mmseg - INFO - Iter [3120/80000]\tlr: 1.380e-06, eta: 2 days, 0:51:41, time: 2.132, data_time: 0.017, memory: 23505, decode.loss_cls: 0.0002, decode.loss_mask: 0.1937, decode.loss_dice: 0.3745, decode.d0.loss_cls: 2.2507, decode.d0.loss_mask: 0.1959, decode.d0.loss_dice: 0.3922, decode.d1.loss_cls: 0.0092, decode.d1.loss_mask: 0.1935, decode.d1.loss_dice: 0.3717, decode.d2.loss_cls: 0.0009, decode.d2.loss_mask: 0.1936, decode.d2.loss_dice: 0.3723, decode.d3.loss_cls: 0.0007, decode.d3.loss_mask: 0.1941, decode.d3.loss_dice: 0.3764, decode.d4.loss_cls: 0.0004, decode.d4.loss_mask: 0.1946, decode.d4.loss_dice: 0.3672, decode.d5.loss_cls: 0.0003, decode.d5.loss_mask: 0.1930, decode.d5.loss_dice: 0.3743, decode.d6.loss_cls: 0.0003, decode.d6.loss_mask: 0.1930, decode.d6.loss_dice: 0.3710, decode.d7.loss_cls: 0.0002, decode.d7.loss_mask: 0.1924, decode.d7.loss_dice: 0.3680, decode.d8.loss_cls: 0.0003, decode.d8.loss_mask: 0.1948, decode.d8.loss_dice: 0.3741, loss: 7.9434\n",
      "2024-02-14 15:32:12,617 - mmseg - INFO - Iter [3130/80000]\tlr: 1.380e-06, eta: 2 days, 0:50:39, time: 2.133, data_time: 0.017, memory: 23505, decode.loss_cls: 0.0002, decode.loss_mask: 0.2015, decode.loss_dice: 0.3810, decode.d0.loss_cls: 2.2438, decode.d0.loss_mask: 0.2152, decode.d0.loss_dice: 0.3971, decode.d1.loss_cls: 0.0089, decode.d1.loss_mask: 0.2048, decode.d1.loss_dice: 0.3820, decode.d2.loss_cls: 0.0009, decode.d2.loss_mask: 0.2035, decode.d2.loss_dice: 0.3846, decode.d3.loss_cls: 0.0006, decode.d3.loss_mask: 0.2032, decode.d3.loss_dice: 0.3837, decode.d4.loss_cls: 0.0004, decode.d4.loss_mask: 0.2060, decode.d4.loss_dice: 0.3873, decode.d5.loss_cls: 0.0003, decode.d5.loss_mask: 0.2023, decode.d5.loss_dice: 0.3860, decode.d6.loss_cls: 0.0003, decode.d6.loss_mask: 0.2039, decode.d6.loss_dice: 0.3824, decode.d7.loss_cls: 0.0002, decode.d7.loss_mask: 0.2030, decode.d7.loss_dice: 0.3828, decode.d8.loss_cls: 0.0002, decode.d8.loss_mask: 0.2038, decode.d8.loss_dice: 0.3803, loss: 8.1503\n",
      "2024-02-14 15:32:33,937 - mmseg - INFO - Iter [3140/80000]\tlr: 1.379e-06, eta: 2 days, 0:49:39, time: 2.132, data_time: 0.017, memory: 23505, decode.loss_cls: 0.0002, decode.loss_mask: 0.2066, decode.loss_dice: 0.3756, decode.d0.loss_cls: 2.2374, decode.d0.loss_mask: 0.2112, decode.d0.loss_dice: 0.3992, decode.d1.loss_cls: 0.0071, decode.d1.loss_mask: 0.2069, decode.d1.loss_dice: 0.3815, decode.d2.loss_cls: 0.0009, decode.d2.loss_mask: 0.2061, decode.d2.loss_dice: 0.3784, decode.d3.loss_cls: 0.0006, decode.d3.loss_mask: 0.2084, decode.d3.loss_dice: 0.3840, decode.d4.loss_cls: 0.0004, decode.d4.loss_mask: 0.2070, decode.d4.loss_dice: 0.3783, decode.d5.loss_cls: 0.0003, decode.d5.loss_mask: 0.2092, decode.d5.loss_dice: 0.3818, decode.d6.loss_cls: 0.0003, decode.d6.loss_mask: 0.2083, decode.d6.loss_dice: 0.3796, decode.d7.loss_cls: 0.0003, decode.d7.loss_mask: 0.2061, decode.d7.loss_dice: 0.3748, decode.d8.loss_cls: 0.0003, decode.d8.loss_mask: 0.2076, decode.d8.loss_dice: 0.3806, loss: 8.1389\n",
      "2024-02-14 15:32:55,277 - mmseg - INFO - Iter [3150/80000]\tlr: 1.379e-06, eta: 2 days, 0:48:38, time: 2.134, data_time: 0.017, memory: 23505, decode.loss_cls: 0.0002, decode.loss_mask: 0.1980, decode.loss_dice: 0.3933, decode.d0.loss_cls: 2.2253, decode.d0.loss_mask: 0.2042, decode.d0.loss_dice: 0.4054, decode.d1.loss_cls: 0.0076, decode.d1.loss_mask: 0.1994, decode.d1.loss_dice: 0.3945, decode.d2.loss_cls: 0.0009, decode.d2.loss_mask: 0.1971, decode.d2.loss_dice: 0.3883, decode.d3.loss_cls: 0.0006, decode.d3.loss_mask: 0.1998, decode.d3.loss_dice: 0.3968, decode.d4.loss_cls: 0.0004, decode.d4.loss_mask: 0.1976, decode.d4.loss_dice: 0.3922, decode.d5.loss_cls: 0.0003, decode.d5.loss_mask: 0.1982, decode.d5.loss_dice: 0.3922, decode.d6.loss_cls: 0.0003, decode.d6.loss_mask: 0.1978, decode.d6.loss_dice: 0.3912, decode.d7.loss_cls: 0.0002, decode.d7.loss_mask: 0.1975, decode.d7.loss_dice: 0.3929, decode.d8.loss_cls: 0.0003, decode.d8.loss_mask: 0.1981, decode.d8.loss_dice: 0.3926, loss: 8.1633\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-14 15:33:16,592 - mmseg - INFO - Iter [3160/80000]\tlr: 1.379e-06, eta: 2 days, 0:47:38, time: 2.132, data_time: 0.017, memory: 23505, decode.loss_cls: 0.0002, decode.loss_mask: 0.2203, decode.loss_dice: 0.4026, decode.d0.loss_cls: 2.2229, decode.d0.loss_mask: 0.2260, decode.d0.loss_dice: 0.4154, decode.d1.loss_cls: 0.0077, decode.d1.loss_mask: 0.2249, decode.d1.loss_dice: 0.4070, decode.d2.loss_cls: 0.0009, decode.d2.loss_mask: 0.2219, decode.d2.loss_dice: 0.4022, decode.d3.loss_cls: 0.0007, decode.d3.loss_mask: 0.2200, decode.d3.loss_dice: 0.4037, decode.d4.loss_cls: 0.0004, decode.d4.loss_mask: 0.2206, decode.d4.loss_dice: 0.3994, decode.d5.loss_cls: 0.0003, decode.d5.loss_mask: 0.2219, decode.d5.loss_dice: 0.4062, decode.d6.loss_cls: 0.0003, decode.d6.loss_mask: 0.2199, decode.d6.loss_dice: 0.4044, decode.d7.loss_cls: 0.0002, decode.d7.loss_mask: 0.2182, decode.d7.loss_dice: 0.4030, decode.d8.loss_cls: 0.0003, decode.d8.loss_mask: 0.2209, decode.d8.loss_dice: 0.4107, loss: 8.5030\n",
      "2024-02-14 15:33:37,933 - mmseg - INFO - Iter [3170/80000]\tlr: 1.379e-06, eta: 2 days, 0:46:38, time: 2.134, data_time: 0.016, memory: 23505, decode.loss_cls: 0.0002, decode.loss_mask: 0.1932, decode.loss_dice: 0.3827, decode.d0.loss_cls: 2.2128, decode.d0.loss_mask: 0.2005, decode.d0.loss_dice: 0.3958, decode.d1.loss_cls: 0.0075, decode.d1.loss_mask: 0.1940, decode.d1.loss_dice: 0.3826, decode.d2.loss_cls: 0.0009, decode.d2.loss_mask: 0.1945, decode.d2.loss_dice: 0.3786, decode.d3.loss_cls: 0.0007, decode.d3.loss_mask: 0.1945, decode.d3.loss_dice: 0.3843, decode.d4.loss_cls: 0.0004, decode.d4.loss_mask: 0.1949, decode.d4.loss_dice: 0.3828, decode.d5.loss_cls: 0.0003, decode.d5.loss_mask: 0.1940, decode.d5.loss_dice: 0.3830, decode.d6.loss_cls: 0.0003, decode.d6.loss_mask: 0.1941, decode.d6.loss_dice: 0.3804, decode.d7.loss_cls: 0.0003, decode.d7.loss_mask: 0.1949, decode.d7.loss_dice: 0.3855, decode.d8.loss_cls: 0.0003, decode.d8.loss_mask: 0.1937, decode.d8.loss_dice: 0.3820, loss: 8.0094\n",
      "2024-02-14 15:33:59,262 - mmseg - INFO - Iter [3180/80000]\tlr: 1.379e-06, eta: 2 days, 0:45:38, time: 2.133, data_time: 0.017, memory: 23505, decode.loss_cls: 0.0002, decode.loss_mask: 0.1827, decode.loss_dice: 0.3406, decode.d0.loss_cls: 2.2003, decode.d0.loss_mask: 0.1785, decode.d0.loss_dice: 0.3580, decode.d1.loss_cls: 0.0107, decode.d1.loss_mask: 0.1813, decode.d1.loss_dice: 0.3460, decode.d2.loss_cls: 0.0009, decode.d2.loss_mask: 0.1832, decode.d2.loss_dice: 0.3435, decode.d3.loss_cls: 0.0008, decode.d3.loss_mask: 0.1807, decode.d3.loss_dice: 0.3406, decode.d4.loss_cls: 0.0003, decode.d4.loss_mask: 0.1824, decode.d4.loss_dice: 0.3434, decode.d5.loss_cls: 0.0003, decode.d5.loss_mask: 0.1818, decode.d5.loss_dice: 0.3457, decode.d6.loss_cls: 0.0003, decode.d6.loss_mask: 0.1842, decode.d6.loss_dice: 0.3451, decode.d7.loss_cls: 0.0003, decode.d7.loss_mask: 0.1816, decode.d7.loss_dice: 0.3377, decode.d8.loss_cls: 0.0003, decode.d8.loss_mask: 0.1822, decode.d8.loss_dice: 0.3429, loss: 7.4767\n",
      "2024-02-14 15:34:20,606 - mmseg - INFO - Iter [3190/80000]\tlr: 1.379e-06, eta: 2 days, 0:44:39, time: 2.134, data_time: 0.016, memory: 23505, decode.loss_cls: 0.0002, decode.loss_mask: 0.1828, decode.loss_dice: 0.3745, decode.d0.loss_cls: 2.1914, decode.d0.loss_mask: 0.1896, decode.d0.loss_dice: 0.3922, decode.d1.loss_cls: 0.0109, decode.d1.loss_mask: 0.1817, decode.d1.loss_dice: 0.3770, decode.d2.loss_cls: 0.0009, decode.d2.loss_mask: 0.1837, decode.d2.loss_dice: 0.3839, decode.d3.loss_cls: 0.0005, decode.d3.loss_mask: 0.1822, decode.d3.loss_dice: 0.3784, decode.d4.loss_cls: 0.0003, decode.d4.loss_mask: 0.1831, decode.d4.loss_dice: 0.3806, decode.d5.loss_cls: 0.0003, decode.d5.loss_mask: 0.1839, decode.d5.loss_dice: 0.3792, decode.d6.loss_cls: 0.0003, decode.d6.loss_mask: 0.1813, decode.d6.loss_dice: 0.3748, decode.d7.loss_cls: 0.0002, decode.d7.loss_mask: 0.1808, decode.d7.loss_dice: 0.3780, decode.d8.loss_cls: 0.0003, decode.d8.loss_mask: 0.1816, decode.d8.loss_dice: 0.3780, loss: 7.8329\n",
      "2024-02-14 15:34:41,963 - mmseg - INFO - Iter [3200/80000]\tlr: 1.378e-06, eta: 2 days, 0:43:41, time: 2.136, data_time: 0.017, memory: 23505, decode.loss_cls: 0.0002, decode.loss_mask: 0.2156, decode.loss_dice: 0.4008, decode.d0.loss_cls: 2.1902, decode.d0.loss_mask: 0.2193, decode.d0.loss_dice: 0.4272, decode.d1.loss_cls: 0.0082, decode.d1.loss_mask: 0.2149, decode.d1.loss_dice: 0.4058, decode.d2.loss_cls: 0.0009, decode.d2.loss_mask: 0.2122, decode.d2.loss_dice: 0.3981, decode.d3.loss_cls: 0.0006, decode.d3.loss_mask: 0.2165, decode.d3.loss_dice: 0.4057, decode.d4.loss_cls: 0.0004, decode.d4.loss_mask: 0.2127, decode.d4.loss_dice: 0.4035, decode.d5.loss_cls: 0.0003, decode.d5.loss_mask: 0.2167, decode.d5.loss_dice: 0.4066, decode.d6.loss_cls: 0.0003, decode.d6.loss_mask: 0.2165, decode.d6.loss_dice: 0.4046, decode.d7.loss_cls: 0.0003, decode.d7.loss_mask: 0.2142, decode.d7.loss_dice: 0.3992, decode.d8.loss_cls: 0.0003, decode.d8.loss_mask: 0.2153, decode.d8.loss_dice: 0.3994, loss: 8.4064\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 40/40, 6.2 task/s, elapsed: 6s, ETA:     0s\n",
      "\n",
      "2024-02-14 15:34:48,413 - mmseg - INFO - per class results:\n",
      "2024-02-14 15:34:48,413 - mmseg - INFO - \n",
      "+---------------+-------+-------+\n",
      "|     Class     |  IoU  |  Acc  |\n",
      "+---------------+-------+-------+\n",
      "|       bg      | 97.57 | 98.74 |\n",
      "|    Anchovy    | 81.47 | 91.46 |\n",
      "|     Olives    | 86.72 | 90.16 |\n",
      "|     Salami    | 70.85 | 82.68 |\n",
      "|   Red_Pepper  | 88.68 | 94.45 |\n",
      "| Yellow_Pepper | 85.89 |  93.4 |\n",
      "+---------------+-------+-------+\n",
      "2024-02-14 15:34:48,413 - mmseg - INFO - Summary:\n",
      "2024-02-14 15:34:48,414 - mmseg - INFO - \n",
      "+-------+-------+-------+\n",
      "|  aAcc |  mIoU |  mAcc |\n",
      "+-------+-------+-------+\n",
      "| 97.63 | 85.19 | 91.81 |\n",
      "+-------+-------+-------+\n",
      "2024-02-14 15:34:48,414 - mmseg - INFO - Iter(val) [10]\taAcc: 0.9763, mIoU: 0.8519, mAcc: 0.9181, IoU.bg: 0.9757, IoU.Anchovy: 0.8147, IoU.Olives: 0.8672, IoU.Salami: 0.7085, IoU.Red_Pepper: 0.8868, IoU.Yellow_Pepper: 0.8589, Acc.bg: 0.9874, Acc.Anchovy: 0.9146, Acc.Olives: 0.9016, Acc.Salami: 0.8268, Acc.Red_Pepper: 0.9445, Acc.Yellow_Pepper: 0.9340\n",
      "2024-02-14 15:35:11,800 - mmseg - INFO - Iter [3210/80000]\tlr: 1.378e-06, eta: 2 days, 0:46:05, time: 2.984, data_time: 0.869, memory: 23505, decode.loss_cls: 0.0002, decode.loss_mask: 0.1703, decode.loss_dice: 0.3287, decode.d0.loss_cls: 2.1809, decode.d0.loss_mask: 0.1728, decode.d0.loss_dice: 0.3551, decode.d1.loss_cls: 0.0085, decode.d1.loss_mask: 0.1717, decode.d1.loss_dice: 0.3318, decode.d2.loss_cls: 0.0009, decode.d2.loss_mask: 0.1704, decode.d2.loss_dice: 0.3284, decode.d3.loss_cls: 0.0006, decode.d3.loss_mask: 0.1706, decode.d3.loss_dice: 0.3278, decode.d4.loss_cls: 0.0004, decode.d4.loss_mask: 0.1694, decode.d4.loss_dice: 0.3288, decode.d5.loss_cls: 0.0003, decode.d5.loss_mask: 0.1679, decode.d5.loss_dice: 0.3249, decode.d6.loss_cls: 0.0003, decode.d6.loss_mask: 0.1711, decode.d6.loss_dice: 0.3339, decode.d7.loss_cls: 0.0003, decode.d7.loss_mask: 0.1696, decode.d7.loss_dice: 0.3333, decode.d8.loss_cls: 0.0003, decode.d8.loss_mask: 0.1720, decode.d8.loss_dice: 0.3313, loss: 7.2223\n",
      "2024-02-14 15:35:33,117 - mmseg - INFO - Iter [3220/80000]\tlr: 1.378e-06, eta: 2 days, 0:45:05, time: 2.132, data_time: 0.017, memory: 23505, decode.loss_cls: 0.0002, decode.loss_mask: 0.2094, decode.loss_dice: 0.3757, decode.d0.loss_cls: 2.1789, decode.d0.loss_mask: 0.2116, decode.d0.loss_dice: 0.3960, decode.d1.loss_cls: 0.0070, decode.d1.loss_mask: 0.2114, decode.d1.loss_dice: 0.3791, decode.d2.loss_cls: 0.0008, decode.d2.loss_mask: 0.2080, decode.d2.loss_dice: 0.3809, decode.d3.loss_cls: 0.0006, decode.d3.loss_mask: 0.2115, decode.d3.loss_dice: 0.3805, decode.d4.loss_cls: 0.0004, decode.d4.loss_mask: 0.2096, decode.d4.loss_dice: 0.3773, decode.d5.loss_cls: 0.0003, decode.d5.loss_mask: 0.2106, decode.d5.loss_dice: 0.3803, decode.d6.loss_cls: 0.0003, decode.d6.loss_mask: 0.2097, decode.d6.loss_dice: 0.3779, decode.d7.loss_cls: 0.0003, decode.d7.loss_mask: 0.2088, decode.d7.loss_dice: 0.3704, decode.d8.loss_cls: 0.0003, decode.d8.loss_mask: 0.2105, decode.d8.loss_dice: 0.3798, loss: 8.0880\n",
      "2024-02-14 15:35:54,444 - mmseg - INFO - Iter [3230/80000]\tlr: 1.378e-06, eta: 2 days, 0:44:06, time: 2.133, data_time: 0.017, memory: 23505, decode.loss_cls: 0.0002, decode.loss_mask: 0.1882, decode.loss_dice: 0.3648, decode.d0.loss_cls: 2.1681, decode.d0.loss_mask: 0.1930, decode.d0.loss_dice: 0.3901, decode.d1.loss_cls: 0.0082, decode.d1.loss_mask: 0.1914, decode.d1.loss_dice: 0.3649, decode.d2.loss_cls: 0.0009, decode.d2.loss_mask: 0.1897, decode.d2.loss_dice: 0.3650, decode.d3.loss_cls: 0.0006, decode.d3.loss_mask: 0.1856, decode.d3.loss_dice: 0.3629, decode.d4.loss_cls: 0.0004, decode.d4.loss_mask: 0.1898, decode.d4.loss_dice: 0.3671, decode.d5.loss_cls: 0.0003, decode.d5.loss_mask: 0.1884, decode.d5.loss_dice: 0.3639, decode.d6.loss_cls: 0.0003, decode.d6.loss_mask: 0.1904, decode.d6.loss_dice: 0.3716, decode.d7.loss_cls: 0.0002, decode.d7.loss_mask: 0.1877, decode.d7.loss_dice: 0.3699, decode.d8.loss_cls: 0.0003, decode.d8.loss_mask: 0.1875, decode.d8.loss_dice: 0.3652, loss: 7.7562\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-14 15:36:15,771 - mmseg - INFO - Iter [3240/80000]\tlr: 1.378e-06, eta: 2 days, 0:43:07, time: 2.133, data_time: 0.017, memory: 23505, decode.loss_cls: 0.0002, decode.loss_mask: 0.1865, decode.loss_dice: 0.3558, decode.d0.loss_cls: 2.1588, decode.d0.loss_mask: 0.1878, decode.d0.loss_dice: 0.3744, decode.d1.loss_cls: 0.0125, decode.d1.loss_mask: 0.1842, decode.d1.loss_dice: 0.3555, decode.d2.loss_cls: 0.0013, decode.d2.loss_mask: 0.1862, decode.d2.loss_dice: 0.3528, decode.d3.loss_cls: 0.0006, decode.d3.loss_mask: 0.1839, decode.d3.loss_dice: 0.3482, decode.d4.loss_cls: 0.0004, decode.d4.loss_mask: 0.1848, decode.d4.loss_dice: 0.3489, decode.d5.loss_cls: 0.0003, decode.d5.loss_mask: 0.1851, decode.d5.loss_dice: 0.3501, decode.d6.loss_cls: 0.0003, decode.d6.loss_mask: 0.1853, decode.d6.loss_dice: 0.3503, decode.d7.loss_cls: 0.0002, decode.d7.loss_mask: 0.1879, decode.d7.loss_dice: 0.3551, decode.d8.loss_cls: 0.0002, decode.d8.loss_mask: 0.1842, decode.d8.loss_dice: 0.3500, loss: 7.5720\n",
      "2024-02-14 15:36:37,084 - mmseg - INFO - Iter [3250/80000]\tlr: 1.377e-06, eta: 2 days, 0:42:08, time: 2.131, data_time: 0.016, memory: 23505, decode.loss_cls: 0.0002, decode.loss_mask: 0.1609, decode.loss_dice: 0.3250, decode.d0.loss_cls: 2.1482, decode.d0.loss_mask: 0.1618, decode.d0.loss_dice: 0.3505, decode.d1.loss_cls: 0.0095, decode.d1.loss_mask: 0.1615, decode.d1.loss_dice: 0.3301, decode.d2.loss_cls: 0.0009, decode.d2.loss_mask: 0.1606, decode.d2.loss_dice: 0.3247, decode.d3.loss_cls: 0.0005, decode.d3.loss_mask: 0.1636, decode.d3.loss_dice: 0.3227, decode.d4.loss_cls: 0.0003, decode.d4.loss_mask: 0.1596, decode.d4.loss_dice: 0.3207, decode.d5.loss_cls: 0.0003, decode.d5.loss_mask: 0.1601, decode.d5.loss_dice: 0.3204, decode.d6.loss_cls: 0.0002, decode.d6.loss_mask: 0.1604, decode.d6.loss_dice: 0.3236, decode.d7.loss_cls: 0.0002, decode.d7.loss_mask: 0.1609, decode.d7.loss_dice: 0.3203, decode.d8.loss_cls: 0.0002, decode.d8.loss_mask: 0.1640, decode.d8.loss_dice: 0.3281, loss: 7.0400\n",
      "2024-02-14 15:36:58,397 - mmseg - INFO - Iter [3260/80000]\tlr: 1.377e-06, eta: 2 days, 0:41:09, time: 2.131, data_time: 0.016, memory: 23505, decode.loss_cls: 0.0002, decode.loss_mask: 0.1733, decode.loss_dice: 0.3325, decode.d0.loss_cls: 2.1417, decode.d0.loss_mask: 0.1761, decode.d0.loss_dice: 0.3608, decode.d1.loss_cls: 0.0108, decode.d1.loss_mask: 0.1726, decode.d1.loss_dice: 0.3337, decode.d2.loss_cls: 0.0017, decode.d2.loss_mask: 0.1746, decode.d2.loss_dice: 0.3386, decode.d3.loss_cls: 0.0006, decode.d3.loss_mask: 0.1727, decode.d3.loss_dice: 0.3338, decode.d4.loss_cls: 0.0004, decode.d4.loss_mask: 0.1712, decode.d4.loss_dice: 0.3375, decode.d5.loss_cls: 0.0003, decode.d5.loss_mask: 0.1735, decode.d5.loss_dice: 0.3367, decode.d6.loss_cls: 0.0003, decode.d6.loss_mask: 0.1731, decode.d6.loss_dice: 0.3365, decode.d7.loss_cls: 0.0003, decode.d7.loss_mask: 0.1734, decode.d7.loss_dice: 0.3373, decode.d8.loss_cls: 0.0003, decode.d8.loss_mask: 0.1732, decode.d8.loss_dice: 0.3361, loss: 7.2734\n",
      "2024-02-14 15:37:19,717 - mmseg - INFO - Iter [3270/80000]\tlr: 1.377e-06, eta: 2 days, 0:40:11, time: 2.132, data_time: 0.016, memory: 23505, decode.loss_cls: 0.0002, decode.loss_mask: 0.1819, decode.loss_dice: 0.3506, decode.d0.loss_cls: 2.1426, decode.d0.loss_mask: 0.1865, decode.d0.loss_dice: 0.3698, decode.d1.loss_cls: 0.0058, decode.d1.loss_mask: 0.1863, decode.d1.loss_dice: 0.3549, decode.d2.loss_cls: 0.0008, decode.d2.loss_mask: 0.1843, decode.d2.loss_dice: 0.3567, decode.d3.loss_cls: 0.0006, decode.d3.loss_mask: 0.1843, decode.d3.loss_dice: 0.3519, decode.d4.loss_cls: 0.0004, decode.d4.loss_mask: 0.1845, decode.d4.loss_dice: 0.3529, decode.d5.loss_cls: 0.0003, decode.d5.loss_mask: 0.1828, decode.d5.loss_dice: 0.3510, decode.d6.loss_cls: 0.0003, decode.d6.loss_mask: 0.1843, decode.d6.loss_dice: 0.3556, decode.d7.loss_cls: 0.0002, decode.d7.loss_mask: 0.1818, decode.d7.loss_dice: 0.3514, decode.d8.loss_cls: 0.0003, decode.d8.loss_mask: 0.1861, decode.d8.loss_dice: 0.3556, loss: 7.5450\n",
      "2024-02-14 15:37:41,058 - mmseg - INFO - Iter [3280/80000]\tlr: 1.377e-06, eta: 2 days, 0:39:13, time: 2.134, data_time: 0.017, memory: 23505, decode.loss_cls: 0.0003, decode.loss_mask: 0.2001, decode.loss_dice: 0.3510, decode.d0.loss_cls: 2.1324, decode.d0.loss_mask: 0.2029, decode.d0.loss_dice: 0.3790, decode.d1.loss_cls: 0.0083, decode.d1.loss_mask: 0.1990, decode.d1.loss_dice: 0.3566, decode.d2.loss_cls: 0.0008, decode.d2.loss_mask: 0.1969, decode.d2.loss_dice: 0.3547, decode.d3.loss_cls: 0.0006, decode.d3.loss_mask: 0.1993, decode.d3.loss_dice: 0.3558, decode.d4.loss_cls: 0.0004, decode.d4.loss_mask: 0.1987, decode.d4.loss_dice: 0.3557, decode.d5.loss_cls: 0.0003, decode.d5.loss_mask: 0.1982, decode.d5.loss_dice: 0.3513, decode.d6.loss_cls: 0.0003, decode.d6.loss_mask: 0.1982, decode.d6.loss_dice: 0.3540, decode.d7.loss_cls: 0.0003, decode.d7.loss_mask: 0.2003, decode.d7.loss_dice: 0.3545, decode.d8.loss_cls: 0.0003, decode.d8.loss_mask: 0.1990, decode.d8.loss_dice: 0.3508, loss: 7.6997\n",
      "2024-02-14 15:38:02,407 - mmseg - INFO - Iter [3290/80000]\tlr: 1.377e-06, eta: 2 days, 0:38:16, time: 2.135, data_time: 0.017, memory: 23505, decode.loss_cls: 0.0002, decode.loss_mask: 0.1934, decode.loss_dice: 0.3790, decode.d0.loss_cls: 2.1231, decode.d0.loss_mask: 0.1968, decode.d0.loss_dice: 0.3939, decode.d1.loss_cls: 0.0073, decode.d1.loss_mask: 0.1916, decode.d1.loss_dice: 0.3786, decode.d2.loss_cls: 0.0008, decode.d2.loss_mask: 0.1943, decode.d2.loss_dice: 0.3818, decode.d3.loss_cls: 0.0006, decode.d3.loss_mask: 0.1925, decode.d3.loss_dice: 0.3797, decode.d4.loss_cls: 0.0003, decode.d4.loss_mask: 0.1909, decode.d4.loss_dice: 0.3748, decode.d5.loss_cls: 0.0003, decode.d5.loss_mask: 0.1929, decode.d5.loss_dice: 0.3785, decode.d6.loss_cls: 0.0002, decode.d6.loss_mask: 0.1917, decode.d6.loss_dice: 0.3813, decode.d7.loss_cls: 0.0002, decode.d7.loss_mask: 0.1920, decode.d7.loss_dice: 0.3787, decode.d8.loss_cls: 0.0002, decode.d8.loss_mask: 0.1893, decode.d8.loss_dice: 0.3747, loss: 7.8597\n",
      "2024-02-14 15:38:23,747 - mmseg - INFO - Iter [3300/80000]\tlr: 1.377e-06, eta: 2 days, 0:37:18, time: 2.134, data_time: 0.016, memory: 23505, decode.loss_cls: 0.0002, decode.loss_mask: 0.1742, decode.loss_dice: 0.3363, decode.d0.loss_cls: 2.1170, decode.d0.loss_mask: 0.1730, decode.d0.loss_dice: 0.3496, decode.d1.loss_cls: 0.0082, decode.d1.loss_mask: 0.1730, decode.d1.loss_dice: 0.3308, decode.d2.loss_cls: 0.0008, decode.d2.loss_mask: 0.1750, decode.d2.loss_dice: 0.3322, decode.d3.loss_cls: 0.0006, decode.d3.loss_mask: 0.1765, decode.d3.loss_dice: 0.3377, decode.d4.loss_cls: 0.0004, decode.d4.loss_mask: 0.1735, decode.d4.loss_dice: 0.3339, decode.d5.loss_cls: 0.0003, decode.d5.loss_mask: 0.1745, decode.d5.loss_dice: 0.3330, decode.d6.loss_cls: 0.0003, decode.d6.loss_mask: 0.1737, decode.d6.loss_dice: 0.3368, decode.d7.loss_cls: 0.0002, decode.d7.loss_mask: 0.1736, decode.d7.loss_dice: 0.3319, decode.d8.loss_cls: 0.0003, decode.d8.loss_mask: 0.1749, decode.d8.loss_dice: 0.3359, loss: 7.2283\n",
      "2024-02-14 15:38:45,072 - mmseg - INFO - Iter [3310/80000]\tlr: 1.376e-06, eta: 2 days, 0:36:21, time: 2.133, data_time: 0.017, memory: 23505, decode.loss_cls: 0.0002, decode.loss_mask: 0.1916, decode.loss_dice: 0.3649, decode.d0.loss_cls: 2.1083, decode.d0.loss_mask: 0.1966, decode.d0.loss_dice: 0.3728, decode.d1.loss_cls: 0.0082, decode.d1.loss_mask: 0.1920, decode.d1.loss_dice: 0.3549, decode.d2.loss_cls: 0.0008, decode.d2.loss_mask: 0.1937, decode.d2.loss_dice: 0.3596, decode.d3.loss_cls: 0.0005, decode.d3.loss_mask: 0.1906, decode.d3.loss_dice: 0.3552, decode.d4.loss_cls: 0.0004, decode.d4.loss_mask: 0.1912, decode.d4.loss_dice: 0.3589, decode.d5.loss_cls: 0.0003, decode.d5.loss_mask: 0.1922, decode.d5.loss_dice: 0.3567, decode.d6.loss_cls: 0.0003, decode.d6.loss_mask: 0.1905, decode.d6.loss_dice: 0.3564, decode.d7.loss_cls: 0.0002, decode.d7.loss_mask: 0.1919, decode.d7.loss_dice: 0.3602, decode.d8.loss_cls: 0.0002, decode.d8.loss_mask: 0.1954, decode.d8.loss_dice: 0.3635, loss: 7.6481\n",
      "2024-02-14 15:39:06,409 - mmseg - INFO - Iter [3320/80000]\tlr: 1.376e-06, eta: 2 days, 0:35:24, time: 2.134, data_time: 0.017, memory: 23505, decode.loss_cls: 0.0002, decode.loss_mask: 0.2042, decode.loss_dice: 0.3956, decode.d0.loss_cls: 2.1047, decode.d0.loss_mask: 0.2106, decode.d0.loss_dice: 0.4112, decode.d1.loss_cls: 0.0074, decode.d1.loss_mask: 0.2080, decode.d1.loss_dice: 0.3932, decode.d2.loss_cls: 0.0008, decode.d2.loss_mask: 0.2052, decode.d2.loss_dice: 0.3974, decode.d3.loss_cls: 0.0006, decode.d3.loss_mask: 0.2076, decode.d3.loss_dice: 0.3960, decode.d4.loss_cls: 0.0004, decode.d4.loss_mask: 0.2059, decode.d4.loss_dice: 0.3965, decode.d5.loss_cls: 0.0003, decode.d5.loss_mask: 0.2066, decode.d5.loss_dice: 0.3939, decode.d6.loss_cls: 0.0002, decode.d6.loss_mask: 0.2077, decode.d6.loss_dice: 0.4009, decode.d7.loss_cls: 0.0002, decode.d7.loss_mask: 0.2057, decode.d7.loss_dice: 0.3950, decode.d8.loss_cls: 0.0002, decode.d8.loss_mask: 0.2054, decode.d8.loss_dice: 0.3980, loss: 8.1592\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-14 15:39:27,742 - mmseg - INFO - Iter [3330/80000]\tlr: 1.376e-06, eta: 2 days, 0:34:27, time: 2.133, data_time: 0.017, memory: 23505, decode.loss_cls: 0.0002, decode.loss_mask: 0.2057, decode.loss_dice: 0.3839, decode.d0.loss_cls: 2.0931, decode.d0.loss_mask: 0.2071, decode.d0.loss_dice: 0.3993, decode.d1.loss_cls: 0.0077, decode.d1.loss_mask: 0.2031, decode.d1.loss_dice: 0.3877, decode.d2.loss_cls: 0.0008, decode.d2.loss_mask: 0.1992, decode.d2.loss_dice: 0.3818, decode.d3.loss_cls: 0.0006, decode.d3.loss_mask: 0.2009, decode.d3.loss_dice: 0.3834, decode.d4.loss_cls: 0.0004, decode.d4.loss_mask: 0.2027, decode.d4.loss_dice: 0.3889, decode.d5.loss_cls: 0.0003, decode.d5.loss_mask: 0.2021, decode.d5.loss_dice: 0.3838, decode.d6.loss_cls: 0.0002, decode.d6.loss_mask: 0.2053, decode.d6.loss_dice: 0.3830, decode.d7.loss_cls: 0.0002, decode.d7.loss_mask: 0.2018, decode.d7.loss_dice: 0.3822, decode.d8.loss_cls: 0.0002, decode.d8.loss_mask: 0.2024, decode.d8.loss_dice: 0.3808, loss: 7.9886\n",
      "2024-02-14 15:39:49,063 - mmseg - INFO - Iter [3340/80000]\tlr: 1.376e-06, eta: 2 days, 0:33:30, time: 2.132, data_time: 0.017, memory: 23505, decode.loss_cls: 0.0002, decode.loss_mask: 0.1608, decode.loss_dice: 0.3259, decode.d0.loss_cls: 2.0825, decode.d0.loss_mask: 0.1640, decode.d0.loss_dice: 0.3449, decode.d1.loss_cls: 0.0095, decode.d1.loss_mask: 0.1609, decode.d1.loss_dice: 0.3274, decode.d2.loss_cls: 0.0007, decode.d2.loss_mask: 0.1596, decode.d2.loss_dice: 0.3282, decode.d3.loss_cls: 0.0005, decode.d3.loss_mask: 0.1612, decode.d3.loss_dice: 0.3259, decode.d4.loss_cls: 0.0003, decode.d4.loss_mask: 0.1616, decode.d4.loss_dice: 0.3256, decode.d5.loss_cls: 0.0003, decode.d5.loss_mask: 0.1622, decode.d5.loss_dice: 0.3271, decode.d6.loss_cls: 0.0002, decode.d6.loss_mask: 0.1620, decode.d6.loss_dice: 0.3237, decode.d7.loss_cls: 0.0002, decode.d7.loss_mask: 0.1609, decode.d7.loss_dice: 0.3284, decode.d8.loss_cls: 0.0002, decode.d8.loss_mask: 0.1616, decode.d8.loss_dice: 0.3273, loss: 6.9940\n",
      "2024-02-14 15:40:10,393 - mmseg - INFO - Iter [3350/80000]\tlr: 1.376e-06, eta: 2 days, 0:32:33, time: 2.133, data_time: 0.017, memory: 23505, decode.loss_cls: 0.0002, decode.loss_mask: 0.2188, decode.loss_dice: 0.3851, decode.d0.loss_cls: 2.0789, decode.d0.loss_mask: 0.2220, decode.d0.loss_dice: 0.4082, decode.d1.loss_cls: 0.0061, decode.d1.loss_mask: 0.2178, decode.d1.loss_dice: 0.3903, decode.d2.loss_cls: 0.0007, decode.d2.loss_mask: 0.2196, decode.d2.loss_dice: 0.3942, decode.d3.loss_cls: 0.0005, decode.d3.loss_mask: 0.2195, decode.d3.loss_dice: 0.3960, decode.d4.loss_cls: 0.0003, decode.d4.loss_mask: 0.2184, decode.d4.loss_dice: 0.3992, decode.d5.loss_cls: 0.0003, decode.d5.loss_mask: 0.2197, decode.d5.loss_dice: 0.3978, decode.d6.loss_cls: 0.0002, decode.d6.loss_mask: 0.2175, decode.d6.loss_dice: 0.3920, decode.d7.loss_cls: 0.0002, decode.d7.loss_mask: 0.2179, decode.d7.loss_dice: 0.3918, decode.d8.loss_cls: 0.0002, decode.d8.loss_mask: 0.2203, decode.d8.loss_dice: 0.3965, loss: 8.2303\n",
      "2024-02-14 15:40:31,702 - mmseg - INFO - Iter [3360/80000]\tlr: 1.376e-06, eta: 2 days, 0:31:37, time: 2.131, data_time: 0.016, memory: 23505, decode.loss_cls: 0.0002, decode.loss_mask: 0.1596, decode.loss_dice: 0.3249, decode.d0.loss_cls: 2.0669, decode.d0.loss_mask: 0.1581, decode.d0.loss_dice: 0.3528, decode.d1.loss_cls: 0.0102, decode.d1.loss_mask: 0.1591, decode.d1.loss_dice: 0.3304, decode.d2.loss_cls: 0.0008, decode.d2.loss_mask: 0.1589, decode.d2.loss_dice: 0.3236, decode.d3.loss_cls: 0.0005, decode.d3.loss_mask: 0.1590, decode.d3.loss_dice: 0.3307, decode.d4.loss_cls: 0.0003, decode.d4.loss_mask: 0.1564, decode.d4.loss_dice: 0.3259, decode.d5.loss_cls: 0.0003, decode.d5.loss_mask: 0.1555, decode.d5.loss_dice: 0.3172, decode.d6.loss_cls: 0.0002, decode.d6.loss_mask: 0.1582, decode.d6.loss_dice: 0.3266, decode.d7.loss_cls: 0.0002, decode.d7.loss_mask: 0.1588, decode.d7.loss_dice: 0.3297, decode.d8.loss_cls: 0.0002, decode.d8.loss_mask: 0.1589, decode.d8.loss_dice: 0.3241, loss: 6.9481\n",
      "2024-02-14 15:40:53,024 - mmseg - INFO - Iter [3370/80000]\tlr: 1.375e-06, eta: 2 days, 0:30:40, time: 2.132, data_time: 0.016, memory: 23505, decode.loss_cls: 0.0002, decode.loss_mask: 0.2122, decode.loss_dice: 0.3877, decode.d0.loss_cls: 2.0633, decode.d0.loss_mask: 0.2154, decode.d0.loss_dice: 0.4031, decode.d1.loss_cls: 0.0094, decode.d1.loss_mask: 0.2154, decode.d1.loss_dice: 0.3842, decode.d2.loss_cls: 0.0008, decode.d2.loss_mask: 0.2132, decode.d2.loss_dice: 0.3824, decode.d3.loss_cls: 0.0005, decode.d3.loss_mask: 0.2159, decode.d3.loss_dice: 0.3840, decode.d4.loss_cls: 0.0003, decode.d4.loss_mask: 0.2109, decode.d4.loss_dice: 0.3812, decode.d5.loss_cls: 0.0003, decode.d5.loss_mask: 0.2137, decode.d5.loss_dice: 0.3843, decode.d6.loss_cls: 0.0003, decode.d6.loss_mask: 0.2117, decode.d6.loss_dice: 0.3814, decode.d7.loss_cls: 0.0002, decode.d7.loss_mask: 0.2125, decode.d7.loss_dice: 0.3858, decode.d8.loss_cls: 0.0003, decode.d8.loss_mask: 0.2118, decode.d8.loss_dice: 0.3844, loss: 8.0668\n",
      "2024-02-14 15:41:14,376 - mmseg - INFO - Iter [3380/80000]\tlr: 1.375e-06, eta: 2 days, 0:29:45, time: 2.135, data_time: 0.018, memory: 23505, decode.loss_cls: 0.0002, decode.loss_mask: 0.2268, decode.loss_dice: 0.4011, decode.d0.loss_cls: 2.0684, decode.d0.loss_mask: 0.2284, decode.d0.loss_dice: 0.4154, decode.d1.loss_cls: 0.0037, decode.d1.loss_mask: 0.2266, decode.d1.loss_dice: 0.4055, decode.d2.loss_cls: 0.0008, decode.d2.loss_mask: 0.2258, decode.d2.loss_dice: 0.4023, decode.d3.loss_cls: 0.0006, decode.d3.loss_mask: 0.2233, decode.d3.loss_dice: 0.3978, decode.d4.loss_cls: 0.0004, decode.d4.loss_mask: 0.2260, decode.d4.loss_dice: 0.4041, decode.d5.loss_cls: 0.0003, decode.d5.loss_mask: 0.2257, decode.d5.loss_dice: 0.4022, decode.d6.loss_cls: 0.0003, decode.d6.loss_mask: 0.2241, decode.d6.loss_dice: 0.4006, decode.d7.loss_cls: 0.0003, decode.d7.loss_mask: 0.2241, decode.d7.loss_dice: 0.4003, decode.d8.loss_cls: 0.0003, decode.d8.loss_mask: 0.2242, decode.d8.loss_dice: 0.3978, loss: 8.3574\n",
      "2024-02-14 15:41:35,726 - mmseg - INFO - Iter [3390/80000]\tlr: 1.375e-06, eta: 2 days, 0:28:50, time: 2.135, data_time: 0.017, memory: 23505, decode.loss_cls: 0.0003, decode.loss_mask: 0.2217, decode.loss_dice: 0.4042, decode.d0.loss_cls: 2.0531, decode.d0.loss_mask: 0.2262, decode.d0.loss_dice: 0.4214, decode.d1.loss_cls: 0.0063, decode.d1.loss_mask: 0.2228, decode.d1.loss_dice: 0.4076, decode.d2.loss_cls: 0.0007, decode.d2.loss_mask: 0.2199, decode.d2.loss_dice: 0.4071, decode.d3.loss_cls: 0.0006, decode.d3.loss_mask: 0.2204, decode.d3.loss_dice: 0.4037, decode.d4.loss_cls: 0.0004, decode.d4.loss_mask: 0.2216, decode.d4.loss_dice: 0.4081, decode.d5.loss_cls: 0.0003, decode.d5.loss_mask: 0.2212, decode.d5.loss_dice: 0.4054, decode.d6.loss_cls: 0.0003, decode.d6.loss_mask: 0.2200, decode.d6.loss_dice: 0.3993, decode.d7.loss_cls: 0.0003, decode.d7.loss_mask: 0.2215, decode.d7.loss_dice: 0.4045, decode.d8.loss_cls: 0.0003, decode.d8.loss_mask: 0.2223, decode.d8.loss_dice: 0.4052, loss: 8.3466\n",
      "2024-02-14 15:41:57,064 - mmseg - INFO - Iter [3400/80000]\tlr: 1.375e-06, eta: 2 days, 0:27:54, time: 2.134, data_time: 0.017, memory: 23505, decode.loss_cls: 0.0002, decode.loss_mask: 0.1797, decode.loss_dice: 0.3599, decode.d0.loss_cls: 2.0378, decode.d0.loss_mask: 0.1812, decode.d0.loss_dice: 0.3817, decode.d1.loss_cls: 0.0113, decode.d1.loss_mask: 0.1785, decode.d1.loss_dice: 0.3626, decode.d2.loss_cls: 0.0008, decode.d2.loss_mask: 0.1790, decode.d2.loss_dice: 0.3537, decode.d3.loss_cls: 0.0006, decode.d3.loss_mask: 0.1786, decode.d3.loss_dice: 0.3555, decode.d4.loss_cls: 0.0003, decode.d4.loss_mask: 0.1791, decode.d4.loss_dice: 0.3596, decode.d5.loss_cls: 0.0003, decode.d5.loss_mask: 0.1791, decode.d5.loss_dice: 0.3609, decode.d6.loss_cls: 0.0003, decode.d6.loss_mask: 0.1811, decode.d6.loss_dice: 0.3577, decode.d7.loss_cls: 0.0003, decode.d7.loss_mask: 0.1780, decode.d7.loss_dice: 0.3528, decode.d8.loss_cls: 0.0003, decode.d8.loss_mask: 0.1796, decode.d8.loss_dice: 0.3617, loss: 7.4521\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 40/40, 6.2 task/s, elapsed: 6s, ETA:     0s\n",
      "\n",
      "2024-02-14 15:42:03,535 - mmseg - INFO - per class results:\n",
      "2024-02-14 15:42:03,535 - mmseg - INFO - \n",
      "+---------------+-------+-------+\n",
      "|     Class     |  IoU  |  Acc  |\n",
      "+---------------+-------+-------+\n",
      "|       bg      | 97.58 |  98.7 |\n",
      "|    Anchovy    | 81.87 | 92.07 |\n",
      "|     Olives    | 85.98 | 89.03 |\n",
      "|     Salami    | 70.99 |  86.2 |\n",
      "|   Red_Pepper  | 88.92 | 93.94 |\n",
      "| Yellow_Pepper | 85.98 | 93.48 |\n",
      "+---------------+-------+-------+\n",
      "2024-02-14 15:42:03,535 - mmseg - INFO - Summary:\n",
      "2024-02-14 15:42:03,536 - mmseg - INFO - \n",
      "+-------+-------+-------+\n",
      "|  aAcc |  mIoU |  mAcc |\n",
      "+-------+-------+-------+\n",
      "| 97.63 | 85.22 | 92.24 |\n",
      "+-------+-------+-------+\n",
      "2024-02-14 15:42:03,536 - mmseg - INFO - Iter(val) [10]\taAcc: 0.9763, mIoU: 0.8522, mAcc: 0.9224, IoU.bg: 0.9758, IoU.Anchovy: 0.8187, IoU.Olives: 0.8598, IoU.Salami: 0.7099, IoU.Red_Pepper: 0.8892, IoU.Yellow_Pepper: 0.8598, Acc.bg: 0.9870, Acc.Anchovy: 0.9207, Acc.Olives: 0.8903, Acc.Salami: 0.8620, Acc.Red_Pepper: 0.9394, Acc.Yellow_Pepper: 0.9348\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-14 15:42:24,857 - mmseg - INFO - Iter [3410/80000]\tlr: 1.375e-06, eta: 2 days, 0:29:24, time: 2.779, data_time: 0.664, memory: 23505, decode.loss_cls: 0.0002, decode.loss_mask: 0.1998, decode.loss_dice: 0.3863, decode.d0.loss_cls: 2.0371, decode.d0.loss_mask: 0.2074, decode.d0.loss_dice: 0.4135, decode.d1.loss_cls: 0.0072, decode.d1.loss_mask: 0.2026, decode.d1.loss_dice: 0.3911, decode.d2.loss_cls: 0.0008, decode.d2.loss_mask: 0.2014, decode.d2.loss_dice: 0.3850, decode.d3.loss_cls: 0.0006, decode.d3.loss_mask: 0.2027, decode.d3.loss_dice: 0.3939, decode.d4.loss_cls: 0.0003, decode.d4.loss_mask: 0.2023, decode.d4.loss_dice: 0.3925, decode.d5.loss_cls: 0.0003, decode.d5.loss_mask: 0.2008, decode.d5.loss_dice: 0.3897, decode.d6.loss_cls: 0.0003, decode.d6.loss_mask: 0.2009, decode.d6.loss_dice: 0.3934, decode.d7.loss_cls: 0.0002, decode.d7.loss_mask: 0.2012, decode.d7.loss_dice: 0.3902, decode.d8.loss_cls: 0.0003, decode.d8.loss_mask: 0.2010, decode.d8.loss_dice: 0.3887, loss: 7.9915\n",
      "2024-02-14 15:42:46,179 - mmseg - INFO - Iter [3420/80000]\tlr: 1.374e-06, eta: 2 days, 0:28:29, time: 2.132, data_time: 0.017, memory: 23505, decode.loss_cls: 0.0002, decode.loss_mask: 0.1615, decode.loss_dice: 0.3239, decode.d0.loss_cls: 2.0242, decode.d0.loss_mask: 0.1574, decode.d0.loss_dice: 0.3464, decode.d1.loss_cls: 0.0091, decode.d1.loss_mask: 0.1615, decode.d1.loss_dice: 0.3261, decode.d2.loss_cls: 0.0008, decode.d2.loss_mask: 0.1614, decode.d2.loss_dice: 0.3266, decode.d3.loss_cls: 0.0005, decode.d3.loss_mask: 0.1609, decode.d3.loss_dice: 0.3225, decode.d4.loss_cls: 0.0003, decode.d4.loss_mask: 0.1605, decode.d4.loss_dice: 0.3256, decode.d5.loss_cls: 0.0003, decode.d5.loss_mask: 0.1595, decode.d5.loss_dice: 0.3181, decode.d6.loss_cls: 0.0002, decode.d6.loss_mask: 0.1630, decode.d6.loss_dice: 0.3309, decode.d7.loss_cls: 0.0002, decode.d7.loss_mask: 0.1598, decode.d7.loss_dice: 0.3237, decode.d8.loss_cls: 0.0002, decode.d8.loss_mask: 0.1622, decode.d8.loss_dice: 0.3252, loss: 6.9129\n",
      "2024-02-14 15:43:07,503 - mmseg - INFO - Iter [3430/80000]\tlr: 1.374e-06, eta: 2 days, 0:27:33, time: 2.132, data_time: 0.017, memory: 23505, decode.loss_cls: 0.0002, decode.loss_mask: 0.1984, decode.loss_dice: 0.3812, decode.d0.loss_cls: 2.0189, decode.d0.loss_mask: 0.2000, decode.d0.loss_dice: 0.3974, decode.d1.loss_cls: 0.0085, decode.d1.loss_mask: 0.1986, decode.d1.loss_dice: 0.3802, decode.d2.loss_cls: 0.0008, decode.d2.loss_mask: 0.2008, decode.d2.loss_dice: 0.3839, decode.d3.loss_cls: 0.0005, decode.d3.loss_mask: 0.1980, decode.d3.loss_dice: 0.3871, decode.d4.loss_cls: 0.0003, decode.d4.loss_mask: 0.1990, decode.d4.loss_dice: 0.3837, decode.d5.loss_cls: 0.0003, decode.d5.loss_mask: 0.1972, decode.d5.loss_dice: 0.3839, decode.d6.loss_cls: 0.0003, decode.d6.loss_mask: 0.1946, decode.d6.loss_dice: 0.3823, decode.d7.loss_cls: 0.0002, decode.d7.loss_mask: 0.1946, decode.d7.loss_dice: 0.3852, decode.d8.loss_cls: 0.0002, decode.d8.loss_mask: 0.1972, decode.d8.loss_dice: 0.3809, loss: 7.8545\n",
      "2024-02-14 15:43:28,826 - mmseg - INFO - Iter [3440/80000]\tlr: 1.374e-06, eta: 2 days, 0:26:38, time: 2.132, data_time: 0.017, memory: 23505, decode.loss_cls: 0.0002, decode.loss_mask: 0.1925, decode.loss_dice: 0.3625, decode.d0.loss_cls: 2.0117, decode.d0.loss_mask: 0.1920, decode.d0.loss_dice: 0.3853, decode.d1.loss_cls: 0.0086, decode.d1.loss_mask: 0.1886, decode.d1.loss_dice: 0.3570, decode.d2.loss_cls: 0.0008, decode.d2.loss_mask: 0.1886, decode.d2.loss_dice: 0.3585, decode.d3.loss_cls: 0.0005, decode.d3.loss_mask: 0.1894, decode.d3.loss_dice: 0.3631, decode.d4.loss_cls: 0.0003, decode.d4.loss_mask: 0.1889, decode.d4.loss_dice: 0.3621, decode.d5.loss_cls: 0.0003, decode.d5.loss_mask: 0.1918, decode.d5.loss_dice: 0.3629, decode.d6.loss_cls: 0.0003, decode.d6.loss_mask: 0.1910, decode.d6.loss_dice: 0.3670, decode.d7.loss_cls: 0.0003, decode.d7.loss_mask: 0.1896, decode.d7.loss_dice: 0.3587, decode.d8.loss_cls: 0.0003, decode.d8.loss_mask: 0.1894, decode.d8.loss_dice: 0.3608, loss: 7.5632\n",
      "2024-02-14 15:43:50,152 - mmseg - INFO - Iter [3450/80000]\tlr: 1.374e-06, eta: 2 days, 0:25:43, time: 2.133, data_time: 0.017, memory: 23505, decode.loss_cls: 0.0002, decode.loss_mask: 0.1902, decode.loss_dice: 0.3717, decode.d0.loss_cls: 2.0064, decode.d0.loss_mask: 0.1939, decode.d0.loss_dice: 0.3958, decode.d1.loss_cls: 0.0088, decode.d1.loss_mask: 0.1922, decode.d1.loss_dice: 0.3755, decode.d2.loss_cls: 0.0008, decode.d2.loss_mask: 0.1934, decode.d2.loss_dice: 0.3695, decode.d3.loss_cls: 0.0005, decode.d3.loss_mask: 0.1919, decode.d3.loss_dice: 0.3725, decode.d4.loss_cls: 0.0003, decode.d4.loss_mask: 0.1930, decode.d4.loss_dice: 0.3742, decode.d5.loss_cls: 0.0003, decode.d5.loss_mask: 0.1906, decode.d5.loss_dice: 0.3722, decode.d6.loss_cls: 0.0003, decode.d6.loss_mask: 0.1923, decode.d6.loss_dice: 0.3717, decode.d7.loss_cls: 0.0002, decode.d7.loss_mask: 0.1927, decode.d7.loss_dice: 0.3745, decode.d8.loss_cls: 0.0003, decode.d8.loss_mask: 0.1905, decode.d8.loss_dice: 0.3692, loss: 7.6856\n",
      "2024-02-14 15:44:11,484 - mmseg - INFO - Iter [3460/80000]\tlr: 1.374e-06, eta: 2 days, 0:24:48, time: 2.133, data_time: 0.017, memory: 23505, decode.loss_cls: 0.0002, decode.loss_mask: 0.2010, decode.loss_dice: 0.3801, decode.d0.loss_cls: 1.9997, decode.d0.loss_mask: 0.2022, decode.d0.loss_dice: 0.4012, decode.d1.loss_cls: 0.0075, decode.d1.loss_mask: 0.1984, decode.d1.loss_dice: 0.3809, decode.d2.loss_cls: 0.0008, decode.d2.loss_mask: 0.2008, decode.d2.loss_dice: 0.3799, decode.d3.loss_cls: 0.0006, decode.d3.loss_mask: 0.1981, decode.d3.loss_dice: 0.3747, decode.d4.loss_cls: 0.0003, decode.d4.loss_mask: 0.2010, decode.d4.loss_dice: 0.3790, decode.d5.loss_cls: 0.0003, decode.d5.loss_mask: 0.1990, decode.d5.loss_dice: 0.3796, decode.d6.loss_cls: 0.0003, decode.d6.loss_mask: 0.1980, decode.d6.loss_dice: 0.3773, decode.d7.loss_cls: 0.0002, decode.d7.loss_mask: 0.1978, decode.d7.loss_dice: 0.3768, decode.d8.loss_cls: 0.0002, decode.d8.loss_mask: 0.1991, decode.d8.loss_dice: 0.3754, loss: 7.8101\n",
      "2024-02-14 15:44:32,811 - mmseg - INFO - Iter [3470/80000]\tlr: 1.374e-06, eta: 2 days, 0:23:53, time: 2.133, data_time: 0.016, memory: 23505, decode.loss_cls: 0.0002, decode.loss_mask: 0.1906, decode.loss_dice: 0.3789, decode.d0.loss_cls: 1.9873, decode.d0.loss_mask: 0.1931, decode.d0.loss_dice: 0.3956, decode.d1.loss_cls: 0.0100, decode.d1.loss_mask: 0.1908, decode.d1.loss_dice: 0.3715, decode.d2.loss_cls: 0.0008, decode.d2.loss_mask: 0.1870, decode.d2.loss_dice: 0.3685, decode.d3.loss_cls: 0.0006, decode.d3.loss_mask: 0.1881, decode.d3.loss_dice: 0.3698, decode.d4.loss_cls: 0.0003, decode.d4.loss_mask: 0.1894, decode.d4.loss_dice: 0.3759, decode.d5.loss_cls: 0.0003, decode.d5.loss_mask: 0.1869, decode.d5.loss_dice: 0.3713, decode.d6.loss_cls: 0.0003, decode.d6.loss_mask: 0.1894, decode.d6.loss_dice: 0.3742, decode.d7.loss_cls: 0.0002, decode.d7.loss_mask: 0.1894, decode.d7.loss_dice: 0.3730, decode.d8.loss_cls: 0.0003, decode.d8.loss_mask: 0.1874, decode.d8.loss_dice: 0.3658, loss: 7.6370\n",
      "2024-02-14 15:44:54,150 - mmseg - INFO - Iter [3480/80000]\tlr: 1.373e-06, eta: 2 days, 0:22:59, time: 2.134, data_time: 0.017, memory: 23505, decode.loss_cls: 0.0002, decode.loss_mask: 0.1918, decode.loss_dice: 0.3764, decode.d0.loss_cls: 1.9868, decode.d0.loss_mask: 0.1941, decode.d0.loss_dice: 0.3851, decode.d1.loss_cls: 0.0072, decode.d1.loss_mask: 0.1928, decode.d1.loss_dice: 0.3714, decode.d2.loss_cls: 0.0008, decode.d2.loss_mask: 0.1911, decode.d2.loss_dice: 0.3715, decode.d3.loss_cls: 0.0006, decode.d3.loss_mask: 0.1931, decode.d3.loss_dice: 0.3761, decode.d4.loss_cls: 0.0003, decode.d4.loss_mask: 0.1917, decode.d4.loss_dice: 0.3729, decode.d5.loss_cls: 0.0003, decode.d5.loss_mask: 0.1903, decode.d5.loss_dice: 0.3738, decode.d6.loss_cls: 0.0003, decode.d6.loss_mask: 0.1913, decode.d6.loss_dice: 0.3689, decode.d7.loss_cls: 0.0002, decode.d7.loss_mask: 0.1921, decode.d7.loss_dice: 0.3758, decode.d8.loss_cls: 0.0002, decode.d8.loss_mask: 0.1911, decode.d8.loss_dice: 0.3729, loss: 7.6613\n",
      "2024-02-14 15:45:15,485 - mmseg - INFO - Iter [3490/80000]\tlr: 1.373e-06, eta: 2 days, 0:22:05, time: 2.133, data_time: 0.017, memory: 23505, decode.loss_cls: 0.0002, decode.loss_mask: 0.1962, decode.loss_dice: 0.3556, decode.d0.loss_cls: 1.9797, decode.d0.loss_mask: 0.1997, decode.d0.loss_dice: 0.3784, decode.d1.loss_cls: 0.0071, decode.d1.loss_mask: 0.1968, decode.d1.loss_dice: 0.3592, decode.d2.loss_cls: 0.0008, decode.d2.loss_mask: 0.1963, decode.d2.loss_dice: 0.3541, decode.d3.loss_cls: 0.0006, decode.d3.loss_mask: 0.1972, decode.d3.loss_dice: 0.3569, decode.d4.loss_cls: 0.0003, decode.d4.loss_mask: 0.1960, decode.d4.loss_dice: 0.3529, decode.d5.loss_cls: 0.0003, decode.d5.loss_mask: 0.1943, decode.d5.loss_dice: 0.3540, decode.d6.loss_cls: 0.0003, decode.d6.loss_mask: 0.1960, decode.d6.loss_dice: 0.3535, decode.d7.loss_cls: 0.0002, decode.d7.loss_mask: 0.1971, decode.d7.loss_dice: 0.3501, decode.d8.loss_cls: 0.0002, decode.d8.loss_mask: 0.1980, decode.d8.loss_dice: 0.3562, loss: 7.5284\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-14 15:45:36,810 - mmseg - INFO - Iter [3500/80000]\tlr: 1.373e-06, eta: 2 days, 0:21:11, time: 2.133, data_time: 0.017, memory: 23505, decode.loss_cls: 0.0002, decode.loss_mask: 0.2013, decode.loss_dice: 0.3658, decode.d0.loss_cls: 1.9746, decode.d0.loss_mask: 0.2080, decode.d0.loss_dice: 0.3872, decode.d1.loss_cls: 0.0063, decode.d1.loss_mask: 0.2033, decode.d1.loss_dice: 0.3675, decode.d2.loss_cls: 0.0007, decode.d2.loss_mask: 0.2035, decode.d2.loss_dice: 0.3726, decode.d3.loss_cls: 0.0005, decode.d3.loss_mask: 0.2051, decode.d3.loss_dice: 0.3698, decode.d4.loss_cls: 0.0003, decode.d4.loss_mask: 0.2043, decode.d4.loss_dice: 0.3710, decode.d5.loss_cls: 0.0003, decode.d5.loss_mask: 0.2029, decode.d5.loss_dice: 0.3675, decode.d6.loss_cls: 0.0003, decode.d6.loss_mask: 0.2040, decode.d6.loss_dice: 0.3676, decode.d7.loss_cls: 0.0002, decode.d7.loss_mask: 0.2046, decode.d7.loss_dice: 0.3703, decode.d8.loss_cls: 0.0002, decode.d8.loss_mask: 0.2045, decode.d8.loss_dice: 0.3704, loss: 7.7347\n",
      "2024-02-14 15:45:58,141 - mmseg - INFO - Iter [3510/80000]\tlr: 1.373e-06, eta: 2 days, 0:20:17, time: 2.133, data_time: 0.016, memory: 23505, decode.loss_cls: 0.0002, decode.loss_mask: 0.1826, decode.loss_dice: 0.3309, decode.d0.loss_cls: 1.9606, decode.d0.loss_mask: 0.1800, decode.d0.loss_dice: 0.3450, decode.d1.loss_cls: 0.0095, decode.d1.loss_mask: 0.1791, decode.d1.loss_dice: 0.3303, decode.d2.loss_cls: 0.0007, decode.d2.loss_mask: 0.1798, decode.d2.loss_dice: 0.3312, decode.d3.loss_cls: 0.0005, decode.d3.loss_mask: 0.1798, decode.d3.loss_dice: 0.3355, decode.d4.loss_cls: 0.0003, decode.d4.loss_mask: 0.1823, decode.d4.loss_dice: 0.3315, decode.d5.loss_cls: 0.0003, decode.d5.loss_mask: 0.1804, decode.d5.loss_dice: 0.3275, decode.d6.loss_cls: 0.0003, decode.d6.loss_mask: 0.1814, decode.d6.loss_dice: 0.3295, decode.d7.loss_cls: 0.0002, decode.d7.loss_mask: 0.1800, decode.d7.loss_dice: 0.3297, decode.d8.loss_cls: 0.0002, decode.d8.loss_mask: 0.1825, decode.d8.loss_dice: 0.3291, loss: 7.1009\n",
      "2024-02-14 15:46:19,470 - mmseg - INFO - Iter [3520/80000]\tlr: 1.373e-06, eta: 2 days, 0:19:24, time: 2.133, data_time: 0.017, memory: 23505, decode.loss_cls: 0.0002, decode.loss_mask: 0.2158, decode.loss_dice: 0.4039, decode.d0.loss_cls: 1.9603, decode.d0.loss_mask: 0.2197, decode.d0.loss_dice: 0.4223, decode.d1.loss_cls: 0.0068, decode.d1.loss_mask: 0.2179, decode.d1.loss_dice: 0.4033, decode.d2.loss_cls: 0.0007, decode.d2.loss_mask: 0.2163, decode.d2.loss_dice: 0.4016, decode.d3.loss_cls: 0.0005, decode.d3.loss_mask: 0.2167, decode.d3.loss_dice: 0.4008, decode.d4.loss_cls: 0.0003, decode.d4.loss_mask: 0.2161, decode.d4.loss_dice: 0.4054, decode.d5.loss_cls: 0.0003, decode.d5.loss_mask: 0.2161, decode.d5.loss_dice: 0.4034, decode.d6.loss_cls: 0.0003, decode.d6.loss_mask: 0.2147, decode.d6.loss_dice: 0.4018, decode.d7.loss_cls: 0.0002, decode.d7.loss_mask: 0.2155, decode.d7.loss_dice: 0.4001, decode.d8.loss_cls: 0.0002, decode.d8.loss_mask: 0.2146, decode.d8.loss_dice: 0.4048, loss: 8.1807\n",
      "2024-02-14 15:46:42,882 - mmseg - INFO - Iter [3530/80000]\tlr: 1.372e-06, eta: 2 days, 0:19:15, time: 2.341, data_time: 0.224, memory: 23505, decode.loss_cls: 0.0002, decode.loss_mask: 0.1939, decode.loss_dice: 0.3707, decode.d0.loss_cls: 1.9513, decode.d0.loss_mask: 0.2036, decode.d0.loss_dice: 0.3975, decode.d1.loss_cls: 0.0081, decode.d1.loss_mask: 0.2003, decode.d1.loss_dice: 0.3750, decode.d2.loss_cls: 0.0007, decode.d2.loss_mask: 0.1964, decode.d2.loss_dice: 0.3718, decode.d3.loss_cls: 0.0006, decode.d3.loss_mask: 0.1956, decode.d3.loss_dice: 0.3767, decode.d4.loss_cls: 0.0003, decode.d4.loss_mask: 0.1968, decode.d4.loss_dice: 0.3788, decode.d5.loss_cls: 0.0003, decode.d5.loss_mask: 0.1966, decode.d5.loss_dice: 0.3752, decode.d6.loss_cls: 0.0003, decode.d6.loss_mask: 0.1951, decode.d6.loss_dice: 0.3713, decode.d7.loss_cls: 0.0002, decode.d7.loss_mask: 0.1984, decode.d7.loss_dice: 0.3778, decode.d8.loss_cls: 0.0003, decode.d8.loss_mask: 0.1967, decode.d8.loss_dice: 0.3772, loss: 7.7078\n",
      "2024-02-14 15:47:04,204 - mmseg - INFO - Iter [3540/80000]\tlr: 1.372e-06, eta: 2 days, 0:18:22, time: 2.132, data_time: 0.016, memory: 23505, decode.loss_cls: 0.0002, decode.loss_mask: 0.1631, decode.loss_dice: 0.3207, decode.d0.loss_cls: 1.9401, decode.d0.loss_mask: 0.1598, decode.d0.loss_dice: 0.3429, decode.d1.loss_cls: 0.0084, decode.d1.loss_mask: 0.1617, decode.d1.loss_dice: 0.3269, decode.d2.loss_cls: 0.0008, decode.d2.loss_mask: 0.1629, decode.d2.loss_dice: 0.3239, decode.d3.loss_cls: 0.0006, decode.d3.loss_mask: 0.1599, decode.d3.loss_dice: 0.3218, decode.d4.loss_cls: 0.0003, decode.d4.loss_mask: 0.1619, decode.d4.loss_dice: 0.3234, decode.d5.loss_cls: 0.0003, decode.d5.loss_mask: 0.1624, decode.d5.loss_dice: 0.3226, decode.d6.loss_cls: 0.0003, decode.d6.loss_mask: 0.1613, decode.d6.loss_dice: 0.3183, decode.d7.loss_cls: 0.0002, decode.d7.loss_mask: 0.1599, decode.d7.loss_dice: 0.3175, decode.d8.loss_cls: 0.0003, decode.d8.loss_mask: 0.1610, decode.d8.loss_dice: 0.3177, loss: 6.8009\n",
      "2024-02-14 15:47:29,476 - mmseg - INFO - Iter [3550/80000]\tlr: 1.372e-06, eta: 2 days, 0:18:53, time: 2.527, data_time: 0.031, memory: 23505, decode.loss_cls: 0.0002, decode.loss_mask: 0.1808, decode.loss_dice: 0.3460, decode.d0.loss_cls: 1.9364, decode.d0.loss_mask: 0.1774, decode.d0.loss_dice: 0.3682, decode.d1.loss_cls: 0.0063, decode.d1.loss_mask: 0.1771, decode.d1.loss_dice: 0.3475, decode.d2.loss_cls: 0.0006, decode.d2.loss_mask: 0.1773, decode.d2.loss_dice: 0.3446, decode.d3.loss_cls: 0.0005, decode.d3.loss_mask: 0.1785, decode.d3.loss_dice: 0.3443, decode.d4.loss_cls: 0.0003, decode.d4.loss_mask: 0.1794, decode.d4.loss_dice: 0.3487, decode.d5.loss_cls: 0.0003, decode.d5.loss_mask: 0.1788, decode.d5.loss_dice: 0.3477, decode.d6.loss_cls: 0.0002, decode.d6.loss_mask: 0.1807, decode.d6.loss_dice: 0.3462, decode.d7.loss_cls: 0.0002, decode.d7.loss_mask: 0.1803, decode.d7.loss_dice: 0.3458, decode.d8.loss_cls: 0.0002, decode.d8.loss_mask: 0.1802, decode.d8.loss_dice: 0.3462, loss: 7.2212\n",
      "2024-02-14 15:47:59,989 - mmseg - INFO - Iter [3560/80000]\tlr: 1.372e-06, eta: 2 days, 0:21:17, time: 3.051, data_time: 0.016, memory: 23505, decode.loss_cls: 0.0002, decode.loss_mask: 0.1788, decode.loss_dice: 0.3342, decode.d0.loss_cls: 1.9284, decode.d0.loss_mask: 0.1791, decode.d0.loss_dice: 0.3576, decode.d1.loss_cls: 0.0083, decode.d1.loss_mask: 0.1794, decode.d1.loss_dice: 0.3340, decode.d2.loss_cls: 0.0007, decode.d2.loss_mask: 0.1776, decode.d2.loss_dice: 0.3289, decode.d3.loss_cls: 0.0005, decode.d3.loss_mask: 0.1782, decode.d3.loss_dice: 0.3318, decode.d4.loss_cls: 0.0003, decode.d4.loss_mask: 0.1773, decode.d4.loss_dice: 0.3358, decode.d5.loss_cls: 0.0003, decode.d5.loss_mask: 0.1770, decode.d5.loss_dice: 0.3332, decode.d6.loss_cls: 0.0003, decode.d6.loss_mask: 0.1781, decode.d6.loss_dice: 0.3309, decode.d7.loss_cls: 0.0002, decode.d7.loss_mask: 0.1790, decode.d7.loss_dice: 0.3343, decode.d8.loss_cls: 0.0002, decode.d8.loss_mask: 0.1783, decode.d8.loss_dice: 0.3334, loss: 7.0763\n",
      "2024-02-14 15:48:56,057 - mmseg - INFO - Iter [3570/80000]\tlr: 1.372e-06, eta: 2 days, 0:32:47, time: 5.606, data_time: 0.015, memory: 23505, decode.loss_cls: 0.0002, decode.loss_mask: 0.1850, decode.loss_dice: 0.3506, decode.d0.loss_cls: 1.9223, decode.d0.loss_mask: 0.1886, decode.d0.loss_dice: 0.3811, decode.d1.loss_cls: 0.0086, decode.d1.loss_mask: 0.1911, decode.d1.loss_dice: 0.3548, decode.d2.loss_cls: 0.0009, decode.d2.loss_mask: 0.1889, decode.d2.loss_dice: 0.3556, decode.d3.loss_cls: 0.0006, decode.d3.loss_mask: 0.1892, decode.d3.loss_dice: 0.3585, decode.d4.loss_cls: 0.0003, decode.d4.loss_mask: 0.1872, decode.d4.loss_dice: 0.3553, decode.d5.loss_cls: 0.0003, decode.d5.loss_mask: 0.1890, decode.d5.loss_dice: 0.3538, decode.d6.loss_cls: 0.0004, decode.d6.loss_mask: 0.1886, decode.d6.loss_dice: 0.3588, decode.d7.loss_cls: 0.0003, decode.d7.loss_mask: 0.1878, decode.d7.loss_dice: 0.3567, decode.d8.loss_cls: 0.0003, decode.d8.loss_mask: 0.1882, decode.d8.loss_dice: 0.3604, loss: 7.4034\n",
      "2024-02-14 15:49:31,652 - mmseg - INFO - Iter [3580/80000]\tlr: 1.372e-06, eta: 2 days, 0:36:56, time: 3.560, data_time: 0.015, memory: 23505, decode.loss_cls: 0.0002, decode.loss_mask: 0.2032, decode.loss_dice: 0.3690, decode.d0.loss_cls: 1.9211, decode.d0.loss_mask: 0.2051, decode.d0.loss_dice: 0.3864, decode.d1.loss_cls: 0.0051, decode.d1.loss_mask: 0.2006, decode.d1.loss_dice: 0.3693, decode.d2.loss_cls: 0.0007, decode.d2.loss_mask: 0.2045, decode.d2.loss_dice: 0.3735, decode.d3.loss_cls: 0.0006, decode.d3.loss_mask: 0.2034, decode.d3.loss_dice: 0.3738, decode.d4.loss_cls: 0.0004, decode.d4.loss_mask: 0.2008, decode.d4.loss_dice: 0.3683, decode.d5.loss_cls: 0.0003, decode.d5.loss_mask: 0.2019, decode.d5.loss_dice: 0.3693, decode.d6.loss_cls: 0.0003, decode.d6.loss_mask: 0.2048, decode.d6.loss_dice: 0.3728, decode.d7.loss_cls: 0.0002, decode.d7.loss_mask: 0.2039, decode.d7.loss_dice: 0.3690, decode.d8.loss_cls: 0.0003, decode.d8.loss_mask: 0.2040, decode.d8.loss_dice: 0.3707, loss: 7.6836\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-14 15:49:52,958 - mmseg - INFO - Iter [3590/80000]\tlr: 1.371e-06, eta: 2 days, 0:35:59, time: 2.131, data_time: 0.017, memory: 23505, decode.loss_cls: 0.0002, decode.loss_mask: 0.1827, decode.loss_dice: 0.3383, decode.d0.loss_cls: 1.9080, decode.d0.loss_mask: 0.1816, decode.d0.loss_dice: 0.3621, decode.d1.loss_cls: 0.0072, decode.d1.loss_mask: 0.1812, decode.d1.loss_dice: 0.3347, decode.d2.loss_cls: 0.0006, decode.d2.loss_mask: 0.1794, decode.d2.loss_dice: 0.3357, decode.d3.loss_cls: 0.0004, decode.d3.loss_mask: 0.1791, decode.d3.loss_dice: 0.3355, decode.d4.loss_cls: 0.0003, decode.d4.loss_mask: 0.1812, decode.d4.loss_dice: 0.3359, decode.d5.loss_cls: 0.0003, decode.d5.loss_mask: 0.1830, decode.d5.loss_dice: 0.3347, decode.d6.loss_cls: 0.0002, decode.d6.loss_mask: 0.1813, decode.d6.loss_dice: 0.3332, decode.d7.loss_cls: 0.0002, decode.d7.loss_mask: 0.1811, decode.d7.loss_dice: 0.3373, decode.d8.loss_cls: 0.0002, decode.d8.loss_mask: 0.1817, decode.d8.loss_dice: 0.3319, loss: 7.1091\n",
      "2024-02-14 15:50:14,290 - mmseg - INFO - Iter [3600/80000]\tlr: 1.371e-06, eta: 2 days, 0:35:03, time: 2.133, data_time: 0.018, memory: 23505, decode.loss_cls: 0.0002, decode.loss_mask: 0.2389, decode.loss_dice: 0.4328, decode.d0.loss_cls: 1.9043, decode.d0.loss_mask: 0.2523, decode.d0.loss_dice: 0.4604, decode.d1.loss_cls: 0.0053, decode.d1.loss_mask: 0.2435, decode.d1.loss_dice: 0.4356, decode.d2.loss_cls: 0.0009, decode.d2.loss_mask: 0.2420, decode.d2.loss_dice: 0.4331, decode.d3.loss_cls: 0.0008, decode.d3.loss_mask: 0.2444, decode.d3.loss_dice: 0.4374, decode.d4.loss_cls: 0.0005, decode.d4.loss_mask: 0.2412, decode.d4.loss_dice: 0.4344, decode.d5.loss_cls: 0.0003, decode.d5.loss_mask: 0.2422, decode.d5.loss_dice: 0.4348, decode.d6.loss_cls: 0.0003, decode.d6.loss_mask: 0.2443, decode.d6.loss_dice: 0.4336, decode.d7.loss_cls: 0.0003, decode.d7.loss_mask: 0.2400, decode.d7.loss_dice: 0.4321, decode.d8.loss_cls: 0.0003, decode.d8.loss_mask: 0.2426, decode.d8.loss_dice: 0.4354, loss: 8.7143\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 40/40, 6.2 task/s, elapsed: 6s, ETA:     0s\n",
      "\n",
      "2024-02-14 15:50:20,722 - mmseg - INFO - per class results:\n",
      "2024-02-14 15:50:20,722 - mmseg - INFO - \n",
      "+---------------+-------+-------+\n",
      "|     Class     |  IoU  |  Acc  |\n",
      "+---------------+-------+-------+\n",
      "|       bg      | 97.38 | 98.31 |\n",
      "|    Anchovy    | 82.12 | 93.99 |\n",
      "|     Olives    | 86.06 | 88.18 |\n",
      "|     Salami    | 71.09 | 86.04 |\n",
      "|   Red_Pepper  | 87.44 | 96.07 |\n",
      "| Yellow_Pepper | 85.95 | 93.74 |\n",
      "+---------------+-------+-------+\n",
      "2024-02-14 15:50:20,722 - mmseg - INFO - Summary:\n",
      "2024-02-14 15:50:20,723 - mmseg - INFO - \n",
      "+-------+-------+-------+\n",
      "|  aAcc |  mIoU |  mAcc |\n",
      "+-------+-------+-------+\n",
      "| 97.47 | 85.01 | 92.72 |\n",
      "+-------+-------+-------+\n",
      "2024-02-14 15:50:20,723 - mmseg - INFO - Iter(val) [10]\taAcc: 0.9747, mIoU: 0.8501, mAcc: 0.9272, IoU.bg: 0.9738, IoU.Anchovy: 0.8212, IoU.Olives: 0.8606, IoU.Salami: 0.7109, IoU.Red_Pepper: 0.8744, IoU.Yellow_Pepper: 0.8595, Acc.bg: 0.9831, Acc.Anchovy: 0.9399, Acc.Olives: 0.8818, Acc.Salami: 0.8604, Acc.Red_Pepper: 0.9607, Acc.Yellow_Pepper: 0.9374\n",
      "2024-02-14 15:50:42,051 - mmseg - INFO - Iter [3610/80000]\tlr: 1.371e-06, eta: 2 days, 0:36:23, time: 2.776, data_time: 0.660, memory: 23505, decode.loss_cls: 0.0002, decode.loss_mask: 0.1846, decode.loss_dice: 0.3559, decode.d0.loss_cls: 1.8935, decode.d0.loss_mask: 0.1891, decode.d0.loss_dice: 0.3777, decode.d1.loss_cls: 0.0072, decode.d1.loss_mask: 0.1871, decode.d1.loss_dice: 0.3600, decode.d2.loss_cls: 0.0007, decode.d2.loss_mask: 0.1855, decode.d2.loss_dice: 0.3549, decode.d3.loss_cls: 0.0004, decode.d3.loss_mask: 0.1845, decode.d3.loss_dice: 0.3606, decode.d4.loss_cls: 0.0003, decode.d4.loss_mask: 0.1870, decode.d4.loss_dice: 0.3551, decode.d5.loss_cls: 0.0003, decode.d5.loss_mask: 0.1849, decode.d5.loss_dice: 0.3580, decode.d6.loss_cls: 0.0002, decode.d6.loss_mask: 0.1860, decode.d6.loss_dice: 0.3551, decode.d7.loss_cls: 0.0002, decode.d7.loss_mask: 0.1857, decode.d7.loss_dice: 0.3576, decode.d8.loss_cls: 0.0002, decode.d8.loss_mask: 0.1854, decode.d8.loss_dice: 0.3555, loss: 7.3532\n",
      "2024-02-14 15:51:03,367 - mmseg - INFO - Iter [3620/80000]\tlr: 1.371e-06, eta: 2 days, 0:35:27, time: 2.132, data_time: 0.018, memory: 23505, decode.loss_cls: 0.0003, decode.loss_mask: 0.1981, decode.loss_dice: 0.3643, decode.d0.loss_cls: 1.8875, decode.d0.loss_mask: 0.1998, decode.d0.loss_dice: 0.3931, decode.d1.loss_cls: 0.0085, decode.d1.loss_mask: 0.2017, decode.d1.loss_dice: 0.3666, decode.d2.loss_cls: 0.0010, decode.d2.loss_mask: 0.2011, decode.d2.loss_dice: 0.3701, decode.d3.loss_cls: 0.0009, decode.d3.loss_mask: 0.1978, decode.d3.loss_dice: 0.3693, decode.d4.loss_cls: 0.0007, decode.d4.loss_mask: 0.1988, decode.d4.loss_dice: 0.3644, decode.d5.loss_cls: 0.0006, decode.d5.loss_mask: 0.1986, decode.d5.loss_dice: 0.3685, decode.d6.loss_cls: 0.0005, decode.d6.loss_mask: 0.1961, decode.d6.loss_dice: 0.3637, decode.d7.loss_cls: 0.0004, decode.d7.loss_mask: 0.1956, decode.d7.loss_dice: 0.3597, decode.d8.loss_cls: 0.0003, decode.d8.loss_mask: 0.1976, decode.d8.loss_dice: 0.3625, loss: 7.5680\n",
      "2024-02-14 15:51:24,683 - mmseg - INFO - Iter [3630/80000]\tlr: 1.371e-06, eta: 2 days, 0:34:31, time: 2.131, data_time: 0.017, memory: 23505, decode.loss_cls: 0.0002, decode.loss_mask: 0.1945, decode.loss_dice: 0.3756, decode.d0.loss_cls: 1.8788, decode.d0.loss_mask: 0.1978, decode.d0.loss_dice: 0.3859, decode.d1.loss_cls: 0.0079, decode.d1.loss_mask: 0.1926, decode.d1.loss_dice: 0.3806, decode.d2.loss_cls: 0.0007, decode.d2.loss_mask: 0.1932, decode.d2.loss_dice: 0.3742, decode.d3.loss_cls: 0.0005, decode.d3.loss_mask: 0.1948, decode.d3.loss_dice: 0.3801, decode.d4.loss_cls: 0.0003, decode.d4.loss_mask: 0.1955, decode.d4.loss_dice: 0.3797, decode.d5.loss_cls: 0.0003, decode.d5.loss_mask: 0.1952, decode.d5.loss_dice: 0.3795, decode.d6.loss_cls: 0.0002, decode.d6.loss_mask: 0.1967, decode.d6.loss_dice: 0.3821, decode.d7.loss_cls: 0.0002, decode.d7.loss_mask: 0.1963, decode.d7.loss_dice: 0.3760, decode.d8.loss_cls: 0.0002, decode.d8.loss_mask: 0.1965, decode.d8.loss_dice: 0.3806, loss: 7.6367\n",
      "2024-02-14 15:51:46,008 - mmseg - INFO - Iter [3640/80000]\tlr: 1.370e-06, eta: 2 days, 0:33:35, time: 2.133, data_time: 0.018, memory: 23505, decode.loss_cls: 0.0003, decode.loss_mask: 0.2232, decode.loss_dice: 0.4037, decode.d0.loss_cls: 1.8738, decode.d0.loss_mask: 0.2270, decode.d0.loss_dice: 0.4225, decode.d1.loss_cls: 0.0064, decode.d1.loss_mask: 0.2233, decode.d1.loss_dice: 0.4092, decode.d2.loss_cls: 0.0007, decode.d2.loss_mask: 0.2220, decode.d2.loss_dice: 0.4075, decode.d3.loss_cls: 0.0006, decode.d3.loss_mask: 0.2243, decode.d3.loss_dice: 0.4078, decode.d4.loss_cls: 0.0003, decode.d4.loss_mask: 0.2233, decode.d4.loss_dice: 0.4053, decode.d5.loss_cls: 0.0003, decode.d5.loss_mask: 0.2238, decode.d5.loss_dice: 0.4034, decode.d6.loss_cls: 0.0003, decode.d6.loss_mask: 0.2238, decode.d6.loss_dice: 0.4049, decode.d7.loss_cls: 0.0003, decode.d7.loss_mask: 0.2241, decode.d7.loss_dice: 0.4067, decode.d8.loss_cls: 0.0003, decode.d8.loss_mask: 0.2241, decode.d8.loss_dice: 0.4110, loss: 8.2041\n",
      "2024-02-14 15:52:07,325 - mmseg - INFO - Iter [3650/80000]\tlr: 1.370e-06, eta: 2 days, 0:32:39, time: 2.132, data_time: 0.016, memory: 23505, decode.loss_cls: 0.0002, decode.loss_mask: 0.1584, decode.loss_dice: 0.3284, decode.d0.loss_cls: 1.8593, decode.d0.loss_mask: 0.1632, decode.d0.loss_dice: 0.3486, decode.d1.loss_cls: 0.0090, decode.d1.loss_mask: 0.1612, decode.d1.loss_dice: 0.3321, decode.d2.loss_cls: 0.0007, decode.d2.loss_mask: 0.1608, decode.d2.loss_dice: 0.3323, decode.d3.loss_cls: 0.0004, decode.d3.loss_mask: 0.1621, decode.d3.loss_dice: 0.3329, decode.d4.loss_cls: 0.0003, decode.d4.loss_mask: 0.1608, decode.d4.loss_dice: 0.3352, decode.d5.loss_cls: 0.0003, decode.d5.loss_mask: 0.1605, decode.d5.loss_dice: 0.3331, decode.d6.loss_cls: 0.0002, decode.d6.loss_mask: 0.1615, decode.d6.loss_dice: 0.3337, decode.d7.loss_cls: 0.0002, decode.d7.loss_mask: 0.1604, decode.d7.loss_dice: 0.3309, decode.d8.loss_cls: 0.0002, decode.d8.loss_mask: 0.1616, decode.d8.loss_dice: 0.3302, loss: 6.8189\n",
      "2024-02-14 15:52:28,655 - mmseg - INFO - Iter [3660/80000]\tlr: 1.370e-06, eta: 2 days, 0:31:43, time: 2.133, data_time: 0.018, memory: 23505, decode.loss_cls: 0.0002, decode.loss_mask: 0.1996, decode.loss_dice: 0.3522, decode.d0.loss_cls: 1.8639, decode.d0.loss_mask: 0.2047, decode.d0.loss_dice: 0.3812, decode.d1.loss_cls: 0.0050, decode.d1.loss_mask: 0.1992, decode.d1.loss_dice: 0.3494, decode.d2.loss_cls: 0.0007, decode.d2.loss_mask: 0.1973, decode.d2.loss_dice: 0.3471, decode.d3.loss_cls: 0.0006, decode.d3.loss_mask: 0.1961, decode.d3.loss_dice: 0.3434, decode.d4.loss_cls: 0.0003, decode.d4.loss_mask: 0.1948, decode.d4.loss_dice: 0.3525, decode.d5.loss_cls: 0.0003, decode.d5.loss_mask: 0.1981, decode.d5.loss_dice: 0.3567, decode.d6.loss_cls: 0.0003, decode.d6.loss_mask: 0.1967, decode.d6.loss_dice: 0.3512, decode.d7.loss_cls: 0.0002, decode.d7.loss_mask: 0.2015, decode.d7.loss_dice: 0.3529, decode.d8.loss_cls: 0.0002, decode.d8.loss_mask: 0.1965, decode.d8.loss_dice: 0.3531, loss: 7.3959\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-14 15:52:49,974 - mmseg - INFO - Iter [3670/80000]\tlr: 1.370e-06, eta: 2 days, 0:30:48, time: 2.132, data_time: 0.016, memory: 23505, decode.loss_cls: 0.0002, decode.loss_mask: 0.1699, decode.loss_dice: 0.3291, decode.d0.loss_cls: 1.8504, decode.d0.loss_mask: 0.1753, decode.d0.loss_dice: 0.3434, decode.d1.loss_cls: 0.0077, decode.d1.loss_mask: 0.1732, decode.d1.loss_dice: 0.3314, decode.d2.loss_cls: 0.0007, decode.d2.loss_mask: 0.1712, decode.d2.loss_dice: 0.3258, decode.d3.loss_cls: 0.0005, decode.d3.loss_mask: 0.1712, decode.d3.loss_dice: 0.3276, decode.d4.loss_cls: 0.0003, decode.d4.loss_mask: 0.1722, decode.d4.loss_dice: 0.3277, decode.d5.loss_cls: 0.0003, decode.d5.loss_mask: 0.1709, decode.d5.loss_dice: 0.3269, decode.d6.loss_cls: 0.0002, decode.d6.loss_mask: 0.1703, decode.d6.loss_dice: 0.3313, decode.d7.loss_cls: 0.0002, decode.d7.loss_mask: 0.1695, decode.d7.loss_dice: 0.3258, decode.d8.loss_cls: 0.0002, decode.d8.loss_mask: 0.1715, decode.d8.loss_dice: 0.3332, loss: 6.8783\n",
      "2024-02-14 15:53:11,286 - mmseg - INFO - Iter [3680/80000]\tlr: 1.370e-06, eta: 2 days, 0:29:53, time: 2.131, data_time: 0.017, memory: 23505, decode.loss_cls: 0.0002, decode.loss_mask: 0.1692, decode.loss_dice: 0.3312, decode.d0.loss_cls: 1.8435, decode.d0.loss_mask: 0.1751, decode.d0.loss_dice: 0.3487, decode.d1.loss_cls: 0.0073, decode.d1.loss_mask: 0.1685, decode.d1.loss_dice: 0.3324, decode.d2.loss_cls: 0.0007, decode.d2.loss_mask: 0.1704, decode.d2.loss_dice: 0.3319, decode.d3.loss_cls: 0.0005, decode.d3.loss_mask: 0.1712, decode.d3.loss_dice: 0.3359, decode.d4.loss_cls: 0.0003, decode.d4.loss_mask: 0.1705, decode.d4.loss_dice: 0.3331, decode.d5.loss_cls: 0.0003, decode.d5.loss_mask: 0.1696, decode.d5.loss_dice: 0.3339, decode.d6.loss_cls: 0.0002, decode.d6.loss_mask: 0.1673, decode.d6.loss_dice: 0.3318, decode.d7.loss_cls: 0.0002, decode.d7.loss_mask: 0.1674, decode.d7.loss_dice: 0.3266, decode.d8.loss_cls: 0.0002, decode.d8.loss_mask: 0.1702, decode.d8.loss_dice: 0.3346, loss: 6.8927\n",
      "2024-02-14 15:53:32,617 - mmseg - INFO - Iter [3690/80000]\tlr: 1.370e-06, eta: 2 days, 0:28:58, time: 2.133, data_time: 0.017, memory: 23505, decode.loss_cls: 0.0002, decode.loss_mask: 0.1849, decode.loss_dice: 0.3442, decode.d0.loss_cls: 1.8367, decode.d0.loss_mask: 0.1898, decode.d0.loss_dice: 0.3675, decode.d1.loss_cls: 0.0078, decode.d1.loss_mask: 0.1829, decode.d1.loss_dice: 0.3390, decode.d2.loss_cls: 0.0007, decode.d2.loss_mask: 0.1843, decode.d2.loss_dice: 0.3418, decode.d3.loss_cls: 0.0004, decode.d3.loss_mask: 0.1854, decode.d3.loss_dice: 0.3438, decode.d4.loss_cls: 0.0003, decode.d4.loss_mask: 0.1833, decode.d4.loss_dice: 0.3400, decode.d5.loss_cls: 0.0003, decode.d5.loss_mask: 0.1866, decode.d5.loss_dice: 0.3454, decode.d6.loss_cls: 0.0002, decode.d6.loss_mask: 0.1848, decode.d6.loss_dice: 0.3463, decode.d7.loss_cls: 0.0002, decode.d7.loss_mask: 0.1847, decode.d7.loss_dice: 0.3426, decode.d8.loss_cls: 0.0002, decode.d8.loss_mask: 0.1832, decode.d8.loss_dice: 0.3414, loss: 7.1487\n",
      "2024-02-14 15:53:53,935 - mmseg - INFO - Iter [3700/80000]\tlr: 1.369e-06, eta: 2 days, 0:28:03, time: 2.132, data_time: 0.017, memory: 23505, decode.loss_cls: 0.0002, decode.loss_mask: 0.1916, decode.loss_dice: 0.3551, decode.d0.loss_cls: 1.8334, decode.d0.loss_mask: 0.1967, decode.d0.loss_dice: 0.3706, decode.d1.loss_cls: 0.0065, decode.d1.loss_mask: 0.1925, decode.d1.loss_dice: 0.3549, decode.d2.loss_cls: 0.0006, decode.d2.loss_mask: 0.1898, decode.d2.loss_dice: 0.3525, decode.d3.loss_cls: 0.0004, decode.d3.loss_mask: 0.1908, decode.d3.loss_dice: 0.3557, decode.d4.loss_cls: 0.0003, decode.d4.loss_mask: 0.1898, decode.d4.loss_dice: 0.3507, decode.d5.loss_cls: 0.0003, decode.d5.loss_mask: 0.1915, decode.d5.loss_dice: 0.3576, decode.d6.loss_cls: 0.0002, decode.d6.loss_mask: 0.1904, decode.d6.loss_dice: 0.3552, decode.d7.loss_cls: 0.0002, decode.d7.loss_mask: 0.1919, decode.d7.loss_dice: 0.3548, decode.d8.loss_cls: 0.0002, decode.d8.loss_mask: 0.1925, decode.d8.loss_dice: 0.3520, loss: 7.3191\n",
      "2024-02-14 15:54:15,285 - mmseg - INFO - Iter [3710/80000]\tlr: 1.369e-06, eta: 2 days, 0:27:09, time: 2.135, data_time: 0.017, memory: 23505, decode.loss_cls: 0.0002, decode.loss_mask: 0.1973, decode.loss_dice: 0.3545, decode.d0.loss_cls: 1.8299, decode.d0.loss_mask: 0.1956, decode.d0.loss_dice: 0.3696, decode.d1.loss_cls: 0.0047, decode.d1.loss_mask: 0.1960, decode.d1.loss_dice: 0.3560, decode.d2.loss_cls: 0.0006, decode.d2.loss_mask: 0.1982, decode.d2.loss_dice: 0.3579, decode.d3.loss_cls: 0.0005, decode.d3.loss_mask: 0.1970, decode.d3.loss_dice: 0.3528, decode.d4.loss_cls: 0.0003, decode.d4.loss_mask: 0.1963, decode.d4.loss_dice: 0.3539, decode.d5.loss_cls: 0.0002, decode.d5.loss_mask: 0.1978, decode.d5.loss_dice: 0.3571, decode.d6.loss_cls: 0.0002, decode.d6.loss_mask: 0.1970, decode.d6.loss_dice: 0.3534, decode.d7.loss_cls: 0.0002, decode.d7.loss_mask: 0.1988, decode.d7.loss_dice: 0.3580, decode.d8.loss_cls: 0.0002, decode.d8.loss_mask: 0.1992, decode.d8.loss_dice: 0.3576, loss: 7.3810\n",
      "2024-02-14 15:54:36,619 - mmseg - INFO - Iter [3720/80000]\tlr: 1.369e-06, eta: 2 days, 0:26:15, time: 2.133, data_time: 0.017, memory: 23505, decode.loss_cls: 0.0002, decode.loss_mask: 0.1696, decode.loss_dice: 0.3327, decode.d0.loss_cls: 1.8135, decode.d0.loss_mask: 0.1702, decode.d0.loss_dice: 0.3448, decode.d1.loss_cls: 0.0091, decode.d1.loss_mask: 0.1703, decode.d1.loss_dice: 0.3358, decode.d2.loss_cls: 0.0006, decode.d2.loss_mask: 0.1682, decode.d2.loss_dice: 0.3296, decode.d3.loss_cls: 0.0004, decode.d3.loss_mask: 0.1697, decode.d3.loss_dice: 0.3317, decode.d4.loss_cls: 0.0002, decode.d4.loss_mask: 0.1721, decode.d4.loss_dice: 0.3367, decode.d5.loss_cls: 0.0003, decode.d5.loss_mask: 0.1705, decode.d5.loss_dice: 0.3332, decode.d6.loss_cls: 0.0002, decode.d6.loss_mask: 0.1692, decode.d6.loss_dice: 0.3316, decode.d7.loss_cls: 0.0002, decode.d7.loss_mask: 0.1697, decode.d7.loss_dice: 0.3361, decode.d8.loss_cls: 0.0002, decode.d8.loss_mask: 0.1673, decode.d8.loss_dice: 0.3303, loss: 6.8641\n",
      "2024-02-14 15:54:57,927 - mmseg - INFO - Iter [3730/80000]\tlr: 1.369e-06, eta: 2 days, 0:25:20, time: 2.131, data_time: 0.017, memory: 23505, decode.loss_cls: 0.0002, decode.loss_mask: 0.1825, decode.loss_dice: 0.3509, decode.d0.loss_cls: 1.8113, decode.d0.loss_mask: 0.1812, decode.d0.loss_dice: 0.3680, decode.d1.loss_cls: 0.0061, decode.d1.loss_mask: 0.1838, decode.d1.loss_dice: 0.3576, decode.d2.loss_cls: 0.0055, decode.d2.loss_mask: 0.1824, decode.d2.loss_dice: 0.3519, decode.d3.loss_cls: 0.0009, decode.d3.loss_mask: 0.1841, decode.d3.loss_dice: 0.3535, decode.d4.loss_cls: 0.0003, decode.d4.loss_mask: 0.1813, decode.d4.loss_dice: 0.3570, decode.d5.loss_cls: 0.0003, decode.d5.loss_mask: 0.1814, decode.d5.loss_dice: 0.3548, decode.d6.loss_cls: 0.0002, decode.d6.loss_mask: 0.1823, decode.d6.loss_dice: 0.3584, decode.d7.loss_cls: 0.0002, decode.d7.loss_mask: 0.1822, decode.d7.loss_dice: 0.3554, decode.d8.loss_cls: 0.0002, decode.d8.loss_mask: 0.1826, decode.d8.loss_dice: 0.3597, loss: 7.2161\n",
      "2024-02-14 15:55:19,253 - mmseg - INFO - Iter [3740/80000]\tlr: 1.369e-06, eta: 2 days, 0:24:26, time: 2.133, data_time: 0.017, memory: 23505, decode.loss_cls: 0.0002, decode.loss_mask: 0.1797, decode.loss_dice: 0.3267, decode.d0.loss_cls: 1.8068, decode.d0.loss_mask: 0.1819, decode.d0.loss_dice: 0.3481, decode.d1.loss_cls: 0.0057, decode.d1.loss_mask: 0.1825, decode.d1.loss_dice: 0.3305, decode.d2.loss_cls: 0.0009, decode.d2.loss_mask: 0.1833, decode.d2.loss_dice: 0.3289, decode.d3.loss_cls: 0.0005, decode.d3.loss_mask: 0.1794, decode.d3.loss_dice: 0.3281, decode.d4.loss_cls: 0.0003, decode.d4.loss_mask: 0.1832, decode.d4.loss_dice: 0.3311, decode.d5.loss_cls: 0.0003, decode.d5.loss_mask: 0.1812, decode.d5.loss_dice: 0.3284, decode.d6.loss_cls: 0.0002, decode.d6.loss_mask: 0.1823, decode.d6.loss_dice: 0.3287, decode.d7.loss_cls: 0.0002, decode.d7.loss_mask: 0.1821, decode.d7.loss_dice: 0.3304, decode.d8.loss_cls: 0.0002, decode.d8.loss_mask: 0.1813, decode.d8.loss_dice: 0.3294, loss: 6.9424\n",
      "2024-02-14 15:55:40,556 - mmseg - INFO - Iter [3750/80000]\tlr: 1.369e-06, eta: 2 days, 0:23:32, time: 2.130, data_time: 0.016, memory: 23505, decode.loss_cls: 0.0001, decode.loss_mask: 0.1633, decode.loss_dice: 0.3325, decode.d0.loss_cls: 1.7924, decode.d0.loss_mask: 0.1652, decode.d0.loss_dice: 0.3529, decode.d1.loss_cls: 0.0081, decode.d1.loss_mask: 0.1654, decode.d1.loss_dice: 0.3349, decode.d2.loss_cls: 0.0013, decode.d2.loss_mask: 0.1657, decode.d2.loss_dice: 0.3326, decode.d3.loss_cls: 0.0005, decode.d3.loss_mask: 0.1664, decode.d3.loss_dice: 0.3379, decode.d4.loss_cls: 0.0002, decode.d4.loss_mask: 0.1660, decode.d4.loss_dice: 0.3358, decode.d5.loss_cls: 0.0002, decode.d5.loss_mask: 0.1622, decode.d5.loss_dice: 0.3260, decode.d6.loss_cls: 0.0002, decode.d6.loss_mask: 0.1672, decode.d6.loss_dice: 0.3363, decode.d7.loss_cls: 0.0002, decode.d7.loss_mask: 0.1648, decode.d7.loss_dice: 0.3377, decode.d8.loss_cls: 0.0002, decode.d8.loss_mask: 0.1627, decode.d8.loss_dice: 0.3376, loss: 6.8165\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-14 15:56:01,873 - mmseg - INFO - Iter [3760/80000]\tlr: 1.368e-06, eta: 2 days, 0:22:38, time: 2.132, data_time: 0.017, memory: 23505, decode.loss_cls: 0.0002, decode.loss_mask: 0.1785, decode.loss_dice: 0.3355, decode.d0.loss_cls: 1.7905, decode.d0.loss_mask: 0.1764, decode.d0.loss_dice: 0.3550, decode.d1.loss_cls: 0.0061, decode.d1.loss_mask: 0.1768, decode.d1.loss_dice: 0.3272, decode.d2.loss_cls: 0.0009, decode.d2.loss_mask: 0.1793, decode.d2.loss_dice: 0.3337, decode.d3.loss_cls: 0.0005, decode.d3.loss_mask: 0.1774, decode.d3.loss_dice: 0.3363, decode.d4.loss_cls: 0.0003, decode.d4.loss_mask: 0.1786, decode.d4.loss_dice: 0.3343, decode.d5.loss_cls: 0.0003, decode.d5.loss_mask: 0.1800, decode.d5.loss_dice: 0.3383, decode.d6.loss_cls: 0.0002, decode.d6.loss_mask: 0.1784, decode.d6.loss_dice: 0.3314, decode.d7.loss_cls: 0.0002, decode.d7.loss_mask: 0.1792, decode.d7.loss_dice: 0.3346, decode.d8.loss_cls: 0.0002, decode.d8.loss_mask: 0.1771, decode.d8.loss_dice: 0.3293, loss: 6.9368\n",
      "2024-02-14 15:56:23,231 - mmseg - INFO - Iter [3770/80000]\tlr: 1.368e-06, eta: 2 days, 0:21:45, time: 2.136, data_time: 0.017, memory: 23505, decode.loss_cls: 0.0002, decode.loss_mask: 0.1888, decode.loss_dice: 0.3466, decode.d0.loss_cls: 1.7858, decode.d0.loss_mask: 0.1916, decode.d0.loss_dice: 0.3670, decode.d1.loss_cls: 0.0056, decode.d1.loss_mask: 0.1882, decode.d1.loss_dice: 0.3459, decode.d2.loss_cls: 0.0007, decode.d2.loss_mask: 0.1878, decode.d2.loss_dice: 0.3441, decode.d3.loss_cls: 0.0005, decode.d3.loss_mask: 0.1880, decode.d3.loss_dice: 0.3480, decode.d4.loss_cls: 0.0003, decode.d4.loss_mask: 0.1884, decode.d4.loss_dice: 0.3507, decode.d5.loss_cls: 0.0003, decode.d5.loss_mask: 0.1866, decode.d5.loss_dice: 0.3433, decode.d6.loss_cls: 0.0002, decode.d6.loss_mask: 0.1866, decode.d6.loss_dice: 0.3460, decode.d7.loss_cls: 0.0002, decode.d7.loss_mask: 0.1890, decode.d7.loss_dice: 0.3432, decode.d8.loss_cls: 0.0002, decode.d8.loss_mask: 0.1893, decode.d8.loss_dice: 0.3452, loss: 7.1584\n",
      "2024-02-14 15:56:44,541 - mmseg - INFO - Iter [3780/80000]\tlr: 1.368e-06, eta: 2 days, 0:20:51, time: 2.131, data_time: 0.017, memory: 23505, decode.loss_cls: 0.0002, decode.loss_mask: 0.1997, decode.loss_dice: 0.3692, decode.d0.loss_cls: 1.7782, decode.d0.loss_mask: 0.2057, decode.d0.loss_dice: 0.3886, decode.d1.loss_cls: 0.0054, decode.d1.loss_mask: 0.1978, decode.d1.loss_dice: 0.3708, decode.d2.loss_cls: 0.0006, decode.d2.loss_mask: 0.1984, decode.d2.loss_dice: 0.3720, decode.d3.loss_cls: 0.0005, decode.d3.loss_mask: 0.1990, decode.d3.loss_dice: 0.3715, decode.d4.loss_cls: 0.0002, decode.d4.loss_mask: 0.2000, decode.d4.loss_dice: 0.3709, decode.d5.loss_cls: 0.0002, decode.d5.loss_mask: 0.1981, decode.d5.loss_dice: 0.3729, decode.d6.loss_cls: 0.0002, decode.d6.loss_mask: 0.1993, decode.d6.loss_dice: 0.3692, decode.d7.loss_cls: 0.0002, decode.d7.loss_mask: 0.2007, decode.d7.loss_dice: 0.3722, decode.d8.loss_cls: 0.0002, decode.d8.loss_mask: 0.2009, decode.d8.loss_dice: 0.3682, loss: 7.5109\n",
      "2024-02-14 15:57:05,879 - mmseg - INFO - Iter [3790/80000]\tlr: 1.368e-06, eta: 2 days, 0:19:58, time: 2.134, data_time: 0.016, memory: 23505, decode.loss_cls: 0.0002, decode.loss_mask: 0.1801, decode.loss_dice: 0.3399, decode.d0.loss_cls: 1.7736, decode.d0.loss_mask: 0.1824, decode.d0.loss_dice: 0.3575, decode.d1.loss_cls: 0.0062, decode.d1.loss_mask: 0.1801, decode.d1.loss_dice: 0.3389, decode.d2.loss_cls: 0.0006, decode.d2.loss_mask: 0.1789, decode.d2.loss_dice: 0.3350, decode.d3.loss_cls: 0.0005, decode.d3.loss_mask: 0.1803, decode.d3.loss_dice: 0.3364, decode.d4.loss_cls: 0.0003, decode.d4.loss_mask: 0.1801, decode.d4.loss_dice: 0.3407, decode.d5.loss_cls: 0.0003, decode.d5.loss_mask: 0.1786, decode.d5.loss_dice: 0.3339, decode.d6.loss_cls: 0.0002, decode.d6.loss_mask: 0.1787, decode.d6.loss_dice: 0.3346, decode.d7.loss_cls: 0.0002, decode.d7.loss_mask: 0.1772, decode.d7.loss_dice: 0.3356, decode.d8.loss_cls: 0.0002, decode.d8.loss_mask: 0.1775, decode.d8.loss_dice: 0.3383, loss: 6.9670\n",
      "2024-02-14 15:57:27,209 - mmseg - INFO - Iter [3800/80000]\tlr: 1.368e-06, eta: 2 days, 0:19:05, time: 2.133, data_time: 0.016, memory: 23505, decode.loss_cls: 0.0002, decode.loss_mask: 0.1746, decode.loss_dice: 0.3389, decode.d0.loss_cls: 1.7600, decode.d0.loss_mask: 0.1814, decode.d0.loss_dice: 0.3587, decode.d1.loss_cls: 0.0076, decode.d1.loss_mask: 0.1782, decode.d1.loss_dice: 0.3476, decode.d2.loss_cls: 0.0006, decode.d2.loss_mask: 0.1780, decode.d2.loss_dice: 0.3454, decode.d3.loss_cls: 0.0004, decode.d3.loss_mask: 0.1765, decode.d3.loss_dice: 0.3463, decode.d4.loss_cls: 0.0003, decode.d4.loss_mask: 0.1767, decode.d4.loss_dice: 0.3496, decode.d5.loss_cls: 0.0003, decode.d5.loss_mask: 0.1761, decode.d5.loss_dice: 0.3467, decode.d6.loss_cls: 0.0002, decode.d6.loss_mask: 0.1753, decode.d6.loss_dice: 0.3457, decode.d7.loss_cls: 0.0002, decode.d7.loss_mask: 0.1752, decode.d7.loss_dice: 0.3453, decode.d8.loss_cls: 0.0002, decode.d8.loss_mask: 0.1763, decode.d8.loss_dice: 0.3528, loss: 7.0153\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 40/40, 6.2 task/s, elapsed: 6s, ETA:     0s\n",
      "\n",
      "2024-02-14 15:57:33,654 - mmseg - INFO - per class results:\n",
      "2024-02-14 15:57:33,655 - mmseg - INFO - \n",
      "+---------------+-------+-------+\n",
      "|     Class     |  IoU  |  Acc  |\n",
      "+---------------+-------+-------+\n",
      "|       bg      | 97.44 | 98.26 |\n",
      "|    Anchovy    | 82.56 | 93.79 |\n",
      "|     Olives    | 86.77 | 89.31 |\n",
      "|     Salami    | 71.44 | 87.15 |\n",
      "|   Red_Pepper  | 87.86 | 96.58 |\n",
      "| Yellow_Pepper | 86.16 | 94.36 |\n",
      "+---------------+-------+-------+\n",
      "2024-02-14 15:57:33,655 - mmseg - INFO - Summary:\n",
      "2024-02-14 15:57:33,655 - mmseg - INFO - \n",
      "+-------+-------+-------+\n",
      "|  aAcc |  mIoU |  mAcc |\n",
      "+-------+-------+-------+\n",
      "| 97.53 | 85.37 | 93.24 |\n",
      "+-------+-------+-------+\n",
      "2024-02-14 15:57:33,655 - mmseg - INFO - Iter(val) [10]\taAcc: 0.9753, mIoU: 0.8537, mAcc: 0.9324, IoU.bg: 0.9744, IoU.Anchovy: 0.8256, IoU.Olives: 0.8677, IoU.Salami: 0.7144, IoU.Red_Pepper: 0.8786, IoU.Yellow_Pepper: 0.8616, Acc.bg: 0.9826, Acc.Anchovy: 0.9379, Acc.Olives: 0.8931, Acc.Salami: 0.8715, Acc.Red_Pepper: 0.9658, Acc.Yellow_Pepper: 0.9436\n",
      "2024-02-14 15:57:54,986 - mmseg - INFO - Iter [3810/80000]\tlr: 1.367e-06, eta: 2 days, 0:20:21, time: 2.778, data_time: 0.661, memory: 23505, decode.loss_cls: 0.0002, decode.loss_mask: 0.1828, decode.loss_dice: 0.3432, decode.d0.loss_cls: 1.7564, decode.d0.loss_mask: 0.1831, decode.d0.loss_dice: 0.3470, decode.d1.loss_cls: 0.0062, decode.d1.loss_mask: 0.1815, decode.d1.loss_dice: 0.3430, decode.d2.loss_cls: 0.0005, decode.d2.loss_mask: 0.1818, decode.d2.loss_dice: 0.3454, decode.d3.loss_cls: 0.0004, decode.d3.loss_mask: 0.1807, decode.d3.loss_dice: 0.3455, decode.d4.loss_cls: 0.0003, decode.d4.loss_mask: 0.1810, decode.d4.loss_dice: 0.3460, decode.d5.loss_cls: 0.0002, decode.d5.loss_mask: 0.1802, decode.d5.loss_dice: 0.3387, decode.d6.loss_cls: 0.0002, decode.d6.loss_mask: 0.1816, decode.d6.loss_dice: 0.3429, decode.d7.loss_cls: 0.0002, decode.d7.loss_mask: 0.1813, decode.d7.loss_dice: 0.3440, decode.d8.loss_cls: 0.0002, decode.d8.loss_mask: 0.1807, decode.d8.loss_dice: 0.3431, loss: 7.0183\n",
      "2024-02-14 15:58:16,307 - mmseg - INFO - Iter [3820/80000]\tlr: 1.367e-06, eta: 2 days, 0:19:28, time: 2.132, data_time: 0.017, memory: 23505, decode.loss_cls: 0.0002, decode.loss_mask: 0.1837, decode.loss_dice: 0.3431, decode.d0.loss_cls: 1.7518, decode.d0.loss_mask: 0.1896, decode.d0.loss_dice: 0.3681, decode.d1.loss_cls: 0.0060, decode.d1.loss_mask: 0.1817, decode.d1.loss_dice: 0.3485, decode.d2.loss_cls: 0.0006, decode.d2.loss_mask: 0.1829, decode.d2.loss_dice: 0.3419, decode.d3.loss_cls: 0.0006, decode.d3.loss_mask: 0.1849, decode.d3.loss_dice: 0.3448, decode.d4.loss_cls: 0.0003, decode.d4.loss_mask: 0.1819, decode.d4.loss_dice: 0.3416, decode.d5.loss_cls: 0.0003, decode.d5.loss_mask: 0.1845, decode.d5.loss_dice: 0.3429, decode.d6.loss_cls: 0.0002, decode.d6.loss_mask: 0.1829, decode.d6.loss_dice: 0.3399, decode.d7.loss_cls: 0.0002, decode.d7.loss_mask: 0.1855, decode.d7.loss_dice: 0.3461, decode.d8.loss_cls: 0.0002, decode.d8.loss_mask: 0.1847, decode.d8.loss_dice: 0.3444, loss: 7.0638\n",
      "2024-02-14 15:58:37,617 - mmseg - INFO - Iter [3830/80000]\tlr: 1.367e-06, eta: 2 days, 0:18:35, time: 2.131, data_time: 0.016, memory: 23505, decode.loss_cls: 0.0002, decode.loss_mask: 0.1837, decode.loss_dice: 0.3483, decode.d0.loss_cls: 1.7422, decode.d0.loss_mask: 0.1797, decode.d0.loss_dice: 0.3664, decode.d1.loss_cls: 0.0071, decode.d1.loss_mask: 0.1812, decode.d1.loss_dice: 0.3434, decode.d2.loss_cls: 0.0005, decode.d2.loss_mask: 0.1808, decode.d2.loss_dice: 0.3461, decode.d3.loss_cls: 0.0006, decode.d3.loss_mask: 0.1785, decode.d3.loss_dice: 0.3440, decode.d4.loss_cls: 0.0003, decode.d4.loss_mask: 0.1811, decode.d4.loss_dice: 0.3455, decode.d5.loss_cls: 0.0003, decode.d5.loss_mask: 0.1797, decode.d5.loss_dice: 0.3457, decode.d6.loss_cls: 0.0002, decode.d6.loss_mask: 0.1816, decode.d6.loss_dice: 0.3473, decode.d7.loss_cls: 0.0002, decode.d7.loss_mask: 0.1817, decode.d7.loss_dice: 0.3490, decode.d8.loss_cls: 0.0002, decode.d8.loss_mask: 0.1809, decode.d8.loss_dice: 0.3443, loss: 7.0405\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-14 15:58:58,936 - mmseg - INFO - Iter [3840/80000]\tlr: 1.367e-06, eta: 2 days, 0:17:42, time: 2.132, data_time: 0.017, memory: 23505, decode.loss_cls: 0.0002, decode.loss_mask: 0.2287, decode.loss_dice: 0.3999, decode.d0.loss_cls: 1.7457, decode.d0.loss_mask: 0.2315, decode.d0.loss_dice: 0.4112, decode.d1.loss_cls: 0.0037, decode.d1.loss_mask: 0.2260, decode.d1.loss_dice: 0.3930, decode.d2.loss_cls: 0.0006, decode.d2.loss_mask: 0.2295, decode.d2.loss_dice: 0.3985, decode.d3.loss_cls: 0.0006, decode.d3.loss_mask: 0.2267, decode.d3.loss_dice: 0.3955, decode.d4.loss_cls: 0.0003, decode.d4.loss_mask: 0.2260, decode.d4.loss_dice: 0.3993, decode.d5.loss_cls: 0.0003, decode.d5.loss_mask: 0.2241, decode.d5.loss_dice: 0.3939, decode.d6.loss_cls: 0.0002, decode.d6.loss_mask: 0.2272, decode.d6.loss_dice: 0.3935, decode.d7.loss_cls: 0.0002, decode.d7.loss_mask: 0.2235, decode.d7.loss_dice: 0.3963, decode.d8.loss_cls: 0.0002, decode.d8.loss_mask: 0.2258, decode.d8.loss_dice: 0.3941, loss: 7.9960\n",
      "2024-02-14 15:59:22,303 - mmseg - INFO - Iter [3850/80000]\tlr: 1.367e-06, eta: 2 days, 0:17:30, time: 2.337, data_time: 0.224, memory: 23505, decode.loss_cls: 0.0002, decode.loss_mask: 0.1593, decode.loss_dice: 0.3187, decode.d0.loss_cls: 1.7291, decode.d0.loss_mask: 0.1631, decode.d0.loss_dice: 0.3406, decode.d1.loss_cls: 0.0071, decode.d1.loss_mask: 0.1617, decode.d1.loss_dice: 0.3175, decode.d2.loss_cls: 0.0007, decode.d2.loss_mask: 0.1602, decode.d2.loss_dice: 0.3144, decode.d3.loss_cls: 0.0005, decode.d3.loss_mask: 0.1593, decode.d3.loss_dice: 0.3138, decode.d4.loss_cls: 0.0004, decode.d4.loss_mask: 0.1577, decode.d4.loss_dice: 0.3098, decode.d5.loss_cls: 0.0003, decode.d5.loss_mask: 0.1603, decode.d5.loss_dice: 0.3160, decode.d6.loss_cls: 0.0002, decode.d6.loss_mask: 0.1612, decode.d6.loss_dice: 0.3169, decode.d7.loss_cls: 0.0002, decode.d7.loss_mask: 0.1577, decode.d7.loss_dice: 0.3141, decode.d8.loss_cls: 0.0002, decode.d8.loss_mask: 0.1616, decode.d8.loss_dice: 0.3196, loss: 6.5225\n",
      "2024-02-14 15:59:43,603 - mmseg - INFO - Iter [3860/80000]\tlr: 1.367e-06, eta: 2 days, 0:16:37, time: 2.130, data_time: 0.017, memory: 23505, decode.loss_cls: 0.0002, decode.loss_mask: 0.1955, decode.loss_dice: 0.3457, decode.d0.loss_cls: 1.7276, decode.d0.loss_mask: 0.1996, decode.d0.loss_dice: 0.3697, decode.d1.loss_cls: 0.0048, decode.d1.loss_mask: 0.1952, decode.d1.loss_dice: 0.3474, decode.d2.loss_cls: 0.0006, decode.d2.loss_mask: 0.1977, decode.d2.loss_dice: 0.3482, decode.d3.loss_cls: 0.0005, decode.d3.loss_mask: 0.1976, decode.d3.loss_dice: 0.3464, decode.d4.loss_cls: 0.0003, decode.d4.loss_mask: 0.1966, decode.d4.loss_dice: 0.3453, decode.d5.loss_cls: 0.0003, decode.d5.loss_mask: 0.1955, decode.d5.loss_dice: 0.3477, decode.d6.loss_cls: 0.0002, decode.d6.loss_mask: 0.1965, decode.d6.loss_dice: 0.3499, decode.d7.loss_cls: 0.0002, decode.d7.loss_mask: 0.1967, decode.d7.loss_dice: 0.3503, decode.d8.loss_cls: 0.0002, decode.d8.loss_mask: 0.1963, decode.d8.loss_dice: 0.3486, loss: 7.2012\n",
      "2024-02-14 16:00:04,923 - mmseg - INFO - Iter [3870/80000]\tlr: 1.366e-06, eta: 2 days, 0:15:45, time: 2.132, data_time: 0.017, memory: 23505, decode.loss_cls: 0.0002, decode.loss_mask: 0.1861, decode.loss_dice: 0.3507, decode.d0.loss_cls: 1.7201, decode.d0.loss_mask: 0.1870, decode.d0.loss_dice: 0.3655, decode.d1.loss_cls: 0.0049, decode.d1.loss_mask: 0.1861, decode.d1.loss_dice: 0.3463, decode.d2.loss_cls: 0.0006, decode.d2.loss_mask: 0.1846, decode.d2.loss_dice: 0.3473, decode.d3.loss_cls: 0.0005, decode.d3.loss_mask: 0.1835, decode.d3.loss_dice: 0.3501, decode.d4.loss_cls: 0.0003, decode.d4.loss_mask: 0.1844, decode.d4.loss_dice: 0.3455, decode.d5.loss_cls: 0.0002, decode.d5.loss_mask: 0.1849, decode.d5.loss_dice: 0.3514, decode.d6.loss_cls: 0.0002, decode.d6.loss_mask: 0.1853, decode.d6.loss_dice: 0.3480, decode.d7.loss_cls: 0.0002, decode.d7.loss_mask: 0.1848, decode.d7.loss_dice: 0.3523, decode.d8.loss_cls: 0.0002, decode.d8.loss_mask: 0.1870, decode.d8.loss_dice: 0.3510, loss: 7.0892\n",
      "2024-02-14 16:00:26,246 - mmseg - INFO - Iter [3880/80000]\tlr: 1.366e-06, eta: 2 days, 0:14:52, time: 2.132, data_time: 0.017, memory: 23505, decode.loss_cls: 0.0002, decode.loss_mask: 0.1675, decode.loss_dice: 0.3198, decode.d0.loss_cls: 1.7127, decode.d0.loss_mask: 0.1721, decode.d0.loss_dice: 0.3453, decode.d1.loss_cls: 0.0047, decode.d1.loss_mask: 0.1678, decode.d1.loss_dice: 0.3194, decode.d2.loss_cls: 0.0005, decode.d2.loss_mask: 0.1697, decode.d2.loss_dice: 0.3207, decode.d3.loss_cls: 0.0005, decode.d3.loss_mask: 0.1681, decode.d3.loss_dice: 0.3209, decode.d4.loss_cls: 0.0003, decode.d4.loss_mask: 0.1678, decode.d4.loss_dice: 0.3224, decode.d5.loss_cls: 0.0003, decode.d5.loss_mask: 0.1686, decode.d5.loss_dice: 0.3197, decode.d6.loss_cls: 0.0002, decode.d6.loss_mask: 0.1672, decode.d6.loss_dice: 0.3181, decode.d7.loss_cls: 0.0002, decode.d7.loss_mask: 0.1674, decode.d7.loss_dice: 0.3171, decode.d8.loss_cls: 0.0002, decode.d8.loss_mask: 0.1685, decode.d8.loss_dice: 0.3215, loss: 6.6294\n",
      "2024-02-14 16:00:47,543 - mmseg - INFO - Iter [3890/80000]\tlr: 1.366e-06, eta: 2 days, 0:14:00, time: 2.130, data_time: 0.016, memory: 23505, decode.loss_cls: 0.0002, decode.loss_mask: 0.1797, decode.loss_dice: 0.3530, decode.d0.loss_cls: 1.7091, decode.d0.loss_mask: 0.1849, decode.d0.loss_dice: 0.3761, decode.d1.loss_cls: 0.0049, decode.d1.loss_mask: 0.1826, decode.d1.loss_dice: 0.3558, decode.d2.loss_cls: 0.0005, decode.d2.loss_mask: 0.1842, decode.d2.loss_dice: 0.3596, decode.d3.loss_cls: 0.0004, decode.d3.loss_mask: 0.1827, decode.d3.loss_dice: 0.3499, decode.d4.loss_cls: 0.0003, decode.d4.loss_mask: 0.1805, decode.d4.loss_dice: 0.3503, decode.d5.loss_cls: 0.0002, decode.d5.loss_mask: 0.1821, decode.d5.loss_dice: 0.3567, decode.d6.loss_cls: 0.0002, decode.d6.loss_mask: 0.1805, decode.d6.loss_dice: 0.3515, decode.d7.loss_cls: 0.0002, decode.d7.loss_mask: 0.1800, decode.d7.loss_dice: 0.3551, decode.d8.loss_cls: 0.0002, decode.d8.loss_mask: 0.1797, decode.d8.loss_dice: 0.3573, loss: 7.0985\n",
      "2024-02-14 16:01:08,839 - mmseg - INFO - Iter [3900/80000]\tlr: 1.366e-06, eta: 2 days, 0:13:07, time: 2.130, data_time: 0.017, memory: 23505, decode.loss_cls: 0.0002, decode.loss_mask: 0.1870, decode.loss_dice: 0.3372, decode.d0.loss_cls: 1.7027, decode.d0.loss_mask: 0.1896, decode.d0.loss_dice: 0.3636, decode.d1.loss_cls: 0.0037, decode.d1.loss_mask: 0.1873, decode.d1.loss_dice: 0.3436, decode.d2.loss_cls: 0.0005, decode.d2.loss_mask: 0.1868, decode.d2.loss_dice: 0.3434, decode.d3.loss_cls: 0.0004, decode.d3.loss_mask: 0.1875, decode.d3.loss_dice: 0.3345, decode.d4.loss_cls: 0.0003, decode.d4.loss_mask: 0.1870, decode.d4.loss_dice: 0.3385, decode.d5.loss_cls: 0.0002, decode.d5.loss_mask: 0.1874, decode.d5.loss_dice: 0.3363, decode.d6.loss_cls: 0.0002, decode.d6.loss_mask: 0.1898, decode.d6.loss_dice: 0.3437, decode.d7.loss_cls: 0.0002, decode.d7.loss_mask: 0.1862, decode.d7.loss_dice: 0.3335, decode.d8.loss_cls: 0.0002, decode.d8.loss_mask: 0.1885, decode.d8.loss_dice: 0.3385, loss: 6.9986\n",
      "2024-02-14 16:01:30,171 - mmseg - INFO - Iter [3910/80000]\tlr: 1.366e-06, eta: 2 days, 0:12:16, time: 2.133, data_time: 0.016, memory: 23505, decode.loss_cls: 0.0002, decode.loss_mask: 0.1788, decode.loss_dice: 0.3312, decode.d0.loss_cls: 1.6934, decode.d0.loss_mask: 0.1823, decode.d0.loss_dice: 0.3489, decode.d1.loss_cls: 0.0059, decode.d1.loss_mask: 0.1811, decode.d1.loss_dice: 0.3349, decode.d2.loss_cls: 0.0006, decode.d2.loss_mask: 0.1783, decode.d2.loss_dice: 0.3312, decode.d3.loss_cls: 0.0004, decode.d3.loss_mask: 0.1778, decode.d3.loss_dice: 0.3323, decode.d4.loss_cls: 0.0003, decode.d4.loss_mask: 0.1796, decode.d4.loss_dice: 0.3366, decode.d5.loss_cls: 0.0002, decode.d5.loss_mask: 0.1790, decode.d5.loss_dice: 0.3364, decode.d6.loss_cls: 0.0002, decode.d6.loss_mask: 0.1761, decode.d6.loss_dice: 0.3347, decode.d7.loss_cls: 0.0002, decode.d7.loss_mask: 0.1761, decode.d7.loss_dice: 0.3328, decode.d8.loss_cls: 0.0002, decode.d8.loss_mask: 0.1784, decode.d8.loss_dice: 0.3359, loss: 6.8438\n",
      "2024-02-14 16:01:51,467 - mmseg - INFO - Iter [3920/80000]\tlr: 1.365e-06, eta: 2 days, 0:11:24, time: 2.130, data_time: 0.017, memory: 23505, decode.loss_cls: 0.0001, decode.loss_mask: 0.1459, decode.loss_dice: 0.2997, decode.d0.loss_cls: 1.6790, decode.d0.loss_mask: 0.1483, decode.d0.loss_dice: 0.3230, decode.d1.loss_cls: 0.0070, decode.d1.loss_mask: 0.1457, decode.d1.loss_dice: 0.3062, decode.d2.loss_cls: 0.0006, decode.d2.loss_mask: 0.1452, decode.d2.loss_dice: 0.3040, decode.d3.loss_cls: 0.0003, decode.d3.loss_mask: 0.1463, decode.d3.loss_dice: 0.3062, decode.d4.loss_cls: 0.0002, decode.d4.loss_mask: 0.1446, decode.d4.loss_dice: 0.3056, decode.d5.loss_cls: 0.0002, decode.d5.loss_mask: 0.1444, decode.d5.loss_dice: 0.3006, decode.d6.loss_cls: 0.0002, decode.d6.loss_mask: 0.1444, decode.d6.loss_dice: 0.2998, decode.d7.loss_cls: 0.0002, decode.d7.loss_mask: 0.1452, decode.d7.loss_dice: 0.3006, decode.d8.loss_cls: 0.0002, decode.d8.loss_mask: 0.1460, decode.d8.loss_dice: 0.3011, loss: 6.1909\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-14 16:02:12,784 - mmseg - INFO - Iter [3930/80000]\tlr: 1.365e-06, eta: 2 days, 0:10:32, time: 2.132, data_time: 0.017, memory: 23505, decode.loss_cls: 0.0002, decode.loss_mask: 0.1968, decode.loss_dice: 0.3541, decode.d0.loss_cls: 1.6835, decode.d0.loss_mask: 0.1987, decode.d0.loss_dice: 0.3675, decode.d1.loss_cls: 0.0044, decode.d1.loss_mask: 0.1972, decode.d1.loss_dice: 0.3525, decode.d2.loss_cls: 0.0005, decode.d2.loss_mask: 0.1967, decode.d2.loss_dice: 0.3584, decode.d3.loss_cls: 0.0004, decode.d3.loss_mask: 0.1986, decode.d3.loss_dice: 0.3553, decode.d4.loss_cls: 0.0003, decode.d4.loss_mask: 0.1991, decode.d4.loss_dice: 0.3502, decode.d5.loss_cls: 0.0002, decode.d5.loss_mask: 0.1961, decode.d5.loss_dice: 0.3567, decode.d6.loss_cls: 0.0002, decode.d6.loss_mask: 0.1999, decode.d6.loss_dice: 0.3567, decode.d7.loss_cls: 0.0002, decode.d7.loss_mask: 0.1987, decode.d7.loss_dice: 0.3523, decode.d8.loss_cls: 0.0002, decode.d8.loss_mask: 0.1972, decode.d8.loss_dice: 0.3548, loss: 7.2276\n",
      "2024-02-14 16:02:34,102 - mmseg - INFO - Iter [3940/80000]\tlr: 1.365e-06, eta: 2 days, 0:09:41, time: 2.132, data_time: 0.017, memory: 23505, decode.loss_cls: 0.0002, decode.loss_mask: 0.1977, decode.loss_dice: 0.3672, decode.d0.loss_cls: 1.6802, decode.d0.loss_mask: 0.2015, decode.d0.loss_dice: 0.3710, decode.d1.loss_cls: 0.0035, decode.d1.loss_mask: 0.1979, decode.d1.loss_dice: 0.3638, decode.d2.loss_cls: 0.0005, decode.d2.loss_mask: 0.1999, decode.d2.loss_dice: 0.3587, decode.d3.loss_cls: 0.0005, decode.d3.loss_mask: 0.1965, decode.d3.loss_dice: 0.3585, decode.d4.loss_cls: 0.0004, decode.d4.loss_mask: 0.1965, decode.d4.loss_dice: 0.3612, decode.d5.loss_cls: 0.0003, decode.d5.loss_mask: 0.1978, decode.d5.loss_dice: 0.3645, decode.d6.loss_cls: 0.0003, decode.d6.loss_mask: 0.1941, decode.d6.loss_dice: 0.3587, decode.d7.loss_cls: 0.0002, decode.d7.loss_mask: 0.1960, decode.d7.loss_dice: 0.3600, decode.d8.loss_cls: 0.0002, decode.d8.loss_mask: 0.1962, decode.d8.loss_dice: 0.3607, loss: 7.2846\n",
      "2024-02-14 16:02:55,410 - mmseg - INFO - Iter [3950/80000]\tlr: 1.365e-06, eta: 2 days, 0:08:49, time: 2.131, data_time: 0.017, memory: 23505, decode.loss_cls: 0.0002, decode.loss_mask: 0.1904, decode.loss_dice: 0.3574, decode.d0.loss_cls: 1.6699, decode.d0.loss_mask: 0.1911, decode.d0.loss_dice: 0.3656, decode.d1.loss_cls: 0.0041, decode.d1.loss_mask: 0.1905, decode.d1.loss_dice: 0.3542, decode.d2.loss_cls: 0.0005, decode.d2.loss_mask: 0.1898, decode.d2.loss_dice: 0.3487, decode.d3.loss_cls: 0.0005, decode.d3.loss_mask: 0.1894, decode.d3.loss_dice: 0.3543, decode.d4.loss_cls: 0.0003, decode.d4.loss_mask: 0.1910, decode.d4.loss_dice: 0.3561, decode.d5.loss_cls: 0.0002, decode.d5.loss_mask: 0.1901, decode.d5.loss_dice: 0.3534, decode.d6.loss_cls: 0.0002, decode.d6.loss_mask: 0.1892, decode.d6.loss_dice: 0.3539, decode.d7.loss_cls: 0.0002, decode.d7.loss_mask: 0.1904, decode.d7.loss_dice: 0.3534, decode.d8.loss_cls: 0.0002, decode.d8.loss_mask: 0.1907, decode.d8.loss_dice: 0.3573, loss: 7.1332\n",
      "2024-02-14 16:03:16,717 - mmseg - INFO - Iter [3960/80000]\tlr: 1.365e-06, eta: 2 days, 0:07:58, time: 2.131, data_time: 0.016, memory: 23505, decode.loss_cls: 0.0002, decode.loss_mask: 0.1585, decode.loss_dice: 0.3106, decode.d0.loss_cls: 1.6586, decode.d0.loss_mask: 0.1546, decode.d0.loss_dice: 0.3201, decode.d1.loss_cls: 0.0087, decode.d1.loss_mask: 0.1539, decode.d1.loss_dice: 0.3074, decode.d2.loss_cls: 0.0010, decode.d2.loss_mask: 0.1562, decode.d2.loss_dice: 0.3105, decode.d3.loss_cls: 0.0005, decode.d3.loss_mask: 0.1546, decode.d3.loss_dice: 0.3088, decode.d4.loss_cls: 0.0003, decode.d4.loss_mask: 0.1557, decode.d4.loss_dice: 0.3115, decode.d5.loss_cls: 0.0003, decode.d5.loss_mask: 0.1540, decode.d5.loss_dice: 0.3063, decode.d6.loss_cls: 0.0003, decode.d6.loss_mask: 0.1547, decode.d6.loss_dice: 0.3108, decode.d7.loss_cls: 0.0002, decode.d7.loss_mask: 0.1552, decode.d7.loss_dice: 0.3104, decode.d8.loss_cls: 0.0002, decode.d8.loss_mask: 0.1565, decode.d8.loss_dice: 0.3085, loss: 6.3291\n",
      "2024-02-14 16:03:38,020 - mmseg - INFO - Iter [3970/80000]\tlr: 1.365e-06, eta: 2 days, 0:07:07, time: 2.130, data_time: 0.017, memory: 23505, decode.loss_cls: 0.0002, decode.loss_mask: 0.1863, decode.loss_dice: 0.3396, decode.d0.loss_cls: 1.6542, decode.d0.loss_mask: 0.1939, decode.d0.loss_dice: 0.3572, decode.d1.loss_cls: 0.0048, decode.d1.loss_mask: 0.1884, decode.d1.loss_dice: 0.3394, decode.d2.loss_cls: 0.0005, decode.d2.loss_mask: 0.1868, decode.d2.loss_dice: 0.3380, decode.d3.loss_cls: 0.0004, decode.d3.loss_mask: 0.1884, decode.d3.loss_dice: 0.3389, decode.d4.loss_cls: 0.0003, decode.d4.loss_mask: 0.1856, decode.d4.loss_dice: 0.3311, decode.d5.loss_cls: 0.0002, decode.d5.loss_mask: 0.1875, decode.d5.loss_dice: 0.3370, decode.d6.loss_cls: 0.0002, decode.d6.loss_mask: 0.1899, decode.d6.loss_dice: 0.3377, decode.d7.loss_cls: 0.0002, decode.d7.loss_mask: 0.1885, decode.d7.loss_dice: 0.3354, decode.d8.loss_cls: 0.0002, decode.d8.loss_mask: 0.1867, decode.d8.loss_dice: 0.3369, loss: 6.9341\n",
      "2024-02-14 16:03:59,298 - mmseg - INFO - Iter [3980/80000]\tlr: 1.364e-06, eta: 2 days, 0:06:15, time: 2.128, data_time: 0.017, memory: 23505, decode.loss_cls: 0.0002, decode.loss_mask: 0.2019, decode.loss_dice: 0.3670, decode.d0.loss_cls: 1.6509, decode.d0.loss_mask: 0.2034, decode.d0.loss_dice: 0.3835, decode.d1.loss_cls: 0.0035, decode.d1.loss_mask: 0.2007, decode.d1.loss_dice: 0.3725, decode.d2.loss_cls: 0.0006, decode.d2.loss_mask: 0.2006, decode.d2.loss_dice: 0.3753, decode.d3.loss_cls: 0.0004, decode.d3.loss_mask: 0.1997, decode.d3.loss_dice: 0.3696, decode.d4.loss_cls: 0.0003, decode.d4.loss_mask: 0.2008, decode.d4.loss_dice: 0.3646, decode.d5.loss_cls: 0.0003, decode.d5.loss_mask: 0.1999, decode.d5.loss_dice: 0.3709, decode.d6.loss_cls: 0.0002, decode.d6.loss_mask: 0.2001, decode.d6.loss_dice: 0.3680, decode.d7.loss_cls: 0.0002, decode.d7.loss_mask: 0.2001, decode.d7.loss_dice: 0.3685, decode.d8.loss_cls: 0.0002, decode.d8.loss_mask: 0.2024, decode.d8.loss_dice: 0.3693, loss: 7.3754\n",
      "2024-02-14 16:04:20,607 - mmseg - INFO - Iter [3990/80000]\tlr: 1.364e-06, eta: 2 days, 0:05:24, time: 2.131, data_time: 0.017, memory: 23505, decode.loss_cls: 0.0002, decode.loss_mask: 0.1978, decode.loss_dice: 0.3494, decode.d0.loss_cls: 1.6476, decode.d0.loss_mask: 0.2036, decode.d0.loss_dice: 0.3720, decode.d1.loss_cls: 0.0029, decode.d1.loss_mask: 0.2030, decode.d1.loss_dice: 0.3515, decode.d2.loss_cls: 0.0005, decode.d2.loss_mask: 0.1994, decode.d2.loss_dice: 0.3536, decode.d3.loss_cls: 0.0005, decode.d3.loss_mask: 0.1998, decode.d3.loss_dice: 0.3575, decode.d4.loss_cls: 0.0003, decode.d4.loss_mask: 0.1997, decode.d4.loss_dice: 0.3491, decode.d5.loss_cls: 0.0003, decode.d5.loss_mask: 0.1998, decode.d5.loss_dice: 0.3493, decode.d6.loss_cls: 0.0002, decode.d6.loss_mask: 0.1999, decode.d6.loss_dice: 0.3563, decode.d7.loss_cls: 0.0002, decode.d7.loss_mask: 0.1978, decode.d7.loss_dice: 0.3515, decode.d8.loss_cls: 0.0002, decode.d8.loss_mask: 0.2003, decode.d8.loss_dice: 0.3542, loss: 7.1982\n",
      "2024-02-14 16:04:41,901 - mmseg - INFO - Exp name: pizze_training_large.py\n",
      "2024-02-14 16:04:41,902 - mmseg - INFO - Iter [4000/80000]\tlr: 1.364e-06, eta: 2 days, 0:04:33, time: 2.129, data_time: 0.017, memory: 23505, decode.loss_cls: 0.0002, decode.loss_mask: 0.1813, decode.loss_dice: 0.3410, decode.d0.loss_cls: 1.6384, decode.d0.loss_mask: 0.1798, decode.d0.loss_dice: 0.3545, decode.d1.loss_cls: 0.0037, decode.d1.loss_mask: 0.1780, decode.d1.loss_dice: 0.3365, decode.d2.loss_cls: 0.0005, decode.d2.loss_mask: 0.1805, decode.d2.loss_dice: 0.3405, decode.d3.loss_cls: 0.0004, decode.d3.loss_mask: 0.1812, decode.d3.loss_dice: 0.3430, decode.d4.loss_cls: 0.0003, decode.d4.loss_mask: 0.1786, decode.d4.loss_dice: 0.3370, decode.d5.loss_cls: 0.0002, decode.d5.loss_mask: 0.1797, decode.d5.loss_dice: 0.3383, decode.d6.loss_cls: 0.0002, decode.d6.loss_mask: 0.1818, decode.d6.loss_dice: 0.3380, decode.d7.loss_cls: 0.0002, decode.d7.loss_mask: 0.1809, decode.d7.loss_dice: 0.3385, decode.d8.loss_cls: 0.0002, decode.d8.loss_mask: 0.1779, decode.d8.loss_dice: 0.3379, loss: 6.8491\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 40/40, 6.3 task/s, elapsed: 6s, ETA:     0s\n",
      "\n",
      "2024-02-14 16:04:48,346 - mmseg - INFO - per class results:\n",
      "2024-02-14 16:04:48,347 - mmseg - INFO - \n",
      "+---------------+-------+-------+\n",
      "|     Class     |  IoU  |  Acc  |\n",
      "+---------------+-------+-------+\n",
      "|       bg      | 97.52 |  98.6 |\n",
      "|    Anchovy    | 82.63 | 93.25 |\n",
      "|     Olives    | 84.89 | 86.94 |\n",
      "|     Salami    | 71.17 | 85.73 |\n",
      "|   Red_Pepper  | 88.97 | 95.02 |\n",
      "| Yellow_Pepper | 86.35 | 94.12 |\n",
      "+---------------+-------+-------+\n",
      "2024-02-14 16:04:48,347 - mmseg - INFO - Summary:\n",
      "2024-02-14 16:04:48,347 - mmseg - INFO - \n",
      "+-------+-------+-------+\n",
      "|  aAcc |  mIoU |  mAcc |\n",
      "+-------+-------+-------+\n",
      "| 97.61 | 85.26 | 92.28 |\n",
      "+-------+-------+-------+\n",
      "2024-02-14 16:04:48,347 - mmseg - INFO - Exp name: pizze_training_large.py\n",
      "2024-02-14 16:04:48,347 - mmseg - INFO - Iter(val) [10]\taAcc: 0.9761, mIoU: 0.8526, mAcc: 0.9228, IoU.bg: 0.9752, IoU.Anchovy: 0.8263, IoU.Olives: 0.8489, IoU.Salami: 0.7117, IoU.Red_Pepper: 0.8897, IoU.Yellow_Pepper: 0.8635, Acc.bg: 0.9860, Acc.Anchovy: 0.9325, Acc.Olives: 0.8694, Acc.Salami: 0.8573, Acc.Red_Pepper: 0.9502, Acc.Yellow_Pepper: 0.9412\n",
      "2024-02-14 16:05:09,645 - mmseg - INFO - Iter [4010/80000]\tlr: 1.364e-06, eta: 2 days, 0:05:45, time: 2.774, data_time: 0.661, memory: 23505, decode.loss_cls: 0.0001, decode.loss_mask: 0.1695, decode.loss_dice: 0.3275, decode.d0.loss_cls: 1.6253, decode.d0.loss_mask: 0.1707, decode.d0.loss_dice: 0.3460, decode.d1.loss_cls: 0.0044, decode.d1.loss_mask: 0.1682, decode.d1.loss_dice: 0.3249, decode.d2.loss_cls: 0.0005, decode.d2.loss_mask: 0.1694, decode.d2.loss_dice: 0.3271, decode.d3.loss_cls: 0.0003, decode.d3.loss_mask: 0.1688, decode.d3.loss_dice: 0.3256, decode.d4.loss_cls: 0.0002, decode.d4.loss_mask: 0.1703, decode.d4.loss_dice: 0.3270, decode.d5.loss_cls: 0.0002, decode.d5.loss_mask: 0.1688, decode.d5.loss_dice: 0.3263, decode.d6.loss_cls: 0.0002, decode.d6.loss_mask: 0.1699, decode.d6.loss_dice: 0.3318, decode.d7.loss_cls: 0.0002, decode.d7.loss_mask: 0.1703, decode.d7.loss_dice: 0.3257, decode.d8.loss_cls: 0.0002, decode.d8.loss_mask: 0.1693, decode.d8.loss_dice: 0.3275, loss: 6.6165\n",
      "2024-02-14 16:05:30,945 - mmseg - INFO - Iter [4020/80000]\tlr: 1.364e-06, eta: 2 days, 0:04:54, time: 2.130, data_time: 0.016, memory: 23505, decode.loss_cls: 0.0002, decode.loss_mask: 0.1700, decode.loss_dice: 0.3322, decode.d0.loss_cls: 1.6190, decode.d0.loss_mask: 0.1713, decode.d0.loss_dice: 0.3547, decode.d1.loss_cls: 0.0042, decode.d1.loss_mask: 0.1706, decode.d1.loss_dice: 0.3283, decode.d2.loss_cls: 0.0006, decode.d2.loss_mask: 0.1727, decode.d2.loss_dice: 0.3308, decode.d3.loss_cls: 0.0004, decode.d3.loss_mask: 0.1699, decode.d3.loss_dice: 0.3339, decode.d4.loss_cls: 0.0002, decode.d4.loss_mask: 0.1714, decode.d4.loss_dice: 0.3318, decode.d5.loss_cls: 0.0002, decode.d5.loss_mask: 0.1697, decode.d5.loss_dice: 0.3310, decode.d6.loss_cls: 0.0002, decode.d6.loss_mask: 0.1686, decode.d6.loss_dice: 0.3290, decode.d7.loss_cls: 0.0002, decode.d7.loss_mask: 0.1701, decode.d7.loss_dice: 0.3280, decode.d8.loss_cls: 0.0002, decode.d8.loss_mask: 0.1693, decode.d8.loss_dice: 0.3293, loss: 6.6580\n",
      "2024-02-14 16:05:52,250 - mmseg - INFO - Iter [4030/80000]\tlr: 1.363e-06, eta: 2 days, 0:04:03, time: 2.130, data_time: 0.016, memory: 23505, decode.loss_cls: 0.0002, decode.loss_mask: 0.2091, decode.loss_dice: 0.3944, decode.d0.loss_cls: 1.6227, decode.d0.loss_mask: 0.2094, decode.d0.loss_dice: 0.4105, decode.d1.loss_cls: 0.0025, decode.d1.loss_mask: 0.2090, decode.d1.loss_dice: 0.3943, decode.d2.loss_cls: 0.0005, decode.d2.loss_mask: 0.2058, decode.d2.loss_dice: 0.3936, decode.d3.loss_cls: 0.0005, decode.d3.loss_mask: 0.2072, decode.d3.loss_dice: 0.3917, decode.d4.loss_cls: 0.0003, decode.d4.loss_mask: 0.2071, decode.d4.loss_dice: 0.3913, decode.d5.loss_cls: 0.0003, decode.d5.loss_mask: 0.2066, decode.d5.loss_dice: 0.3923, decode.d6.loss_cls: 0.0002, decode.d6.loss_mask: 0.2068, decode.d6.loss_dice: 0.3903, decode.d7.loss_cls: 0.0002, decode.d7.loss_mask: 0.2093, decode.d7.loss_dice: 0.3996, decode.d8.loss_cls: 0.0002, decode.d8.loss_mask: 0.2092, decode.d8.loss_dice: 0.3932, loss: 7.6584\n",
      "2024-02-14 16:06:13,565 - mmseg - INFO - Iter [4040/80000]\tlr: 1.363e-06, eta: 2 days, 0:03:13, time: 2.131, data_time: 0.017, memory: 23505, decode.loss_cls: 0.0002, decode.loss_mask: 0.2029, decode.loss_dice: 0.3661, decode.d0.loss_cls: 1.6146, decode.d0.loss_mask: 0.2035, decode.d0.loss_dice: 0.3794, decode.d1.loss_cls: 0.0028, decode.d1.loss_mask: 0.2011, decode.d1.loss_dice: 0.3678, decode.d2.loss_cls: 0.0005, decode.d2.loss_mask: 0.2003, decode.d2.loss_dice: 0.3687, decode.d3.loss_cls: 0.0004, decode.d3.loss_mask: 0.2010, decode.d3.loss_dice: 0.3663, decode.d4.loss_cls: 0.0003, decode.d4.loss_mask: 0.2025, decode.d4.loss_dice: 0.3691, decode.d5.loss_cls: 0.0002, decode.d5.loss_mask: 0.2015, decode.d5.loss_dice: 0.3685, decode.d6.loss_cls: 0.0002, decode.d6.loss_mask: 0.2006, decode.d6.loss_dice: 0.3687, decode.d7.loss_cls: 0.0002, decode.d7.loss_mask: 0.2002, decode.d7.loss_dice: 0.3683, decode.d8.loss_cls: 0.0002, decode.d8.loss_mask: 0.2042, decode.d8.loss_dice: 0.3671, loss: 7.3272\n",
      "2024-02-14 16:06:34,866 - mmseg - INFO - Iter [4050/80000]\tlr: 1.363e-06, eta: 2 days, 0:02:23, time: 2.130, data_time: 0.016, memory: 23505, decode.loss_cls: 0.0002, decode.loss_mask: 0.1600, decode.loss_dice: 0.3067, decode.d0.loss_cls: 1.6005, decode.d0.loss_mask: 0.1626, decode.d0.loss_dice: 0.3363, decode.d1.loss_cls: 0.0035, decode.d1.loss_mask: 0.1633, decode.d1.loss_dice: 0.3149, decode.d2.loss_cls: 0.0005, decode.d2.loss_mask: 0.1615, decode.d2.loss_dice: 0.3057, decode.d3.loss_cls: 0.0004, decode.d3.loss_mask: 0.1617, decode.d3.loss_dice: 0.3061, decode.d4.loss_cls: 0.0002, decode.d4.loss_mask: 0.1645, decode.d4.loss_dice: 0.3122, decode.d5.loss_cls: 0.0002, decode.d5.loss_mask: 0.1635, decode.d5.loss_dice: 0.3095, decode.d6.loss_cls: 0.0002, decode.d6.loss_mask: 0.1621, decode.d6.loss_dice: 0.3068, decode.d7.loss_cls: 0.0002, decode.d7.loss_mask: 0.1626, decode.d7.loss_dice: 0.3132, decode.d8.loss_cls: 0.0002, decode.d8.loss_mask: 0.1608, decode.d8.loss_dice: 0.3045, loss: 6.3444\n",
      "2024-02-14 16:06:56,143 - mmseg - INFO - Iter [4060/80000]\tlr: 1.363e-06, eta: 2 days, 0:01:32, time: 2.128, data_time: 0.017, memory: 23505, decode.loss_cls: 0.0002, decode.loss_mask: 0.1763, decode.loss_dice: 0.3406, decode.d0.loss_cls: 1.5993, decode.d0.loss_mask: 0.1777, decode.d0.loss_dice: 0.3635, decode.d1.loss_cls: 0.0028, decode.d1.loss_mask: 0.1778, decode.d1.loss_dice: 0.3461, decode.d2.loss_cls: 0.0005, decode.d2.loss_mask: 0.1786, decode.d2.loss_dice: 0.3459, decode.d3.loss_cls: 0.0004, decode.d3.loss_mask: 0.1780, decode.d3.loss_dice: 0.3468, decode.d4.loss_cls: 0.0003, decode.d4.loss_mask: 0.1731, decode.d4.loss_dice: 0.3441, decode.d5.loss_cls: 0.0002, decode.d5.loss_mask: 0.1767, decode.d5.loss_dice: 0.3452, decode.d6.loss_cls: 0.0002, decode.d6.loss_mask: 0.1766, decode.d6.loss_dice: 0.3451, decode.d7.loss_cls: 0.0002, decode.d7.loss_mask: 0.1752, decode.d7.loss_dice: 0.3413, decode.d8.loss_cls: 0.0002, decode.d8.loss_mask: 0.1775, decode.d8.loss_dice: 0.3450, loss: 6.8353\n",
      "2024-02-14 16:07:17,417 - mmseg - INFO - Iter [4070/80000]\tlr: 1.363e-06, eta: 2 days, 0:00:41, time: 2.127, data_time: 0.016, memory: 23505, decode.loss_cls: 0.0002, decode.loss_mask: 0.1418, decode.loss_dice: 0.3034, decode.d0.loss_cls: 1.5882, decode.d0.loss_mask: 0.1449, decode.d0.loss_dice: 0.3232, decode.d1.loss_cls: 0.0036, decode.d1.loss_mask: 0.1442, decode.d1.loss_dice: 0.3039, decode.d2.loss_cls: 0.0005, decode.d2.loss_mask: 0.1424, decode.d2.loss_dice: 0.3000, decode.d3.loss_cls: 0.0003, decode.d3.loss_mask: 0.1412, decode.d3.loss_dice: 0.2969, decode.d4.loss_cls: 0.0002, decode.d4.loss_mask: 0.1412, decode.d4.loss_dice: 0.3016, decode.d5.loss_cls: 0.0002, decode.d5.loss_mask: 0.1424, decode.d5.loss_dice: 0.3022, decode.d6.loss_cls: 0.0002, decode.d6.loss_mask: 0.1424, decode.d6.loss_dice: 0.3024, decode.d7.loss_cls: 0.0002, decode.d7.loss_mask: 0.1428, decode.d7.loss_dice: 0.3025, decode.d8.loss_cls: 0.0002, decode.d8.loss_mask: 0.1397, decode.d8.loss_dice: 0.3005, loss: 6.0535\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-14 16:07:38,695 - mmseg - INFO - Iter [4080/80000]\tlr: 1.363e-06, eta: 1 day, 23:59:51, time: 2.128, data_time: 0.017, memory: 23505, decode.loss_cls: 0.0002, decode.loss_mask: 0.1907, decode.loss_dice: 0.3437, decode.d0.loss_cls: 1.5880, decode.d0.loss_mask: 0.1926, decode.d0.loss_dice: 0.3627, decode.d1.loss_cls: 0.0025, decode.d1.loss_mask: 0.1922, decode.d1.loss_dice: 0.3466, decode.d2.loss_cls: 0.0005, decode.d2.loss_mask: 0.1885, decode.d2.loss_dice: 0.3435, decode.d3.loss_cls: 0.0004, decode.d3.loss_mask: 0.1894, decode.d3.loss_dice: 0.3465, decode.d4.loss_cls: 0.0003, decode.d4.loss_mask: 0.1910, decode.d4.loss_dice: 0.3496, decode.d5.loss_cls: 0.0002, decode.d5.loss_mask: 0.1880, decode.d5.loss_dice: 0.3458, decode.d6.loss_cls: 0.0002, decode.d6.loss_mask: 0.1902, decode.d6.loss_dice: 0.3418, decode.d7.loss_cls: 0.0002, decode.d7.loss_mask: 0.1900, decode.d7.loss_dice: 0.3460, decode.d8.loss_cls: 0.0002, decode.d8.loss_mask: 0.1887, decode.d8.loss_dice: 0.3443, loss: 6.9647\n",
      "2024-02-14 16:08:00,004 - mmseg - INFO - Iter [4090/80000]\tlr: 1.362e-06, eta: 1 day, 23:59:01, time: 2.131, data_time: 0.015, memory: 23505, decode.loss_cls: 0.0002, decode.loss_mask: 0.1858, decode.loss_dice: 0.3567, decode.d0.loss_cls: 1.5789, decode.d0.loss_mask: 0.1897, decode.d0.loss_dice: 0.3627, decode.d1.loss_cls: 0.0032, decode.d1.loss_mask: 0.1878, decode.d1.loss_dice: 0.3609, decode.d2.loss_cls: 0.0005, decode.d2.loss_mask: 0.1871, decode.d2.loss_dice: 0.3595, decode.d3.loss_cls: 0.0004, decode.d3.loss_mask: 0.1873, decode.d3.loss_dice: 0.3578, decode.d4.loss_cls: 0.0002, decode.d4.loss_mask: 0.1856, decode.d4.loss_dice: 0.3590, decode.d5.loss_cls: 0.0002, decode.d5.loss_mask: 0.1871, decode.d5.loss_dice: 0.3616, decode.d6.loss_cls: 0.0002, decode.d6.loss_mask: 0.1862, decode.d6.loss_dice: 0.3589, decode.d7.loss_cls: 0.0002, decode.d7.loss_mask: 0.1871, decode.d7.loss_dice: 0.3608, decode.d8.loss_cls: 0.0002, decode.d8.loss_mask: 0.1867, decode.d8.loss_dice: 0.3591, loss: 7.0518\n",
      "2024-02-14 16:08:21,270 - mmseg - INFO - Iter [4100/80000]\tlr: 1.362e-06, eta: 1 day, 23:58:11, time: 2.127, data_time: 0.016, memory: 23505, decode.loss_cls: 0.0002, decode.loss_mask: 0.1889, decode.loss_dice: 0.3565, decode.d0.loss_cls: 1.5749, decode.d0.loss_mask: 0.1955, decode.d0.loss_dice: 0.3760, decode.d1.loss_cls: 0.0028, decode.d1.loss_mask: 0.1919, decode.d1.loss_dice: 0.3620, decode.d2.loss_cls: 0.0005, decode.d2.loss_mask: 0.1910, decode.d2.loss_dice: 0.3600, decode.d3.loss_cls: 0.0004, decode.d3.loss_mask: 0.1909, decode.d3.loss_dice: 0.3595, decode.d4.loss_cls: 0.0003, decode.d4.loss_mask: 0.1910, decode.d4.loss_dice: 0.3641, decode.d5.loss_cls: 0.0002, decode.d5.loss_mask: 0.1889, decode.d5.loss_dice: 0.3581, decode.d6.loss_cls: 0.0002, decode.d6.loss_mask: 0.1893, decode.d6.loss_dice: 0.3606, decode.d7.loss_cls: 0.0002, decode.d7.loss_mask: 0.1912, decode.d7.loss_dice: 0.3651, decode.d8.loss_cls: 0.0002, decode.d8.loss_mask: 0.1886, decode.d8.loss_dice: 0.3568, loss: 7.1056\n",
      "2024-02-14 16:08:42,552 - mmseg - INFO - Iter [4110/80000]\tlr: 1.362e-06, eta: 1 day, 23:57:21, time: 2.128, data_time: 0.016, memory: 23505, decode.loss_cls: 0.0002, decode.loss_mask: 0.1501, decode.loss_dice: 0.2952, decode.d0.loss_cls: 1.5638, decode.d0.loss_mask: 0.1518, decode.d0.loss_dice: 0.3192, decode.d1.loss_cls: 0.0031, decode.d1.loss_mask: 0.1468, decode.d1.loss_dice: 0.2954, decode.d2.loss_cls: 0.0004, decode.d2.loss_mask: 0.1505, decode.d2.loss_dice: 0.2947, decode.d3.loss_cls: 0.0004, decode.d3.loss_mask: 0.1470, decode.d3.loss_dice: 0.2916, decode.d4.loss_cls: 0.0002, decode.d4.loss_mask: 0.1487, decode.d4.loss_dice: 0.2930, decode.d5.loss_cls: 0.0002, decode.d5.loss_mask: 0.1490, decode.d5.loss_dice: 0.2951, decode.d6.loss_cls: 0.0002, decode.d6.loss_mask: 0.1490, decode.d6.loss_dice: 0.2934, decode.d7.loss_cls: 0.0002, decode.d7.loss_mask: 0.1479, decode.d7.loss_dice: 0.2942, decode.d8.loss_cls: 0.0002, decode.d8.loss_mask: 0.1511, decode.d8.loss_dice: 0.2962, loss: 6.0289\n",
      "2024-02-14 16:09:03,844 - mmseg - INFO - Iter [4120/80000]\tlr: 1.362e-06, eta: 1 day, 23:56:31, time: 2.129, data_time: 0.017, memory: 23505, decode.loss_cls: 0.0002, decode.loss_mask: 0.2015, decode.loss_dice: 0.3622, decode.d0.loss_cls: 1.5669, decode.d0.loss_mask: 0.2063, decode.d0.loss_dice: 0.3793, decode.d1.loss_cls: 0.0026, decode.d1.loss_mask: 0.2016, decode.d1.loss_dice: 0.3651, decode.d2.loss_cls: 0.0004, decode.d2.loss_mask: 0.2013, decode.d2.loss_dice: 0.3636, decode.d3.loss_cls: 0.0004, decode.d3.loss_mask: 0.2002, decode.d3.loss_dice: 0.3610, decode.d4.loss_cls: 0.0003, decode.d4.loss_mask: 0.1994, decode.d4.loss_dice: 0.3574, decode.d5.loss_cls: 0.0002, decode.d5.loss_mask: 0.2020, decode.d5.loss_dice: 0.3617, decode.d6.loss_cls: 0.0002, decode.d6.loss_mask: 0.2025, decode.d6.loss_dice: 0.3683, decode.d7.loss_cls: 0.0002, decode.d7.loss_mask: 0.2004, decode.d7.loss_dice: 0.3652, decode.d8.loss_cls: 0.0002, decode.d8.loss_mask: 0.1997, decode.d8.loss_dice: 0.3611, loss: 7.2315\n",
      "2024-02-14 16:09:25,151 - mmseg - INFO - Iter [4130/80000]\tlr: 1.362e-06, eta: 1 day, 23:55:42, time: 2.131, data_time: 0.017, memory: 23505, decode.loss_cls: 0.0002, decode.loss_mask: 0.1961, decode.loss_dice: 0.3596, decode.d0.loss_cls: 1.5609, decode.d0.loss_mask: 0.1979, decode.d0.loss_dice: 0.3754, decode.d1.loss_cls: 0.0027, decode.d1.loss_mask: 0.1967, decode.d1.loss_dice: 0.3602, decode.d2.loss_cls: 0.0006, decode.d2.loss_mask: 0.1934, decode.d2.loss_dice: 0.3527, decode.d3.loss_cls: 0.0004, decode.d3.loss_mask: 0.1963, decode.d3.loss_dice: 0.3602, decode.d4.loss_cls: 0.0003, decode.d4.loss_mask: 0.1980, decode.d4.loss_dice: 0.3609, decode.d5.loss_cls: 0.0002, decode.d5.loss_mask: 0.1936, decode.d5.loss_dice: 0.3570, decode.d6.loss_cls: 0.0002, decode.d6.loss_mask: 0.1959, decode.d6.loss_dice: 0.3591, decode.d7.loss_cls: 0.0002, decode.d7.loss_mask: 0.1940, decode.d7.loss_dice: 0.3582, decode.d8.loss_cls: 0.0002, decode.d8.loss_mask: 0.1929, decode.d8.loss_dice: 0.3570, loss: 7.1211\n",
      "^C\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"./train.py\", line 216, in <module>\n",
      "  File \"./train.py\", line 216, in <module>\n",
      "Traceback (most recent call last):\n",
      "  File \"./train.py\", line 216, in <module>\n",
      "    main()\n",
      "      File \"./train.py\", line 212, in main\n",
      "main()\n",
      "    meta=meta)  File \"./train.py\", line 212, in main\n",
      "\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/mmseg/apis/train.py\", line 167, in train_segmentor\n",
      "    meta=meta)\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/mmseg/apis/train.py\", line 167, in train_segmentor\n",
      "runner.run(data_loaders, cfg.workflow)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/mmcv/runner/iter_based_runner.py\", line 134, in run\n",
      "    main()\n",
      "          File \"./train.py\", line 212, in main\n",
      "runner.run(data_loaders, cfg.workflow)iter_runner(iter_loaders[i], **kwargs)\n",
      "\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/mmcv/runner/iter_based_runner.py\", line 134, in run\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/mmcv/runner/iter_based_runner.py\", line 67, in train\n",
      "    self.call_hook('after_train_iter')\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/mmcv/runner/base_runner.py\", line 309, in call_hook\n",
      "    meta=meta)\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/mmseg/apis/train.py\", line 167, in train_segmentor\n",
      "iter_runner(iter_loaders[i], **kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/mmcv/runner/iter_based_runner.py\", line 67, in train\n",
      "    getattr(hook, fn_name)(self)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/mmcv/runner/hooks/optimizer.py\", line 64, in after_train_iter\n",
      "        self.call_hook('after_train_iter')runner.run(data_loaders, cfg.workflow)\n",
      "\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/mmcv/runner/base_runner.py\", line 309, in call_hook\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/mmcv/runner/iter_based_runner.py\", line 134, in run\n",
      "runner.optimizer.step()\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/optim/optimizer.py\", line 88, in wrapper\n",
      "        iter_runner(iter_loaders[i], **kwargs)return func(*args, **kwargs)\n",
      "\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/mmcv/runner/iter_based_runner.py\", line 67, in train\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n",
      "    getattr(hook, fn_name)(self)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/mmcv/runner/hooks/optimizer.py\", line 64, in after_train_iter\n",
      "    self.call_hook('after_train_iter')\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/mmcv/runner/base_runner.py\", line 309, in call_hook\n",
      "    return func(*args, **kwargs)\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/torch/optim/adamw.py\", line 121, in step\n",
      "runner.optimizer.step()\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/optim/optimizer.py\", line 88, in wrapper\n",
      "    eps=group['eps'])\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/optim/_functional.py\", line 131, in adamw\n",
      "        getattr(hook, fn_name)(self)return func(*args, **kwargs)\n",
      "\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/mmcv/runner/hooks/optimizer.py\", line 64, in after_train_iter\n",
      "    exp_avg.mul_(beta1).add_(grad, alpha=1 - beta1)\n",
      "KeyboardInterrupt\n",
      "        return func(*args, **kwargs)runner.optimizer.step()\n",
      "\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/optim/adamw.py\", line 121, in step\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/optim/optimizer.py\", line 88, in wrapper\n",
      "    return func(*args, **kwargs)    \n",
      "eps=group['eps'])\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/optim/_functional.py\", line 143, in adamw\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/optim/adamw.py\", line 121, in step\n",
      "    param.addcdiv_(exp_avg, denom, value=-step_size)\n",
      "KeyboardInterrupt\n",
      "    eps=group['eps'])\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/optim/_functional.py\", line 139, in adamw\n",
      "    denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(eps)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!./dist_train.sh configs/pizze-sv/pizze_training_large.py 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-14 11:35:59,615 - mmseg - INFO - Loaded 40 images\n",
      "/workspace/ViT-Adapter/segmentation/mmseg_custom/models/losses/cross_entropy_loss.py:231: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n",
      "  'Default ``avg_non_ignore`` is False, if you would like to '\n",
      "load checkpoint from local path: work_dirs/pizze_training_base/best_mIoU_iter_19600.pth\n",
      "[                                                  ] 0/40, elapsed: 0s, ETA:/opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:3658: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and now uses scale_factor directly, instead of relying on the computed output size. If you wish to restore the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
      "  \"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
      "/opt/conda/lib/python3.7/site-packages/torch/_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.\n",
      "To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /pytorch/aten/src/ATen/native/BinaryOps.cpp:467.)\n",
      "  return torch.floor_divide(self, other)\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 40/40, 3.1 task/s, elapsed: 13s, ETA:     0sper class results:\n",
      "\n",
      "+---------------+-------+-------+\n",
      "|     Class     |  IoU  |  Acc  |\n",
      "+---------------+-------+-------+\n",
      "|       bg      | 96.48 | 98.07 |\n",
      "|    Anchovy    | 86.21 | 92.59 |\n",
      "|     Olives    | 87.73 | 92.58 |\n",
      "|     Salami    | 57.54 | 74.01 |\n",
      "|   Red_Pepper  | 81.86 | 91.74 |\n",
      "| Yellow_Pepper |  80.8 | 88.31 |\n",
      "+---------------+-------+-------+\n",
      "Summary:\n",
      "\n",
      "+-------+-------+-------+\n",
      "|  aAcc |  mIoU |  mAcc |\n",
      "+-------+-------+-------+\n",
      "| 96.58 | 81.77 | 89.55 |\n",
      "+-------+-------+-------+\n"
     ]
    }
   ],
   "source": [
    "!python test.py configs/pizze-sv/pizze_training_base.py work_dirs/pizze_training_base/best_mIoU_iter_19600.pth --eval mIoU --show-dir risultati"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
