{"env_info": "sys.platform: linux\nPython: 3.7.13 (default, Mar 29 2022, 02:18:16) [GCC 7.5.0]\nCUDA available: True\nGPU 0,1: NVIDIA L40\nCUDA_HOME: /usr/local/cuda\nNVCC: Build cuda_11.3.r11.3/compiler.29920130_0\nGCC: gcc (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0\nPyTorch: 1.9.0+cu111\nPyTorch compiling details: PyTorch built with:\n  - GCC 7.3\n  - C++ Version: 201402\n  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications\n  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)\n  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n  - NNPACK is enabled\n  - CPU capability usage: AVX2\n  - CUDA Runtime 11.1\n  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86\n  - CuDNN 8.0.5\n  - Magma 2.5.2\n  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, \n\nTorchVision: 0.10.0+cu111\nOpenCV: 4.9.0\nMMCV: 1.4.2\nMMCV Compiler: GCC 7.3\nMMCV CUDA Compiler: 11.1\nMMSegmentation: 0.20.2+94ffa6b", "seed": 1938159955, "exp_name": "pizze_training.py", "mmseg_version": "0.20.2+94ffa6b", "config": "num_things_classes = 6\nnum_stuff_classes = 0\nnum_classes = 6\nnorm_cfg = dict(type='SyncBN', requires_grad=True)\nmodel = dict(\n    type='EncoderDecoderMask2Former',\n    pretrained=\n    '/workspace/ViT-Adapter/segmentation/mask2former_beit_adapter_base_512_40k_cocostuff10k.pth.tar',\n    backbone=dict(\n        type='BEiTAdapter',\n        patch_size=16,\n        embed_dim=768,\n        depth=12,\n        num_heads=12,\n        mlp_ratio=4,\n        qkv_bias=True,\n        use_abs_pos_emb=False,\n        use_rel_pos_bias=True,\n        img_size=512,\n        init_values=1e-06,\n        drop_path_rate=0.2,\n        conv_inplane=64,\n        n_points=4,\n        deform_num_heads=12,\n        cffn_ratio=0.25,\n        deform_ratio=0.5,\n        interaction_indexes=[[0, 2], [3, 5], [6, 8], [9, 11]],\n        pretrained=\n        '/workspace/ViT-Adapter/segmentation/mask2former_beit_adapter_base_512_40k_cocostuff10k.pth.tar'\n    ),\n    decode_head=dict(\n        type='Mask2FormerHead',\n        in_channels=[768, 768, 768, 768],\n        feat_channels=256,\n        out_channels=256,\n        in_index=[0, 1, 2, 3],\n        num_things_classes=6,\n        num_stuff_classes=0,\n        num_queries=100,\n        num_transformer_feat_level=3,\n        pixel_decoder=dict(\n            type='MSDeformAttnPixelDecoder',\n            num_outs=3,\n            norm_cfg=dict(type='GN', num_groups=32),\n            act_cfg=dict(type='ReLU'),\n            encoder=dict(\n                type='DetrTransformerEncoder',\n                num_layers=6,\n                transformerlayers=dict(\n                    type='BaseTransformerLayer',\n                    attn_cfgs=dict(\n                        type='MultiScaleDeformableAttention',\n                        embed_dims=256,\n                        num_heads=8,\n                        num_levels=3,\n                        num_points=4,\n                        im2col_step=64,\n                        dropout=0.0,\n                        batch_first=False,\n                        norm_cfg=None,\n                        init_cfg=None),\n                    ffn_cfgs=dict(\n                        type='FFN',\n                        embed_dims=256,\n                        feedforward_channels=1024,\n                        num_fcs=2,\n                        ffn_drop=0.0,\n                        act_cfg=dict(type='ReLU', inplace=True)),\n                    operation_order=('self_attn', 'norm', 'ffn', 'norm')),\n                init_cfg=None),\n            positional_encoding=dict(\n                type='SinePositionalEncoding', num_feats=128, normalize=True),\n            init_cfg=None),\n        enforce_decoder_input_project=False,\n        positional_encoding=dict(\n            type='SinePositionalEncoding', num_feats=128, normalize=True),\n        transformer_decoder=dict(\n            type='DetrTransformerDecoder',\n            return_intermediate=True,\n            num_layers=9,\n            transformerlayers=dict(\n                type='DetrTransformerDecoderLayer',\n                attn_cfgs=dict(\n                    type='MultiheadAttention',\n                    embed_dims=256,\n                    num_heads=8,\n                    attn_drop=0.0,\n                    proj_drop=0.0,\n                    dropout_layer=None,\n                    batch_first=False),\n                ffn_cfgs=dict(\n                    embed_dims=256,\n                    feedforward_channels=2048,\n                    num_fcs=2,\n                    act_cfg=dict(type='ReLU', inplace=True),\n                    ffn_drop=0.0,\n                    dropout_layer=None,\n                    add_identity=True),\n                feedforward_channels=2048,\n                operation_order=('cross_attn', 'norm', 'self_attn', 'norm',\n                                 'ffn', 'norm')),\n            init_cfg=None),\n        loss_cls=dict(\n            type='CrossEntropyLoss',\n            use_sigmoid=False,\n            loss_weight=2.0,\n            reduction='mean',\n            class_weight=[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.1]),\n        loss_mask=dict(\n            type='CrossEntropyLoss',\n            use_sigmoid=True,\n            reduction='mean',\n            loss_weight=5.0),\n        loss_dice=dict(\n            type='DiceLoss',\n            use_sigmoid=True,\n            activate=True,\n            reduction='mean',\n            naive_dice=True,\n            eps=1.0,\n            loss_weight=5.0),\n        train_cfg=dict(\n            num_points=12544,\n            oversample_ratio=3.0,\n            importance_sample_ratio=0.75,\n            assigner=dict(\n                type='MaskHungarianAssigner',\n                cls_cost=dict(type='ClassificationCost', weight=2.0),\n                mask_cost=dict(\n                    type='CrossEntropyLossCost', weight=5.0, use_sigmoid=True),\n                dice_cost=dict(\n                    type='DiceCost', weight=5.0, pred_act=True, eps=1.0)),\n            sampler=dict(type='MaskPseudoSampler')),\n        test_cfg=dict(\n            panoptic_on=True,\n            semantic_on=False,\n            instance_on=True,\n            max_per_image=100,\n            iou_thr=0.8,\n            filter_low_score=True,\n            mode='slide',\n            crop_size=(512, 512),\n            stride=(341, 341))),\n    train_cfg=dict(\n        num_points=12544,\n        oversample_ratio=3.0,\n        importance_sample_ratio=0.75,\n        assigner=dict(\n            type='MaskHungarianAssigner',\n            cls_cost=dict(type='ClassificationCost', weight=2.0),\n            mask_cost=dict(\n                type='CrossEntropyLossCost', weight=5.0, use_sigmoid=True),\n            dice_cost=dict(\n                type='DiceCost', weight=5.0, pred_act=True, eps=1.0)),\n        sampler=dict(type='MaskPseudoSampler')),\n    test_cfg=dict(\n        panoptic_on=True,\n        semantic_on=False,\n        instance_on=True,\n        max_per_image=100,\n        iou_thr=0.8,\n        filter_low_score=True,\n        mode='slide',\n        crop_size=(512, 512),\n        stride=(341, 341)),\n    init_cfg=None)\ndataset_type = 'PizzeDataset'\ndata_root = 'data/dataset'\nimg_norm_cfg = dict(\n    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)\ncrop_size = (512, 512)\ntrain_pipeline = [\n    dict(type='LoadImageFromFile'),\n    dict(type='LoadAnnotations', reduce_zero_label=True),\n    dict(type='Resize', img_scale=(2048, 512), ratio_range=(0.5, 2.0)),\n    dict(type='RandomCrop', crop_size=(512, 512), cat_max_ratio=0.75),\n    dict(type='RandomFlip', prob=0.5),\n    dict(type='PhotoMetricDistortion'),\n    dict(\n        type='Normalize',\n        mean=[123.675, 116.28, 103.53],\n        std=[58.395, 57.12, 57.375],\n        to_rgb=True),\n    dict(type='Pad', size=(512, 512), pad_val=0, seg_pad_val=255),\n    dict(type='ToMask'),\n    dict(type='DefaultFormatBundle'),\n    dict(\n        type='Collect',\n        keys=['img', 'gt_semantic_seg', 'gt_masks', 'gt_labels'])\n]\ntest_pipeline = [\n    dict(type='LoadImageFromFile'),\n    dict(\n        type='MultiScaleFlipAug',\n        img_scale=(2048, 512),\n        flip=False,\n        transforms=[\n            dict(type='Resize', keep_ratio=True),\n            dict(type='ResizeToMultiple', size_divisor=32),\n            dict(type='RandomFlip'),\n            dict(\n                type='Normalize',\n                mean=[123.675, 116.28, 103.53],\n                std=[58.395, 57.12, 57.375],\n                to_rgb=True),\n            dict(type='ImageToTensor', keys=['img']),\n            dict(type='Collect', keys=['img'])\n        ])\n]\ndata = dict(\n    samples_per_gpu=2,\n    workers_per_gpu=4,\n    train=dict(\n        type='PizzeDataset',\n        data_root='data/dataset',\n        img_dir='images/training',\n        ann_dir='annotations/training',\n        pipeline=[\n            dict(type='LoadImageFromFile'),\n            dict(type='LoadAnnotations', reduce_zero_label=True),\n            dict(type='Resize', img_scale=(2048, 512), ratio_range=(0.5, 2.0)),\n            dict(type='RandomCrop', crop_size=(512, 512), cat_max_ratio=0.75),\n            dict(type='RandomFlip', prob=0.5),\n            dict(type='PhotoMetricDistortion'),\n            dict(\n                type='Normalize',\n                mean=[123.675, 116.28, 103.53],\n                std=[58.395, 57.12, 57.375],\n                to_rgb=True),\n            dict(type='Pad', size=(512, 512), pad_val=0, seg_pad_val=255),\n            dict(type='ToMask'),\n            dict(type='DefaultFormatBundle'),\n            dict(\n                type='Collect',\n                keys=['img', 'gt_semantic_seg', 'gt_masks', 'gt_labels'])\n        ]),\n    val=dict(\n        type='PizzeDataset',\n        data_root='data/dataset',\n        img_dir='images/validation',\n        ann_dir='annotations/validation',\n        pipeline=[\n            dict(type='LoadImageFromFile'),\n            dict(\n                type='MultiScaleFlipAug',\n                img_scale=(2048, 512),\n                flip=False,\n                transforms=[\n                    dict(type='Resize', keep_ratio=True),\n                    dict(type='ResizeToMultiple', size_divisor=32),\n                    dict(type='RandomFlip'),\n                    dict(\n                        type='Normalize',\n                        mean=[123.675, 116.28, 103.53],\n                        std=[58.395, 57.12, 57.375],\n                        to_rgb=True),\n                    dict(type='ImageToTensor', keys=['img']),\n                    dict(type='Collect', keys=['img'])\n                ])\n        ]),\n    test=dict(\n        type='PizzeDataset',\n        data_root='data/dataset',\n        img_dir='images/validation',\n        ann_dir='annotations/validation',\n        pipeline=[\n            dict(type='LoadImageFromFile'),\n            dict(\n                type='MultiScaleFlipAug',\n                img_scale=(2048, 512),\n                flip=False,\n                transforms=[\n                    dict(type='Resize', keep_ratio=True),\n                    dict(type='ResizeToMultiple', size_divisor=32),\n                    dict(type='RandomFlip'),\n                    dict(\n                        type='Normalize',\n                        mean=[123.675, 116.28, 103.53],\n                        std=[58.395, 57.12, 57.375],\n                        to_rgb=True),\n                    dict(type='ImageToTensor', keys=['img']),\n                    dict(type='Collect', keys=['img'])\n                ])\n        ]))\nlog_config = dict(\n    interval=10, hooks=[dict(type='TextLoggerHook', by_epoch=False)])\ndist_params = dict(backend='nccl')\nlog_level = 'INFO'\nload_from = None\nresume_from = None\nworkflow = [('train', 1)]\ncudnn_benchmark = True\noptimizer = dict(\n    type='AdamW',\n    lr=3e-05,\n    betas=(0.9, 0.999),\n    weight_decay=0.05,\n    constructor='LayerDecayOptimizerConstructor',\n    paramwise_cfg=dict(num_layers=12, layer_decay_rate=0.95))\noptimizer_config = dict()\nlr_config = dict(\n    policy='poly',\n    warmup='linear',\n    warmup_iters=1500,\n    warmup_ratio=1e-06,\n    power=1.0,\n    min_lr=0.0,\n    by_epoch=False)\nrunner = dict(type='IterBasedRunner', max_iters=40000)\ncheckpoint_config = dict(by_epoch=False, interval=1000, max_keep_ckpts=1)\nevaluation = dict(interval=200, metric='mIoU', pre_eval=True, save_best='mIoU')\npretrained = '/workspace/ViT-Adapter/segmentation/mask2former_beit_adapter_base_512_40k_cocostuff10k.pth.tar'\nwork_dir = './work_dirs/pizze_training'\ngpu_ids = range(0, 2)\nauto_resume = False\ndevice = 'cuda'\nseed = 1938159955\n", "CLASSES": ["bg", "Anchovy", "Olives", "Salami", "Red_Pepper", "Yellow_Pepper"], "PALETTE": [[255, 255, 255], [0, 0, 255], [0, 255, 255], [0, 255, 0], [255, 255, 0], [255, 0, 0]], "hook_msgs": {}}
{"mode": "train", "epoch": 1, "iter": 10, "lr": 0.0, "memory": 9602, "data_time": 0.57453, "decode.loss_cls": 5.78234, "decode.loss_mask": 3.79832, "decode.loss_dice": 4.31373, "decode.d0.loss_cls": 4.00474, "decode.d0.loss_mask": 3.39073, "decode.d0.loss_dice": 4.32754, "decode.d1.loss_cls": 3.48906, "decode.d1.loss_mask": 3.68933, "decode.d1.loss_dice": 4.31678, "decode.d2.loss_cls": 4.09461, "decode.d2.loss_mask": 3.97651, "decode.d2.loss_dice": 4.33145, "decode.d3.loss_cls": 3.6651, "decode.d3.loss_mask": 3.83984, "decode.d3.loss_dice": 4.30908, "decode.d4.loss_cls": 5.03588, "decode.d4.loss_mask": 4.34612, "decode.d4.loss_dice": 4.36833, "decode.d5.loss_cls": 4.838, "decode.d5.loss_mask": 3.60211, "decode.d5.loss_dice": 4.28578, "decode.d6.loss_cls": 4.71687, "decode.d6.loss_mask": 3.52988, "decode.d6.loss_dice": 4.25264, "decode.d7.loss_cls": 4.56955, "decode.d7.loss_mask": 3.30643, "decode.d7.loss_dice": 4.32643, "decode.d8.loss_cls": 5.0141, "decode.d8.loss_mask": 3.55433, "decode.d8.loss_dice": 4.31573, "loss": 125.39135, "time": 0.94394}
{"mode": "train", "epoch": 1, "iter": 20, "lr": 0.0, "memory": 9602, "data_time": 0.00609, "decode.loss_cls": 5.69355, "decode.loss_mask": 3.67572, "decode.loss_dice": 4.41978, "decode.d0.loss_cls": 4.0131, "decode.d0.loss_mask": 3.3408, "decode.d0.loss_dice": 4.46788, "decode.d1.loss_cls": 3.41316, "decode.d1.loss_mask": 3.62068, "decode.d1.loss_dice": 4.4218, "decode.d2.loss_cls": 4.04858, "decode.d2.loss_mask": 3.86245, "decode.d2.loss_dice": 4.41036, "decode.d3.loss_cls": 3.53812, "decode.d3.loss_mask": 3.72968, "decode.d3.loss_dice": 4.40863, "decode.d4.loss_cls": 4.93329, "decode.d4.loss_mask": 4.11693, "decode.d4.loss_dice": 4.44793, "decode.d5.loss_cls": 4.75874, "decode.d5.loss_mask": 3.48558, "decode.d5.loss_dice": 4.40422, "decode.d6.loss_cls": 4.62551, "decode.d6.loss_mask": 3.39643, "decode.d6.loss_dice": 4.35024, "decode.d7.loss_cls": 4.43262, "decode.d7.loss_mask": 3.16379, "decode.d7.loss_dice": 4.48627, "decode.d8.loss_cls": 4.89328, "decode.d8.loss_mask": 3.42848, "decode.d8.loss_dice": 4.45526, "loss": 124.44285, "time": 0.33878}
{"mode": "train", "epoch": 1, "iter": 30, "lr": 0.0, "memory": 9602, "data_time": 0.00601, "decode.loss_cls": 5.58626, "decode.loss_mask": 3.5241, "decode.loss_dice": 4.3786, "decode.d0.loss_cls": 3.99078, "decode.d0.loss_mask": 3.2414, "decode.d0.loss_dice": 4.41113, "decode.d1.loss_cls": 3.34784, "decode.d1.loss_mask": 3.52531, "decode.d1.loss_dice": 4.3606, "decode.d2.loss_cls": 4.01702, "decode.d2.loss_mask": 3.6763, "decode.d2.loss_dice": 4.35407, "decode.d3.loss_cls": 3.48079, "decode.d3.loss_mask": 3.55866, "decode.d3.loss_dice": 4.36626, "decode.d4.loss_cls": 4.85131, "decode.d4.loss_mask": 3.77292, "decode.d4.loss_dice": 4.37343, "decode.d5.loss_cls": 4.664, "decode.d5.loss_mask": 3.33348, "decode.d5.loss_dice": 4.32766, "decode.d6.loss_cls": 4.53591, "decode.d6.loss_mask": 3.22592, "decode.d6.loss_dice": 4.33046, "decode.d7.loss_cls": 4.35704, "decode.d7.loss_mask": 2.94718, "decode.d7.loss_dice": 4.46124, "decode.d8.loss_cls": 4.74398, "decode.d8.loss_mask": 3.28326, "decode.d8.loss_dice": 4.44569, "loss": 121.47264, "time": 0.3374}
{"mode": "train", "epoch": 1, "iter": 40, "lr": 0.0, "memory": 9602, "data_time": 0.00576, "decode.loss_cls": 5.34117, "decode.loss_mask": 3.26406, "decode.loss_dice": 4.45086, "decode.d0.loss_cls": 3.96252, "decode.d0.loss_mask": 3.06483, "decode.d0.loss_dice": 4.44503, "decode.d1.loss_cls": 3.19697, "decode.d1.loss_mask": 3.36609, "decode.d1.loss_dice": 4.40266, "decode.d2.loss_cls": 3.90633, "decode.d2.loss_mask": 3.49835, "decode.d2.loss_dice": 4.40531, "decode.d3.loss_cls": 3.25899, "decode.d3.loss_mask": 3.35178, "decode.d3.loss_dice": 4.45451, "decode.d4.loss_cls": 4.66641, "decode.d4.loss_mask": 3.5318, "decode.d4.loss_dice": 4.36787, "decode.d5.loss_cls": 4.47949, "decode.d5.loss_mask": 3.01498, "decode.d5.loss_dice": 4.39968, "decode.d6.loss_cls": 4.32676, "decode.d6.loss_mask": 2.87912, "decode.d6.loss_dice": 4.45075, "decode.d7.loss_cls": 4.10535, "decode.d7.loss_mask": 2.58482, "decode.d7.loss_dice": 4.5256, "decode.d8.loss_cls": 4.44891, "decode.d8.loss_mask": 2.87422, "decode.d8.loss_dice": 4.54584, "loss": 117.57107, "time": 0.3331}
{"mode": "train", "epoch": 2, "iter": 50, "lr": 0.0, "memory": 9602, "data_time": 0.21473, "decode.loss_cls": 4.87146, "decode.loss_mask": 2.73176, "decode.loss_dice": 4.57392, "decode.d0.loss_cls": 3.94714, "decode.d0.loss_mask": 2.78174, "decode.d0.loss_dice": 4.49249, "decode.d1.loss_cls": 3.18315, "decode.d1.loss_mask": 3.16345, "decode.d1.loss_dice": 4.45234, "decode.d2.loss_cls": 3.86767, "decode.d2.loss_mask": 3.25473, "decode.d2.loss_dice": 4.50141, "decode.d3.loss_cls": 3.1424, "decode.d3.loss_mask": 3.01175, "decode.d3.loss_dice": 4.58811, "decode.d4.loss_cls": 4.41498, "decode.d4.loss_mask": 3.13148, "decode.d4.loss_dice": 4.47761, "decode.d5.loss_cls": 4.22725, "decode.d5.loss_mask": 2.4119, "decode.d5.loss_dice": 4.501, "decode.d6.loss_cls": 4.05984, "decode.d6.loss_mask": 2.23157, "decode.d6.loss_dice": 4.56622, "decode.d7.loss_cls": 3.80535, "decode.d7.loss_mask": 1.88755, "decode.d7.loss_dice": 4.63037, "decode.d8.loss_cls": 4.06731, "decode.d8.loss_mask": 2.14786, "decode.d8.loss_dice": 4.65921, "loss": 111.78301, "time": 0.54643}
{"mode": "train", "epoch": 2, "iter": 60, "lr": 0.0, "memory": 9602, "data_time": 0.00617, "decode.loss_cls": 4.38612, "decode.loss_mask": 2.20273, "decode.loss_dice": 4.5763, "decode.d0.loss_cls": 3.93243, "decode.d0.loss_mask": 2.51835, "decode.d0.loss_dice": 4.4277, "decode.d1.loss_cls": 3.07001, "decode.d1.loss_mask": 2.85612, "decode.d1.loss_dice": 4.39334, "decode.d2.loss_cls": 3.78699, "decode.d2.loss_mask": 2.87688, "decode.d2.loss_dice": 4.48615, "decode.d3.loss_cls": 2.88409, "decode.d3.loss_mask": 2.56987, "decode.d3.loss_dice": 4.52902, "decode.d4.loss_cls": 4.01871, "decode.d4.loss_mask": 2.69814, "decode.d4.loss_dice": 4.44003, "decode.d5.loss_cls": 3.93376, "decode.d5.loss_mask": 1.9471, "decode.d5.loss_dice": 4.46426, "decode.d6.loss_cls": 3.68447, "decode.d6.loss_mask": 1.81797, "decode.d6.loss_dice": 4.51477, "decode.d7.loss_cls": 3.45751, "decode.d7.loss_mask": 1.6092, "decode.d7.loss_dice": 4.61483, "decode.d8.loss_cls": 3.71352, "decode.d8.loss_mask": 1.79633, "decode.d8.loss_dice": 4.62274, "loss": 104.82945, "time": 0.33706}
{"mode": "train", "epoch": 2, "iter": 70, "lr": 0.0, "memory": 9602, "data_time": 0.00612, "decode.loss_cls": 3.85062, "decode.loss_mask": 1.75713, "decode.loss_dice": 4.57173, "decode.d0.loss_cls": 3.87636, "decode.d0.loss_mask": 2.25062, "decode.d0.loss_dice": 4.41696, "decode.d1.loss_cls": 2.90802, "decode.d1.loss_mask": 2.45195, "decode.d1.loss_dice": 4.38868, "decode.d2.loss_cls": 3.58604, "decode.d2.loss_mask": 2.36044, "decode.d2.loss_dice": 4.46201, "decode.d3.loss_cls": 2.5797, "decode.d3.loss_mask": 2.05556, "decode.d3.loss_dice": 4.52127, "decode.d4.loss_cls": 3.72796, "decode.d4.loss_mask": 2.18189, "decode.d4.loss_dice": 4.4931, "decode.d5.loss_cls": 3.55572, "decode.d5.loss_mask": 1.66595, "decode.d5.loss_dice": 4.49244, "decode.d6.loss_cls": 3.19292, "decode.d6.loss_mask": 1.57734, "decode.d6.loss_dice": 4.54388, "decode.d7.loss_cls": 3.0223, "decode.d7.loss_mask": 1.4216, "decode.d7.loss_dice": 4.64292, "decode.d8.loss_cls": 3.21179, "decode.d8.loss_mask": 1.51415, "decode.d8.loss_dice": 4.64326, "loss": 97.92432, "time": 0.33596}
{"mode": "train", "epoch": 2, "iter": 80, "lr": 0.0, "memory": 9602, "data_time": 0.0061, "decode.loss_cls": 3.2498, "decode.loss_mask": 1.52053, "decode.loss_dice": 4.59928, "decode.d0.loss_cls": 3.84624, "decode.d0.loss_mask": 2.10747, "decode.d0.loss_dice": 4.35932, "decode.d1.loss_cls": 2.84808, "decode.d1.loss_mask": 2.06509, "decode.d1.loss_dice": 4.36443, "decode.d2.loss_cls": 3.39161, "decode.d2.loss_mask": 1.85992, "decode.d2.loss_dice": 4.45208, "decode.d3.loss_cls": 2.29885, "decode.d3.loss_mask": 1.7762, "decode.d3.loss_dice": 4.4718, "decode.d4.loss_cls": 3.31545, "decode.d4.loss_mask": 1.90546, "decode.d4.loss_dice": 4.41999, "decode.d5.loss_cls": 3.17636, "decode.d5.loss_mask": 1.62163, "decode.d5.loss_dice": 4.43887, "decode.d6.loss_cls": 2.80389, "decode.d6.loss_mask": 1.50653, "decode.d6.loss_dice": 4.52418, "decode.d7.loss_cls": 2.65063, "decode.d7.loss_mask": 1.36949, "decode.d7.loss_dice": 4.64971, "decode.d8.loss_cls": 2.66436, "decode.d8.loss_mask": 1.38938, "decode.d8.loss_dice": 4.62736, "loss": 92.274, "time": 0.33517}
{"mode": "train", "epoch": 3, "iter": 90, "lr": 0.0, "memory": 9602, "data_time": 0.21423, "decode.loss_cls": 2.79105, "decode.loss_mask": 1.56178, "decode.loss_dice": 4.54153, "decode.d0.loss_cls": 3.82422, "decode.d0.loss_mask": 2.05334, "decode.d0.loss_dice": 4.33401, "decode.d1.loss_cls": 2.68186, "decode.d1.loss_mask": 1.95377, "decode.d1.loss_dice": 4.32075, "decode.d2.loss_cls": 3.08479, "decode.d2.loss_mask": 1.78882, "decode.d2.loss_dice": 4.37812, "decode.d3.loss_cls": 2.11707, "decode.d3.loss_mask": 1.76155, "decode.d3.loss_dice": 4.39465, "decode.d4.loss_cls": 2.95456, "decode.d4.loss_mask": 1.86507, "decode.d4.loss_dice": 4.37548, "decode.d5.loss_cls": 2.80782, "decode.d5.loss_mask": 1.65482, "decode.d5.loss_dice": 4.4177, "decode.d6.loss_cls": 2.47419, "decode.d6.loss_mask": 1.6099, "decode.d6.loss_dice": 4.44288, "decode.d7.loss_cls": 2.33665, "decode.d7.loss_mask": 1.48503, "decode.d7.loss_dice": 4.58157, "decode.d8.loss_cls": 2.32961, "decode.d8.loss_mask": 1.47154, "decode.d8.loss_dice": 4.55407, "loss": 88.94818, "time": 0.54578}
{"mode": "train", "epoch": 3, "iter": 100, "lr": 0.0, "memory": 9602, "data_time": 0.00596, "decode.loss_cls": 2.31058, "decode.loss_mask": 1.61559, "decode.loss_dice": 4.44372, "decode.d0.loss_cls": 3.81407, "decode.d0.loss_mask": 2.06171, "decode.d0.loss_dice": 4.2744, "decode.d1.loss_cls": 2.48428, "decode.d1.loss_mask": 1.82873, "decode.d1.loss_dice": 4.30612, "decode.d2.loss_cls": 2.69826, "decode.d2.loss_mask": 1.66849, "decode.d2.loss_dice": 4.34628, "decode.d3.loss_cls": 1.85895, "decode.d3.loss_mask": 1.71685, "decode.d3.loss_dice": 4.35543, "decode.d4.loss_cls": 2.60393, "decode.d4.loss_mask": 1.84534, "decode.d4.loss_dice": 4.35245, "decode.d5.loss_cls": 2.37079, "decode.d5.loss_mask": 1.69088, "decode.d5.loss_dice": 4.33111, "decode.d6.loss_cls": 2.12913, "decode.d6.loss_mask": 1.69605, "decode.d6.loss_dice": 4.36237, "decode.d7.loss_cls": 2.02643, "decode.d7.loss_mask": 1.57235, "decode.d7.loss_dice": 4.47543, "decode.d8.loss_cls": 1.99646, "decode.d8.loss_mask": 1.59525, "decode.d8.loss_dice": 4.4446, "loss": 85.27605, "time": 0.33557}
{"mode": "train", "epoch": 3, "iter": 110, "lr": 0.0, "memory": 9602, "data_time": 0.00599, "decode.loss_cls": 2.05593, "decode.loss_mask": 1.80256, "decode.loss_dice": 4.37706, "decode.d0.loss_cls": 3.80273, "decode.d0.loss_mask": 2.09708, "decode.d0.loss_dice": 4.15549, "decode.d1.loss_cls": 2.28583, "decode.d1.loss_mask": 1.89039, "decode.d1.loss_dice": 4.17898, "decode.d2.loss_cls": 2.41801, "decode.d2.loss_mask": 1.82169, "decode.d2.loss_dice": 4.20462, "decode.d3.loss_cls": 1.78138, "decode.d3.loss_mask": 1.8634, "decode.d3.loss_dice": 4.2292, "decode.d4.loss_cls": 2.28171, "decode.d4.loss_mask": 1.93155, "decode.d4.loss_dice": 4.24599, "decode.d5.loss_cls": 2.12789, "decode.d5.loss_mask": 1.88146, "decode.d5.loss_dice": 4.2398, "decode.d6.loss_cls": 1.93977, "decode.d6.loss_mask": 1.86852, "decode.d6.loss_dice": 4.28282, "decode.d7.loss_cls": 1.87954, "decode.d7.loss_mask": 1.78423, "decode.d7.loss_dice": 4.38918, "decode.d8.loss_cls": 1.85876, "decode.d8.loss_mask": 1.8092, "decode.d8.loss_dice": 4.3351, "loss": 83.81987, "time": 0.33649}
{"mode": "train", "epoch": 3, "iter": 120, "lr": 0.0, "memory": 9602, "data_time": 0.00579, "decode.loss_cls": 1.9236, "decode.loss_mask": 1.79206, "decode.loss_dice": 4.31507, "decode.d0.loss_cls": 3.78394, "decode.d0.loss_mask": 2.06449, "decode.d0.loss_dice": 4.17476, "decode.d1.loss_cls": 2.17845, "decode.d1.loss_mask": 1.80784, "decode.d1.loss_dice": 4.20561, "decode.d2.loss_cls": 2.24122, "decode.d2.loss_mask": 1.7458, "decode.d2.loss_dice": 4.24456, "decode.d3.loss_cls": 1.74095, "decode.d3.loss_mask": 1.82764, "decode.d3.loss_dice": 4.22224, "decode.d4.loss_cls": 2.03193, "decode.d4.loss_mask": 1.86013, "decode.d4.loss_dice": 4.24404, "decode.d5.loss_cls": 1.97503, "decode.d5.loss_mask": 1.84931, "decode.d5.loss_dice": 4.22382, "decode.d6.loss_cls": 1.83966, "decode.d6.loss_mask": 1.86471, "decode.d6.loss_dice": 4.23345, "decode.d7.loss_cls": 1.8166, "decode.d7.loss_mask": 1.76721, "decode.d7.loss_dice": 4.3128, "decode.d8.loss_cls": 1.81058, "decode.d8.loss_mask": 1.81388, "decode.d8.loss_dice": 4.28833, "loss": 82.19972, "time": 0.33345}
{"mode": "train", "epoch": 4, "iter": 130, "lr": 0.0, "memory": 9602, "data_time": 0.21303, "decode.loss_cls": 1.83013, "decode.loss_mask": 1.84634, "decode.loss_dice": 4.26556, "decode.d0.loss_cls": 3.78774, "decode.d0.loss_mask": 1.99138, "decode.d0.loss_dice": 4.14368, "decode.d1.loss_cls": 2.07815, "decode.d1.loss_mask": 1.81143, "decode.d1.loss_dice": 4.16763, "decode.d2.loss_cls": 2.04707, "decode.d2.loss_mask": 1.77551, "decode.d2.loss_dice": 4.21599, "decode.d3.loss_cls": 1.71618, "decode.d3.loss_mask": 1.81993, "decode.d3.loss_dice": 4.20695, "decode.d4.loss_cls": 1.88984, "decode.d4.loss_mask": 1.85278, "decode.d4.loss_dice": 4.23394, "decode.d5.loss_cls": 1.85219, "decode.d5.loss_mask": 1.85413, "decode.d5.loss_dice": 4.21163, "decode.d6.loss_cls": 1.75704, "decode.d6.loss_mask": 1.88767, "decode.d6.loss_dice": 4.21377, "decode.d7.loss_cls": 1.76165, "decode.d7.loss_mask": 1.83144, "decode.d7.loss_dice": 4.2741, "decode.d8.loss_cls": 1.76146, "decode.d8.loss_mask": 1.84611, "decode.d8.loss_dice": 4.24967, "loss": 81.18108, "time": 0.54353}
{"mode": "train", "epoch": 4, "iter": 140, "lr": 0.0, "memory": 9602, "data_time": 0.00657, "decode.loss_cls": 1.73297, "decode.loss_mask": 1.82349, "decode.loss_dice": 4.22605, "decode.d0.loss_cls": 3.78993, "decode.d0.loss_mask": 1.91325, "decode.d0.loss_dice": 4.18036, "decode.d1.loss_cls": 1.87728, "decode.d1.loss_mask": 1.75703, "decode.d1.loss_dice": 4.20795, "decode.d2.loss_cls": 1.87067, "decode.d2.loss_mask": 1.71552, "decode.d2.loss_dice": 4.23745, "decode.d3.loss_cls": 1.64357, "decode.d3.loss_mask": 1.79912, "decode.d3.loss_dice": 4.19289, "decode.d4.loss_cls": 1.77126, "decode.d4.loss_mask": 1.80557, "decode.d4.loss_dice": 4.23937, "decode.d5.loss_cls": 1.75211, "decode.d5.loss_mask": 1.81005, "decode.d5.loss_dice": 4.20165, "decode.d6.loss_cls": 1.69888, "decode.d6.loss_mask": 1.87413, "decode.d6.loss_dice": 4.18012, "decode.d7.loss_cls": 1.69134, "decode.d7.loss_mask": 1.80473, "decode.d7.loss_dice": 4.2259, "decode.d8.loss_cls": 1.74707, "decode.d8.loss_mask": 1.84849, "decode.d8.loss_dice": 4.21662, "loss": 79.8348, "time": 0.33474}
{"mode": "train", "epoch": 4, "iter": 150, "lr": 0.0, "memory": 9602, "data_time": 0.00601, "decode.loss_cls": 1.72382, "decode.loss_mask": 1.82324, "decode.loss_dice": 4.21242, "decode.d0.loss_cls": 3.78414, "decode.d0.loss_mask": 1.94918, "decode.d0.loss_dice": 4.10111, "decode.d1.loss_cls": 1.85591, "decode.d1.loss_mask": 1.78137, "decode.d1.loss_dice": 4.13186, "decode.d2.loss_cls": 1.76626, "decode.d2.loss_mask": 1.74481, "decode.d2.loss_dice": 4.18488, "decode.d3.loss_cls": 1.68389, "decode.d3.loss_mask": 1.83332, "decode.d3.loss_dice": 4.12777, "decode.d4.loss_cls": 1.74447, "decode.d4.loss_mask": 1.81451, "decode.d4.loss_dice": 4.19905, "decode.d5.loss_cls": 1.74569, "decode.d5.loss_mask": 1.8342, "decode.d5.loss_dice": 4.15144, "decode.d6.loss_cls": 1.70639, "decode.d6.loss_mask": 1.87243, "decode.d6.loss_dice": 4.1639, "decode.d7.loss_cls": 1.70449, "decode.d7.loss_mask": 1.81217, "decode.d7.loss_dice": 4.22206, "decode.d8.loss_cls": 1.72464, "decode.d8.loss_mask": 1.8199, "decode.d8.loss_dice": 4.21479, "loss": 79.4341, "time": 0.3355}
{"mode": "train", "epoch": 4, "iter": 160, "lr": 0.0, "memory": 9602, "data_time": 0.00599, "decode.loss_cls": 1.75946, "decode.loss_mask": 1.91572, "decode.loss_dice": 4.18631, "decode.d0.loss_cls": 3.77336, "decode.d0.loss_mask": 1.97706, "decode.d0.loss_dice": 4.08472, "decode.d1.loss_cls": 1.82928, "decode.d1.loss_mask": 1.86018, "decode.d1.loss_dice": 4.11171, "decode.d2.loss_cls": 1.757, "decode.d2.loss_mask": 1.84145, "decode.d2.loss_dice": 4.12347, "decode.d3.loss_cls": 1.72459, "decode.d3.loss_mask": 1.89501, "decode.d3.loss_dice": 4.11176, "decode.d4.loss_cls": 1.73446, "decode.d4.loss_mask": 1.8776, "decode.d4.loss_dice": 4.18243, "decode.d5.loss_cls": 1.77773, "decode.d5.loss_mask": 1.89862, "decode.d5.loss_dice": 4.15464, "decode.d6.loss_cls": 1.73752, "decode.d6.loss_mask": 1.91116, "decode.d6.loss_dice": 4.17256, "decode.d7.loss_cls": 1.74283, "decode.d7.loss_mask": 1.8798, "decode.d7.loss_dice": 4.22535, "decode.d8.loss_cls": 1.76412, "decode.d8.loss_mask": 1.90014, "decode.d8.loss_dice": 4.19628, "loss": 80.10631, "time": 0.33415}
{"mode": "train", "epoch": 5, "iter": 170, "lr": 0.0, "memory": 9602, "data_time": 0.21484, "decode.loss_cls": 1.76473, "decode.loss_mask": 1.99998, "decode.loss_dice": 4.12374, "decode.d0.loss_cls": 3.7626, "decode.d0.loss_mask": 2.05282, "decode.d0.loss_dice": 4.04295, "decode.d1.loss_cls": 1.76393, "decode.d1.loss_mask": 1.91494, "decode.d1.loss_dice": 4.06174, "decode.d2.loss_cls": 1.70244, "decode.d2.loss_mask": 1.88325, "decode.d2.loss_dice": 4.07704, "decode.d3.loss_cls": 1.69796, "decode.d3.loss_mask": 1.96035, "decode.d3.loss_dice": 4.0527, "decode.d4.loss_cls": 1.70915, "decode.d4.loss_mask": 1.91465, "decode.d4.loss_dice": 4.14431, "decode.d5.loss_cls": 1.77418, "decode.d5.loss_mask": 1.97257, "decode.d5.loss_dice": 4.09617, "decode.d6.loss_cls": 1.74888, "decode.d6.loss_mask": 2.01307, "decode.d6.loss_dice": 4.11211, "decode.d7.loss_cls": 1.75009, "decode.d7.loss_mask": 1.9557, "decode.d7.loss_dice": 4.14511, "decode.d8.loss_cls": 1.76502, "decode.d8.loss_mask": 1.99971, "decode.d8.loss_dice": 4.11903, "loss": 80.08092, "time": 0.54599}
{"mode": "train", "epoch": 5, "iter": 180, "lr": 0.0, "memory": 9602, "data_time": 0.00597, "decode.loss_cls": 1.67068, "decode.loss_mask": 1.9459, "decode.loss_dice": 4.07819, "decode.d0.loss_cls": 3.78498, "decode.d0.loss_mask": 1.99266, "decode.d0.loss_dice": 3.99413, "decode.d1.loss_cls": 1.67663, "decode.d1.loss_mask": 1.90022, "decode.d1.loss_dice": 4.04566, "decode.d2.loss_cls": 1.62568, "decode.d2.loss_mask": 1.8714, "decode.d2.loss_dice": 4.04419, "decode.d3.loss_cls": 1.63429, "decode.d3.loss_mask": 1.91898, "decode.d3.loss_dice": 4.03244, "decode.d4.loss_cls": 1.67845, "decode.d4.loss_mask": 1.90593, "decode.d4.loss_dice": 4.10695, "decode.d5.loss_cls": 1.67152, "decode.d5.loss_mask": 1.93183, "decode.d5.loss_dice": 4.03709, "decode.d6.loss_cls": 1.66936, "decode.d6.loss_mask": 1.94307, "decode.d6.loss_dice": 4.07163, "decode.d7.loss_cls": 1.67145, "decode.d7.loss_mask": 1.92095, "decode.d7.loss_dice": 4.10991, "decode.d8.loss_cls": 1.69237, "decode.d8.loss_mask": 1.94026, "decode.d8.loss_dice": 4.07671, "loss": 78.64351, "time": 0.33595}
{"mode": "train", "epoch": 5, "iter": 190, "lr": 0.0, "memory": 9602, "data_time": 0.00602, "decode.loss_cls": 1.72078, "decode.loss_mask": 2.07826, "decode.loss_dice": 4.07689, "decode.d0.loss_cls": 3.76778, "decode.d0.loss_mask": 2.06745, "decode.d0.loss_dice": 3.99666, "decode.d1.loss_cls": 1.67374, "decode.d1.loss_mask": 1.99013, "decode.d1.loss_dice": 4.0027, "decode.d2.loss_cls": 1.63385, "decode.d2.loss_mask": 1.96763, "decode.d2.loss_dice": 4.01595, "decode.d3.loss_cls": 1.68623, "decode.d3.loss_mask": 2.02044, "decode.d3.loss_dice": 4.02032, "decode.d4.loss_cls": 1.69671, "decode.d4.loss_mask": 2.01465, "decode.d4.loss_dice": 4.06833, "decode.d5.loss_cls": 1.73116, "decode.d5.loss_mask": 2.0583, "decode.d5.loss_dice": 4.02389, "decode.d6.loss_cls": 1.71256, "decode.d6.loss_mask": 2.05862, "decode.d6.loss_dice": 4.06035, "decode.d7.loss_cls": 1.71064, "decode.d7.loss_mask": 2.0424, "decode.d7.loss_dice": 4.09727, "decode.d8.loss_cls": 1.72994, "decode.d8.loss_mask": 2.06333, "decode.d8.loss_dice": 4.07277, "loss": 79.85973, "time": 0.33557}
{"mode": "train", "epoch": 5, "iter": 200, "lr": 0.0, "memory": 9602, "data_time": 0.00595, "decode.loss_cls": 1.69819, "decode.loss_mask": 1.87866, "decode.loss_dice": 4.01611, "decode.d0.loss_cls": 3.78534, "decode.d0.loss_mask": 1.93085, "decode.d0.loss_dice": 3.99082, "decode.d1.loss_cls": 1.63013, "decode.d1.loss_mask": 1.81542, "decode.d1.loss_dice": 4.02055, "decode.d2.loss_cls": 1.58787, "decode.d2.loss_mask": 1.82742, "decode.d2.loss_dice": 3.98374, "decode.d3.loss_cls": 1.62082, "decode.d3.loss_mask": 1.85071, "decode.d3.loss_dice": 3.97177, "decode.d4.loss_cls": 1.66406, "decode.d4.loss_mask": 1.8435, "decode.d4.loss_dice": 4.03455, "decode.d5.loss_cls": 1.67806, "decode.d5.loss_mask": 1.87027, "decode.d5.loss_dice": 3.97351, "decode.d6.loss_cls": 1.67542, "decode.d6.loss_mask": 1.8881, "decode.d6.loss_dice": 3.99928, "decode.d7.loss_cls": 1.69204, "decode.d7.loss_mask": 1.86376, "decode.d7.loss_dice": 4.03055, "decode.d8.loss_cls": 1.70403, "decode.d8.loss_mask": 1.91307, "decode.d8.loss_dice": 4.02287, "loss": 77.46149, "time": 0.33258}
{"mode": "val", "epoch": 5, "iter": 20, "lr": 0.0, "aAcc": 0.1448, "mIoU": 0.028, "mAcc": 0.181, "IoU.bg": 0.0854, "IoU.Anchovy": 0.0, "IoU.Olives": 0.0, "IoU.Salami": 0.0, "IoU.Red_Pepper": 0.0826, "IoU.Yellow_Pepper": 0.0, "Acc.bg": 0.0859, "Acc.Anchovy": 0.0, "Acc.Olives": 0.0, "Acc.Salami": 0.0, "Acc.Red_Pepper": 1.0, "Acc.Yellow_Pepper": 0.0}
{"mode": "train", "epoch": 6, "iter": 210, "lr": 0.0, "memory": 9602, "data_time": 1.23366, "decode.loss_cls": 1.71639, "decode.loss_mask": 1.88752, "decode.loss_dice": 4.05903, "decode.d0.loss_cls": 3.77663, "decode.d0.loss_mask": 1.92789, "decode.d0.loss_dice": 4.01206, "decode.d1.loss_cls": 1.62489, "decode.d1.loss_mask": 1.82954, "decode.d1.loss_dice": 4.04103, "decode.d2.loss_cls": 1.60995, "decode.d2.loss_mask": 1.83978, "decode.d2.loss_dice": 3.99902, "decode.d3.loss_cls": 1.6311, "decode.d3.loss_mask": 1.86527, "decode.d3.loss_dice": 4.01734, "decode.d4.loss_cls": 1.67637, "decode.d4.loss_mask": 1.86251, "decode.d4.loss_dice": 4.05154, "decode.d5.loss_cls": 1.71358, "decode.d5.loss_mask": 1.88282, "decode.d5.loss_dice": 4.02107, "decode.d6.loss_cls": 1.70237, "decode.d6.loss_mask": 1.91481, "decode.d6.loss_dice": 4.03595, "decode.d7.loss_cls": 1.71198, "decode.d7.loss_mask": 1.89197, "decode.d7.loss_dice": 4.04612, "decode.d8.loss_cls": 1.7079, "decode.d8.loss_mask": 1.92971, "decode.d8.loss_dice": 4.05759, "loss": 78.04374, "time": 1.56752}
{"mode": "train", "epoch": 6, "iter": 220, "lr": 0.0, "memory": 9602, "data_time": 0.00616, "decode.loss_cls": 1.69193, "decode.loss_mask": 1.99894, "decode.loss_dice": 3.92009, "decode.d0.loss_cls": 3.77359, "decode.d0.loss_mask": 1.99309, "decode.d0.loss_dice": 3.90876, "decode.d1.loss_cls": 1.60698, "decode.d1.loss_mask": 1.89108, "decode.d1.loss_dice": 3.93231, "decode.d2.loss_cls": 1.57254, "decode.d2.loss_mask": 1.886, "decode.d2.loss_dice": 3.88408, "decode.d3.loss_cls": 1.60885, "decode.d3.loss_mask": 1.9218, "decode.d3.loss_dice": 3.90113, "decode.d4.loss_cls": 1.66034, "decode.d4.loss_mask": 1.90943, "decode.d4.loss_dice": 3.95224, "decode.d5.loss_cls": 1.67102, "decode.d5.loss_mask": 1.93329, "decode.d5.loss_dice": 3.89453, "decode.d6.loss_cls": 1.67743, "decode.d6.loss_mask": 1.98778, "decode.d6.loss_dice": 3.91265, "decode.d7.loss_cls": 1.69418, "decode.d7.loss_mask": 1.98586, "decode.d7.loss_dice": 3.90977, "decode.d8.loss_cls": 1.70203, "decode.d8.loss_mask": 2.00128, "decode.d8.loss_dice": 3.94553, "loss": 77.32853, "time": 0.33692}
{"mode": "train", "epoch": 6, "iter": 230, "lr": 0.0, "memory": 9602, "data_time": 0.00643, "decode.loss_cls": 1.69576, "decode.loss_mask": 1.87319, "decode.loss_dice": 3.9428, "decode.d0.loss_cls": 3.76646, "decode.d0.loss_mask": 1.93999, "decode.d0.loss_dice": 3.91443, "decode.d1.loss_cls": 1.57518, "decode.d1.loss_mask": 1.84153, "decode.d1.loss_dice": 3.9393, "decode.d2.loss_cls": 1.59441, "decode.d2.loss_mask": 1.80841, "decode.d2.loss_dice": 3.88547, "decode.d3.loss_cls": 1.62051, "decode.d3.loss_mask": 1.84265, "decode.d3.loss_dice": 3.89107, "decode.d4.loss_cls": 1.67662, "decode.d4.loss_mask": 1.82711, "decode.d4.loss_dice": 3.92872, "decode.d5.loss_cls": 1.68104, "decode.d5.loss_mask": 1.85951, "decode.d5.loss_dice": 3.86968, "decode.d6.loss_cls": 1.68852, "decode.d6.loss_mask": 1.87794, "decode.d6.loss_dice": 3.94472, "decode.d7.loss_cls": 1.70052, "decode.d7.loss_mask": 1.8541, "decode.d7.loss_dice": 3.96012, "decode.d8.loss_cls": 1.69568, "decode.d8.loss_mask": 1.87575, "decode.d8.loss_dice": 3.99178, "loss": 76.56298, "time": 0.33994}
{"mode": "train", "epoch": 6, "iter": 240, "lr": 0.0, "memory": 9602, "data_time": 0.00589, "decode.loss_cls": 1.69511, "decode.loss_mask": 1.92309, "decode.loss_dice": 3.95555, "decode.d0.loss_cls": 3.75697, "decode.d0.loss_mask": 1.93529, "decode.d0.loss_dice": 3.93725, "decode.d1.loss_cls": 1.56434, "decode.d1.loss_mask": 1.84605, "decode.d1.loss_dice": 3.9416, "decode.d2.loss_cls": 1.53068, "decode.d2.loss_mask": 1.83107, "decode.d2.loss_dice": 3.90041, "decode.d3.loss_cls": 1.61486, "decode.d3.loss_mask": 1.87059, "decode.d3.loss_dice": 3.91811, "decode.d4.loss_cls": 1.64902, "decode.d4.loss_mask": 1.86201, "decode.d4.loss_dice": 3.95044, "decode.d5.loss_cls": 1.65836, "decode.d5.loss_mask": 1.89073, "decode.d5.loss_dice": 3.91018, "decode.d6.loss_cls": 1.68288, "decode.d6.loss_mask": 1.89134, "decode.d6.loss_dice": 3.95586, "decode.d7.loss_cls": 1.68813, "decode.d7.loss_mask": 1.90085, "decode.d7.loss_dice": 3.96438, "decode.d8.loss_cls": 1.68972, "decode.d8.loss_mask": 1.94096, "decode.d8.loss_dice": 3.98817, "loss": 76.84396, "time": 0.33189}
{"mode": "train", "epoch": 7, "iter": 250, "lr": 0.0, "memory": 9602, "data_time": 0.21558, "decode.loss_cls": 1.68219, "decode.loss_mask": 1.84589, "decode.loss_dice": 3.93124, "decode.d0.loss_cls": 3.76511, "decode.d0.loss_mask": 1.8635, "decode.d0.loss_dice": 3.9164, "decode.d1.loss_cls": 1.55684, "decode.d1.loss_mask": 1.76969, "decode.d1.loss_dice": 3.92053, "decode.d2.loss_cls": 1.5255, "decode.d2.loss_mask": 1.74823, "decode.d2.loss_dice": 3.88952, "decode.d3.loss_cls": 1.60356, "decode.d3.loss_mask": 1.77412, "decode.d3.loss_dice": 3.92047, "decode.d4.loss_cls": 1.62499, "decode.d4.loss_mask": 1.7829, "decode.d4.loss_dice": 3.94182, "decode.d5.loss_cls": 1.65911, "decode.d5.loss_mask": 1.81728, "decode.d5.loss_dice": 3.89658, "decode.d6.loss_cls": 1.66285, "decode.d6.loss_mask": 1.8538, "decode.d6.loss_dice": 3.94334, "decode.d7.loss_cls": 1.68623, "decode.d7.loss_mask": 1.84123, "decode.d7.loss_dice": 3.95067, "decode.d8.loss_cls": 1.69296, "decode.d8.loss_mask": 1.88258, "decode.d8.loss_dice": 3.95644, "loss": 75.90555, "time": 0.54846}
{"mode": "train", "epoch": 7, "iter": 260, "lr": 0.0, "memory": 9602, "data_time": 0.00634, "decode.loss_cls": 1.699, "decode.loss_mask": 1.88425, "decode.loss_dice": 3.90531, "decode.d0.loss_cls": 3.76891, "decode.d0.loss_mask": 1.8962, "decode.d0.loss_dice": 3.91546, "decode.d1.loss_cls": 1.58316, "decode.d1.loss_mask": 1.80577, "decode.d1.loss_dice": 3.90323, "decode.d2.loss_cls": 1.56808, "decode.d2.loss_mask": 1.77989, "decode.d2.loss_dice": 3.87085, "decode.d3.loss_cls": 1.59894, "decode.d3.loss_mask": 1.82646, "decode.d3.loss_dice": 3.8795, "decode.d4.loss_cls": 1.61783, "decode.d4.loss_mask": 1.82287, "decode.d4.loss_dice": 3.90312, "decode.d5.loss_cls": 1.66576, "decode.d5.loss_mask": 1.84032, "decode.d5.loss_dice": 3.87179, "decode.d6.loss_cls": 1.67723, "decode.d6.loss_mask": 1.86905, "decode.d6.loss_dice": 3.89983, "decode.d7.loss_cls": 1.6871, "decode.d7.loss_mask": 1.86246, "decode.d7.loss_dice": 3.8918, "decode.d8.loss_cls": 1.69844, "decode.d8.loss_mask": 1.88938, "decode.d8.loss_dice": 3.92949, "loss": 76.01148, "time": 0.3344}
{"mode": "train", "epoch": 7, "iter": 270, "lr": 0.0, "memory": 9602, "data_time": 0.00624, "decode.loss_cls": 1.65163, "decode.loss_mask": 1.91819, "decode.loss_dice": 3.79987, "decode.d0.loss_cls": 3.75497, "decode.d0.loss_mask": 1.94271, "decode.d0.loss_dice": 3.80589, "decode.d1.loss_cls": 1.52724, "decode.d1.loss_mask": 1.84658, "decode.d1.loss_dice": 3.79743, "decode.d2.loss_cls": 1.53132, "decode.d2.loss_mask": 1.84704, "decode.d2.loss_dice": 3.71469, "decode.d3.loss_cls": 1.56267, "decode.d3.loss_mask": 1.86373, "decode.d3.loss_dice": 3.75747, "decode.d4.loss_cls": 1.60458, "decode.d4.loss_mask": 1.84763, "decode.d4.loss_dice": 3.77951, "decode.d5.loss_cls": 1.6309, "decode.d5.loss_mask": 1.87397, "decode.d5.loss_dice": 3.72827, "decode.d6.loss_cls": 1.64579, "decode.d6.loss_mask": 1.8743, "decode.d6.loss_dice": 3.81047, "decode.d7.loss_cls": 1.66087, "decode.d7.loss_mask": 1.85878, "decode.d7.loss_dice": 3.81695, "decode.d8.loss_cls": 1.66277, "decode.d8.loss_mask": 1.88173, "decode.d8.loss_dice": 3.83843, "loss": 74.83639, "time": 0.3361}
{"mode": "train", "epoch": 7, "iter": 280, "lr": 0.0, "memory": 9602, "data_time": 0.0063, "decode.loss_cls": 1.69866, "decode.loss_mask": 2.1492, "decode.loss_dice": 3.88937, "decode.d0.loss_cls": 3.74464, "decode.d0.loss_mask": 2.10279, "decode.d0.loss_dice": 3.80368, "decode.d1.loss_cls": 1.53151, "decode.d1.loss_mask": 2.00983, "decode.d1.loss_dice": 3.8171, "decode.d2.loss_cls": 1.55406, "decode.d2.loss_mask": 2.00155, "decode.d2.loss_dice": 3.79649, "decode.d3.loss_cls": 1.61312, "decode.d3.loss_mask": 2.03046, "decode.d3.loss_dice": 3.82163, "decode.d4.loss_cls": 1.62448, "decode.d4.loss_mask": 2.0428, "decode.d4.loss_dice": 3.83491, "decode.d5.loss_cls": 1.68631, "decode.d5.loss_mask": 2.08092, "decode.d5.loss_dice": 3.81344, "decode.d6.loss_cls": 1.68823, "decode.d6.loss_mask": 2.07707, "decode.d6.loss_dice": 3.88474, "decode.d7.loss_cls": 1.70378, "decode.d7.loss_mask": 2.09731, "decode.d7.loss_dice": 3.86649, "decode.d8.loss_cls": 1.69806, "decode.d8.loss_mask": 2.08715, "decode.d8.loss_dice": 3.88936, "loss": 77.63913, "time": 0.33339}
